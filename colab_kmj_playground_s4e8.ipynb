{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6caf2d5",
   "metadata": {
    "id": "a6caf2d5"
   },
   "source": [
    "# 1. 데이터 살펴보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "UUJjQy33SQMW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22908,
     "status": "ok",
     "timestamp": 1723975825550,
     "user": {
      "displayName": "곽명조",
      "userId": "03864110971804242579"
     },
     "user_tz": -540
    },
    "id": "UUJjQy33SQMW",
    "outputId": "0a49462b-0e9c-4554-b37b-bcc5972a989a"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[0;32m      2\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07b70f69",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 578
    },
    "executionInfo": {
     "elapsed": 19346,
     "status": "ok",
     "timestamp": 1723975854063,
     "user": {
      "displayName": "곽명조",
      "userId": "03864110971804242579"
     },
     "user_tz": -540
    },
    "id": "07b70f69",
    "outputId": "8f832ba5-530d-42c4-df9f-220e6d4157a8",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "      <th>cap-diameter</th>\n",
       "      <th>cap-shape</th>\n",
       "      <th>cap-surface</th>\n",
       "      <th>cap-color</th>\n",
       "      <th>does-bruise-or-bleed</th>\n",
       "      <th>gill-attachment</th>\n",
       "      <th>gill-spacing</th>\n",
       "      <th>gill-color</th>\n",
       "      <th>...</th>\n",
       "      <th>stem-root</th>\n",
       "      <th>stem-surface</th>\n",
       "      <th>stem-color</th>\n",
       "      <th>veil-type</th>\n",
       "      <th>veil-color</th>\n",
       "      <th>has-ring</th>\n",
       "      <th>ring-type</th>\n",
       "      <th>spore-print-color</th>\n",
       "      <th>habitat</th>\n",
       "      <th>season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>e</td>\n",
       "      <td>8.80</td>\n",
       "      <td>f</td>\n",
       "      <td>s</td>\n",
       "      <td>u</td>\n",
       "      <td>f</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>w</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>w</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>d</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>p</td>\n",
       "      <td>4.51</td>\n",
       "      <td>x</td>\n",
       "      <td>h</td>\n",
       "      <td>o</td>\n",
       "      <td>f</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>y</td>\n",
       "      <td>o</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t</td>\n",
       "      <td>z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>d</td>\n",
       "      <td>w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>e</td>\n",
       "      <td>6.94</td>\n",
       "      <td>f</td>\n",
       "      <td>s</td>\n",
       "      <td>b</td>\n",
       "      <td>f</td>\n",
       "      <td>x</td>\n",
       "      <td>c</td>\n",
       "      <td>w</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>s</td>\n",
       "      <td>n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l</td>\n",
       "      <td>w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>e</td>\n",
       "      <td>3.88</td>\n",
       "      <td>f</td>\n",
       "      <td>y</td>\n",
       "      <td>g</td>\n",
       "      <td>f</td>\n",
       "      <td>s</td>\n",
       "      <td>NaN</td>\n",
       "      <td>g</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>w</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>d</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>e</td>\n",
       "      <td>5.85</td>\n",
       "      <td>x</td>\n",
       "      <td>l</td>\n",
       "      <td>w</td>\n",
       "      <td>f</td>\n",
       "      <td>d</td>\n",
       "      <td>NaN</td>\n",
       "      <td>w</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>w</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>g</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id class  cap-diameter cap-shape cap-surface cap-color  \\\n",
       "0   0     e          8.80         f           s         u   \n",
       "1   1     p          4.51         x           h         o   \n",
       "2   2     e          6.94         f           s         b   \n",
       "3   3     e          3.88         f           y         g   \n",
       "4   4     e          5.85         x           l         w   \n",
       "\n",
       "  does-bruise-or-bleed gill-attachment gill-spacing gill-color  ...  \\\n",
       "0                    f               a            c          w  ...   \n",
       "1                    f               a            c          n  ...   \n",
       "2                    f               x            c          w  ...   \n",
       "3                    f               s          NaN          g  ...   \n",
       "4                    f               d          NaN          w  ...   \n",
       "\n",
       "   stem-root  stem-surface stem-color veil-type veil-color has-ring ring-type  \\\n",
       "0        NaN           NaN          w       NaN        NaN        f         f   \n",
       "1        NaN             y          o       NaN        NaN        t         z   \n",
       "2        NaN             s          n       NaN        NaN        f         f   \n",
       "3        NaN           NaN          w       NaN        NaN        f         f   \n",
       "4        NaN           NaN          w       NaN        NaN        f         f   \n",
       "\n",
       "  spore-print-color habitat season  \n",
       "0               NaN       d      a  \n",
       "1               NaN       d      w  \n",
       "2               NaN       l      w  \n",
       "3               NaN       d      u  \n",
       "4               NaN       g      a  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cap-diameter</th>\n",
       "      <th>cap-shape</th>\n",
       "      <th>cap-surface</th>\n",
       "      <th>cap-color</th>\n",
       "      <th>does-bruise-or-bleed</th>\n",
       "      <th>gill-attachment</th>\n",
       "      <th>gill-spacing</th>\n",
       "      <th>gill-color</th>\n",
       "      <th>stem-height</th>\n",
       "      <th>...</th>\n",
       "      <th>stem-root</th>\n",
       "      <th>stem-surface</th>\n",
       "      <th>stem-color</th>\n",
       "      <th>veil-type</th>\n",
       "      <th>veil-color</th>\n",
       "      <th>has-ring</th>\n",
       "      <th>ring-type</th>\n",
       "      <th>spore-print-color</th>\n",
       "      <th>habitat</th>\n",
       "      <th>season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3116945</td>\n",
       "      <td>8.64</td>\n",
       "      <td>x</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n</td>\n",
       "      <td>t</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>w</td>\n",
       "      <td>11.13</td>\n",
       "      <td>...</td>\n",
       "      <td>b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>w</td>\n",
       "      <td>u</td>\n",
       "      <td>w</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>NaN</td>\n",
       "      <td>d</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3116946</td>\n",
       "      <td>6.90</td>\n",
       "      <td>o</td>\n",
       "      <td>t</td>\n",
       "      <td>o</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>c</td>\n",
       "      <td>y</td>\n",
       "      <td>1.27</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>d</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3116947</td>\n",
       "      <td>2.00</td>\n",
       "      <td>b</td>\n",
       "      <td>g</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>6.18</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>d</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3116948</td>\n",
       "      <td>3.47</td>\n",
       "      <td>x</td>\n",
       "      <td>t</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>s</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>4.98</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>w</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n</td>\n",
       "      <td>t</td>\n",
       "      <td>z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>d</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3116949</td>\n",
       "      <td>6.17</td>\n",
       "      <td>x</td>\n",
       "      <td>h</td>\n",
       "      <td>y</td>\n",
       "      <td>f</td>\n",
       "      <td>p</td>\n",
       "      <td>NaN</td>\n",
       "      <td>y</td>\n",
       "      <td>6.73</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>y</td>\n",
       "      <td>t</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>d</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  cap-diameter cap-shape cap-surface cap-color does-bruise-or-bleed  \\\n",
       "0  3116945          8.64         x         NaN         n                    t   \n",
       "1  3116946          6.90         o           t         o                    f   \n",
       "2  3116947          2.00         b           g         n                    f   \n",
       "3  3116948          3.47         x           t         n                    f   \n",
       "4  3116949          6.17         x           h         y                    f   \n",
       "\n",
       "  gill-attachment gill-spacing gill-color  stem-height  ...  stem-root  \\\n",
       "0             NaN          NaN          w        11.13  ...          b   \n",
       "1             NaN            c          y         1.27  ...        NaN   \n",
       "2             NaN            c          n         6.18  ...        NaN   \n",
       "3               s            c          n         4.98  ...        NaN   \n",
       "4               p          NaN          y         6.73  ...        NaN   \n",
       "\n",
       "  stem-surface stem-color veil-type veil-color has-ring ring-type  \\\n",
       "0          NaN          w         u          w        t         g   \n",
       "1          NaN          n       NaN        NaN        f         f   \n",
       "2          NaN          n       NaN        NaN        f         f   \n",
       "3          NaN          w       NaN          n        t         z   \n",
       "4          NaN          y       NaN          y        t       NaN   \n",
       "\n",
       "  spore-print-color habitat season  \n",
       "0               NaN       d      a  \n",
       "1               NaN       d      a  \n",
       "2               NaN       d      s  \n",
       "3               NaN       d      u  \n",
       "4               NaN       d      u  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 경로: /content/drive/Othercomputers/내 노트북/인공지능/Kaggle 참여/2. Binary Prediction of Poisonous Mushrooms/playground-series-s4e8/train.csv\n",
    "# 경로: /content/drive/Othercomputers/내 노트북/인공지능/Kaggle 참여/2. Binary Prediction of Poisonous Mushrooms/playground-series-s4e8/test.csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "Train = pd.read_csv(\"./playground-series-s4e8/train.csv\")\n",
    "Test = pd.read_csv(\"./playground-series-s4e8/test.csv\")\n",
    "\n",
    "train_df = pd.DataFrame(Train)\n",
    "test_df = pd.DataFrame(Test)\n",
    "\n",
    "display(train_df.head())\n",
    "display(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b98fee24",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "executionInfo": {
     "elapsed": 1076,
     "status": "ok",
     "timestamp": 1723975858761,
     "user": {
      "displayName": "곽명조",
      "userId": "03864110971804242579"
     },
     "user_tz": -540
    },
    "id": "b98fee24",
    "outputId": "d87b8733-4107-4e1a-891a-7f6bd6cad2d5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>cap-diameter</th>\n",
       "      <th>cap-shape</th>\n",
       "      <th>cap-surface</th>\n",
       "      <th>cap-color</th>\n",
       "      <th>does-bruise-or-bleed</th>\n",
       "      <th>gill-attachment</th>\n",
       "      <th>gill-spacing</th>\n",
       "      <th>gill-color</th>\n",
       "      <th>stem-height</th>\n",
       "      <th>...</th>\n",
       "      <th>stem-root</th>\n",
       "      <th>stem-surface</th>\n",
       "      <th>stem-color</th>\n",
       "      <th>veil-type</th>\n",
       "      <th>veil-color</th>\n",
       "      <th>has-ring</th>\n",
       "      <th>ring-type</th>\n",
       "      <th>spore-print-color</th>\n",
       "      <th>habitat</th>\n",
       "      <th>season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e</td>\n",
       "      <td>8.80</td>\n",
       "      <td>f</td>\n",
       "      <td>s</td>\n",
       "      <td>u</td>\n",
       "      <td>f</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>w</td>\n",
       "      <td>4.51</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>w</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>d</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p</td>\n",
       "      <td>4.51</td>\n",
       "      <td>x</td>\n",
       "      <td>h</td>\n",
       "      <td>o</td>\n",
       "      <td>f</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>4.79</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>y</td>\n",
       "      <td>o</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t</td>\n",
       "      <td>z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>d</td>\n",
       "      <td>w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e</td>\n",
       "      <td>6.94</td>\n",
       "      <td>f</td>\n",
       "      <td>s</td>\n",
       "      <td>b</td>\n",
       "      <td>f</td>\n",
       "      <td>x</td>\n",
       "      <td>c</td>\n",
       "      <td>w</td>\n",
       "      <td>6.85</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>s</td>\n",
       "      <td>n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l</td>\n",
       "      <td>w</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  class  cap-diameter cap-shape cap-surface cap-color does-bruise-or-bleed  \\\n",
       "0     e          8.80         f           s         u                    f   \n",
       "1     p          4.51         x           h         o                    f   \n",
       "2     e          6.94         f           s         b                    f   \n",
       "\n",
       "  gill-attachment gill-spacing gill-color  stem-height  ...  stem-root  \\\n",
       "0               a            c          w         4.51  ...        NaN   \n",
       "1               a            c          n         4.79  ...        NaN   \n",
       "2               x            c          w         6.85  ...        NaN   \n",
       "\n",
       "  stem-surface stem-color veil-type veil-color has-ring ring-type  \\\n",
       "0          NaN          w       NaN        NaN        f         f   \n",
       "1            y          o       NaN        NaN        t         z   \n",
       "2            s          n       NaN        NaN        f         f   \n",
       "\n",
       "  spore-print-color habitat season  \n",
       "0               NaN       d      a  \n",
       "1               NaN       d      w  \n",
       "2               NaN       l      w  \n",
       "\n",
       "[3 rows x 21 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cap-diameter</th>\n",
       "      <th>cap-shape</th>\n",
       "      <th>cap-surface</th>\n",
       "      <th>cap-color</th>\n",
       "      <th>does-bruise-or-bleed</th>\n",
       "      <th>gill-attachment</th>\n",
       "      <th>gill-spacing</th>\n",
       "      <th>gill-color</th>\n",
       "      <th>stem-height</th>\n",
       "      <th>stem-width</th>\n",
       "      <th>stem-root</th>\n",
       "      <th>stem-surface</th>\n",
       "      <th>stem-color</th>\n",
       "      <th>veil-type</th>\n",
       "      <th>veil-color</th>\n",
       "      <th>has-ring</th>\n",
       "      <th>ring-type</th>\n",
       "      <th>spore-print-color</th>\n",
       "      <th>habitat</th>\n",
       "      <th>season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.64</td>\n",
       "      <td>x</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n</td>\n",
       "      <td>t</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>w</td>\n",
       "      <td>11.13</td>\n",
       "      <td>17.12</td>\n",
       "      <td>b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>w</td>\n",
       "      <td>u</td>\n",
       "      <td>w</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>NaN</td>\n",
       "      <td>d</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.90</td>\n",
       "      <td>o</td>\n",
       "      <td>t</td>\n",
       "      <td>o</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>c</td>\n",
       "      <td>y</td>\n",
       "      <td>1.27</td>\n",
       "      <td>10.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>d</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.00</td>\n",
       "      <td>b</td>\n",
       "      <td>g</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>6.18</td>\n",
       "      <td>3.14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>d</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cap-diameter cap-shape cap-surface cap-color does-bruise-or-bleed  \\\n",
       "0          8.64         x         NaN         n                    t   \n",
       "1          6.90         o           t         o                    f   \n",
       "2          2.00         b           g         n                    f   \n",
       "\n",
       "  gill-attachment gill-spacing gill-color  stem-height  stem-width stem-root  \\\n",
       "0             NaN          NaN          w        11.13       17.12         b   \n",
       "1             NaN            c          y         1.27       10.75       NaN   \n",
       "2             NaN            c          n         6.18        3.14       NaN   \n",
       "\n",
       "  stem-surface stem-color veil-type veil-color has-ring ring-type  \\\n",
       "0          NaN          w         u          w        t         g   \n",
       "1          NaN          n       NaN        NaN        f         f   \n",
       "2          NaN          n       NaN        NaN        f         f   \n",
       "\n",
       "  spore-print-color habitat season  \n",
       "0               NaN       d      a  \n",
       "1               NaN       d      a  \n",
       "2               NaN       d      s  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "IDtest = test_df[\"id\"]\n",
    "train_df.drop(labels=[\"id\"], axis=1, inplace=True)\n",
    "test_df.drop(labels=[\"id\"], axis=1, inplace=True)\n",
    "display(train_df.head(3))\n",
    "display(test_df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a18395",
   "metadata": {
    "id": "01a18395"
   },
   "source": [
    "* 최빈값들과 그 비율이 train과 test셋에서 비슷함\n",
    "* 만들어진 느낌이 나긴함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "GjFuyZxUnu3i",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "executionInfo": {
     "elapsed": 864,
     "status": "ok",
     "timestamp": 1723975861485,
     "user": {
      "displayName": "곽명조",
      "userId": "03864110971804242579"
     },
     "user_tz": -540
    },
    "id": "GjFuyZxUnu3i",
    "outputId": "fa41a99e-c5cc-42ba-fc9e-abe95237b2db"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cap-diameter</th>\n",
       "      <th>stem-height</th>\n",
       "      <th>stem-width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.116941e+06</td>\n",
       "      <td>3.116945e+06</td>\n",
       "      <td>3.116945e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.309848e+00</td>\n",
       "      <td>6.348333e+00</td>\n",
       "      <td>1.115379e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.657931e+00</td>\n",
       "      <td>2.699755e+00</td>\n",
       "      <td>8.095477e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.000000e-02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.320000e+00</td>\n",
       "      <td>4.670000e+00</td>\n",
       "      <td>4.970000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.750000e+00</td>\n",
       "      <td>5.880000e+00</td>\n",
       "      <td>9.650000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.240000e+00</td>\n",
       "      <td>7.410000e+00</td>\n",
       "      <td>1.563000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8.067000e+01</td>\n",
       "      <td>8.872000e+01</td>\n",
       "      <td>1.029000e+02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cap-diameter   stem-height    stem-width\n",
       "count  3.116941e+06  3.116945e+06  3.116945e+06\n",
       "mean   6.309848e+00  6.348333e+00  1.115379e+01\n",
       "std    4.657931e+00  2.699755e+00  8.095477e+00\n",
       "min    3.000000e-02  0.000000e+00  0.000000e+00\n",
       "25%    3.320000e+00  4.670000e+00  4.970000e+00\n",
       "50%    5.750000e+00  5.880000e+00  9.650000e+00\n",
       "75%    8.240000e+00  7.410000e+00  1.563000e+01\n",
       "max    8.067000e+01  8.872000e+01  1.029000e+02"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b14cdad",
   "metadata": {
    "id": "9b14cdad"
   },
   "source": [
    "# 2. Outlier Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d12bf462",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1271,
     "status": "ok",
     "timestamp": 1723975866206,
     "user": {
      "displayName": "곽명조",
      "userId": "03864110971804242579"
     },
     "user_tz": -540
    },
    "id": "d12bf462",
    "outputId": "51d52021-1073-43f1-c0ec-61366c6241e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Tukey method 이용해서 연속값들로부터 outlier 분석하기\n",
    "# Age, SibSp, Parch, Fare\n",
    "from collections import Counter\n",
    "\n",
    "def detect_outlier(df, n: int, features: list):\n",
    "    result_list = []\n",
    "\n",
    "    for col in features:\n",
    "        p25 = np.percentile(df[col], 25)\n",
    "        p75 = np.percentile(df[col], 75)\n",
    "        # Interquartile range(IQR)\n",
    "        IQR = p75 - p25\n",
    "\n",
    "        # outlier step\n",
    "        outlier_step = 1.5 * IQR\n",
    "\n",
    "        outlier_list = df[(df[col] < p25 - outlier_step) | (df[col] > p75 + outlier_step)].index\n",
    "\n",
    "        result_list.extend(outlier_list) # append하면 오류임\n",
    "\n",
    "    result_list = Counter(result_list).items()\n",
    "    result = [k for k, v in result_list if v > n]\n",
    "    return result\n",
    "\n",
    "outlier = detect_outlier(train_df, 2, [\"cap-diameter\",\"stem-height\",\"stem-width\"])\n",
    "print(outlier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a327c2a4",
   "metadata": {
    "id": "a327c2a4"
   },
   "source": [
    "* 숫자형 feature에는 눈에 띄는 outlier가 없음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0220069d",
   "metadata": {
    "id": "0220069d"
   },
   "source": [
    "# 3. Null 값 핸들링 (EDA에서 중요한거 있으면 전 단계에 추가하자)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b63f3055",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2105,
     "status": "ok",
     "timestamp": 1723975873581,
     "user": {
      "displayName": "곽명조",
      "userId": "03864110971804242579"
     },
     "user_tz": -540
    },
    "id": "b63f3055",
    "outputId": "32c5f3b5-2f28-4397-87d8-522e6da8a0d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "def drop_high_null(df):\n",
    "    null_rate = df.isnull().mean() * 100\n",
    "    high_null_cols = null_rate[null_rate >= 85].index\n",
    "\n",
    "    df = df.drop(labels=high_null_cols, axis=1)\n",
    "    return df\n",
    "\n",
    "train_df = drop_high_null(train_df)\n",
    "test_df = drop_high_null(test_df)\n",
    "\n",
    "print(train_df.shape[1])\n",
    "print(test_df.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6405e7a6",
   "metadata": {
    "id": "6405e7a6"
   },
   "source": [
    "#### 3.2 duplicate 값들 핸들링하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a9a936d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8312,
     "status": "ok",
     "timestamp": 1723975884455,
     "user": {
      "displayName": "곽명조",
      "userId": "03864110971804242579"
     },
     "user_tz": -540
    },
    "id": "6a9a936d",
    "outputId": "a1416747-a8b6-45c4-bf0e-becaf73908a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drop 이후 Train 데이터의 중복 건수: 0\n",
      "\n",
      "Train 데이터의 줄어든 데이터 건수: 157\n"
     ]
    }
   ],
   "source": [
    "# 중복이 문제되는 경우는 train뿐임\n",
    "# test는 처리 안해야됨\n",
    "# new_index 부여하자\n",
    "train_shape = train_df.shape\n",
    "\n",
    "train_df = train_df.drop_duplicates(ignore_index=True)\n",
    "\n",
    "print(\"Drop 이후 Train 데이터의 중복 건수:\", train_df.duplicated().sum())\n",
    "print()\n",
    "print(\"Train 데이터의 줄어든 데이터 건수:\", train_shape[0] - train_df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c87e59",
   "metadata": {
    "id": "29c87e59"
   },
   "source": [
    "#### 3.3 각 feature에서 data type에 맞지 않는 값들 있음, 찾아서 처리하기\n",
    "* 이 처리로 성능 향상 될수도?\n",
    "* 일단은 알파벳 아닌 값들 np.nan으로 일괄 변경하자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35d55312",
   "metadata": {
    "executionInfo": {
     "elapsed": 360,
     "status": "ok",
     "timestamp": 1723975886956,
     "user": {
      "displayName": "곽명조",
      "userId": "03864110971804242579"
     },
     "user_tz": -540
    },
    "id": "35d55312"
   },
   "outputs": [],
   "source": [
    "def replace_weird_to_nan(df, object_cols):\n",
    "    alphabet_list = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
    "\n",
    "    for col in object_cols:\n",
    "        df[col] = df[col].apply(lambda x: x if type(x)==str and len(x)==1 and x in alphabet_list else 'error')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "428cb6bb",
   "metadata": {
    "executionInfo": {
     "elapsed": 36071,
     "status": "ok",
     "timestamp": 1723975924446,
     "user": {
      "displayName": "곽명조",
      "userId": "03864110971804242579"
     },
     "user_tz": -540
    },
    "id": "428cb6bb"
   },
   "outputs": [],
   "source": [
    "train_df   = replace_weird_to_nan(train_df, train_df.describe(include='object').columns)\n",
    "test_df = replace_weird_to_nan(test_df, test_df.describe(include='object').columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66cc922",
   "metadata": {
    "id": "a66cc922"
   },
   "source": [
    "# 4. Null Filling/Encoding 전에 데이터 분포 살펴보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4941e91",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 343,
     "status": "ok",
     "timestamp": 1723975926396,
     "user": {
      "displayName": "곽명조",
      "userId": "03864110971804242579"
     },
     "user_tz": -540
    },
    "id": "f4941e91",
    "outputId": "88715df3-d411-47e9-e209-2fcfe16bde64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# train, test의 feature가 동일한지 확인\n",
    "train_cols = train_df.columns.tolist()\n",
    "train_cols.pop(0)\n",
    "test_cols = test_df.columns.tolist()\n",
    "print(len(train_cols) == len(test_cols))\n",
    "print(train_cols == test_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f59bd8a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1620,
     "status": "ok",
     "timestamp": 1723975931202,
     "user": {
      "displayName": "곽명조",
      "userId": "03864110971804242579"
     },
     "user_tz": -540
    },
    "id": "8f59bd8a",
    "outputId": "5d7a5428-8673-4c91-db76-ebdcb709f0db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cap-diameter', 'stem-height', 'stem-width']\n",
      "['cap-shape', 'cap-surface', 'cap-color', 'does-bruise-or-bleed', 'gill-attachment', 'gill-spacing', 'gill-color', 'stem-surface', 'stem-color', 'has-ring', 'ring-type', 'habitat', 'season']\n"
     ]
    }
   ],
   "source": [
    "# target feature인 class는 Labe Encoding 해줄꺼기 때문에 빼\n",
    "# 마지막에 inverse_transform 사용하기 위함\n",
    "num_cols = train_df.select_dtypes('number').columns.tolist()\n",
    "cat_cols = train_df.select_dtypes('object').columns.tolist()\n",
    "cat_cols.pop(0)\n",
    "\n",
    "print(num_cols)\n",
    "print(cat_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1fa173",
   "metadata": {
    "id": "fb1fa173"
   },
   "source": [
    "# 5. Null Filling / Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89610de1",
   "metadata": {
    "executionInfo": {
     "elapsed": 525,
     "status": "ok",
     "timestamp": 1723975934046,
     "user": {
      "displayName": "곽명조",
      "userId": "03864110971804242579"
     },
     "user_tz": -540
    },
    "id": "89610de1"
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.preprocessing import OrdinalEncoder, LabelEncoder, StandardScaler, FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import matthews_corrcoef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "IWnJdmlagazy",
   "metadata": {
    "executionInfo": {
     "elapsed": 19237,
     "status": "ok",
     "timestamp": 1723975955143,
     "user": {
      "displayName": "곽명조",
      "userId": "03864110971804242579"
     },
     "user_tz": -540
    },
    "id": "IWnJdmlagazy"
   },
   "outputs": [],
   "source": [
    "for col in num_cols:\n",
    "    train_df[col] = train_df[col].apply(lambda x: np.log(x) if x>0 else 0)\n",
    "    test_df[col] = test_df[col].apply(lambda x: np.log(x) if x>0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "yeO3-4Zxg5aC",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 518,
     "status": "ok",
     "timestamp": 1723975955628,
     "user": {
      "displayName": "곽명조",
      "userId": "03864110971804242579"
     },
     "user_tz": -540
    },
    "id": "yeO3-4Zxg5aC",
    "outputId": "b46650af-e66f-49c6-8e38-f8fabef6d742"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train cap-diameter의 skew: -0.5298, 평균: 1.6144, 분산: 0.5054\n",
      "Train stem-height의 skew: 0.0046, 평균: 1.7703, 분산: 0.1538\n",
      "Train stem-width의 skew: -0.5689, 평균: 2.1084, 분산: 0.7228\n",
      "====================\n",
      "Test cap-diameter의 skew: -0.526580893774004, 평균: 1.6134, 분산: 0.5060\n",
      "Test stem-height의 skew: 0.008050280011222922, 평균: 1.7701, 분산: 0.1536\n",
      "Test stem-width의 skew: -0.5680847615045285, 평균: 2.1078, 분산: 0.7230\n"
     ]
    }
   ],
   "source": [
    "# train, test dataset num_cols에서의 skew 값\n",
    "for col in num_cols:\n",
    "    print(\"Train {}의 skew: {:.4f}, 평균: {:.4f}, 분산: {:.4f}\".format(col, train_df[col].skew(), train_df[col].mean(), train_df[col].var()))\n",
    "print(\"====================\")\n",
    "for col in num_cols:\n",
    "    print(\"Test {}의 skew: {}, 평균: {:.4f}, 분산: {:.4f}\".format(col, test_df[col].skew(), test_df[col].mean(), test_df[col].var()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "daf4748f",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1723975955628,
     "user": {
      "displayName": "곽명조",
      "userId": "03864110971804242579"
     },
     "user_tz": -540
    },
    "id": "daf4748f"
   },
   "outputs": [],
   "source": [
    "num_transformer = Pipeline(steps=[\n",
    "    ('imputer', KNNImputer(n_neighbors=3)),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('convert_to_float32', FunctionTransformer(lambda x: x.astype(np.float32)))\n",
    "])\n",
    "\n",
    "cat_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', num_transformer, num_cols),\n",
    "    ('cat', cat_transformer, cat_cols)\n",
    "])\n",
    "\n",
    "def fillingNull_encoding(df, preprocessor, training=True):\n",
    "    if training:\n",
    "        df_transformed = pd.DataFrame(preprocessor.fit_transform(df[num_cols + cat_cols]), columns=num_cols+cat_cols)\n",
    "        df_transformed['class'] = df['class']\n",
    "    else:\n",
    "        df_transformed = pd.DataFrame(preprocessor.transform(df[num_cols + cat_cols]), columns=num_cols+cat_cols)\n",
    "\n",
    "    display(df_transformed.isnull().sum())\n",
    "    return df_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d5fa3803",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 617
    },
    "executionInfo": {
     "elapsed": 16652,
     "status": "ok",
     "timestamp": 1723975975380,
     "user": {
      "displayName": "곽명조",
      "userId": "03864110971804242579"
     },
     "user_tz": -540
    },
    "id": "d5fa3803",
    "outputId": "f7526a67-fef1-4bcd-8b5b-11442354dd84"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cap-diameter            0\n",
       "stem-height             0\n",
       "stem-width              0\n",
       "cap-shape               0\n",
       "cap-surface             0\n",
       "cap-color               0\n",
       "does-bruise-or-bleed    0\n",
       "gill-attachment         0\n",
       "gill-spacing            0\n",
       "gill-color              0\n",
       "stem-surface            0\n",
       "stem-color              0\n",
       "has-ring                0\n",
       "ring-type               0\n",
       "habitat                 0\n",
       "season                  0\n",
       "class                   0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "changed_train_df = fillingNull_encoding(train_df, preprocessor, training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8288d889",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 586
    },
    "executionInfo": {
     "elapsed": 7314,
     "status": "ok",
     "timestamp": 1723975982689,
     "user": {
      "displayName": "곽명조",
      "userId": "03864110971804242579"
     },
     "user_tz": -540
    },
    "id": "8288d889",
    "outputId": "afd34306-b4d8-4a81-fc5d-85792fa3f15e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cap-diameter            0\n",
       "stem-height             0\n",
       "stem-width              0\n",
       "cap-shape               0\n",
       "cap-surface             0\n",
       "cap-color               0\n",
       "does-bruise-or-bleed    0\n",
       "gill-attachment         0\n",
       "gill-spacing            0\n",
       "gill-color              0\n",
       "stem-surface            0\n",
       "stem-color              0\n",
       "has-ring                0\n",
       "ring-type               0\n",
       "habitat                 0\n",
       "season                  0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "changed_test_df = fillingNull_encoding(test_df, preprocessor, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6726ed72",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 278
    },
    "executionInfo": {
     "elapsed": 641,
     "status": "ok",
     "timestamp": 1723975983325,
     "user": {
      "displayName": "곽명조",
      "userId": "03864110971804242579"
     },
     "user_tz": -540
    },
    "id": "6726ed72",
    "outputId": "59bc4550-ab20-45b1-f638-7566e0ffdaa0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cap-diameter</th>\n",
       "      <th>stem-height</th>\n",
       "      <th>stem-width</th>\n",
       "      <th>cap-shape</th>\n",
       "      <th>cap-surface</th>\n",
       "      <th>cap-color</th>\n",
       "      <th>does-bruise-or-bleed</th>\n",
       "      <th>gill-attachment</th>\n",
       "      <th>gill-spacing</th>\n",
       "      <th>gill-color</th>\n",
       "      <th>stem-surface</th>\n",
       "      <th>stem-color</th>\n",
       "      <th>has-ring</th>\n",
       "      <th>ring-type</th>\n",
       "      <th>habitat</th>\n",
       "      <th>season</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.788150</td>\n",
       "      <td>-0.673283</td>\n",
       "      <td>0.735473</td>\n",
       "      <td>6.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.152124</td>\n",
       "      <td>-0.519694</td>\n",
       "      <td>-0.281953</td>\n",
       "      <td>21.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.454143</td>\n",
       "      <td>0.392448</td>\n",
       "      <td>0.220104</td>\n",
       "      <td>6.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.363770</td>\n",
       "      <td>-0.879268</td>\n",
       "      <td>-0.272912</td>\n",
       "      <td>6.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.213805</td>\n",
       "      <td>-1.416281</td>\n",
       "      <td>0.017675</td>\n",
       "      <td>21.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cap-diameter  stem-height  stem-width  cap-shape  cap-surface  cap-color  \\\n",
       "0      0.788150    -0.673283    0.735473        6.0         17.0       19.0   \n",
       "1     -0.152124    -0.519694   -0.281953       21.0          8.0       14.0   \n",
       "2      0.454143     0.392448    0.220104        6.0         17.0        1.0   \n",
       "3     -0.363770    -0.879268   -0.272912        6.0         22.0        7.0   \n",
       "4      0.213805    -1.416281    0.017675       21.0         11.0       20.0   \n",
       "\n",
       "   does-bruise-or-bleed  gill-attachment  gill-spacing  gill-color  \\\n",
       "0                   6.0              0.0           2.0        20.0   \n",
       "1                   6.0              0.0           2.0        13.0   \n",
       "2                   6.0             21.0           2.0        20.0   \n",
       "3                   6.0             17.0           5.0         7.0   \n",
       "4                   6.0              3.0           5.0        20.0   \n",
       "\n",
       "   stem-surface  stem-color  has-ring  ring-type  habitat  season  class  \n",
       "0           5.0        20.0       5.0        6.0      3.0     0.0      0  \n",
       "1          22.0        14.0      17.0       23.0      3.0     3.0      1  \n",
       "2          17.0        13.0       5.0        6.0     11.0     3.0      0  \n",
       "3           5.0        20.0       5.0        6.0      3.0     2.0      0  \n",
       "4           5.0        20.0       5.0        6.0      7.0     0.0      0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Target 값 LabelEncoding하기\n",
    "le = LabelEncoder()\n",
    "changed_train_df['class'] = le.fit_transform(changed_train_df['class'])\n",
    "changed_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "VaVYPa8qhsq2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 697,
     "status": "ok",
     "timestamp": 1723975984016,
     "user": {
      "displayName": "곽명조",
      "userId": "03864110971804242579"
     },
     "user_tz": -540
    },
    "id": "VaVYPa8qhsq2",
    "outputId": "727d7b54-eee6-4e96-a948-f386e9604085"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train cap-diameter의 skew: -0.5298, 평균: 0.0000, 분산: 1.0000\n",
      "Train stem-height의 skew: 0.0046, 평균: -0.0000, 분산: 1.0000\n",
      "Train stem-width의 skew: -0.5689, 평균: 0.0000, 분산: 1.0000\n",
      "====================\n",
      "Test cap-diameter의 skew: -0.5265808909752238, 평균: -0.0015, 분산: 1.0011\n",
      "Test stem-height의 skew: 0.00805027187872713, 평균: -0.0006, 분산: 0.9989\n",
      "Test stem-width의 skew: -0.5680847577447173, 평균: -0.0008, 분산: 1.0003\n"
     ]
    }
   ],
   "source": [
    "# train, test dataset num_cols에서의 skew 값\n",
    "for col in num_cols:\n",
    "    print(\"Train {}의 skew: {:.4f}, 평균: {:.4f}, 분산: {:.4f}\".format(col, changed_train_df[col].skew(), changed_train_df[col].mean(), changed_train_df[col].var()))\n",
    "print(\"====================\")\n",
    "for col in num_cols:\n",
    "    print(\"Test {}의 skew: {}, 평균: {:.4f}, 분산: {:.4f}\".format(col, changed_test_df[col].skew(), changed_test_df[col].mean(), changed_test_df[col].var()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa8b074",
   "metadata": {
    "id": "baa8b074"
   },
   "source": [
    "# 6. Modeling\n",
    "* 실험 편리를 위해 changed_train_df, chagned_test_df 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "331fbcd2",
   "metadata": {
    "executionInfo": {
     "elapsed": 516,
     "status": "ok",
     "timestamp": 1723975987010,
     "user": {
      "displayName": "곽명조",
      "userId": "03864110971804242579"
     },
     "user_tz": -540
    },
    "id": "331fbcd2"
   },
   "outputs": [],
   "source": [
    "y_data = changed_train_df['class']\n",
    "x_data = changed_train_df.drop(labels=['class'], axis=1, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3c6a3078",
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1723975988276,
     "user": {
      "displayName": "곽명조",
      "userId": "03864110971804242579"
     },
     "user_tz": -540
    },
    "id": "3c6a3078"
   },
   "outputs": [],
   "source": [
    "def mcc_metric(y_pred, dmatrix):\n",
    "    y_true = dmatrix.get_label()\n",
    "    y_pred = (y_pred > 0.5).astype(int)\n",
    "    mcc = matthews_corrcoef(y_true, y_pred)\n",
    "    return 'mcc', mcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "qIETbeUG-orC",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8818,
     "status": "ok",
     "timestamp": 1723976046595,
     "user": {
      "displayName": "곽명조",
      "userId": "03864110971804242579"
     },
     "user_tz": -540
    },
    "id": "qIETbeUG-orC",
    "outputId": "3c190d4a-6f4c-42f8-c3b4-cdf422bb988b",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting catboost\n",
      "  Obtaining dependency information for catboost from https://files.pythonhosted.org/packages/35/7e/35fa1a7cf6925ff438e849cca50c88b8d28e02d9c3486442f2f85b86184a/catboost-1.2.5-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading catboost-1.2.5-cp311-cp311-win_amd64.whl.metadata (1.2 kB)\n",
      "Collecting graphviz (from catboost)\n",
      "  Obtaining dependency information for graphviz from https://files.pythonhosted.org/packages/00/be/d59db2d1d52697c6adc9eacaf50e8965b6345cc143f671e1ed068818d5cf/graphviz-0.20.3-py3-none-any.whl.metadata\n",
      "  Downloading graphviz-0.20.3-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\82108\\anaconda3\\lib\\site-packages (from catboost) (3.7.2)\n",
      "Requirement already satisfied: numpy>=1.16.0 in c:\\users\\82108\\anaconda3\\lib\\site-packages (from catboost) (1.24.3)\n",
      "Requirement already satisfied: pandas>=0.24 in c:\\users\\82108\\anaconda3\\lib\\site-packages (from catboost) (2.0.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\82108\\anaconda3\\lib\\site-packages (from catboost) (1.11.1)\n",
      "Requirement already satisfied: plotly in c:\\users\\82108\\anaconda3\\lib\\site-packages (from catboost) (5.9.0)\n",
      "Requirement already satisfied: six in c:\\users\\82108\\anaconda3\\lib\\site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\82108\\anaconda3\\lib\\site-packages (from pandas>=0.24->catboost) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\82108\\anaconda3\\lib\\site-packages (from pandas>=0.24->catboost) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\82108\\anaconda3\\lib\\site-packages (from pandas>=0.24->catboost) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\82108\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\82108\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\82108\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\82108\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\82108\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\82108\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (9.4.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\users\\82108\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (3.0.9)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\82108\\anaconda3\\lib\\site-packages (from plotly->catboost) (8.2.2)\n",
      "Downloading catboost-1.2.5-cp311-cp311-win_amd64.whl (101.1 MB)\n",
      "   ---------------------------------------- 0.0/101.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.4/101.1 MB 13.5 MB/s eta 0:00:08\n",
      "   ---------------------------------------- 1.1/101.1 MB 9.8 MB/s eta 0:00:11\n",
      "    --------------------------------------- 1.6/101.1 MB 11.3 MB/s eta 0:00:09\n",
      "    --------------------------------------- 2.1/101.1 MB 10.3 MB/s eta 0:00:10\n",
      "   - -------------------------------------- 2.7/101.1 MB 10.3 MB/s eta 0:00:10\n",
      "   - -------------------------------------- 3.3/101.1 MB 10.7 MB/s eta 0:00:10\n",
      "   - -------------------------------------- 3.9/101.1 MB 10.7 MB/s eta 0:00:10\n",
      "   - -------------------------------------- 4.6/101.1 MB 10.9 MB/s eta 0:00:09\n",
      "   -- ------------------------------------- 5.4/101.1 MB 11.4 MB/s eta 0:00:09\n",
      "   -- ------------------------------------- 6.1/101.1 MB 11.5 MB/s eta 0:00:09\n",
      "   -- ------------------------------------- 6.9/101.1 MB 11.6 MB/s eta 0:00:09\n",
      "   --- ------------------------------------ 7.7/101.1 MB 11.7 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 8.3/101.1 MB 11.8 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 8.8/101.1 MB 11.8 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 9.5/101.1 MB 11.9 MB/s eta 0:00:08\n",
      "   ---- ----------------------------------- 10.2/101.1 MB 12.0 MB/s eta 0:00:08\n",
      "   ---- ----------------------------------- 10.8/101.1 MB 12.4 MB/s eta 0:00:08\n",
      "   ---- ----------------------------------- 11.5/101.1 MB 12.4 MB/s eta 0:00:08\n",
      "   ---- ----------------------------------- 12.2/101.1 MB 12.6 MB/s eta 0:00:08\n",
      "   ----- ---------------------------------- 12.9/101.1 MB 12.6 MB/s eta 0:00:08\n",
      "   ----- ---------------------------------- 13.6/101.1 MB 12.6 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 14.2/101.1 MB 12.8 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 15.1/101.1 MB 12.8 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 15.6/101.1 MB 12.6 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 16.3/101.1 MB 12.8 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 17.0/101.1 MB 13.1 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 17.8/101.1 MB 13.4 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 18.6/101.1 MB 13.6 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 19.4/101.1 MB 13.9 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 20.3/101.1 MB 14.2 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 21.3/101.1 MB 14.9 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 22.2/101.1 MB 15.6 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 23.2/101.1 MB 16.4 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 24.2/101.1 MB 17.2 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 25.1/101.1 MB 17.7 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 26.1/101.1 MB 18.7 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 27.1/101.1 MB 19.8 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 27.8/101.1 MB 19.8 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 28.6/101.1 MB 19.8 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 29.4/101.1 MB 20.5 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 30.3/101.1 MB 20.5 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 31.2/101.1 MB 19.9 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 32.1/101.1 MB 19.8 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 32.7/101.1 MB 19.3 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 32.9/101.1 MB 17.7 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 33.0/101.1 MB 16.8 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 33.3/101.1 MB 15.6 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 33.9/101.1 MB 15.2 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 34.7/101.1 MB 15.2 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 35.7/101.1 MB 14.9 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 36.6/101.1 MB 14.9 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 37.5/101.1 MB 14.9 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 38.3/101.1 MB 14.9 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 39.1/101.1 MB 14.9 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 40.2/101.1 MB 14.6 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 41.3/101.1 MB 14.6 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 42.0/101.1 MB 14.6 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 42.9/101.1 MB 14.6 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 43.7/101.1 MB 17.2 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 44.4/101.1 MB 17.2 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 45.2/101.1 MB 17.7 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 46.0/101.1 MB 17.7 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 46.8/101.1 MB 17.3 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 47.5/101.1 MB 16.8 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 48.1/101.1 MB 16.8 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 49.2/101.1 MB 17.2 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 50.5/101.1 MB 18.2 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 51.4/101.1 MB 18.2 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 52.0/101.1 MB 17.7 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 52.7/101.1 MB 17.7 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 53.3/101.1 MB 17.3 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 54.2/101.1 MB 16.8 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 55.3/101.1 MB 16.8 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 56.3/101.1 MB 17.2 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 57.1/101.1 MB 17.2 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 57.8/101.1 MB 17.2 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 58.8/101.1 MB 17.2 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 59.7/101.1 MB 17.3 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 60.5/101.1 MB 16.4 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 61.0/101.1 MB 16.0 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 61.7/101.1 MB 16.0 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 62.5/101.1 MB 16.0 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 63.3/101.1 MB 16.4 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 64.0/101.1 MB 16.4 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 64.7/101.1 MB 16.4 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 65.5/101.1 MB 16.4 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 66.4/101.1 MB 16.4 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 67.1/101.1 MB 16.4 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 67.9/101.1 MB 16.4 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 68.7/101.1 MB 16.0 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 69.5/101.1 MB 16.0 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 70.2/101.1 MB 16.0 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 71.0/101.1 MB 16.4 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 71.7/101.1 MB 16.4 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 72.8/101.1 MB 16.4 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 73.7/101.1 MB 16.8 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 74.5/101.1 MB 16.8 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 75.4/101.1 MB 16.8 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 76.1/101.1 MB 16.8 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 76.9/101.1 MB 16.8 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 77.8/101.1 MB 16.8 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 78.6/101.1 MB 16.8 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 78.9/101.1 MB 16.8 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 79.0/101.1 MB 16.0 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 79.2/101.1 MB 14.6 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 79.3/101.1 MB 14.2 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 79.6/101.1 MB 13.4 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 80.4/101.1 MB 13.4 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 81.5/101.1 MB 13.4 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 82.2/101.1 MB 13.4 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 83.3/101.1 MB 13.4 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 84.1/101.1 MB 13.4 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 84.9/101.1 MB 13.4 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 85.6/101.1 MB 13.4 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 86.4/101.1 MB 13.4 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 87.4/101.1 MB 13.1 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 88.4/101.1 MB 13.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 89.1/101.1 MB 12.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 89.8/101.1 MB 16.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 90.4/101.1 MB 16.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 91.6/101.1 MB 16.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 92.6/101.1 MB 16.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 93.6/101.1 MB 16.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 94.7/101.1 MB 16.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 95.6/101.1 MB 16.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 96.3/101.1 MB 16.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 97.0/101.1 MB 16.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 97.9/101.1 MB 16.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  98.7/101.1 MB 15.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.4/101.1 MB 14.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  100.4/101.1 MB 15.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  101.1/101.1 MB 15.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  101.1/101.1 MB 15.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  101.1/101.1 MB 15.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  101.1/101.1 MB 15.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  101.1/101.1 MB 15.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  101.1/101.1 MB 15.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  101.1/101.1 MB 15.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  101.1/101.1 MB 15.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 101.1/101.1 MB 6.5 MB/s eta 0:00:00\n",
      "Downloading graphviz-0.20.3-py3-none-any.whl (47 kB)\n",
      "   ---------------------------------------- 0.0/47.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 47.1/47.1 kB 2.3 MB/s eta 0:00:00\n",
      "Installing collected packages: graphviz, catboost\n",
      "Successfully installed catboost-1.2.5 graphviz-0.20.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2070c9d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightgbm\n",
      "  Obtaining dependency information for lightgbm from https://files.pythonhosted.org/packages/d9/28/3be76b591a2e14a031b681b8283acf1dec2ad521f6f1701b7957df68c466/lightgbm-4.5.0-py3-none-win_amd64.whl.metadata\n",
      "  Downloading lightgbm-4.5.0-py3-none-win_amd64.whl.metadata (17 kB)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\82108\\anaconda3\\lib\\site-packages (from lightgbm) (1.24.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\82108\\anaconda3\\lib\\site-packages (from lightgbm) (1.11.1)\n",
      "Downloading lightgbm-4.5.0-py3-none-win_amd64.whl (1.4 MB)\n",
      "   ---------------------------------------- 0.0/1.4 MB ? eta -:--:--\n",
      "   -------------------- ------------------- 0.7/1.4 MB 15.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.4/1.4 MB 15.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.4/1.4 MB 13.2 MB/s eta 0:00:00\n",
      "Installing collected packages: lightgbm\n",
      "Successfully installed lightgbm-4.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "NeUblf4ilPur",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5770,
     "status": "ok",
     "timestamp": 1723976058763,
     "user": {
      "displayName": "곽명조",
      "userId": "03864110971804242579"
     },
     "user_tz": -540
    },
    "id": "NeUblf4ilPur",
    "outputId": "70c1521d-8220-4be7-f336-0754c55d81df"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.base import clone\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from lightgbm import LGBMClassifier\n",
    "from lightgbm.callback import early_stopping, log_evaluation\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "uwWYbfaPlbOC",
   "metadata": {
    "executionInfo": {
     "elapsed": 353,
     "status": "ok",
     "timestamp": 1723976424176,
     "user": {
      "displayName": "곽명조",
      "userId": "03864110971804242579"
     },
     "user_tz": -540
    },
    "id": "uwWYbfaPlbOC"
   },
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=2, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "47-i2jqIliZQ",
   "metadata": {
    "executionInfo": {
     "elapsed": 348,
     "status": "ok",
     "timestamp": 1723978650351,
     "user": {
      "displayName": "곽명조",
      "userId": "03864110971804242579"
     },
     "user_tz": -540
    },
    "id": "47-i2jqIliZQ"
   },
   "outputs": [],
   "source": [
    "def cross_validate_score(model, train_df, y, cv, test_data):\n",
    "    val_scores = []\n",
    "    test_preds = np.zeros((test_data.shape[0],))\n",
    "    oof_preds = np.zeros((train_df.shape[0],))\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(cv.split(train_df, y)):\n",
    "        X_train = train_df.iloc[train_idx].reset_index(drop=True)\n",
    "        y_train = y.iloc[train_idx].reset_index(drop=True)\n",
    "\n",
    "        X_val = train_df.iloc[val_idx].reset_index(drop=True)\n",
    "        y_val = y.iloc[val_idx].reset_index(drop=True)\n",
    "\n",
    "        model = clone(model)\n",
    "\n",
    "        eval_set = [(X_val, y_val)]\n",
    "\n",
    "        if isinstance(model, LGBMClassifier):\n",
    "            model.fit(\n",
    "                X_train, y_train,\n",
    "                eval_set=eval_set,\n",
    "                callbacks=[early_stopping(70)],\n",
    "            )\n",
    "        elif isinstance(model, XGBClassifier):\n",
    "            model.fit(\n",
    "                X_train, y_train,\n",
    "                eval_set=eval_set,\n",
    "                eval_metric = mcc_metric,\n",
    "                verbose=True\n",
    "            )\n",
    "        elif isinstance(model, CatBoostClassifier):\n",
    "            model.fit(\n",
    "                X_train, y_train,\n",
    "                eval_set=eval_set,\n",
    "                early_stopping_rounds=70,\n",
    "                verbose=True\n",
    "            )\n",
    "        else:\n",
    "            model.fit(\n",
    "                X_train, y_train,\n",
    "            )\n",
    "\n",
    "        val_probs = model.predict_proba(X_val)[:, 1]  # Get the probabilities\n",
    "        val_preds = (val_probs > 0.5).astype(int)     # Convert probabilities to class labels for MCC\n",
    "\n",
    "        val_score = matthews_corrcoef(y_val, val_preds)  # Calculate MCC\n",
    "        print(f'Fold {fold}: MCC = {val_score:.5f}')\n",
    "\n",
    "        val_scores.append(val_score)\n",
    "\n",
    "        oof_preds[val_idx] = val_probs  # Store the probabilities for OOF predictions\n",
    "\n",
    "        test_preds += model.predict_proba(test_data)[:, 1] / cv.get_n_splits()  # Aggregate test probabilities\n",
    "\n",
    "    mean_val_score = np.mean(val_scores)\n",
    "    std_val_score = np.std(val_scores)\n",
    "    print(f'Mean Validation MCC: {mean_val_score:.7f}')\n",
    "    print(f'Std Validation MCC: {std_val_score:.7f}')\n",
    "\n",
    "    return val_scores, test_preds, oof_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e3U3MhrEmw4u",
   "metadata": {
    "executionInfo": {
     "elapsed": 336,
     "status": "ok",
     "timestamp": 1723976433269,
     "user": {
      "displayName": "곽명조",
      "userId": "03864110971804242579"
     },
     "user_tz": -540
    },
    "id": "e3U3MhrEmw4u"
   },
   "outputs": [],
   "source": [
    "cv_summary, test_preds, oof_preds = pd.DataFrame(), pd.DataFrame(), pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sK0fam4OmzDT",
   "metadata": {
    "id": "sK0fam4OmzDT"
   },
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07310e7b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1162679,
     "status": "ok",
     "timestamp": 1723977671863,
     "user": {
      "displayName": "곽명조",
      "userId": "03864110971804242579"
     },
     "user_tz": -540
    },
    "id": "07310e7b",
    "outputId": "dfe6e680-9d07-4176-ebad-a26924e35434"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\82108\\anaconda3\\Lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-logloss:0.67771\tvalidation_0-mcc:0.84019\n",
      "[1]\tvalidation_0-logloss:0.66729\tvalidation_0-mcc:0.84705\n",
      "[2]\tvalidation_0-logloss:0.65245\tvalidation_0-mcc:0.92531\n",
      "[3]\tvalidation_0-logloss:0.63818\tvalidation_0-mcc:0.95593\n",
      "[4]\tvalidation_0-logloss:0.62445\tvalidation_0-mcc:0.96612\n",
      "[5]\tvalidation_0-logloss:0.60966\tvalidation_0-mcc:0.97031\n",
      "[6]\tvalidation_0-logloss:0.59608\tvalidation_0-mcc:0.97310\n",
      "[7]\tvalidation_0-logloss:0.58215\tvalidation_0-mcc:0.97581\n",
      "[8]\tvalidation_0-logloss:0.57006\tvalidation_0-mcc:0.97781\n",
      "[9]\tvalidation_0-logloss:0.55813\tvalidation_0-mcc:0.97808\n",
      "[10]\tvalidation_0-logloss:0.54547\tvalidation_0-mcc:0.97846\n",
      "[11]\tvalidation_0-logloss:0.53380\tvalidation_0-mcc:0.97952\n",
      "[12]\tvalidation_0-logloss:0.52184\tvalidation_0-mcc:0.98023\n",
      "[13]\tvalidation_0-logloss:0.51307\tvalidation_0-mcc:0.98045\n",
      "[14]\tvalidation_0-logloss:0.50370\tvalidation_0-mcc:0.98084\n",
      "[15]\tvalidation_0-logloss:0.49428\tvalidation_0-mcc:0.98080\n",
      "[16]\tvalidation_0-logloss:0.48446\tvalidation_0-mcc:0.98118\n",
      "[17]\tvalidation_0-logloss:0.47431\tvalidation_0-mcc:0.98163\n",
      "[18]\tvalidation_0-logloss:0.46519\tvalidation_0-mcc:0.98186\n",
      "[19]\tvalidation_0-logloss:0.45639\tvalidation_0-mcc:0.98194\n",
      "[20]\tvalidation_0-logloss:0.44940\tvalidation_0-mcc:0.98204\n",
      "[21]\tvalidation_0-logloss:0.44046\tvalidation_0-mcc:0.98209\n",
      "[22]\tvalidation_0-logloss:0.43338\tvalidation_0-mcc:0.98207\n",
      "[23]\tvalidation_0-logloss:0.42830\tvalidation_0-mcc:0.98208\n",
      "[24]\tvalidation_0-logloss:0.41946\tvalidation_0-mcc:0.98214\n",
      "[25]\tvalidation_0-logloss:0.41078\tvalidation_0-mcc:0.98222\n",
      "[26]\tvalidation_0-logloss:0.40483\tvalidation_0-mcc:0.98223\n",
      "[27]\tvalidation_0-logloss:0.39827\tvalidation_0-mcc:0.98219\n",
      "[28]\tvalidation_0-logloss:0.39230\tvalidation_0-mcc:0.98214\n",
      "[29]\tvalidation_0-logloss:0.38708\tvalidation_0-mcc:0.98223\n",
      "[30]\tvalidation_0-logloss:0.37921\tvalidation_0-mcc:0.98246\n",
      "[31]\tvalidation_0-logloss:0.37209\tvalidation_0-mcc:0.98246\n",
      "[32]\tvalidation_0-logloss:0.36643\tvalidation_0-mcc:0.98241\n",
      "[33]\tvalidation_0-logloss:0.35941\tvalidation_0-mcc:0.98252\n",
      "[34]\tvalidation_0-logloss:0.35377\tvalidation_0-mcc:0.98252\n",
      "[35]\tvalidation_0-logloss:0.34730\tvalidation_0-mcc:0.98257\n",
      "[36]\tvalidation_0-logloss:0.34033\tvalidation_0-mcc:0.98257\n",
      "[37]\tvalidation_0-logloss:0.33502\tvalidation_0-mcc:0.98262\n",
      "[38]\tvalidation_0-logloss:0.32873\tvalidation_0-mcc:0.98266\n",
      "[39]\tvalidation_0-logloss:0.32267\tvalidation_0-mcc:0.98271\n",
      "[40]\tvalidation_0-logloss:0.31683\tvalidation_0-mcc:0.98259\n",
      "[41]\tvalidation_0-logloss:0.31150\tvalidation_0-mcc:0.98265\n",
      "[42]\tvalidation_0-logloss:0.30637\tvalidation_0-mcc:0.98272\n",
      "[43]\tvalidation_0-logloss:0.30145\tvalidation_0-mcc:0.98272\n",
      "[44]\tvalidation_0-logloss:0.29697\tvalidation_0-mcc:0.98268\n",
      "[45]\tvalidation_0-logloss:0.29210\tvalidation_0-mcc:0.98266\n",
      "[46]\tvalidation_0-logloss:0.28749\tvalidation_0-mcc:0.98260\n",
      "[47]\tvalidation_0-logloss:0.28313\tvalidation_0-mcc:0.98262\n",
      "[48]\tvalidation_0-logloss:0.27786\tvalidation_0-mcc:0.98258\n",
      "[49]\tvalidation_0-logloss:0.27422\tvalidation_0-mcc:0.98257\n",
      "[50]\tvalidation_0-logloss:0.27008\tvalidation_0-mcc:0.98256\n",
      "[51]\tvalidation_0-logloss:0.26488\tvalidation_0-mcc:0.98262\n",
      "[52]\tvalidation_0-logloss:0.26083\tvalidation_0-mcc:0.98258\n",
      "[53]\tvalidation_0-logloss:0.25615\tvalidation_0-mcc:0.98260\n",
      "[54]\tvalidation_0-logloss:0.25239\tvalidation_0-mcc:0.98259\n",
      "[55]\tvalidation_0-logloss:0.24774\tvalidation_0-mcc:0.98267\n",
      "[56]\tvalidation_0-logloss:0.24410\tvalidation_0-mcc:0.98265\n",
      "[57]\tvalidation_0-logloss:0.24051\tvalidation_0-mcc:0.98269\n",
      "[58]\tvalidation_0-logloss:0.23618\tvalidation_0-mcc:0.98272\n",
      "[59]\tvalidation_0-logloss:0.23206\tvalidation_0-mcc:0.98278\n",
      "[60]\tvalidation_0-logloss:0.22868\tvalidation_0-mcc:0.98282\n",
      "[61]\tvalidation_0-logloss:0.22512\tvalidation_0-mcc:0.98283\n",
      "[62]\tvalidation_0-logloss:0.22143\tvalidation_0-mcc:0.98283\n",
      "[63]\tvalidation_0-logloss:0.21765\tvalidation_0-mcc:0.98284\n",
      "[64]\tvalidation_0-logloss:0.21475\tvalidation_0-mcc:0.98291\n",
      "[65]\tvalidation_0-logloss:0.21115\tvalidation_0-mcc:0.98291\n",
      "[66]\tvalidation_0-logloss:0.20886\tvalidation_0-mcc:0.98292\n",
      "[67]\tvalidation_0-logloss:0.20547\tvalidation_0-mcc:0.98302\n",
      "[68]\tvalidation_0-logloss:0.20281\tvalidation_0-mcc:0.98296\n",
      "[69]\tvalidation_0-logloss:0.19958\tvalidation_0-mcc:0.98298\n",
      "[70]\tvalidation_0-logloss:0.19652\tvalidation_0-mcc:0.98298\n",
      "[71]\tvalidation_0-logloss:0.19342\tvalidation_0-mcc:0.98296\n",
      "[72]\tvalidation_0-logloss:0.19120\tvalidation_0-mcc:0.98298\n",
      "[73]\tvalidation_0-logloss:0.18887\tvalidation_0-mcc:0.98298\n",
      "[74]\tvalidation_0-logloss:0.18599\tvalidation_0-mcc:0.98304\n",
      "[75]\tvalidation_0-logloss:0.18339\tvalidation_0-mcc:0.98305\n",
      "[76]\tvalidation_0-logloss:0.18122\tvalidation_0-mcc:0.98309\n",
      "[77]\tvalidation_0-logloss:0.17858\tvalidation_0-mcc:0.98308\n",
      "[78]\tvalidation_0-logloss:0.17600\tvalidation_0-mcc:0.98315\n",
      "[79]\tvalidation_0-logloss:0.17328\tvalidation_0-mcc:0.98318\n",
      "[80]\tvalidation_0-logloss:0.17108\tvalidation_0-mcc:0.98316\n",
      "[81]\tvalidation_0-logloss:0.16873\tvalidation_0-mcc:0.98319\n",
      "[82]\tvalidation_0-logloss:0.16626\tvalidation_0-mcc:0.98321\n",
      "[83]\tvalidation_0-logloss:0.16383\tvalidation_0-mcc:0.98323\n",
      "[84]\tvalidation_0-logloss:0.16120\tvalidation_0-mcc:0.98320\n",
      "[85]\tvalidation_0-logloss:0.15919\tvalidation_0-mcc:0.98324\n",
      "[86]\tvalidation_0-logloss:0.15695\tvalidation_0-mcc:0.98323\n",
      "[87]\tvalidation_0-logloss:0.15489\tvalidation_0-mcc:0.98322\n",
      "[88]\tvalidation_0-logloss:0.15302\tvalidation_0-mcc:0.98321\n",
      "[89]\tvalidation_0-logloss:0.15129\tvalidation_0-mcc:0.98321\n",
      "[90]\tvalidation_0-logloss:0.14907\tvalidation_0-mcc:0.98323\n",
      "[91]\tvalidation_0-logloss:0.14766\tvalidation_0-mcc:0.98321\n",
      "[92]\tvalidation_0-logloss:0.14618\tvalidation_0-mcc:0.98320\n",
      "[93]\tvalidation_0-logloss:0.14438\tvalidation_0-mcc:0.98321\n",
      "[94]\tvalidation_0-logloss:0.14244\tvalidation_0-mcc:0.98321\n",
      "[95]\tvalidation_0-logloss:0.14050\tvalidation_0-mcc:0.98321\n",
      "[96]\tvalidation_0-logloss:0.13850\tvalidation_0-mcc:0.98322\n",
      "[97]\tvalidation_0-logloss:0.13720\tvalidation_0-mcc:0.98324\n",
      "[98]\tvalidation_0-logloss:0.13534\tvalidation_0-mcc:0.98328\n",
      "[99]\tvalidation_0-logloss:0.13371\tvalidation_0-mcc:0.98327\n",
      "[100]\tvalidation_0-logloss:0.13182\tvalidation_0-mcc:0.98332\n",
      "[101]\tvalidation_0-logloss:0.12995\tvalidation_0-mcc:0.98329\n",
      "[102]\tvalidation_0-logloss:0.12829\tvalidation_0-mcc:0.98332\n",
      "[103]\tvalidation_0-logloss:0.12730\tvalidation_0-mcc:0.98332\n",
      "[104]\tvalidation_0-logloss:0.12569\tvalidation_0-mcc:0.98329\n",
      "[105]\tvalidation_0-logloss:0.12416\tvalidation_0-mcc:0.98331\n",
      "[106]\tvalidation_0-logloss:0.12298\tvalidation_0-mcc:0.98330\n",
      "[107]\tvalidation_0-logloss:0.12171\tvalidation_0-mcc:0.98332\n",
      "[108]\tvalidation_0-logloss:0.12052\tvalidation_0-mcc:0.98334\n",
      "[109]\tvalidation_0-logloss:0.11917\tvalidation_0-mcc:0.98333\n",
      "[110]\tvalidation_0-logloss:0.11837\tvalidation_0-mcc:0.98334\n",
      "[111]\tvalidation_0-logloss:0.11724\tvalidation_0-mcc:0.98335\n",
      "[112]\tvalidation_0-logloss:0.11563\tvalidation_0-mcc:0.98335\n",
      "[113]\tvalidation_0-logloss:0.11456\tvalidation_0-mcc:0.98337\n",
      "[114]\tvalidation_0-logloss:0.11322\tvalidation_0-mcc:0.98334\n",
      "[115]\tvalidation_0-logloss:0.11197\tvalidation_0-mcc:0.98334\n",
      "[116]\tvalidation_0-logloss:0.11047\tvalidation_0-mcc:0.98337\n",
      "[117]\tvalidation_0-logloss:0.10940\tvalidation_0-mcc:0.98337\n",
      "[118]\tvalidation_0-logloss:0.10857\tvalidation_0-mcc:0.98336\n",
      "[119]\tvalidation_0-logloss:0.10749\tvalidation_0-mcc:0.98339\n",
      "[120]\tvalidation_0-logloss:0.10607\tvalidation_0-mcc:0.98342\n",
      "[121]\tvalidation_0-logloss:0.10524\tvalidation_0-mcc:0.98342\n",
      "[122]\tvalidation_0-logloss:0.10392\tvalidation_0-mcc:0.98342\n",
      "[123]\tvalidation_0-logloss:0.10271\tvalidation_0-mcc:0.98342\n",
      "[124]\tvalidation_0-logloss:0.10184\tvalidation_0-mcc:0.98343\n",
      "[125]\tvalidation_0-logloss:0.10074\tvalidation_0-mcc:0.98342\n",
      "[126]\tvalidation_0-logloss:0.10028\tvalidation_0-mcc:0.98339\n",
      "[127]\tvalidation_0-logloss:0.09952\tvalidation_0-mcc:0.98341\n",
      "[128]\tvalidation_0-logloss:0.09837\tvalidation_0-mcc:0.98342\n",
      "[129]\tvalidation_0-logloss:0.09769\tvalidation_0-mcc:0.98342\n",
      "[130]\tvalidation_0-logloss:0.09654\tvalidation_0-mcc:0.98342\n",
      "[131]\tvalidation_0-logloss:0.09533\tvalidation_0-mcc:0.98342\n",
      "[132]\tvalidation_0-logloss:0.09418\tvalidation_0-mcc:0.98343\n",
      "[133]\tvalidation_0-logloss:0.09368\tvalidation_0-mcc:0.98344\n",
      "[134]\tvalidation_0-logloss:0.09275\tvalidation_0-mcc:0.98347\n",
      "[135]\tvalidation_0-logloss:0.09204\tvalidation_0-mcc:0.98345\n",
      "[136]\tvalidation_0-logloss:0.09107\tvalidation_0-mcc:0.98348\n",
      "[137]\tvalidation_0-logloss:0.09021\tvalidation_0-mcc:0.98347\n",
      "[138]\tvalidation_0-logloss:0.08950\tvalidation_0-mcc:0.98351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[139]\tvalidation_0-logloss:0.08857\tvalidation_0-mcc:0.98352\n",
      "[140]\tvalidation_0-logloss:0.08760\tvalidation_0-mcc:0.98351\n",
      "[141]\tvalidation_0-logloss:0.08684\tvalidation_0-mcc:0.98350\n",
      "[142]\tvalidation_0-logloss:0.08589\tvalidation_0-mcc:0.98350\n",
      "[143]\tvalidation_0-logloss:0.08500\tvalidation_0-mcc:0.98352\n",
      "[144]\tvalidation_0-logloss:0.08439\tvalidation_0-mcc:0.98353\n",
      "[145]\tvalidation_0-logloss:0.08363\tvalidation_0-mcc:0.98352\n",
      "[146]\tvalidation_0-logloss:0.08301\tvalidation_0-mcc:0.98352\n",
      "[147]\tvalidation_0-logloss:0.08229\tvalidation_0-mcc:0.98352\n",
      "[148]\tvalidation_0-logloss:0.08153\tvalidation_0-mcc:0.98351\n",
      "[149]\tvalidation_0-logloss:0.08089\tvalidation_0-mcc:0.98353\n",
      "[150]\tvalidation_0-logloss:0.08004\tvalidation_0-mcc:0.98353\n",
      "[151]\tvalidation_0-logloss:0.07939\tvalidation_0-mcc:0.98352\n",
      "[152]\tvalidation_0-logloss:0.07899\tvalidation_0-mcc:0.98352\n",
      "[153]\tvalidation_0-logloss:0.07822\tvalidation_0-mcc:0.98354\n",
      "[154]\tvalidation_0-logloss:0.07751\tvalidation_0-mcc:0.98353\n",
      "[155]\tvalidation_0-logloss:0.07692\tvalidation_0-mcc:0.98353\n",
      "[156]\tvalidation_0-logloss:0.07642\tvalidation_0-mcc:0.98353\n",
      "[157]\tvalidation_0-logloss:0.07570\tvalidation_0-mcc:0.98353\n",
      "[158]\tvalidation_0-logloss:0.07495\tvalidation_0-mcc:0.98355\n",
      "[159]\tvalidation_0-logloss:0.07438\tvalidation_0-mcc:0.98355\n",
      "[160]\tvalidation_0-logloss:0.07368\tvalidation_0-mcc:0.98358\n",
      "[161]\tvalidation_0-logloss:0.07306\tvalidation_0-mcc:0.98358\n",
      "[162]\tvalidation_0-logloss:0.07254\tvalidation_0-mcc:0.98357\n",
      "[163]\tvalidation_0-logloss:0.07225\tvalidation_0-mcc:0.98358\n",
      "[164]\tvalidation_0-logloss:0.07174\tvalidation_0-mcc:0.98357\n",
      "[165]\tvalidation_0-logloss:0.07128\tvalidation_0-mcc:0.98356\n",
      "[166]\tvalidation_0-logloss:0.07087\tvalidation_0-mcc:0.98358\n",
      "[167]\tvalidation_0-logloss:0.07028\tvalidation_0-mcc:0.98361\n",
      "[168]\tvalidation_0-logloss:0.06962\tvalidation_0-mcc:0.98364\n",
      "[169]\tvalidation_0-logloss:0.06911\tvalidation_0-mcc:0.98364\n",
      "[170]\tvalidation_0-logloss:0.06871\tvalidation_0-mcc:0.98364\n",
      "[171]\tvalidation_0-logloss:0.06815\tvalidation_0-mcc:0.98364\n",
      "[172]\tvalidation_0-logloss:0.06757\tvalidation_0-mcc:0.98367\n",
      "[173]\tvalidation_0-logloss:0.06700\tvalidation_0-mcc:0.98366\n",
      "[174]\tvalidation_0-logloss:0.06648\tvalidation_0-mcc:0.98368\n",
      "[175]\tvalidation_0-logloss:0.06608\tvalidation_0-mcc:0.98367\n",
      "[176]\tvalidation_0-logloss:0.06558\tvalidation_0-mcc:0.98369\n",
      "[177]\tvalidation_0-logloss:0.06512\tvalidation_0-mcc:0.98367\n",
      "[178]\tvalidation_0-logloss:0.06484\tvalidation_0-mcc:0.98367\n",
      "[179]\tvalidation_0-logloss:0.06437\tvalidation_0-mcc:0.98369\n",
      "[180]\tvalidation_0-logloss:0.06390\tvalidation_0-mcc:0.98366\n",
      "[181]\tvalidation_0-logloss:0.06343\tvalidation_0-mcc:0.98367\n",
      "[182]\tvalidation_0-logloss:0.06305\tvalidation_0-mcc:0.98367\n",
      "[183]\tvalidation_0-logloss:0.06263\tvalidation_0-mcc:0.98369\n",
      "[184]\tvalidation_0-logloss:0.06223\tvalidation_0-mcc:0.98369\n",
      "[185]\tvalidation_0-logloss:0.06192\tvalidation_0-mcc:0.98369\n",
      "[186]\tvalidation_0-logloss:0.06157\tvalidation_0-mcc:0.98369\n",
      "[187]\tvalidation_0-logloss:0.06129\tvalidation_0-mcc:0.98368\n",
      "[188]\tvalidation_0-logloss:0.06097\tvalidation_0-mcc:0.98368\n",
      "[189]\tvalidation_0-logloss:0.06057\tvalidation_0-mcc:0.98368\n",
      "[190]\tvalidation_0-logloss:0.06023\tvalidation_0-mcc:0.98369\n",
      "[191]\tvalidation_0-logloss:0.05993\tvalidation_0-mcc:0.98369\n",
      "[192]\tvalidation_0-logloss:0.05957\tvalidation_0-mcc:0.98369\n",
      "[193]\tvalidation_0-logloss:0.05927\tvalidation_0-mcc:0.98370\n",
      "[194]\tvalidation_0-logloss:0.05896\tvalidation_0-mcc:0.98371\n",
      "[195]\tvalidation_0-logloss:0.05859\tvalidation_0-mcc:0.98371\n",
      "[196]\tvalidation_0-logloss:0.05822\tvalidation_0-mcc:0.98373\n",
      "[197]\tvalidation_0-logloss:0.05781\tvalidation_0-mcc:0.98374\n",
      "[198]\tvalidation_0-logloss:0.05753\tvalidation_0-mcc:0.98374\n",
      "[199]\tvalidation_0-logloss:0.05723\tvalidation_0-mcc:0.98374\n",
      "[200]\tvalidation_0-logloss:0.05693\tvalidation_0-mcc:0.98375\n",
      "[201]\tvalidation_0-logloss:0.05660\tvalidation_0-mcc:0.98376\n",
      "[202]\tvalidation_0-logloss:0.05633\tvalidation_0-mcc:0.98377\n",
      "[203]\tvalidation_0-logloss:0.05594\tvalidation_0-mcc:0.98379\n",
      "[204]\tvalidation_0-logloss:0.05569\tvalidation_0-mcc:0.98379\n",
      "[205]\tvalidation_0-logloss:0.05533\tvalidation_0-mcc:0.98381\n",
      "[206]\tvalidation_0-logloss:0.05497\tvalidation_0-mcc:0.98383\n",
      "[207]\tvalidation_0-logloss:0.05464\tvalidation_0-mcc:0.98383\n",
      "[208]\tvalidation_0-logloss:0.05429\tvalidation_0-mcc:0.98384\n",
      "[209]\tvalidation_0-logloss:0.05398\tvalidation_0-mcc:0.98384\n",
      "[210]\tvalidation_0-logloss:0.05374\tvalidation_0-mcc:0.98384\n",
      "[211]\tvalidation_0-logloss:0.05354\tvalidation_0-mcc:0.98383\n",
      "[212]\tvalidation_0-logloss:0.05326\tvalidation_0-mcc:0.98382\n",
      "[213]\tvalidation_0-logloss:0.05298\tvalidation_0-mcc:0.98384\n",
      "[214]\tvalidation_0-logloss:0.05266\tvalidation_0-mcc:0.98384\n",
      "[215]\tvalidation_0-logloss:0.05246\tvalidation_0-mcc:0.98383\n",
      "[216]\tvalidation_0-logloss:0.05236\tvalidation_0-mcc:0.98383\n",
      "[217]\tvalidation_0-logloss:0.05204\tvalidation_0-mcc:0.98384\n",
      "[218]\tvalidation_0-logloss:0.05182\tvalidation_0-mcc:0.98384\n",
      "[219]\tvalidation_0-logloss:0.05165\tvalidation_0-mcc:0.98384\n",
      "[220]\tvalidation_0-logloss:0.05145\tvalidation_0-mcc:0.98387\n",
      "[221]\tvalidation_0-logloss:0.05121\tvalidation_0-mcc:0.98389\n",
      "[222]\tvalidation_0-logloss:0.05098\tvalidation_0-mcc:0.98388\n",
      "[223]\tvalidation_0-logloss:0.05084\tvalidation_0-mcc:0.98389\n",
      "[224]\tvalidation_0-logloss:0.05061\tvalidation_0-mcc:0.98388\n",
      "[225]\tvalidation_0-logloss:0.05042\tvalidation_0-mcc:0.98387\n",
      "[226]\tvalidation_0-logloss:0.05020\tvalidation_0-mcc:0.98388\n",
      "[227]\tvalidation_0-logloss:0.04996\tvalidation_0-mcc:0.98387\n",
      "[228]\tvalidation_0-logloss:0.04973\tvalidation_0-mcc:0.98390\n",
      "[229]\tvalidation_0-logloss:0.04954\tvalidation_0-mcc:0.98390\n",
      "[230]\tvalidation_0-logloss:0.04932\tvalidation_0-mcc:0.98391\n",
      "[231]\tvalidation_0-logloss:0.04913\tvalidation_0-mcc:0.98391\n",
      "[232]\tvalidation_0-logloss:0.04892\tvalidation_0-mcc:0.98392\n",
      "[233]\tvalidation_0-logloss:0.04872\tvalidation_0-mcc:0.98393\n",
      "[234]\tvalidation_0-logloss:0.04852\tvalidation_0-mcc:0.98392\n",
      "[235]\tvalidation_0-logloss:0.04832\tvalidation_0-mcc:0.98395\n",
      "[236]\tvalidation_0-logloss:0.04813\tvalidation_0-mcc:0.98396\n",
      "[237]\tvalidation_0-logloss:0.04799\tvalidation_0-mcc:0.98396\n",
      "[238]\tvalidation_0-logloss:0.04786\tvalidation_0-mcc:0.98395\n",
      "[239]\tvalidation_0-logloss:0.04767\tvalidation_0-mcc:0.98397\n",
      "[240]\tvalidation_0-logloss:0.04753\tvalidation_0-mcc:0.98396\n",
      "[241]\tvalidation_0-logloss:0.04738\tvalidation_0-mcc:0.98397\n",
      "[242]\tvalidation_0-logloss:0.04728\tvalidation_0-mcc:0.98397\n",
      "[243]\tvalidation_0-logloss:0.04713\tvalidation_0-mcc:0.98397\n",
      "[244]\tvalidation_0-logloss:0.04699\tvalidation_0-mcc:0.98397\n",
      "[245]\tvalidation_0-logloss:0.04683\tvalidation_0-mcc:0.98397\n",
      "[246]\tvalidation_0-logloss:0.04677\tvalidation_0-mcc:0.98397\n",
      "[247]\tvalidation_0-logloss:0.04659\tvalidation_0-mcc:0.98397\n",
      "[248]\tvalidation_0-logloss:0.04643\tvalidation_0-mcc:0.98398\n",
      "[249]\tvalidation_0-logloss:0.04627\tvalidation_0-mcc:0.98396\n",
      "[250]\tvalidation_0-logloss:0.04618\tvalidation_0-mcc:0.98397\n",
      "[251]\tvalidation_0-logloss:0.04606\tvalidation_0-mcc:0.98396\n",
      "[252]\tvalidation_0-logloss:0.04596\tvalidation_0-mcc:0.98397\n",
      "[253]\tvalidation_0-logloss:0.04588\tvalidation_0-mcc:0.98397\n",
      "[254]\tvalidation_0-logloss:0.04580\tvalidation_0-mcc:0.98397\n",
      "[255]\tvalidation_0-logloss:0.04568\tvalidation_0-mcc:0.98397\n",
      "[256]\tvalidation_0-logloss:0.04558\tvalidation_0-mcc:0.98397\n",
      "[257]\tvalidation_0-logloss:0.04541\tvalidation_0-mcc:0.98396\n",
      "[258]\tvalidation_0-logloss:0.04533\tvalidation_0-mcc:0.98396\n",
      "[259]\tvalidation_0-logloss:0.04520\tvalidation_0-mcc:0.98396\n",
      "[260]\tvalidation_0-logloss:0.04509\tvalidation_0-mcc:0.98396\n",
      "[261]\tvalidation_0-logloss:0.04499\tvalidation_0-mcc:0.98396\n",
      "[262]\tvalidation_0-logloss:0.04487\tvalidation_0-mcc:0.98397\n",
      "[263]\tvalidation_0-logloss:0.04476\tvalidation_0-mcc:0.98397\n",
      "[264]\tvalidation_0-logloss:0.04463\tvalidation_0-mcc:0.98398\n",
      "[265]\tvalidation_0-logloss:0.04450\tvalidation_0-mcc:0.98397\n",
      "[266]\tvalidation_0-logloss:0.04440\tvalidation_0-mcc:0.98397\n",
      "[267]\tvalidation_0-logloss:0.04427\tvalidation_0-mcc:0.98399\n",
      "[268]\tvalidation_0-logloss:0.04418\tvalidation_0-mcc:0.98399\n",
      "[269]\tvalidation_0-logloss:0.04408\tvalidation_0-mcc:0.98399\n",
      "[270]\tvalidation_0-logloss:0.04398\tvalidation_0-mcc:0.98399\n",
      "[271]\tvalidation_0-logloss:0.04388\tvalidation_0-mcc:0.98398\n",
      "[272]\tvalidation_0-logloss:0.04377\tvalidation_0-mcc:0.98399\n",
      "[273]\tvalidation_0-logloss:0.04364\tvalidation_0-mcc:0.98399\n",
      "[274]\tvalidation_0-logloss:0.04358\tvalidation_0-mcc:0.98400\n",
      "[275]\tvalidation_0-logloss:0.04346\tvalidation_0-mcc:0.98400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[276]\tvalidation_0-logloss:0.04333\tvalidation_0-mcc:0.98402\n",
      "[277]\tvalidation_0-logloss:0.04326\tvalidation_0-mcc:0.98401\n",
      "[278]\tvalidation_0-logloss:0.04317\tvalidation_0-mcc:0.98402\n",
      "[279]\tvalidation_0-logloss:0.04305\tvalidation_0-mcc:0.98402\n",
      "[280]\tvalidation_0-logloss:0.04300\tvalidation_0-mcc:0.98402\n",
      "[281]\tvalidation_0-logloss:0.04292\tvalidation_0-mcc:0.98402\n",
      "[282]\tvalidation_0-logloss:0.04285\tvalidation_0-mcc:0.98402\n",
      "[283]\tvalidation_0-logloss:0.04274\tvalidation_0-mcc:0.98402\n",
      "[284]\tvalidation_0-logloss:0.04264\tvalidation_0-mcc:0.98403\n",
      "[285]\tvalidation_0-logloss:0.04260\tvalidation_0-mcc:0.98403\n",
      "[286]\tvalidation_0-logloss:0.04253\tvalidation_0-mcc:0.98402\n",
      "[287]\tvalidation_0-logloss:0.04247\tvalidation_0-mcc:0.98403\n",
      "[288]\tvalidation_0-logloss:0.04239\tvalidation_0-mcc:0.98403\n",
      "[289]\tvalidation_0-logloss:0.04232\tvalidation_0-mcc:0.98404\n",
      "[290]\tvalidation_0-logloss:0.04227\tvalidation_0-mcc:0.98402\n",
      "[291]\tvalidation_0-logloss:0.04219\tvalidation_0-mcc:0.98404\n",
      "[292]\tvalidation_0-logloss:0.04210\tvalidation_0-mcc:0.98404\n",
      "[293]\tvalidation_0-logloss:0.04203\tvalidation_0-mcc:0.98404\n",
      "[294]\tvalidation_0-logloss:0.04196\tvalidation_0-mcc:0.98403\n",
      "[295]\tvalidation_0-logloss:0.04189\tvalidation_0-mcc:0.98404\n",
      "[296]\tvalidation_0-logloss:0.04185\tvalidation_0-mcc:0.98404\n",
      "[297]\tvalidation_0-logloss:0.04182\tvalidation_0-mcc:0.98405\n",
      "[298]\tvalidation_0-logloss:0.04175\tvalidation_0-mcc:0.98405\n",
      "[299]\tvalidation_0-logloss:0.04167\tvalidation_0-mcc:0.98405\n",
      "[300]\tvalidation_0-logloss:0.04160\tvalidation_0-mcc:0.98406\n",
      "[301]\tvalidation_0-logloss:0.04153\tvalidation_0-mcc:0.98406\n",
      "[302]\tvalidation_0-logloss:0.04147\tvalidation_0-mcc:0.98406\n",
      "[303]\tvalidation_0-logloss:0.04140\tvalidation_0-mcc:0.98407\n",
      "[304]\tvalidation_0-logloss:0.04135\tvalidation_0-mcc:0.98408\n",
      "[305]\tvalidation_0-logloss:0.04125\tvalidation_0-mcc:0.98408\n",
      "[306]\tvalidation_0-logloss:0.04119\tvalidation_0-mcc:0.98408\n",
      "[307]\tvalidation_0-logloss:0.04113\tvalidation_0-mcc:0.98408\n",
      "[308]\tvalidation_0-logloss:0.04107\tvalidation_0-mcc:0.98407\n",
      "[309]\tvalidation_0-logloss:0.04100\tvalidation_0-mcc:0.98408\n",
      "[310]\tvalidation_0-logloss:0.04095\tvalidation_0-mcc:0.98408\n",
      "[311]\tvalidation_0-logloss:0.04088\tvalidation_0-mcc:0.98408\n",
      "[312]\tvalidation_0-logloss:0.04082\tvalidation_0-mcc:0.98407\n",
      "[313]\tvalidation_0-logloss:0.04074\tvalidation_0-mcc:0.98409\n",
      "[314]\tvalidation_0-logloss:0.04067\tvalidation_0-mcc:0.98409\n",
      "[315]\tvalidation_0-logloss:0.04062\tvalidation_0-mcc:0.98409\n",
      "[316]\tvalidation_0-logloss:0.04055\tvalidation_0-mcc:0.98409\n",
      "[317]\tvalidation_0-logloss:0.04049\tvalidation_0-mcc:0.98409\n",
      "[318]\tvalidation_0-logloss:0.04042\tvalidation_0-mcc:0.98409\n",
      "[319]\tvalidation_0-logloss:0.04039\tvalidation_0-mcc:0.98409\n",
      "[320]\tvalidation_0-logloss:0.04033\tvalidation_0-mcc:0.98410\n",
      "[321]\tvalidation_0-logloss:0.04029\tvalidation_0-mcc:0.98410\n",
      "[322]\tvalidation_0-logloss:0.04023\tvalidation_0-mcc:0.98410\n",
      "[323]\tvalidation_0-logloss:0.04020\tvalidation_0-mcc:0.98410\n",
      "[324]\tvalidation_0-logloss:0.04016\tvalidation_0-mcc:0.98411\n",
      "[325]\tvalidation_0-logloss:0.04010\tvalidation_0-mcc:0.98411\n",
      "[326]\tvalidation_0-logloss:0.04004\tvalidation_0-mcc:0.98410\n",
      "[327]\tvalidation_0-logloss:0.03999\tvalidation_0-mcc:0.98411\n",
      "[328]\tvalidation_0-logloss:0.03996\tvalidation_0-mcc:0.98411\n",
      "[329]\tvalidation_0-logloss:0.03991\tvalidation_0-mcc:0.98412\n",
      "[330]\tvalidation_0-logloss:0.03989\tvalidation_0-mcc:0.98412\n",
      "[331]\tvalidation_0-logloss:0.03985\tvalidation_0-mcc:0.98412\n",
      "[332]\tvalidation_0-logloss:0.03982\tvalidation_0-mcc:0.98412\n",
      "[333]\tvalidation_0-logloss:0.03978\tvalidation_0-mcc:0.98412\n",
      "[334]\tvalidation_0-logloss:0.03976\tvalidation_0-mcc:0.98411\n",
      "[335]\tvalidation_0-logloss:0.03971\tvalidation_0-mcc:0.98409\n",
      "[336]\tvalidation_0-logloss:0.03966\tvalidation_0-mcc:0.98411\n",
      "[337]\tvalidation_0-logloss:0.03963\tvalidation_0-mcc:0.98411\n",
      "[338]\tvalidation_0-logloss:0.03960\tvalidation_0-mcc:0.98411\n",
      "[339]\tvalidation_0-logloss:0.03958\tvalidation_0-mcc:0.98411\n",
      "[340]\tvalidation_0-logloss:0.03954\tvalidation_0-mcc:0.98412\n",
      "[341]\tvalidation_0-logloss:0.03949\tvalidation_0-mcc:0.98412\n",
      "[342]\tvalidation_0-logloss:0.03946\tvalidation_0-mcc:0.98412\n",
      "[343]\tvalidation_0-logloss:0.03942\tvalidation_0-mcc:0.98411\n",
      "[344]\tvalidation_0-logloss:0.03939\tvalidation_0-mcc:0.98412\n",
      "[345]\tvalidation_0-logloss:0.03936\tvalidation_0-mcc:0.98411\n",
      "[346]\tvalidation_0-logloss:0.03931\tvalidation_0-mcc:0.98412\n",
      "[347]\tvalidation_0-logloss:0.03928\tvalidation_0-mcc:0.98412\n",
      "[348]\tvalidation_0-logloss:0.03926\tvalidation_0-mcc:0.98413\n",
      "[349]\tvalidation_0-logloss:0.03922\tvalidation_0-mcc:0.98413\n",
      "[350]\tvalidation_0-logloss:0.03918\tvalidation_0-mcc:0.98414\n",
      "[351]\tvalidation_0-logloss:0.03915\tvalidation_0-mcc:0.98413\n",
      "[352]\tvalidation_0-logloss:0.03912\tvalidation_0-mcc:0.98413\n",
      "[353]\tvalidation_0-logloss:0.03910\tvalidation_0-mcc:0.98414\n",
      "[354]\tvalidation_0-logloss:0.03908\tvalidation_0-mcc:0.98415\n",
      "[355]\tvalidation_0-logloss:0.03906\tvalidation_0-mcc:0.98414\n",
      "[356]\tvalidation_0-logloss:0.03901\tvalidation_0-mcc:0.98415\n",
      "[357]\tvalidation_0-logloss:0.03898\tvalidation_0-mcc:0.98415\n",
      "[358]\tvalidation_0-logloss:0.03895\tvalidation_0-mcc:0.98415\n",
      "[359]\tvalidation_0-logloss:0.03892\tvalidation_0-mcc:0.98415\n",
      "[360]\tvalidation_0-logloss:0.03889\tvalidation_0-mcc:0.98415\n",
      "[361]\tvalidation_0-logloss:0.03886\tvalidation_0-mcc:0.98415\n",
      "[362]\tvalidation_0-logloss:0.03883\tvalidation_0-mcc:0.98416\n",
      "[363]\tvalidation_0-logloss:0.03882\tvalidation_0-mcc:0.98417\n",
      "[364]\tvalidation_0-logloss:0.03879\tvalidation_0-mcc:0.98417\n",
      "[365]\tvalidation_0-logloss:0.03876\tvalidation_0-mcc:0.98417\n",
      "[366]\tvalidation_0-logloss:0.03873\tvalidation_0-mcc:0.98416\n",
      "[367]\tvalidation_0-logloss:0.03871\tvalidation_0-mcc:0.98416\n",
      "[368]\tvalidation_0-logloss:0.03868\tvalidation_0-mcc:0.98417\n",
      "[369]\tvalidation_0-logloss:0.03864\tvalidation_0-mcc:0.98417\n",
      "[370]\tvalidation_0-logloss:0.03862\tvalidation_0-mcc:0.98417\n",
      "[371]\tvalidation_0-logloss:0.03860\tvalidation_0-mcc:0.98417\n",
      "[372]\tvalidation_0-logloss:0.03859\tvalidation_0-mcc:0.98417\n",
      "[373]\tvalidation_0-logloss:0.03856\tvalidation_0-mcc:0.98418\n",
      "[374]\tvalidation_0-logloss:0.03853\tvalidation_0-mcc:0.98418\n",
      "[375]\tvalidation_0-logloss:0.03851\tvalidation_0-mcc:0.98418\n",
      "[376]\tvalidation_0-logloss:0.03847\tvalidation_0-mcc:0.98419\n",
      "[377]\tvalidation_0-logloss:0.03845\tvalidation_0-mcc:0.98418\n",
      "[378]\tvalidation_0-logloss:0.03845\tvalidation_0-mcc:0.98418\n",
      "[379]\tvalidation_0-logloss:0.03843\tvalidation_0-mcc:0.98419\n",
      "[380]\tvalidation_0-logloss:0.03840\tvalidation_0-mcc:0.98419\n",
      "[381]\tvalidation_0-logloss:0.03839\tvalidation_0-mcc:0.98419\n"
     ]
    }
   ],
   "source": [
    "xgb_params = {\n",
    "#     'tree_method': 'gpu_hist',\n",
    " 'n_estimators': 1000,\n",
    " 'subsample': 0.8,\n",
    " 'colsample_bytree': 0.4,\n",
    " 'max_depth': 15,\n",
    " 'min_child_weight': 6,\n",
    " 'learning_rate': 0.02\n",
    "}\n",
    "\n",
    "xgb_tuned = XGBClassifier(**xgb_params, random_state=42)\n",
    "\n",
    "cv_summary['xgb'], test_preds['xgb'], oof_preds['xgb'] = cross_validate_score(xgb_tuned, x_data , y_data,  cv, changed_test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jLXSaovwARbB",
   "metadata": {
    "id": "jLXSaovwARbB"
   },
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "FqhGL0TRARNp",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5924302,
     "status": "ok",
     "timestamp": 1723988461608,
     "user": {
      "displayName": "곽명조",
      "userId": "03864110971804242579"
     },
     "user_tz": -540
    },
    "id": "FqhGL0TRARNp",
    "outputId": "89fa0dce-6376-4b7d-e1d3-1c1a6757231a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;30;43m스트리밍 출력 내용이 길어서 마지막 5000줄이 삭제되었습니다.\u001b[0m\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "Early stopping, best iteration is:\n",
      "[6283]\tvalid_0's binary_logloss: 0.038037\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=85, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=85\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6946327643448142, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6946327643448142\n",
      "Fold 1: MCC = 0.98362\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=85, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=85\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6946327643448142, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6946327643448142\n",
      "Mean Validation MCC: 0.9835723\n",
      "Std Validation MCC: 0.0000517\n"
     ]
    }
   ],
   "source": [
    "lgbm_optuna_params = {\n",
    "    'n_estimators': 10000,\n",
    "    'learning_rate': 0.02,\n",
    "    'max_depth': 15,\n",
    "    'min_data_in_leaf': 85,\n",
    "    'subsample': 0.8,\n",
    "}\n",
    "\n",
    "lgbm_tuned = LGBMClassifier(**lgbm_optuna_params, random_state=42, verbose=10)\n",
    "\n",
    "cv_summary['lgbm'], test_preds['lgbm'], oof_preds['lgbm'] = cross_validate_score(lgbm_tuned, x_data , y_data,  cv, changed_test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fDGHEeCBBYQT",
   "metadata": {
    "id": "fDGHEeCBBYQT"
   },
   "source": [
    "# Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s6am029nBYj4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s6am029nBYj4",
    "outputId": "353b49b8-92a9-4397-f97e-34191cb7d665"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;30;43m스트리밍 출력 내용이 길어서 마지막 5000줄이 삭제되었습니다.\u001b[0m\n",
      "2135:\tlearn: 0.0367522\ttest: 0.0392224\tbest: 0.0392224 (2135)\ttotal: 10m 59s\tremaining: 40m 27s\n",
      "2136:\tlearn: 0.0367522\ttest: 0.0392224\tbest: 0.0392224 (2136)\ttotal: 10m 59s\tremaining: 40m 26s\n",
      "2137:\tlearn: 0.0367476\ttest: 0.0392194\tbest: 0.0392194 (2137)\ttotal: 10m 59s\tremaining: 40m 26s\n",
      "2138:\tlearn: 0.0367476\ttest: 0.0392194\tbest: 0.0392194 (2138)\ttotal: 11m\tremaining: 40m 25s\n",
      "2139:\tlearn: 0.0367475\ttest: 0.0392194\tbest: 0.0392194 (2139)\ttotal: 11m\tremaining: 40m 25s\n",
      "2140:\tlearn: 0.0367417\ttest: 0.0392168\tbest: 0.0392168 (2140)\ttotal: 11m\tremaining: 40m 25s\n",
      "2141:\tlearn: 0.0367320\ttest: 0.0392101\tbest: 0.0392101 (2141)\ttotal: 11m\tremaining: 40m 24s\n",
      "2142:\tlearn: 0.0367285\ttest: 0.0392081\tbest: 0.0392081 (2142)\ttotal: 11m 1s\tremaining: 40m 24s\n",
      "2143:\tlearn: 0.0367285\ttest: 0.0392081\tbest: 0.0392081 (2143)\ttotal: 11m 1s\tremaining: 40m 23s\n",
      "2144:\tlearn: 0.0367236\ttest: 0.0392056\tbest: 0.0392056 (2144)\ttotal: 11m 1s\tremaining: 40m 23s\n",
      "2145:\tlearn: 0.0367167\ttest: 0.0392003\tbest: 0.0392003 (2145)\ttotal: 11m 2s\tremaining: 40m 23s\n",
      "2146:\tlearn: 0.0367167\ttest: 0.0392003\tbest: 0.0392003 (2146)\ttotal: 11m 2s\tremaining: 40m 22s\n",
      "2147:\tlearn: 0.0367167\ttest: 0.0392003\tbest: 0.0392003 (2147)\ttotal: 11m 2s\tremaining: 40m 22s\n",
      "2148:\tlearn: 0.0367140\ttest: 0.0391990\tbest: 0.0391990 (2148)\ttotal: 11m 2s\tremaining: 40m 21s\n",
      "2149:\tlearn: 0.0367140\ttest: 0.0391990\tbest: 0.0391990 (2148)\ttotal: 11m 3s\tremaining: 40m 21s\n",
      "2150:\tlearn: 0.0367058\ttest: 0.0391930\tbest: 0.0391930 (2150)\ttotal: 11m 3s\tremaining: 40m 21s\n",
      "2151:\tlearn: 0.0367058\ttest: 0.0391930\tbest: 0.0391930 (2151)\ttotal: 11m 3s\tremaining: 40m 20s\n",
      "2152:\tlearn: 0.0367058\ttest: 0.0391930\tbest: 0.0391930 (2152)\ttotal: 11m 4s\tremaining: 40m 20s\n",
      "2153:\tlearn: 0.0367058\ttest: 0.0391930\tbest: 0.0391930 (2153)\ttotal: 11m 4s\tremaining: 40m 19s\n",
      "2154:\tlearn: 0.0367058\ttest: 0.0391930\tbest: 0.0391930 (2154)\ttotal: 11m 4s\tremaining: 40m 18s\n",
      "2155:\tlearn: 0.0367058\ttest: 0.0391930\tbest: 0.0391930 (2155)\ttotal: 11m 4s\tremaining: 40m 18s\n",
      "2156:\tlearn: 0.0367014\ttest: 0.0391914\tbest: 0.0391914 (2156)\ttotal: 11m 5s\tremaining: 40m 18s\n",
      "2157:\tlearn: 0.0366967\ttest: 0.0391912\tbest: 0.0391912 (2157)\ttotal: 11m 5s\tremaining: 40m 17s\n",
      "2158:\tlearn: 0.0366967\ttest: 0.0391912\tbest: 0.0391912 (2158)\ttotal: 11m 5s\tremaining: 40m 17s\n",
      "2159:\tlearn: 0.0366894\ttest: 0.0391873\tbest: 0.0391873 (2159)\ttotal: 11m 5s\tremaining: 40m 16s\n",
      "2160:\tlearn: 0.0366874\ttest: 0.0391864\tbest: 0.0391864 (2160)\ttotal: 11m 6s\tremaining: 40m 16s\n",
      "2161:\tlearn: 0.0366874\ttest: 0.0391864\tbest: 0.0391864 (2161)\ttotal: 11m 6s\tremaining: 40m 16s\n",
      "2162:\tlearn: 0.0366874\ttest: 0.0391864\tbest: 0.0391864 (2162)\ttotal: 11m 6s\tremaining: 40m 15s\n",
      "2163:\tlearn: 0.0366734\ttest: 0.0391783\tbest: 0.0391783 (2163)\ttotal: 11m 6s\tremaining: 40m 15s\n",
      "2164:\tlearn: 0.0366734\ttest: 0.0391783\tbest: 0.0391783 (2164)\ttotal: 11m 7s\tremaining: 40m 14s\n",
      "2165:\tlearn: 0.0366734\ttest: 0.0391783\tbest: 0.0391783 (2164)\ttotal: 11m 7s\tremaining: 40m 14s\n",
      "2166:\tlearn: 0.0366734\ttest: 0.0391783\tbest: 0.0391783 (2164)\ttotal: 11m 7s\tremaining: 40m 14s\n",
      "2167:\tlearn: 0.0366734\ttest: 0.0391783\tbest: 0.0391783 (2167)\ttotal: 11m 8s\tremaining: 40m 14s\n",
      "2168:\tlearn: 0.0366734\ttest: 0.0391783\tbest: 0.0391783 (2168)\ttotal: 11m 8s\tremaining: 40m 14s\n",
      "2169:\tlearn: 0.0366734\ttest: 0.0391783\tbest: 0.0391783 (2169)\ttotal: 11m 9s\tremaining: 40m 14s\n",
      "2170:\tlearn: 0.0366734\ttest: 0.0391783\tbest: 0.0391783 (2169)\ttotal: 11m 9s\tremaining: 40m 14s\n",
      "2171:\tlearn: 0.0366734\ttest: 0.0391783\tbest: 0.0391783 (2169)\ttotal: 11m 10s\tremaining: 40m 15s\n",
      "2172:\tlearn: 0.0366706\ttest: 0.0391773\tbest: 0.0391773 (2172)\ttotal: 11m 10s\tremaining: 40m 15s\n",
      "2173:\tlearn: 0.0366706\ttest: 0.0391773\tbest: 0.0391773 (2173)\ttotal: 11m 11s\tremaining: 40m 15s\n",
      "2174:\tlearn: 0.0366669\ttest: 0.0391760\tbest: 0.0391760 (2174)\ttotal: 11m 11s\tremaining: 40m 16s\n",
      "2175:\tlearn: 0.0366669\ttest: 0.0391760\tbest: 0.0391760 (2175)\ttotal: 11m 11s\tremaining: 40m 15s\n",
      "2176:\tlearn: 0.0366668\ttest: 0.0391760\tbest: 0.0391760 (2176)\ttotal: 11m 12s\tremaining: 40m 14s\n",
      "2177:\tlearn: 0.0366635\ttest: 0.0391760\tbest: 0.0391760 (2176)\ttotal: 11m 12s\tremaining: 40m 14s\n",
      "2178:\tlearn: 0.0366635\ttest: 0.0391760\tbest: 0.0391760 (2176)\ttotal: 11m 12s\tremaining: 40m 14s\n",
      "2179:\tlearn: 0.0366635\ttest: 0.0391760\tbest: 0.0391760 (2176)\ttotal: 11m 12s\tremaining: 40m 13s\n",
      "2180:\tlearn: 0.0366606\ttest: 0.0391741\tbest: 0.0391741 (2180)\ttotal: 11m 13s\tremaining: 40m 13s\n",
      "2181:\tlearn: 0.0366606\ttest: 0.0391741\tbest: 0.0391741 (2181)\ttotal: 11m 13s\tremaining: 40m 12s\n",
      "2182:\tlearn: 0.0366606\ttest: 0.0391741\tbest: 0.0391741 (2182)\ttotal: 11m 13s\tremaining: 40m 12s\n",
      "2183:\tlearn: 0.0366606\ttest: 0.0391741\tbest: 0.0391741 (2182)\ttotal: 11m 13s\tremaining: 40m 11s\n",
      "2184:\tlearn: 0.0366606\ttest: 0.0391741\tbest: 0.0391741 (2184)\ttotal: 11m 14s\tremaining: 40m 10s\n",
      "2185:\tlearn: 0.0366606\ttest: 0.0391741\tbest: 0.0391741 (2185)\ttotal: 11m 14s\tremaining: 40m 10s\n",
      "2186:\tlearn: 0.0366606\ttest: 0.0391740\tbest: 0.0391740 (2186)\ttotal: 11m 14s\tremaining: 40m 9s\n",
      "2187:\tlearn: 0.0366606\ttest: 0.0391740\tbest: 0.0391740 (2187)\ttotal: 11m 14s\tremaining: 40m 9s\n",
      "2188:\tlearn: 0.0366606\ttest: 0.0391740\tbest: 0.0391740 (2188)\ttotal: 11m 15s\tremaining: 40m 8s\n",
      "2189:\tlearn: 0.0366606\ttest: 0.0391740\tbest: 0.0391740 (2189)\ttotal: 11m 15s\tremaining: 40m 8s\n",
      "2190:\tlearn: 0.0366564\ttest: 0.0391727\tbest: 0.0391727 (2190)\ttotal: 11m 15s\tremaining: 40m 8s\n",
      "2191:\tlearn: 0.0366564\ttest: 0.0391727\tbest: 0.0391727 (2190)\ttotal: 11m 15s\tremaining: 40m 7s\n",
      "2192:\tlearn: 0.0366564\ttest: 0.0391727\tbest: 0.0391727 (2192)\ttotal: 11m 16s\tremaining: 40m 7s\n",
      "2193:\tlearn: 0.0366564\ttest: 0.0391727\tbest: 0.0391727 (2193)\ttotal: 11m 16s\tremaining: 40m 6s\n",
      "2194:\tlearn: 0.0366564\ttest: 0.0391727\tbest: 0.0391727 (2194)\ttotal: 11m 16s\tremaining: 40m 6s\n",
      "2195:\tlearn: 0.0366477\ttest: 0.0391688\tbest: 0.0391688 (2195)\ttotal: 11m 16s\tremaining: 40m 5s\n",
      "2196:\tlearn: 0.0366452\ttest: 0.0391683\tbest: 0.0391683 (2196)\ttotal: 11m 17s\tremaining: 40m 5s\n",
      "2197:\tlearn: 0.0366392\ttest: 0.0391657\tbest: 0.0391657 (2197)\ttotal: 11m 17s\tremaining: 40m 5s\n",
      "2198:\tlearn: 0.0366392\ttest: 0.0391657\tbest: 0.0391657 (2198)\ttotal: 11m 17s\tremaining: 40m 4s\n",
      "2199:\tlearn: 0.0366392\ttest: 0.0391657\tbest: 0.0391657 (2198)\ttotal: 11m 18s\tremaining: 40m 3s\n",
      "2200:\tlearn: 0.0366392\ttest: 0.0391657\tbest: 0.0391657 (2198)\ttotal: 11m 18s\tremaining: 40m 3s\n",
      "2201:\tlearn: 0.0366392\ttest: 0.0391657\tbest: 0.0391657 (2198)\ttotal: 11m 18s\tremaining: 40m 2s\n",
      "2202:\tlearn: 0.0366392\ttest: 0.0391657\tbest: 0.0391657 (2198)\ttotal: 11m 18s\tremaining: 40m 2s\n",
      "2203:\tlearn: 0.0366392\ttest: 0.0391657\tbest: 0.0391657 (2198)\ttotal: 11m 18s\tremaining: 40m 1s\n",
      "2204:\tlearn: 0.0366392\ttest: 0.0391657\tbest: 0.0391657 (2198)\ttotal: 11m 19s\tremaining: 40m 1s\n",
      "2205:\tlearn: 0.0366392\ttest: 0.0391657\tbest: 0.0391657 (2198)\ttotal: 11m 19s\tremaining: 40m\n",
      "2206:\tlearn: 0.0366323\ttest: 0.0391627\tbest: 0.0391627 (2206)\ttotal: 11m 19s\tremaining: 40m\n",
      "2207:\tlearn: 0.0366323\ttest: 0.0391627\tbest: 0.0391627 (2207)\ttotal: 11m 20s\tremaining: 39m 59s\n",
      "2208:\tlearn: 0.0366323\ttest: 0.0391627\tbest: 0.0391627 (2208)\ttotal: 11m 20s\tremaining: 39m 59s\n",
      "2209:\tlearn: 0.0366323\ttest: 0.0391627\tbest: 0.0391627 (2209)\ttotal: 11m 20s\tremaining: 39m 58s\n",
      "2210:\tlearn: 0.0366279\ttest: 0.0391622\tbest: 0.0391622 (2210)\ttotal: 11m 20s\tremaining: 39m 58s\n",
      "2211:\tlearn: 0.0366279\ttest: 0.0391622\tbest: 0.0391622 (2210)\ttotal: 11m 21s\tremaining: 39m 57s\n",
      "2212:\tlearn: 0.0366279\ttest: 0.0391622\tbest: 0.0391622 (2212)\ttotal: 11m 21s\tremaining: 39m 57s\n",
      "2213:\tlearn: 0.0366279\ttest: 0.0391622\tbest: 0.0391622 (2213)\ttotal: 11m 21s\tremaining: 39m 56s\n",
      "2214:\tlearn: 0.0366279\ttest: 0.0391622\tbest: 0.0391622 (2214)\ttotal: 11m 21s\tremaining: 39m 56s\n",
      "2215:\tlearn: 0.0366279\ttest: 0.0391622\tbest: 0.0391622 (2215)\ttotal: 11m 22s\tremaining: 39m 57s\n",
      "2216:\tlearn: 0.0366279\ttest: 0.0391622\tbest: 0.0391622 (2216)\ttotal: 11m 22s\tremaining: 39m 57s\n",
      "2217:\tlearn: 0.0366279\ttest: 0.0391622\tbest: 0.0391622 (2217)\ttotal: 11m 23s\tremaining: 39m 57s\n",
      "2218:\tlearn: 0.0366279\ttest: 0.0391622\tbest: 0.0391622 (2218)\ttotal: 11m 23s\tremaining: 39m 57s\n",
      "2219:\tlearn: 0.0366279\ttest: 0.0391622\tbest: 0.0391622 (2219)\ttotal: 11m 24s\tremaining: 39m 57s\n",
      "2220:\tlearn: 0.0366279\ttest: 0.0391622\tbest: 0.0391622 (2220)\ttotal: 11m 24s\tremaining: 39m 57s\n",
      "2221:\tlearn: 0.0366279\ttest: 0.0391622\tbest: 0.0391622 (2221)\ttotal: 11m 24s\tremaining: 39m 57s\n",
      "2222:\tlearn: 0.0366279\ttest: 0.0391622\tbest: 0.0391622 (2221)\ttotal: 11m 25s\tremaining: 39m 57s\n",
      "2223:\tlearn: 0.0366279\ttest: 0.0391622\tbest: 0.0391622 (2223)\ttotal: 11m 25s\tremaining: 39m 56s\n",
      "2224:\tlearn: 0.0366279\ttest: 0.0391622\tbest: 0.0391622 (2224)\ttotal: 11m 25s\tremaining: 39m 56s\n",
      "2225:\tlearn: 0.0366279\ttest: 0.0391622\tbest: 0.0391622 (2225)\ttotal: 11m 26s\tremaining: 39m 55s\n",
      "2226:\tlearn: 0.0366279\ttest: 0.0391622\tbest: 0.0391622 (2226)\ttotal: 11m 26s\tremaining: 39m 55s\n",
      "2227:\tlearn: 0.0366279\ttest: 0.0391622\tbest: 0.0391622 (2227)\ttotal: 11m 26s\tremaining: 39m 54s\n",
      "2228:\tlearn: 0.0366244\ttest: 0.0391624\tbest: 0.0391622 (2227)\ttotal: 11m 26s\tremaining: 39m 54s\n",
      "2229:\tlearn: 0.0366194\ttest: 0.0391601\tbest: 0.0391601 (2229)\ttotal: 11m 27s\tremaining: 39m 54s\n",
      "2230:\tlearn: 0.0366194\ttest: 0.0391601\tbest: 0.0391601 (2229)\ttotal: 11m 27s\tremaining: 39m 53s\n",
      "2231:\tlearn: 0.0366194\ttest: 0.0391601\tbest: 0.0391601 (2229)\ttotal: 11m 27s\tremaining: 39m 53s\n",
      "2232:\tlearn: 0.0366194\ttest: 0.0391601\tbest: 0.0391601 (2229)\ttotal: 11m 27s\tremaining: 39m 52s\n",
      "2233:\tlearn: 0.0366194\ttest: 0.0391601\tbest: 0.0391601 (2233)\ttotal: 11m 28s\tremaining: 39m 52s\n",
      "2234:\tlearn: 0.0366148\ttest: 0.0391597\tbest: 0.0391597 (2234)\ttotal: 11m 28s\tremaining: 39m 51s\n",
      "2235:\tlearn: 0.0366102\ttest: 0.0391590\tbest: 0.0391590 (2235)\ttotal: 11m 28s\tremaining: 39m 51s\n",
      "2236:\tlearn: 0.0366102\ttest: 0.0391590\tbest: 0.0391590 (2236)\ttotal: 11m 28s\tremaining: 39m 50s\n",
      "2237:\tlearn: 0.0366102\ttest: 0.0391590\tbest: 0.0391590 (2236)\ttotal: 11m 29s\tremaining: 39m 50s\n",
      "2238:\tlearn: 0.0366102\ttest: 0.0391590\tbest: 0.0391590 (2236)\ttotal: 11m 29s\tremaining: 39m 49s\n",
      "2239:\tlearn: 0.0366102\ttest: 0.0391590\tbest: 0.0391590 (2239)\ttotal: 11m 29s\tremaining: 39m 49s\n",
      "2240:\tlearn: 0.0366102\ttest: 0.0391590\tbest: 0.0391590 (2239)\ttotal: 11m 29s\tremaining: 39m 48s\n",
      "2241:\tlearn: 0.0366102\ttest: 0.0391590\tbest: 0.0391590 (2241)\ttotal: 11m 30s\tremaining: 39m 48s\n",
      "2242:\tlearn: 0.0366052\ttest: 0.0391583\tbest: 0.0391583 (2242)\ttotal: 11m 30s\tremaining: 39m 47s\n",
      "2243:\tlearn: 0.0366052\ttest: 0.0391583\tbest: 0.0391583 (2242)\ttotal: 11m 30s\tremaining: 39m 47s\n",
      "2244:\tlearn: 0.0366052\ttest: 0.0391583\tbest: 0.0391583 (2242)\ttotal: 11m 30s\tremaining: 39m 46s\n",
      "2245:\tlearn: 0.0366052\ttest: 0.0391583\tbest: 0.0391583 (2245)\ttotal: 11m 31s\tremaining: 39m 46s\n",
      "2246:\tlearn: 0.0366052\ttest: 0.0391583\tbest: 0.0391583 (2245)\ttotal: 11m 31s\tremaining: 39m 45s\n",
      "2247:\tlearn: 0.0366052\ttest: 0.0391583\tbest: 0.0391583 (2245)\ttotal: 11m 31s\tremaining: 39m 45s\n",
      "2248:\tlearn: 0.0366052\ttest: 0.0391583\tbest: 0.0391583 (2248)\ttotal: 11m 31s\tremaining: 39m 44s\n",
      "2249:\tlearn: 0.0366052\ttest: 0.0391583\tbest: 0.0391583 (2249)\ttotal: 11m 32s\tremaining: 39m 43s\n",
      "2250:\tlearn: 0.0366052\ttest: 0.0391583\tbest: 0.0391583 (2250)\ttotal: 11m 32s\tremaining: 39m 43s\n",
      "2251:\tlearn: 0.0366052\ttest: 0.0391583\tbest: 0.0391583 (2251)\ttotal: 11m 32s\tremaining: 39m 42s\n",
      "2252:\tlearn: 0.0366052\ttest: 0.0391583\tbest: 0.0391583 (2251)\ttotal: 11m 32s\tremaining: 39m 42s\n",
      "2253:\tlearn: 0.0365985\ttest: 0.0391545\tbest: 0.0391545 (2253)\ttotal: 11m 33s\tremaining: 39m 42s\n",
      "2254:\tlearn: 0.0365985\ttest: 0.0391545\tbest: 0.0391545 (2254)\ttotal: 11m 33s\tremaining: 39m 41s\n",
      "2255:\tlearn: 0.0365930\ttest: 0.0391526\tbest: 0.0391526 (2255)\ttotal: 11m 33s\tremaining: 39m 41s\n",
      "2256:\tlearn: 0.0365866\ttest: 0.0391514\tbest: 0.0391514 (2256)\ttotal: 11m 34s\tremaining: 39m 41s\n",
      "2257:\tlearn: 0.0365826\ttest: 0.0391516\tbest: 0.0391514 (2256)\ttotal: 11m 34s\tremaining: 39m 40s\n",
      "2258:\tlearn: 0.0365773\ttest: 0.0391499\tbest: 0.0391499 (2258)\ttotal: 11m 34s\tremaining: 39m 40s\n",
      "2259:\tlearn: 0.0365773\ttest: 0.0391499\tbest: 0.0391499 (2259)\ttotal: 11m 34s\tremaining: 39m 39s\n",
      "2260:\tlearn: 0.0365773\ttest: 0.0391499\tbest: 0.0391499 (2259)\ttotal: 11m 35s\tremaining: 39m 39s\n",
      "2261:\tlearn: 0.0365773\ttest: 0.0391499\tbest: 0.0391499 (2259)\ttotal: 11m 35s\tremaining: 39m 38s\n",
      "2262:\tlearn: 0.0365725\ttest: 0.0391473\tbest: 0.0391473 (2262)\ttotal: 11m 35s\tremaining: 39m 39s\n",
      "2263:\tlearn: 0.0365725\ttest: 0.0391473\tbest: 0.0391473 (2263)\ttotal: 11m 36s\tremaining: 39m 39s\n",
      "2264:\tlearn: 0.0365725\ttest: 0.0391473\tbest: 0.0391473 (2264)\ttotal: 11m 36s\tremaining: 39m 39s\n",
      "2265:\tlearn: 0.0365686\ttest: 0.0391452\tbest: 0.0391452 (2265)\ttotal: 11m 37s\tremaining: 39m 40s\n",
      "2266:\tlearn: 0.0365686\ttest: 0.0391452\tbest: 0.0391452 (2266)\ttotal: 11m 37s\tremaining: 39m 40s\n",
      "2267:\tlearn: 0.0365686\ttest: 0.0391452\tbest: 0.0391452 (2267)\ttotal: 11m 38s\tremaining: 39m 40s\n",
      "2268:\tlearn: 0.0365686\ttest: 0.0391452\tbest: 0.0391452 (2268)\ttotal: 11m 38s\tremaining: 39m 40s\n",
      "2269:\tlearn: 0.0365686\ttest: 0.0391452\tbest: 0.0391452 (2269)\ttotal: 11m 39s\tremaining: 39m 40s\n",
      "2270:\tlearn: 0.0365686\ttest: 0.0391452\tbest: 0.0391452 (2270)\ttotal: 11m 39s\tremaining: 39m 40s\n",
      "2271:\tlearn: 0.0365686\ttest: 0.0391452\tbest: 0.0391452 (2271)\ttotal: 11m 39s\tremaining: 39m 40s\n",
      "2272:\tlearn: 0.0365686\ttest: 0.0391452\tbest: 0.0391452 (2272)\ttotal: 11m 40s\tremaining: 39m 39s\n",
      "2273:\tlearn: 0.0365686\ttest: 0.0391452\tbest: 0.0391452 (2272)\ttotal: 11m 40s\tremaining: 39m 39s\n",
      "2274:\tlearn: 0.0365686\ttest: 0.0391452\tbest: 0.0391452 (2274)\ttotal: 11m 40s\tremaining: 39m 38s\n",
      "2275:\tlearn: 0.0365686\ttest: 0.0391452\tbest: 0.0391452 (2275)\ttotal: 11m 40s\tremaining: 39m 38s\n",
      "2276:\tlearn: 0.0365686\ttest: 0.0391452\tbest: 0.0391452 (2275)\ttotal: 11m 41s\tremaining: 39m 37s\n",
      "2277:\tlearn: 0.0365686\ttest: 0.0391452\tbest: 0.0391452 (2275)\ttotal: 11m 41s\tremaining: 39m 37s\n",
      "2278:\tlearn: 0.0365686\ttest: 0.0391452\tbest: 0.0391452 (2278)\ttotal: 11m 41s\tremaining: 39m 36s\n",
      "2279:\tlearn: 0.0365686\ttest: 0.0391452\tbest: 0.0391452 (2278)\ttotal: 11m 41s\tremaining: 39m 36s\n",
      "2280:\tlearn: 0.0365615\ttest: 0.0391421\tbest: 0.0391421 (2280)\ttotal: 11m 42s\tremaining: 39m 35s\n",
      "2281:\tlearn: 0.0365615\ttest: 0.0391421\tbest: 0.0391421 (2280)\ttotal: 11m 42s\tremaining: 39m 35s\n",
      "2282:\tlearn: 0.0365583\ttest: 0.0391408\tbest: 0.0391408 (2282)\ttotal: 11m 42s\tremaining: 39m 35s\n",
      "2283:\tlearn: 0.0365583\ttest: 0.0391408\tbest: 0.0391408 (2283)\ttotal: 11m 42s\tremaining: 39m 34s\n",
      "2284:\tlearn: 0.0365546\ttest: 0.0391389\tbest: 0.0391389 (2284)\ttotal: 11m 43s\tremaining: 39m 34s\n",
      "2285:\tlearn: 0.0365546\ttest: 0.0391389\tbest: 0.0391389 (2285)\ttotal: 11m 43s\tremaining: 39m 33s\n",
      "2286:\tlearn: 0.0365546\ttest: 0.0391389\tbest: 0.0391389 (2286)\ttotal: 11m 43s\tremaining: 39m 33s\n",
      "2287:\tlearn: 0.0365546\ttest: 0.0391389\tbest: 0.0391389 (2287)\ttotal: 11m 43s\tremaining: 39m 32s\n",
      "2288:\tlearn: 0.0365485\ttest: 0.0391364\tbest: 0.0391364 (2288)\ttotal: 11m 44s\tremaining: 39m 32s\n",
      "2289:\tlearn: 0.0365485\ttest: 0.0391364\tbest: 0.0391364 (2288)\ttotal: 11m 44s\tremaining: 39m 31s\n",
      "2290:\tlearn: 0.0365485\ttest: 0.0391364\tbest: 0.0391364 (2290)\ttotal: 11m 44s\tremaining: 39m 31s\n",
      "2291:\tlearn: 0.0365485\ttest: 0.0391364\tbest: 0.0391364 (2291)\ttotal: 11m 44s\tremaining: 39m 30s\n",
      "2292:\tlearn: 0.0365485\ttest: 0.0391364\tbest: 0.0391364 (2292)\ttotal: 11m 45s\tremaining: 39m 30s\n",
      "2293:\tlearn: 0.0365485\ttest: 0.0391364\tbest: 0.0391364 (2293)\ttotal: 11m 45s\tremaining: 39m 29s\n",
      "2294:\tlearn: 0.0365485\ttest: 0.0391364\tbest: 0.0391364 (2294)\ttotal: 11m 45s\tremaining: 39m 29s\n",
      "2295:\tlearn: 0.0365485\ttest: 0.0391364\tbest: 0.0391364 (2295)\ttotal: 11m 45s\tremaining: 39m 28s\n",
      "2296:\tlearn: 0.0365485\ttest: 0.0391364\tbest: 0.0391364 (2296)\ttotal: 11m 46s\tremaining: 39m 28s\n",
      "2297:\tlearn: 0.0365441\ttest: 0.0391350\tbest: 0.0391350 (2297)\ttotal: 11m 46s\tremaining: 39m 28s\n",
      "2298:\tlearn: 0.0365441\ttest: 0.0391350\tbest: 0.0391350 (2297)\ttotal: 11m 46s\tremaining: 39m 27s\n",
      "2299:\tlearn: 0.0365442\ttest: 0.0391350\tbest: 0.0391350 (2299)\ttotal: 11m 47s\tremaining: 39m 27s\n",
      "2300:\tlearn: 0.0365441\ttest: 0.0391350\tbest: 0.0391350 (2300)\ttotal: 11m 47s\tremaining: 39m 26s\n",
      "2301:\tlearn: 0.0365380\ttest: 0.0391346\tbest: 0.0391346 (2301)\ttotal: 11m 47s\tremaining: 39m 26s\n",
      "2302:\tlearn: 0.0365351\ttest: 0.0391337\tbest: 0.0391337 (2302)\ttotal: 11m 47s\tremaining: 39m 26s\n",
      "2303:\tlearn: 0.0365301\ttest: 0.0391307\tbest: 0.0391307 (2303)\ttotal: 11m 48s\tremaining: 39m 25s\n",
      "2304:\tlearn: 0.0365268\ttest: 0.0391298\tbest: 0.0391298 (2304)\ttotal: 11m 48s\tremaining: 39m 25s\n",
      "2305:\tlearn: 0.0365268\ttest: 0.0391298\tbest: 0.0391298 (2304)\ttotal: 11m 48s\tremaining: 39m 25s\n",
      "2306:\tlearn: 0.0365268\ttest: 0.0391298\tbest: 0.0391298 (2306)\ttotal: 11m 49s\tremaining: 39m 24s\n",
      "2307:\tlearn: 0.0365268\ttest: 0.0391298\tbest: 0.0391298 (2306)\ttotal: 11m 49s\tremaining: 39m 24s\n",
      "2308:\tlearn: 0.0365268\ttest: 0.0391298\tbest: 0.0391298 (2308)\ttotal: 11m 49s\tremaining: 39m 24s\n",
      "2309:\tlearn: 0.0365189\ttest: 0.0391259\tbest: 0.0391259 (2309)\ttotal: 11m 50s\tremaining: 39m 24s\n",
      "2310:\tlearn: 0.0365189\ttest: 0.0391259\tbest: 0.0391259 (2310)\ttotal: 11m 50s\tremaining: 39m 24s\n",
      "2311:\tlearn: 0.0365152\ttest: 0.0391253\tbest: 0.0391253 (2311)\ttotal: 11m 51s\tremaining: 39m 25s\n",
      "2312:\tlearn: 0.0365116\ttest: 0.0391251\tbest: 0.0391251 (2312)\ttotal: 11m 51s\tremaining: 39m 25s\n",
      "2313:\tlearn: 0.0365115\ttest: 0.0391251\tbest: 0.0391251 (2313)\ttotal: 11m 52s\tremaining: 39m 25s\n",
      "2314:\tlearn: 0.0365071\ttest: 0.0391236\tbest: 0.0391236 (2314)\ttotal: 11m 52s\tremaining: 39m 26s\n",
      "2315:\tlearn: 0.0365013\ttest: 0.0391208\tbest: 0.0391208 (2315)\ttotal: 11m 53s\tremaining: 39m 27s\n",
      "2316:\tlearn: 0.0365013\ttest: 0.0391208\tbest: 0.0391208 (2316)\ttotal: 11m 53s\tremaining: 39m 26s\n",
      "2317:\tlearn: 0.0365013\ttest: 0.0391208\tbest: 0.0391208 (2316)\ttotal: 11m 53s\tremaining: 39m 26s\n",
      "2318:\tlearn: 0.0365013\ttest: 0.0391208\tbest: 0.0391208 (2316)\ttotal: 11m 54s\tremaining: 39m 25s\n",
      "2319:\tlearn: 0.0365013\ttest: 0.0391208\tbest: 0.0391208 (2316)\ttotal: 11m 54s\tremaining: 39m 24s\n",
      "2320:\tlearn: 0.0365013\ttest: 0.0391208\tbest: 0.0391208 (2320)\ttotal: 11m 54s\tremaining: 39m 24s\n",
      "2321:\tlearn: 0.0365013\ttest: 0.0391208\tbest: 0.0391208 (2321)\ttotal: 11m 54s\tremaining: 39m 23s\n",
      "2322:\tlearn: 0.0364976\ttest: 0.0391185\tbest: 0.0391185 (2322)\ttotal: 11m 55s\tremaining: 39m 23s\n",
      "2323:\tlearn: 0.0364975\ttest: 0.0391185\tbest: 0.0391185 (2323)\ttotal: 11m 55s\tremaining: 39m 22s\n",
      "2324:\tlearn: 0.0364975\ttest: 0.0391185\tbest: 0.0391185 (2324)\ttotal: 11m 55s\tremaining: 39m 22s\n",
      "2325:\tlearn: 0.0364975\ttest: 0.0391185\tbest: 0.0391185 (2325)\ttotal: 11m 55s\tremaining: 39m 22s\n",
      "2326:\tlearn: 0.0364946\ttest: 0.0391173\tbest: 0.0391173 (2326)\ttotal: 11m 56s\tremaining: 39m 21s\n",
      "2327:\tlearn: 0.0364946\ttest: 0.0391173\tbest: 0.0391173 (2327)\ttotal: 11m 56s\tremaining: 39m 21s\n",
      "2328:\tlearn: 0.0364946\ttest: 0.0391173\tbest: 0.0391173 (2327)\ttotal: 11m 56s\tremaining: 39m 20s\n",
      "2329:\tlearn: 0.0364885\ttest: 0.0391155\tbest: 0.0391155 (2329)\ttotal: 11m 57s\tremaining: 39m 20s\n",
      "2330:\tlearn: 0.0364849\ttest: 0.0391152\tbest: 0.0391152 (2330)\ttotal: 11m 57s\tremaining: 39m 20s\n",
      "2331:\tlearn: 0.0364849\ttest: 0.0391152\tbest: 0.0391152 (2330)\ttotal: 11m 57s\tremaining: 39m 19s\n",
      "2332:\tlearn: 0.0364849\ttest: 0.0391152\tbest: 0.0391152 (2332)\ttotal: 11m 57s\tremaining: 39m 19s\n",
      "2333:\tlearn: 0.0364849\ttest: 0.0391152\tbest: 0.0391152 (2333)\ttotal: 11m 58s\tremaining: 39m 18s\n",
      "2334:\tlearn: 0.0364849\ttest: 0.0391152\tbest: 0.0391152 (2334)\ttotal: 11m 58s\tremaining: 39m 18s\n",
      "2335:\tlearn: 0.0364849\ttest: 0.0391152\tbest: 0.0391152 (2335)\ttotal: 11m 58s\tremaining: 39m 17s\n",
      "2336:\tlearn: 0.0364804\ttest: 0.0391146\tbest: 0.0391146 (2336)\ttotal: 11m 58s\tremaining: 39m 17s\n",
      "2337:\tlearn: 0.0364717\ttest: 0.0391087\tbest: 0.0391087 (2337)\ttotal: 11m 59s\tremaining: 39m 17s\n",
      "2338:\tlearn: 0.0364674\ttest: 0.0391071\tbest: 0.0391071 (2338)\ttotal: 11m 59s\tremaining: 39m 16s\n",
      "2339:\tlearn: 0.0364647\ttest: 0.0391060\tbest: 0.0391060 (2339)\ttotal: 11m 59s\tremaining: 39m 16s\n",
      "2340:\tlearn: 0.0364647\ttest: 0.0391060\tbest: 0.0391060 (2340)\ttotal: 12m\tremaining: 39m 15s\n",
      "2341:\tlearn: 0.0364646\ttest: 0.0391060\tbest: 0.0391060 (2340)\ttotal: 12m\tremaining: 39m 15s\n",
      "2342:\tlearn: 0.0364646\ttest: 0.0391059\tbest: 0.0391059 (2342)\ttotal: 12m\tremaining: 39m 14s\n",
      "2343:\tlearn: 0.0364646\ttest: 0.0391059\tbest: 0.0391059 (2343)\ttotal: 12m\tremaining: 39m 14s\n",
      "2344:\tlearn: 0.0364608\ttest: 0.0391060\tbest: 0.0391059 (2343)\ttotal: 12m 1s\tremaining: 39m 14s\n",
      "2345:\tlearn: 0.0364608\ttest: 0.0391060\tbest: 0.0391059 (2343)\ttotal: 12m 1s\tremaining: 39m 13s\n",
      "2346:\tlearn: 0.0364608\ttest: 0.0391060\tbest: 0.0391059 (2343)\ttotal: 12m 1s\tremaining: 39m 13s\n",
      "2347:\tlearn: 0.0364608\ttest: 0.0391060\tbest: 0.0391059 (2343)\ttotal: 12m 1s\tremaining: 39m 12s\n",
      "2348:\tlearn: 0.0364524\ttest: 0.0391024\tbest: 0.0391024 (2348)\ttotal: 12m 2s\tremaining: 39m 12s\n",
      "2349:\tlearn: 0.0364466\ttest: 0.0390997\tbest: 0.0390997 (2349)\ttotal: 12m 2s\tremaining: 39m 12s\n",
      "2350:\tlearn: 0.0364466\ttest: 0.0390997\tbest: 0.0390997 (2350)\ttotal: 12m 2s\tremaining: 39m 11s\n",
      "2351:\tlearn: 0.0364466\ttest: 0.0390997\tbest: 0.0390997 (2350)\ttotal: 12m 3s\tremaining: 39m 11s\n",
      "2352:\tlearn: 0.0364466\ttest: 0.0390997\tbest: 0.0390997 (2352)\ttotal: 12m 3s\tremaining: 39m 10s\n",
      "2353:\tlearn: 0.0364466\ttest: 0.0390997\tbest: 0.0390997 (2353)\ttotal: 12m 3s\tremaining: 39m 10s\n",
      "2354:\tlearn: 0.0364466\ttest: 0.0390997\tbest: 0.0390997 (2354)\ttotal: 12m 3s\tremaining: 39m 10s\n",
      "2355:\tlearn: 0.0364466\ttest: 0.0390997\tbest: 0.0390997 (2355)\ttotal: 12m 4s\tremaining: 39m 10s\n",
      "2356:\tlearn: 0.0364430\ttest: 0.0390981\tbest: 0.0390981 (2356)\ttotal: 12m 4s\tremaining: 39m 10s\n",
      "2357:\tlearn: 0.0364430\ttest: 0.0390981\tbest: 0.0390981 (2357)\ttotal: 12m 5s\tremaining: 39m 10s\n",
      "2358:\tlearn: 0.0364346\ttest: 0.0390945\tbest: 0.0390945 (2358)\ttotal: 12m 5s\tremaining: 39m 11s\n",
      "2359:\tlearn: 0.0364311\ttest: 0.0390921\tbest: 0.0390921 (2359)\ttotal: 12m 6s\tremaining: 39m 11s\n",
      "2360:\tlearn: 0.0364311\ttest: 0.0390921\tbest: 0.0390921 (2360)\ttotal: 12m 6s\tremaining: 39m 11s\n",
      "2361:\tlearn: 0.0364311\ttest: 0.0390921\tbest: 0.0390921 (2361)\ttotal: 12m 7s\tremaining: 39m 12s\n",
      "2362:\tlearn: 0.0364311\ttest: 0.0390921\tbest: 0.0390921 (2362)\ttotal: 12m 7s\tremaining: 39m 11s\n",
      "2363:\tlearn: 0.0364311\ttest: 0.0390921\tbest: 0.0390921 (2362)\ttotal: 12m 7s\tremaining: 39m 11s\n",
      "2364:\tlearn: 0.0364311\ttest: 0.0390921\tbest: 0.0390921 (2364)\ttotal: 12m 8s\tremaining: 39m 10s\n",
      "2365:\tlearn: 0.0364311\ttest: 0.0390921\tbest: 0.0390921 (2365)\ttotal: 12m 8s\tremaining: 39m 10s\n",
      "2366:\tlearn: 0.0364311\ttest: 0.0390921\tbest: 0.0390921 (2366)\ttotal: 12m 8s\tremaining: 39m 9s\n",
      "2367:\tlearn: 0.0364311\ttest: 0.0390921\tbest: 0.0390921 (2366)\ttotal: 12m 8s\tremaining: 39m 9s\n",
      "2368:\tlearn: 0.0364311\ttest: 0.0390921\tbest: 0.0390921 (2366)\ttotal: 12m 9s\tremaining: 39m 8s\n",
      "2369:\tlearn: 0.0364311\ttest: 0.0390921\tbest: 0.0390921 (2366)\ttotal: 12m 9s\tremaining: 39m 8s\n",
      "2370:\tlearn: 0.0364311\ttest: 0.0390921\tbest: 0.0390921 (2370)\ttotal: 12m 9s\tremaining: 39m 8s\n",
      "2371:\tlearn: 0.0364311\ttest: 0.0390921\tbest: 0.0390921 (2370)\ttotal: 12m 9s\tremaining: 39m 7s\n",
      "2372:\tlearn: 0.0364311\ttest: 0.0390921\tbest: 0.0390921 (2372)\ttotal: 12m 10s\tremaining: 39m 6s\n",
      "2373:\tlearn: 0.0364311\ttest: 0.0390921\tbest: 0.0390921 (2373)\ttotal: 12m 10s\tremaining: 39m 6s\n",
      "2374:\tlearn: 0.0364311\ttest: 0.0390921\tbest: 0.0390921 (2374)\ttotal: 12m 10s\tremaining: 39m 6s\n",
      "2375:\tlearn: 0.0364260\ttest: 0.0390913\tbest: 0.0390913 (2375)\ttotal: 12m 11s\tremaining: 39m 5s\n",
      "2376:\tlearn: 0.0364260\ttest: 0.0390913\tbest: 0.0390913 (2375)\ttotal: 12m 11s\tremaining: 39m 5s\n",
      "2377:\tlearn: 0.0364211\ttest: 0.0390892\tbest: 0.0390892 (2377)\ttotal: 12m 11s\tremaining: 39m 5s\n",
      "2378:\tlearn: 0.0364211\ttest: 0.0390892\tbest: 0.0390892 (2377)\ttotal: 12m 11s\tremaining: 39m 4s\n",
      "2379:\tlearn: 0.0364211\ttest: 0.0390892\tbest: 0.0390892 (2379)\ttotal: 12m 12s\tremaining: 39m 3s\n",
      "2380:\tlearn: 0.0364211\ttest: 0.0390892\tbest: 0.0390892 (2380)\ttotal: 12m 12s\tremaining: 39m 3s\n",
      "2381:\tlearn: 0.0364211\ttest: 0.0390892\tbest: 0.0390892 (2380)\ttotal: 12m 12s\tremaining: 39m 2s\n",
      "2382:\tlearn: 0.0364211\ttest: 0.0390892\tbest: 0.0390892 (2382)\ttotal: 12m 12s\tremaining: 39m 2s\n",
      "2383:\tlearn: 0.0364211\ttest: 0.0390892\tbest: 0.0390892 (2382)\ttotal: 12m 13s\tremaining: 39m 1s\n",
      "2384:\tlearn: 0.0364183\ttest: 0.0390877\tbest: 0.0390877 (2384)\ttotal: 12m 13s\tremaining: 39m 1s\n",
      "2385:\tlearn: 0.0364106\ttest: 0.0390847\tbest: 0.0390847 (2385)\ttotal: 12m 13s\tremaining: 39m 1s\n",
      "2386:\tlearn: 0.0364106\ttest: 0.0390847\tbest: 0.0390847 (2386)\ttotal: 12m 13s\tremaining: 39m\n",
      "2387:\tlearn: 0.0364106\ttest: 0.0390847\tbest: 0.0390847 (2387)\ttotal: 12m 14s\tremaining: 39m\n",
      "2388:\tlearn: 0.0364042\ttest: 0.0390821\tbest: 0.0390821 (2388)\ttotal: 12m 14s\tremaining: 39m\n",
      "2389:\tlearn: 0.0364015\ttest: 0.0390817\tbest: 0.0390817 (2389)\ttotal: 12m 14s\tremaining: 38m 59s\n",
      "2390:\tlearn: 0.0364015\ttest: 0.0390817\tbest: 0.0390817 (2390)\ttotal: 12m 15s\tremaining: 38m 59s\n",
      "2391:\tlearn: 0.0364015\ttest: 0.0390817\tbest: 0.0390817 (2390)\ttotal: 12m 15s\tremaining: 38m 58s\n",
      "2392:\tlearn: 0.0363990\ttest: 0.0390820\tbest: 0.0390817 (2390)\ttotal: 12m 15s\tremaining: 38m 58s\n",
      "2393:\tlearn: 0.0363989\ttest: 0.0390820\tbest: 0.0390817 (2390)\ttotal: 12m 15s\tremaining: 38m 58s\n",
      "2394:\tlearn: 0.0363989\ttest: 0.0390820\tbest: 0.0390817 (2390)\ttotal: 12m 16s\tremaining: 38m 57s\n",
      "2395:\tlearn: 0.0363943\ttest: 0.0390814\tbest: 0.0390814 (2395)\ttotal: 12m 16s\tremaining: 38m 57s\n",
      "2396:\tlearn: 0.0363943\ttest: 0.0390814\tbest: 0.0390814 (2396)\ttotal: 12m 16s\tremaining: 38m 56s\n",
      "2397:\tlearn: 0.0363869\ttest: 0.0390786\tbest: 0.0390786 (2397)\ttotal: 12m 17s\tremaining: 38m 56s\n",
      "2398:\tlearn: 0.0363869\ttest: 0.0390786\tbest: 0.0390786 (2397)\ttotal: 12m 17s\tremaining: 38m 55s\n",
      "2399:\tlearn: 0.0363869\ttest: 0.0390786\tbest: 0.0390786 (2397)\ttotal: 12m 17s\tremaining: 38m 55s\n",
      "2400:\tlearn: 0.0363869\ttest: 0.0390786\tbest: 0.0390786 (2397)\ttotal: 12m 17s\tremaining: 38m 55s\n",
      "2401:\tlearn: 0.0363869\ttest: 0.0390786\tbest: 0.0390786 (2401)\ttotal: 12m 18s\tremaining: 38m 55s\n",
      "2402:\tlearn: 0.0363869\ttest: 0.0390786\tbest: 0.0390786 (2401)\ttotal: 12m 18s\tremaining: 38m 55s\n",
      "2403:\tlearn: 0.0363818\ttest: 0.0390776\tbest: 0.0390776 (2403)\ttotal: 12m 19s\tremaining: 38m 56s\n",
      "2404:\tlearn: 0.0363818\ttest: 0.0390776\tbest: 0.0390776 (2403)\ttotal: 12m 19s\tremaining: 38m 56s\n",
      "2405:\tlearn: 0.0363818\ttest: 0.0390776\tbest: 0.0390776 (2403)\ttotal: 12m 20s\tremaining: 38m 56s\n",
      "2406:\tlearn: 0.0363818\ttest: 0.0390776\tbest: 0.0390776 (2403)\ttotal: 12m 20s\tremaining: 38m 56s\n",
      "2407:\tlearn: 0.0363818\ttest: 0.0390776\tbest: 0.0390776 (2407)\ttotal: 12m 21s\tremaining: 38m 56s\n",
      "2408:\tlearn: 0.0363818\ttest: 0.0390775\tbest: 0.0390775 (2408)\ttotal: 12m 21s\tremaining: 38m 56s\n",
      "2409:\tlearn: 0.0363818\ttest: 0.0390775\tbest: 0.0390775 (2409)\ttotal: 12m 21s\tremaining: 38m 56s\n",
      "2410:\tlearn: 0.0363818\ttest: 0.0390775\tbest: 0.0390775 (2410)\ttotal: 12m 21s\tremaining: 38m 55s\n",
      "2411:\tlearn: 0.0363739\ttest: 0.0390713\tbest: 0.0390713 (2411)\ttotal: 12m 22s\tremaining: 38m 55s\n",
      "2412:\tlearn: 0.0363690\ttest: 0.0390708\tbest: 0.0390708 (2412)\ttotal: 12m 22s\tremaining: 38m 55s\n",
      "2413:\tlearn: 0.0363689\ttest: 0.0390708\tbest: 0.0390708 (2413)\ttotal: 12m 22s\tremaining: 38m 54s\n",
      "2414:\tlearn: 0.0363689\ttest: 0.0390708\tbest: 0.0390708 (2414)\ttotal: 12m 23s\tremaining: 38m 54s\n",
      "2415:\tlearn: 0.0363689\ttest: 0.0390708\tbest: 0.0390708 (2415)\ttotal: 12m 23s\tremaining: 38m 53s\n",
      "2416:\tlearn: 0.0363689\ttest: 0.0390708\tbest: 0.0390708 (2415)\ttotal: 12m 23s\tremaining: 38m 53s\n",
      "2417:\tlearn: 0.0363625\ttest: 0.0390686\tbest: 0.0390686 (2417)\ttotal: 12m 23s\tremaining: 38m 52s\n",
      "2418:\tlearn: 0.0363625\ttest: 0.0390686\tbest: 0.0390686 (2418)\ttotal: 12m 24s\tremaining: 38m 52s\n",
      "2419:\tlearn: 0.0363625\ttest: 0.0390686\tbest: 0.0390686 (2419)\ttotal: 12m 24s\tremaining: 38m 51s\n",
      "2420:\tlearn: 0.0363625\ttest: 0.0390686\tbest: 0.0390686 (2420)\ttotal: 12m 24s\tremaining: 38m 51s\n",
      "2421:\tlearn: 0.0363625\ttest: 0.0390686\tbest: 0.0390686 (2421)\ttotal: 12m 24s\tremaining: 38m 50s\n",
      "2422:\tlearn: 0.0363586\ttest: 0.0390668\tbest: 0.0390668 (2422)\ttotal: 12m 25s\tremaining: 38m 50s\n",
      "2423:\tlearn: 0.0363586\ttest: 0.0390668\tbest: 0.0390668 (2423)\ttotal: 12m 25s\tremaining: 38m 50s\n",
      "2424:\tlearn: 0.0363586\ttest: 0.0390668\tbest: 0.0390668 (2424)\ttotal: 12m 25s\tremaining: 38m 49s\n",
      "2425:\tlearn: 0.0363584\ttest: 0.0390667\tbest: 0.0390667 (2425)\ttotal: 12m 26s\tremaining: 38m 49s\n",
      "2426:\tlearn: 0.0363546\ttest: 0.0390651\tbest: 0.0390651 (2426)\ttotal: 12m 26s\tremaining: 38m 48s\n",
      "2427:\tlearn: 0.0363498\ttest: 0.0390625\tbest: 0.0390625 (2427)\ttotal: 12m 26s\tremaining: 38m 48s\n",
      "2428:\tlearn: 0.0363498\ttest: 0.0390625\tbest: 0.0390625 (2428)\ttotal: 12m 26s\tremaining: 38m 48s\n",
      "2429:\tlearn: 0.0363498\ttest: 0.0390625\tbest: 0.0390625 (2428)\ttotal: 12m 27s\tremaining: 38m 47s\n",
      "2430:\tlearn: 0.0363498\ttest: 0.0390625\tbest: 0.0390625 (2428)\ttotal: 12m 27s\tremaining: 38m 47s\n",
      "2431:\tlearn: 0.0363498\ttest: 0.0390625\tbest: 0.0390625 (2431)\ttotal: 12m 27s\tremaining: 38m 46s\n",
      "2432:\tlearn: 0.0363498\ttest: 0.0390624\tbest: 0.0390624 (2432)\ttotal: 12m 28s\tremaining: 38m 46s\n",
      "2433:\tlearn: 0.0363498\ttest: 0.0390624\tbest: 0.0390624 (2433)\ttotal: 12m 28s\tremaining: 38m 45s\n",
      "2434:\tlearn: 0.0363456\ttest: 0.0390600\tbest: 0.0390600 (2434)\ttotal: 12m 28s\tremaining: 38m 45s\n",
      "2435:\tlearn: 0.0363456\ttest: 0.0390600\tbest: 0.0390600 (2435)\ttotal: 12m 28s\tremaining: 38m 45s\n",
      "2436:\tlearn: 0.0363456\ttest: 0.0390600\tbest: 0.0390600 (2436)\ttotal: 12m 29s\tremaining: 38m 44s\n",
      "2437:\tlearn: 0.0363456\ttest: 0.0390600\tbest: 0.0390600 (2437)\ttotal: 12m 29s\tremaining: 38m 44s\n",
      "2438:\tlearn: 0.0363456\ttest: 0.0390600\tbest: 0.0390600 (2438)\ttotal: 12m 29s\tremaining: 38m 43s\n",
      "2439:\tlearn: 0.0363455\ttest: 0.0390600\tbest: 0.0390600 (2439)\ttotal: 12m 29s\tremaining: 38m 43s\n",
      "2440:\tlearn: 0.0363455\ttest: 0.0390600\tbest: 0.0390600 (2440)\ttotal: 12m 30s\tremaining: 38m 42s\n",
      "2441:\tlearn: 0.0363455\ttest: 0.0390600\tbest: 0.0390600 (2441)\ttotal: 12m 30s\tremaining: 38m 42s\n",
      "2442:\tlearn: 0.0363455\ttest: 0.0390600\tbest: 0.0390600 (2442)\ttotal: 12m 30s\tremaining: 38m 43s\n",
      "2443:\tlearn: 0.0363411\ttest: 0.0390599\tbest: 0.0390599 (2443)\ttotal: 12m 31s\tremaining: 38m 43s\n",
      "2444:\tlearn: 0.0363411\ttest: 0.0390599\tbest: 0.0390599 (2443)\ttotal: 12m 31s\tremaining: 38m 43s\n",
      "2445:\tlearn: 0.0363411\ttest: 0.0390599\tbest: 0.0390599 (2445)\ttotal: 12m 32s\tremaining: 38m 43s\n",
      "2446:\tlearn: 0.0363411\ttest: 0.0390599\tbest: 0.0390599 (2445)\ttotal: 12m 32s\tremaining: 38m 44s\n",
      "2447:\tlearn: 0.0363411\ttest: 0.0390599\tbest: 0.0390599 (2447)\ttotal: 12m 33s\tremaining: 38m 44s\n",
      "2448:\tlearn: 0.0363373\ttest: 0.0390595\tbest: 0.0390595 (2448)\ttotal: 12m 33s\tremaining: 38m 44s\n",
      "2449:\tlearn: 0.0363373\ttest: 0.0390595\tbest: 0.0390595 (2449)\ttotal: 12m 34s\tremaining: 38m 44s\n",
      "2450:\tlearn: 0.0363373\ttest: 0.0390595\tbest: 0.0390595 (2449)\ttotal: 12m 34s\tremaining: 38m 44s\n",
      "2451:\tlearn: 0.0363320\ttest: 0.0390573\tbest: 0.0390573 (2451)\ttotal: 12m 35s\tremaining: 38m 45s\n",
      "2452:\tlearn: 0.0363320\ttest: 0.0390573\tbest: 0.0390573 (2452)\ttotal: 12m 35s\tremaining: 38m 45s\n",
      "2453:\tlearn: 0.0363269\ttest: 0.0390550\tbest: 0.0390550 (2453)\ttotal: 12m 36s\tremaining: 38m 45s\n",
      "2454:\tlearn: 0.0363269\ttest: 0.0390549\tbest: 0.0390549 (2454)\ttotal: 12m 36s\tremaining: 38m 46s\n",
      "2455:\tlearn: 0.0363269\ttest: 0.0390549\tbest: 0.0390549 (2454)\ttotal: 12m 37s\tremaining: 38m 46s\n",
      "2456:\tlearn: 0.0363269\ttest: 0.0390549\tbest: 0.0390549 (2456)\ttotal: 12m 37s\tremaining: 38m 46s\n",
      "2457:\tlearn: 0.0363269\ttest: 0.0390549\tbest: 0.0390549 (2457)\ttotal: 12m 38s\tremaining: 38m 45s\n",
      "2458:\tlearn: 0.0363269\ttest: 0.0390549\tbest: 0.0390549 (2458)\ttotal: 12m 38s\tremaining: 38m 45s\n",
      "2459:\tlearn: 0.0363269\ttest: 0.0390549\tbest: 0.0390549 (2459)\ttotal: 12m 38s\tremaining: 38m 45s\n",
      "2460:\tlearn: 0.0363225\ttest: 0.0390523\tbest: 0.0390523 (2460)\ttotal: 12m 38s\tremaining: 38m 44s\n",
      "2461:\tlearn: 0.0363178\ttest: 0.0390494\tbest: 0.0390494 (2461)\ttotal: 12m 39s\tremaining: 38m 44s\n",
      "2462:\tlearn: 0.0363178\ttest: 0.0390494\tbest: 0.0390494 (2462)\ttotal: 12m 39s\tremaining: 38m 44s\n",
      "2463:\tlearn: 0.0363178\ttest: 0.0390494\tbest: 0.0390494 (2462)\ttotal: 12m 39s\tremaining: 38m 43s\n",
      "2464:\tlearn: 0.0363178\ttest: 0.0390494\tbest: 0.0390494 (2464)\ttotal: 12m 40s\tremaining: 38m 43s\n",
      "2465:\tlearn: 0.0363178\ttest: 0.0390494\tbest: 0.0390494 (2465)\ttotal: 12m 40s\tremaining: 38m 42s\n",
      "2466:\tlearn: 0.0363166\ttest: 0.0390491\tbest: 0.0390491 (2466)\ttotal: 12m 40s\tremaining: 38m 42s\n",
      "2467:\tlearn: 0.0363130\ttest: 0.0390480\tbest: 0.0390480 (2467)\ttotal: 12m 40s\tremaining: 38m 42s\n",
      "2468:\tlearn: 0.0363130\ttest: 0.0390480\tbest: 0.0390480 (2467)\ttotal: 12m 41s\tremaining: 38m 41s\n",
      "2469:\tlearn: 0.0363087\ttest: 0.0390479\tbest: 0.0390479 (2469)\ttotal: 12m 41s\tremaining: 38m 41s\n",
      "2470:\tlearn: 0.0363087\ttest: 0.0390479\tbest: 0.0390479 (2470)\ttotal: 12m 41s\tremaining: 38m 40s\n",
      "2471:\tlearn: 0.0363087\ttest: 0.0390479\tbest: 0.0390479 (2471)\ttotal: 12m 41s\tremaining: 38m 40s\n",
      "2472:\tlearn: 0.0363087\ttest: 0.0390479\tbest: 0.0390479 (2472)\ttotal: 12m 42s\tremaining: 38m 39s\n",
      "2473:\tlearn: 0.0363087\ttest: 0.0390479\tbest: 0.0390479 (2473)\ttotal: 12m 42s\tremaining: 38m 39s\n",
      "2474:\tlearn: 0.0363087\ttest: 0.0390479\tbest: 0.0390479 (2474)\ttotal: 12m 42s\tremaining: 38m 39s\n",
      "2475:\tlearn: 0.0363087\ttest: 0.0390479\tbest: 0.0390479 (2475)\ttotal: 12m 43s\tremaining: 38m 38s\n",
      "2476:\tlearn: 0.0363087\ttest: 0.0390479\tbest: 0.0390479 (2476)\ttotal: 12m 43s\tremaining: 38m 38s\n",
      "2477:\tlearn: 0.0363087\ttest: 0.0390478\tbest: 0.0390478 (2477)\ttotal: 12m 43s\tremaining: 38m 37s\n",
      "2478:\tlearn: 0.0363087\ttest: 0.0390478\tbest: 0.0390478 (2478)\ttotal: 12m 43s\tremaining: 38m 37s\n",
      "2479:\tlearn: 0.0363087\ttest: 0.0390478\tbest: 0.0390478 (2479)\ttotal: 12m 44s\tremaining: 38m 36s\n",
      "2480:\tlearn: 0.0363020\ttest: 0.0390440\tbest: 0.0390440 (2480)\ttotal: 12m 44s\tremaining: 38m 36s\n",
      "2481:\tlearn: 0.0362975\ttest: 0.0390414\tbest: 0.0390414 (2481)\ttotal: 12m 44s\tremaining: 38m 36s\n",
      "2482:\tlearn: 0.0362927\ttest: 0.0390401\tbest: 0.0390401 (2482)\ttotal: 12m 44s\tremaining: 38m 35s\n",
      "2483:\tlearn: 0.0362927\ttest: 0.0390400\tbest: 0.0390400 (2483)\ttotal: 12m 45s\tremaining: 38m 35s\n",
      "2484:\tlearn: 0.0362906\ttest: 0.0390383\tbest: 0.0390383 (2484)\ttotal: 12m 45s\tremaining: 38m 34s\n",
      "2485:\tlearn: 0.0362906\ttest: 0.0390383\tbest: 0.0390383 (2485)\ttotal: 12m 45s\tremaining: 38m 34s\n",
      "2486:\tlearn: 0.0362833\ttest: 0.0390350\tbest: 0.0390350 (2486)\ttotal: 12m 46s\tremaining: 38m 34s\n",
      "2487:\tlearn: 0.0362833\ttest: 0.0390350\tbest: 0.0390350 (2486)\ttotal: 12m 46s\tremaining: 38m 33s\n",
      "2488:\tlearn: 0.0362832\ttest: 0.0390350\tbest: 0.0390350 (2486)\ttotal: 12m 46s\tremaining: 38m 33s\n",
      "2489:\tlearn: 0.0362832\ttest: 0.0390350\tbest: 0.0390350 (2489)\ttotal: 12m 46s\tremaining: 38m 32s\n",
      "2490:\tlearn: 0.0362796\ttest: 0.0390329\tbest: 0.0390329 (2490)\ttotal: 12m 47s\tremaining: 38m 32s\n",
      "2491:\tlearn: 0.0362796\ttest: 0.0390329\tbest: 0.0390329 (2491)\ttotal: 12m 47s\tremaining: 38m 32s\n",
      "2492:\tlearn: 0.0362796\ttest: 0.0390329\tbest: 0.0390329 (2492)\ttotal: 12m 47s\tremaining: 38m 31s\n",
      "2493:\tlearn: 0.0362796\ttest: 0.0390329\tbest: 0.0390329 (2492)\ttotal: 12m 48s\tremaining: 38m 31s\n",
      "2494:\tlearn: 0.0362741\ttest: 0.0390306\tbest: 0.0390306 (2494)\ttotal: 12m 48s\tremaining: 38m 31s\n",
      "2495:\tlearn: 0.0362715\ttest: 0.0390304\tbest: 0.0390304 (2495)\ttotal: 12m 49s\tremaining: 38m 32s\n",
      "2496:\tlearn: 0.0362715\ttest: 0.0390304\tbest: 0.0390304 (2495)\ttotal: 12m 49s\tremaining: 38m 32s\n",
      "2497:\tlearn: 0.0362671\ttest: 0.0390278\tbest: 0.0390278 (2497)\ttotal: 12m 50s\tremaining: 38m 32s\n",
      "2498:\tlearn: 0.0362670\ttest: 0.0390277\tbest: 0.0390277 (2498)\ttotal: 12m 50s\tremaining: 38m 32s\n",
      "2499:\tlearn: 0.0362670\ttest: 0.0390277\tbest: 0.0390277 (2499)\ttotal: 12m 51s\tremaining: 38m 33s\n",
      "2500:\tlearn: 0.0362670\ttest: 0.0390277\tbest: 0.0390277 (2499)\ttotal: 12m 51s\tremaining: 38m 33s\n",
      "2501:\tlearn: 0.0362670\ttest: 0.0390277\tbest: 0.0390277 (2499)\ttotal: 12m 51s\tremaining: 38m 32s\n",
      "2502:\tlearn: 0.0362670\ttest: 0.0390277\tbest: 0.0390277 (2502)\ttotal: 12m 51s\tremaining: 38m 32s\n",
      "2503:\tlearn: 0.0362626\ttest: 0.0390266\tbest: 0.0390266 (2503)\ttotal: 12m 52s\tremaining: 38m 31s\n",
      "2504:\tlearn: 0.0362626\ttest: 0.0390266\tbest: 0.0390266 (2504)\ttotal: 12m 52s\tremaining: 38m 31s\n",
      "2505:\tlearn: 0.0362626\ttest: 0.0390266\tbest: 0.0390266 (2505)\ttotal: 12m 52s\tremaining: 38m 30s\n",
      "2506:\tlearn: 0.0362626\ttest: 0.0390266\tbest: 0.0390266 (2506)\ttotal: 12m 53s\tremaining: 38m 30s\n",
      "2507:\tlearn: 0.0362626\ttest: 0.0390266\tbest: 0.0390266 (2507)\ttotal: 12m 53s\tremaining: 38m 29s\n",
      "2508:\tlearn: 0.0362625\ttest: 0.0390266\tbest: 0.0390266 (2508)\ttotal: 12m 53s\tremaining: 38m 29s\n",
      "2509:\tlearn: 0.0362625\ttest: 0.0390266\tbest: 0.0390266 (2509)\ttotal: 12m 53s\tremaining: 38m 29s\n",
      "2510:\tlearn: 0.0362580\ttest: 0.0390254\tbest: 0.0390254 (2510)\ttotal: 12m 54s\tremaining: 38m 28s\n",
      "2511:\tlearn: 0.0362579\ttest: 0.0390254\tbest: 0.0390254 (2511)\ttotal: 12m 54s\tremaining: 38m 28s\n",
      "2512:\tlearn: 0.0362579\ttest: 0.0390254\tbest: 0.0390254 (2512)\ttotal: 12m 54s\tremaining: 38m 27s\n",
      "2513:\tlearn: 0.0362553\ttest: 0.0390230\tbest: 0.0390230 (2513)\ttotal: 12m 54s\tremaining: 38m 27s\n",
      "2514:\tlearn: 0.0362553\ttest: 0.0390230\tbest: 0.0390230 (2514)\ttotal: 12m 55s\tremaining: 38m 27s\n",
      "2515:\tlearn: 0.0362553\ttest: 0.0390230\tbest: 0.0390230 (2515)\ttotal: 12m 55s\tremaining: 38m 26s\n",
      "2516:\tlearn: 0.0362553\ttest: 0.0390230\tbest: 0.0390230 (2516)\ttotal: 12m 55s\tremaining: 38m 26s\n",
      "2517:\tlearn: 0.0362553\ttest: 0.0390230\tbest: 0.0390230 (2517)\ttotal: 12m 55s\tremaining: 38m 25s\n",
      "2518:\tlearn: 0.0362553\ttest: 0.0390230\tbest: 0.0390230 (2517)\ttotal: 12m 56s\tremaining: 38m 25s\n",
      "2519:\tlearn: 0.0362553\ttest: 0.0390230\tbest: 0.0390230 (2517)\ttotal: 12m 56s\tremaining: 38m 24s\n",
      "2520:\tlearn: 0.0362509\ttest: 0.0390209\tbest: 0.0390209 (2520)\ttotal: 12m 56s\tremaining: 38m 24s\n",
      "2521:\tlearn: 0.0362509\ttest: 0.0390209\tbest: 0.0390209 (2521)\ttotal: 12m 56s\tremaining: 38m 23s\n",
      "2522:\tlearn: 0.0362470\ttest: 0.0390196\tbest: 0.0390196 (2522)\ttotal: 12m 57s\tremaining: 38m 23s\n",
      "2523:\tlearn: 0.0362469\ttest: 0.0390196\tbest: 0.0390196 (2523)\ttotal: 12m 57s\tremaining: 38m 23s\n",
      "2524:\tlearn: 0.0362440\ttest: 0.0390196\tbest: 0.0390196 (2524)\ttotal: 12m 57s\tremaining: 38m 22s\n",
      "2525:\tlearn: 0.0362395\ttest: 0.0390166\tbest: 0.0390166 (2525)\ttotal: 12m 58s\tremaining: 38m 22s\n",
      "2526:\tlearn: 0.0362395\ttest: 0.0390166\tbest: 0.0390166 (2526)\ttotal: 12m 58s\tremaining: 38m 22s\n",
      "2527:\tlearn: 0.0362395\ttest: 0.0390166\tbest: 0.0390166 (2526)\ttotal: 12m 58s\tremaining: 38m 21s\n",
      "2528:\tlearn: 0.0362395\ttest: 0.0390166\tbest: 0.0390166 (2526)\ttotal: 12m 58s\tremaining: 38m 21s\n",
      "2529:\tlearn: 0.0362365\ttest: 0.0390151\tbest: 0.0390151 (2529)\ttotal: 12m 59s\tremaining: 38m 20s\n",
      "2530:\tlearn: 0.0362365\ttest: 0.0390151\tbest: 0.0390151 (2529)\ttotal: 12m 59s\tremaining: 38m 20s\n",
      "2531:\tlearn: 0.0362343\ttest: 0.0390142\tbest: 0.0390142 (2531)\ttotal: 12m 59s\tremaining: 38m 19s\n",
      "2532:\tlearn: 0.0362343\ttest: 0.0390142\tbest: 0.0390142 (2532)\ttotal: 13m\tremaining: 38m 19s\n",
      "2533:\tlearn: 0.0362343\ttest: 0.0390142\tbest: 0.0390142 (2533)\ttotal: 13m\tremaining: 38m 19s\n",
      "2534:\tlearn: 0.0362343\ttest: 0.0390142\tbest: 0.0390142 (2534)\ttotal: 13m\tremaining: 38m 18s\n",
      "2535:\tlearn: 0.0362343\ttest: 0.0390141\tbest: 0.0390141 (2535)\ttotal: 13m\tremaining: 38m 18s\n",
      "2536:\tlearn: 0.0362304\ttest: 0.0390121\tbest: 0.0390121 (2536)\ttotal: 13m 1s\tremaining: 38m 17s\n",
      "2537:\tlearn: 0.0362304\ttest: 0.0390121\tbest: 0.0390121 (2537)\ttotal: 13m 1s\tremaining: 38m 17s\n",
      "2538:\tlearn: 0.0362304\ttest: 0.0390121\tbest: 0.0390121 (2538)\ttotal: 13m 1s\tremaining: 38m 17s\n",
      "2539:\tlearn: 0.0362302\ttest: 0.0390119\tbest: 0.0390119 (2539)\ttotal: 13m 2s\tremaining: 38m 17s\n",
      "2540:\tlearn: 0.0362302\ttest: 0.0390119\tbest: 0.0390119 (2540)\ttotal: 13m 2s\tremaining: 38m 17s\n",
      "2541:\tlearn: 0.0362302\ttest: 0.0390119\tbest: 0.0390119 (2541)\ttotal: 13m 3s\tremaining: 38m 17s\n",
      "2542:\tlearn: 0.0362302\ttest: 0.0390119\tbest: 0.0390119 (2542)\ttotal: 13m 3s\tremaining: 38m 17s\n",
      "2543:\tlearn: 0.0362302\ttest: 0.0390119\tbest: 0.0390119 (2542)\ttotal: 13m 3s\tremaining: 38m 17s\n",
      "2544:\tlearn: 0.0362256\ttest: 0.0390111\tbest: 0.0390111 (2544)\ttotal: 13m 4s\tremaining: 38m 17s\n",
      "2545:\tlearn: 0.0362199\ttest: 0.0390069\tbest: 0.0390069 (2545)\ttotal: 13m 4s\tremaining: 38m 18s\n",
      "2546:\tlearn: 0.0362199\ttest: 0.0390069\tbest: 0.0390069 (2546)\ttotal: 13m 5s\tremaining: 38m 18s\n",
      "2547:\tlearn: 0.0362199\ttest: 0.0390069\tbest: 0.0390069 (2547)\ttotal: 13m 5s\tremaining: 38m 18s\n",
      "2548:\tlearn: 0.0362199\ttest: 0.0390069\tbest: 0.0390069 (2548)\ttotal: 13m 6s\tremaining: 38m 17s\n",
      "2549:\tlearn: 0.0362160\ttest: 0.0390052\tbest: 0.0390052 (2549)\ttotal: 13m 6s\tremaining: 38m 17s\n",
      "2550:\tlearn: 0.0362160\ttest: 0.0390051\tbest: 0.0390051 (2550)\ttotal: 13m 6s\tremaining: 38m 16s\n",
      "2551:\tlearn: 0.0362160\ttest: 0.0390051\tbest: 0.0390051 (2551)\ttotal: 13m 6s\tremaining: 38m 16s\n",
      "2552:\tlearn: 0.0362160\ttest: 0.0390051\tbest: 0.0390051 (2552)\ttotal: 13m 7s\tremaining: 38m 15s\n",
      "2553:\tlearn: 0.0362160\ttest: 0.0390051\tbest: 0.0390051 (2553)\ttotal: 13m 7s\tremaining: 38m 15s\n",
      "2554:\tlearn: 0.0362119\ttest: 0.0390058\tbest: 0.0390051 (2553)\ttotal: 13m 7s\tremaining: 38m 14s\n",
      "2555:\tlearn: 0.0362119\ttest: 0.0390058\tbest: 0.0390051 (2553)\ttotal: 13m 7s\tremaining: 38m 14s\n",
      "2556:\tlearn: 0.0362119\ttest: 0.0390058\tbest: 0.0390051 (2553)\ttotal: 13m 8s\tremaining: 38m 14s\n",
      "2557:\tlearn: 0.0362119\ttest: 0.0390058\tbest: 0.0390051 (2553)\ttotal: 13m 8s\tremaining: 38m 13s\n",
      "2558:\tlearn: 0.0362088\ttest: 0.0390041\tbest: 0.0390041 (2558)\ttotal: 13m 8s\tremaining: 38m 13s\n",
      "2559:\tlearn: 0.0362088\ttest: 0.0390041\tbest: 0.0390041 (2559)\ttotal: 13m 8s\tremaining: 38m 12s\n",
      "2560:\tlearn: 0.0362088\ttest: 0.0390041\tbest: 0.0390041 (2559)\ttotal: 13m 9s\tremaining: 38m 12s\n",
      "2561:\tlearn: 0.0362088\ttest: 0.0390041\tbest: 0.0390041 (2559)\ttotal: 13m 9s\tremaining: 38m 11s\n",
      "2562:\tlearn: 0.0362087\ttest: 0.0390041\tbest: 0.0390041 (2559)\ttotal: 13m 9s\tremaining: 38m 11s\n",
      "2563:\tlearn: 0.0362087\ttest: 0.0390041\tbest: 0.0390041 (2559)\ttotal: 13m 9s\tremaining: 38m 10s\n",
      "2564:\tlearn: 0.0362038\ttest: 0.0390015\tbest: 0.0390015 (2564)\ttotal: 13m 10s\tremaining: 38m 10s\n",
      "2565:\tlearn: 0.0362038\ttest: 0.0390015\tbest: 0.0390015 (2565)\ttotal: 13m 10s\tremaining: 38m 10s\n",
      "2566:\tlearn: 0.0362038\ttest: 0.0390015\tbest: 0.0390015 (2566)\ttotal: 13m 10s\tremaining: 38m 9s\n",
      "2567:\tlearn: 0.0362038\ttest: 0.0390015\tbest: 0.0390015 (2567)\ttotal: 13m 10s\tremaining: 38m 9s\n",
      "2568:\tlearn: 0.0362038\ttest: 0.0390015\tbest: 0.0390015 (2568)\ttotal: 13m 11s\tremaining: 38m 8s\n",
      "2569:\tlearn: 0.0362038\ttest: 0.0390015\tbest: 0.0390015 (2568)\ttotal: 13m 11s\tremaining: 38m 8s\n",
      "2570:\tlearn: 0.0361977\ttest: 0.0389997\tbest: 0.0389997 (2570)\ttotal: 13m 11s\tremaining: 38m 8s\n",
      "2571:\tlearn: 0.0361976\ttest: 0.0389997\tbest: 0.0389997 (2570)\ttotal: 13m 12s\tremaining: 38m 7s\n",
      "2572:\tlearn: 0.0361976\ttest: 0.0389997\tbest: 0.0389997 (2572)\ttotal: 13m 12s\tremaining: 38m 7s\n",
      "2573:\tlearn: 0.0361976\ttest: 0.0389997\tbest: 0.0389997 (2573)\ttotal: 13m 12s\tremaining: 38m 6s\n",
      "2574:\tlearn: 0.0361889\ttest: 0.0389974\tbest: 0.0389974 (2574)\ttotal: 13m 12s\tremaining: 38m 6s\n",
      "2575:\tlearn: 0.0361889\ttest: 0.0389974\tbest: 0.0389974 (2574)\ttotal: 13m 13s\tremaining: 38m 5s\n",
      "2576:\tlearn: 0.0361889\ttest: 0.0389974\tbest: 0.0389974 (2576)\ttotal: 13m 13s\tremaining: 38m 5s\n",
      "2577:\tlearn: 0.0361889\ttest: 0.0389974\tbest: 0.0389974 (2577)\ttotal: 13m 13s\tremaining: 38m 4s\n",
      "2578:\tlearn: 0.0361889\ttest: 0.0389974\tbest: 0.0389974 (2577)\ttotal: 13m 13s\tremaining: 38m 4s\n",
      "2579:\tlearn: 0.0361889\ttest: 0.0389974\tbest: 0.0389974 (2577)\ttotal: 13m 14s\tremaining: 38m 3s\n",
      "2580:\tlearn: 0.0361889\ttest: 0.0389974\tbest: 0.0389974 (2580)\ttotal: 13m 14s\tremaining: 38m 3s\n",
      "2581:\tlearn: 0.0361889\ttest: 0.0389974\tbest: 0.0389974 (2581)\ttotal: 13m 14s\tremaining: 38m 2s\n",
      "2582:\tlearn: 0.0361889\ttest: 0.0389974\tbest: 0.0389974 (2582)\ttotal: 13m 14s\tremaining: 38m 2s\n",
      "2583:\tlearn: 0.0361825\ttest: 0.0389928\tbest: 0.0389928 (2583)\ttotal: 13m 15s\tremaining: 38m 2s\n",
      "2584:\tlearn: 0.0361825\ttest: 0.0389928\tbest: 0.0389928 (2584)\ttotal: 13m 15s\tremaining: 38m 1s\n",
      "2585:\tlearn: 0.0361823\ttest: 0.0389927\tbest: 0.0389927 (2585)\ttotal: 13m 15s\tremaining: 38m 1s\n",
      "2586:\tlearn: 0.0361823\ttest: 0.0389927\tbest: 0.0389927 (2586)\ttotal: 13m 16s\tremaining: 38m 1s\n",
      "2587:\tlearn: 0.0361823\ttest: 0.0389927\tbest: 0.0389927 (2587)\ttotal: 13m 16s\tremaining: 38m 1s\n",
      "2588:\tlearn: 0.0361823\ttest: 0.0389927\tbest: 0.0389927 (2588)\ttotal: 13m 17s\tremaining: 38m 1s\n",
      "2589:\tlearn: 0.0361823\ttest: 0.0389927\tbest: 0.0389927 (2589)\ttotal: 13m 17s\tremaining: 38m 1s\n",
      "2590:\tlearn: 0.0361777\ttest: 0.0389915\tbest: 0.0389915 (2590)\ttotal: 13m 18s\tremaining: 38m 2s\n",
      "2591:\tlearn: 0.0361777\ttest: 0.0389915\tbest: 0.0389915 (2591)\ttotal: 13m 18s\tremaining: 38m 2s\n",
      "2592:\tlearn: 0.0361737\ttest: 0.0389906\tbest: 0.0389906 (2592)\ttotal: 13m 19s\tremaining: 38m 2s\n",
      "2593:\tlearn: 0.0361736\ttest: 0.0389906\tbest: 0.0389906 (2593)\ttotal: 13m 19s\tremaining: 38m 2s\n",
      "2594:\tlearn: 0.0361736\ttest: 0.0389906\tbest: 0.0389906 (2594)\ttotal: 13m 19s\tremaining: 38m 2s\n",
      "2595:\tlearn: 0.0361736\ttest: 0.0389906\tbest: 0.0389906 (2595)\ttotal: 13m 20s\tremaining: 38m 2s\n",
      "2596:\tlearn: 0.0361736\ttest: 0.0389906\tbest: 0.0389906 (2596)\ttotal: 13m 20s\tremaining: 38m 1s\n",
      "2597:\tlearn: 0.0361736\ttest: 0.0389906\tbest: 0.0389906 (2597)\ttotal: 13m 20s\tremaining: 38m 1s\n",
      "2598:\tlearn: 0.0361712\ttest: 0.0389892\tbest: 0.0389892 (2598)\ttotal: 13m 20s\tremaining: 38m\n",
      "2599:\tlearn: 0.0361669\ttest: 0.0389882\tbest: 0.0389882 (2599)\ttotal: 13m 21s\tremaining: 38m\n",
      "2600:\tlearn: 0.0361628\ttest: 0.0389863\tbest: 0.0389863 (2600)\ttotal: 13m 21s\tremaining: 38m\n",
      "2601:\tlearn: 0.0361627\ttest: 0.0389863\tbest: 0.0389863 (2601)\ttotal: 13m 21s\tremaining: 38m\n",
      "2602:\tlearn: 0.0361589\ttest: 0.0389861\tbest: 0.0389861 (2602)\ttotal: 13m 22s\tremaining: 37m 59s\n",
      "2603:\tlearn: 0.0361589\ttest: 0.0389861\tbest: 0.0389861 (2603)\ttotal: 13m 22s\tremaining: 37m 59s\n",
      "2604:\tlearn: 0.0361589\ttest: 0.0389861\tbest: 0.0389861 (2603)\ttotal: 13m 22s\tremaining: 37m 58s\n",
      "2605:\tlearn: 0.0361589\ttest: 0.0389861\tbest: 0.0389861 (2605)\ttotal: 13m 23s\tremaining: 37m 58s\n",
      "2606:\tlearn: 0.0361589\ttest: 0.0389861\tbest: 0.0389861 (2605)\ttotal: 13m 23s\tremaining: 37m 57s\n",
      "2607:\tlearn: 0.0361589\ttest: 0.0389861\tbest: 0.0389861 (2607)\ttotal: 13m 23s\tremaining: 37m 57s\n",
      "2608:\tlearn: 0.0361589\ttest: 0.0389861\tbest: 0.0389861 (2608)\ttotal: 13m 23s\tremaining: 37m 57s\n",
      "2609:\tlearn: 0.0361589\ttest: 0.0389861\tbest: 0.0389861 (2609)\ttotal: 13m 24s\tremaining: 37m 56s\n",
      "2610:\tlearn: 0.0361545\ttest: 0.0389858\tbest: 0.0389858 (2610)\ttotal: 13m 24s\tremaining: 37m 56s\n",
      "2611:\tlearn: 0.0361545\ttest: 0.0389858\tbest: 0.0389858 (2611)\ttotal: 13m 24s\tremaining: 37m 56s\n",
      "2612:\tlearn: 0.0361545\ttest: 0.0389858\tbest: 0.0389858 (2612)\ttotal: 13m 24s\tremaining: 37m 55s\n",
      "2613:\tlearn: 0.0361491\ttest: 0.0389848\tbest: 0.0389848 (2613)\ttotal: 13m 25s\tremaining: 37m 55s\n",
      "2614:\tlearn: 0.0361491\ttest: 0.0389848\tbest: 0.0389848 (2613)\ttotal: 13m 25s\tremaining: 37m 54s\n",
      "2615:\tlearn: 0.0361491\ttest: 0.0389848\tbest: 0.0389848 (2613)\ttotal: 13m 25s\tremaining: 37m 54s\n",
      "2616:\tlearn: 0.0361491\ttest: 0.0389848\tbest: 0.0389848 (2616)\ttotal: 13m 26s\tremaining: 37m 53s\n",
      "2617:\tlearn: 0.0361491\ttest: 0.0389848\tbest: 0.0389848 (2617)\ttotal: 13m 26s\tremaining: 37m 53s\n",
      "2618:\tlearn: 0.0361491\ttest: 0.0389848\tbest: 0.0389848 (2618)\ttotal: 13m 26s\tremaining: 37m 52s\n",
      "2619:\tlearn: 0.0361491\ttest: 0.0389848\tbest: 0.0389848 (2619)\ttotal: 13m 26s\tremaining: 37m 52s\n",
      "2620:\tlearn: 0.0361491\ttest: 0.0389848\tbest: 0.0389848 (2620)\ttotal: 13m 27s\tremaining: 37m 52s\n",
      "2621:\tlearn: 0.0361491\ttest: 0.0389848\tbest: 0.0389848 (2620)\ttotal: 13m 27s\tremaining: 37m 51s\n",
      "2622:\tlearn: 0.0361444\ttest: 0.0389829\tbest: 0.0389829 (2622)\ttotal: 13m 27s\tremaining: 37m 51s\n",
      "2623:\tlearn: 0.0361444\ttest: 0.0389829\tbest: 0.0389829 (2623)\ttotal: 13m 27s\tremaining: 37m 50s\n",
      "2624:\tlearn: 0.0361444\ttest: 0.0389829\tbest: 0.0389829 (2624)\ttotal: 13m 28s\tremaining: 37m 50s\n",
      "2625:\tlearn: 0.0361444\ttest: 0.0389829\tbest: 0.0389829 (2625)\ttotal: 13m 28s\tremaining: 37m 50s\n",
      "2626:\tlearn: 0.0361444\ttest: 0.0389829\tbest: 0.0389829 (2626)\ttotal: 13m 28s\tremaining: 37m 49s\n",
      "2627:\tlearn: 0.0361444\ttest: 0.0389829\tbest: 0.0389829 (2627)\ttotal: 13m 28s\tremaining: 37m 49s\n",
      "2628:\tlearn: 0.0361444\ttest: 0.0389829\tbest: 0.0389829 (2627)\ttotal: 13m 29s\tremaining: 37m 48s\n",
      "2629:\tlearn: 0.0361444\ttest: 0.0389829\tbest: 0.0389829 (2627)\ttotal: 13m 29s\tremaining: 37m 48s\n",
      "2630:\tlearn: 0.0361444\ttest: 0.0389829\tbest: 0.0389829 (2630)\ttotal: 13m 29s\tremaining: 37m 47s\n",
      "2631:\tlearn: 0.0361383\ttest: 0.0389819\tbest: 0.0389819 (2631)\ttotal: 13m 30s\tremaining: 37m 48s\n",
      "2632:\tlearn: 0.0361383\ttest: 0.0389818\tbest: 0.0389818 (2632)\ttotal: 13m 30s\tremaining: 37m 48s\n",
      "2633:\tlearn: 0.0361383\ttest: 0.0389818\tbest: 0.0389818 (2633)\ttotal: 13m 31s\tremaining: 37m 48s\n",
      "2634:\tlearn: 0.0361328\ttest: 0.0389783\tbest: 0.0389783 (2634)\ttotal: 13m 31s\tremaining: 37m 48s\n",
      "2635:\tlearn: 0.0361328\ttest: 0.0389783\tbest: 0.0389783 (2635)\ttotal: 13m 31s\tremaining: 37m 48s\n",
      "2636:\tlearn: 0.0361328\ttest: 0.0389783\tbest: 0.0389783 (2635)\ttotal: 13m 32s\tremaining: 37m 48s\n",
      "2637:\tlearn: 0.0361328\ttest: 0.0389783\tbest: 0.0389783 (2635)\ttotal: 13m 32s\tremaining: 37m 48s\n",
      "2638:\tlearn: 0.0361299\ttest: 0.0389774\tbest: 0.0389774 (2638)\ttotal: 13m 33s\tremaining: 37m 48s\n",
      "2639:\tlearn: 0.0361259\ttest: 0.0389757\tbest: 0.0389757 (2639)\ttotal: 13m 33s\tremaining: 37m 49s\n",
      "2640:\tlearn: 0.0361203\ttest: 0.0389733\tbest: 0.0389733 (2640)\ttotal: 13m 34s\tremaining: 37m 48s\n",
      "2641:\tlearn: 0.0361203\ttest: 0.0389733\tbest: 0.0389733 (2641)\ttotal: 13m 34s\tremaining: 37m 48s\n",
      "2642:\tlearn: 0.0361203\ttest: 0.0389733\tbest: 0.0389733 (2642)\ttotal: 13m 34s\tremaining: 37m 48s\n",
      "2643:\tlearn: 0.0361131\ttest: 0.0389702\tbest: 0.0389702 (2643)\ttotal: 13m 35s\tremaining: 37m 47s\n",
      "2644:\tlearn: 0.0361131\ttest: 0.0389702\tbest: 0.0389702 (2643)\ttotal: 13m 35s\tremaining: 37m 47s\n",
      "2645:\tlearn: 0.0361099\ttest: 0.0389699\tbest: 0.0389699 (2645)\ttotal: 13m 35s\tremaining: 37m 47s\n",
      "2646:\tlearn: 0.0361099\ttest: 0.0389699\tbest: 0.0389699 (2646)\ttotal: 13m 35s\tremaining: 37m 46s\n",
      "2647:\tlearn: 0.0361050\ttest: 0.0389693\tbest: 0.0389693 (2647)\ttotal: 13m 36s\tremaining: 37m 46s\n",
      "2648:\tlearn: 0.0361006\ttest: 0.0389671\tbest: 0.0389671 (2648)\ttotal: 13m 36s\tremaining: 37m 46s\n",
      "2649:\tlearn: 0.0361006\ttest: 0.0389671\tbest: 0.0389671 (2649)\ttotal: 13m 36s\tremaining: 37m 45s\n",
      "2650:\tlearn: 0.0361006\ttest: 0.0389671\tbest: 0.0389671 (2650)\ttotal: 13m 37s\tremaining: 37m 45s\n",
      "2651:\tlearn: 0.0361006\ttest: 0.0389671\tbest: 0.0389671 (2651)\ttotal: 13m 37s\tremaining: 37m 44s\n",
      "2652:\tlearn: 0.0361006\ttest: 0.0389671\tbest: 0.0389671 (2651)\ttotal: 13m 37s\tremaining: 37m 44s\n",
      "2653:\tlearn: 0.0361006\ttest: 0.0389671\tbest: 0.0389671 (2653)\ttotal: 13m 37s\tremaining: 37m 43s\n",
      "2654:\tlearn: 0.0361006\ttest: 0.0389671\tbest: 0.0389671 (2653)\ttotal: 13m 38s\tremaining: 37m 43s\n",
      "2655:\tlearn: 0.0361006\ttest: 0.0389671\tbest: 0.0389671 (2655)\ttotal: 13m 38s\tremaining: 37m 42s\n",
      "2656:\tlearn: 0.0361006\ttest: 0.0389671\tbest: 0.0389671 (2656)\ttotal: 13m 38s\tremaining: 37m 42s\n",
      "2657:\tlearn: 0.0361000\ttest: 0.0389669\tbest: 0.0389669 (2657)\ttotal: 13m 38s\tremaining: 37m 42s\n",
      "2658:\tlearn: 0.0361000\ttest: 0.0389669\tbest: 0.0389669 (2658)\ttotal: 13m 39s\tremaining: 37m 41s\n",
      "2659:\tlearn: 0.0361000\ttest: 0.0389669\tbest: 0.0389669 (2658)\ttotal: 13m 39s\tremaining: 37m 41s\n",
      "2660:\tlearn: 0.0361000\ttest: 0.0389669\tbest: 0.0389669 (2660)\ttotal: 13m 39s\tremaining: 37m 40s\n",
      "2661:\tlearn: 0.0361000\ttest: 0.0389669\tbest: 0.0389669 (2661)\ttotal: 13m 39s\tremaining: 37m 40s\n",
      "2662:\tlearn: 0.0360964\ttest: 0.0389649\tbest: 0.0389649 (2662)\ttotal: 13m 40s\tremaining: 37m 40s\n",
      "2663:\tlearn: 0.0360964\ttest: 0.0389649\tbest: 0.0389649 (2663)\ttotal: 13m 40s\tremaining: 37m 39s\n",
      "2664:\tlearn: 0.0360964\ttest: 0.0389649\tbest: 0.0389649 (2664)\ttotal: 13m 40s\tremaining: 37m 39s\n",
      "2665:\tlearn: 0.0360934\ttest: 0.0389628\tbest: 0.0389628 (2665)\ttotal: 13m 41s\tremaining: 37m 38s\n",
      "2666:\tlearn: 0.0360934\ttest: 0.0389628\tbest: 0.0389628 (2666)\ttotal: 13m 41s\tremaining: 37m 38s\n",
      "2667:\tlearn: 0.0360894\ttest: 0.0389610\tbest: 0.0389610 (2667)\ttotal: 13m 41s\tremaining: 37m 38s\n",
      "2668:\tlearn: 0.0360894\ttest: 0.0389610\tbest: 0.0389610 (2668)\ttotal: 13m 41s\tremaining: 37m 37s\n",
      "2669:\tlearn: 0.0360894\ttest: 0.0389610\tbest: 0.0389610 (2668)\ttotal: 13m 42s\tremaining: 37m 37s\n",
      "2670:\tlearn: 0.0360894\ttest: 0.0389610\tbest: 0.0389610 (2670)\ttotal: 13m 42s\tremaining: 37m 36s\n",
      "2671:\tlearn: 0.0360894\ttest: 0.0389610\tbest: 0.0389610 (2671)\ttotal: 13m 42s\tremaining: 37m 36s\n",
      "2672:\tlearn: 0.0360858\ttest: 0.0389603\tbest: 0.0389603 (2672)\ttotal: 13m 43s\tremaining: 37m 35s\n",
      "2673:\tlearn: 0.0360858\ttest: 0.0389603\tbest: 0.0389603 (2673)\ttotal: 13m 43s\tremaining: 37m 35s\n",
      "2674:\tlearn: 0.0360858\ttest: 0.0389603\tbest: 0.0389603 (2673)\ttotal: 13m 43s\tremaining: 37m 35s\n",
      "2675:\tlearn: 0.0360810\ttest: 0.0389598\tbest: 0.0389598 (2675)\ttotal: 13m 43s\tremaining: 37m 34s\n",
      "2676:\tlearn: 0.0360810\ttest: 0.0389598\tbest: 0.0389598 (2676)\ttotal: 13m 44s\tremaining: 37m 34s\n",
      "2677:\tlearn: 0.0360810\ttest: 0.0389598\tbest: 0.0389598 (2677)\ttotal: 13m 44s\tremaining: 37m 34s\n",
      "2678:\tlearn: 0.0360810\ttest: 0.0389598\tbest: 0.0389598 (2678)\ttotal: 13m 45s\tremaining: 37m 34s\n",
      "2679:\tlearn: 0.0360753\ttest: 0.0389582\tbest: 0.0389582 (2679)\ttotal: 13m 45s\tremaining: 37m 34s\n",
      "2680:\tlearn: 0.0360753\ttest: 0.0389582\tbest: 0.0389582 (2679)\ttotal: 13m 46s\tremaining: 37m 35s\n",
      "2681:\tlearn: 0.0360753\ttest: 0.0389582\tbest: 0.0389582 (2681)\ttotal: 13m 46s\tremaining: 37m 35s\n",
      "2682:\tlearn: 0.0360753\ttest: 0.0389582\tbest: 0.0389582 (2682)\ttotal: 13m 46s\tremaining: 37m 35s\n",
      "2683:\tlearn: 0.0360753\ttest: 0.0389582\tbest: 0.0389582 (2683)\ttotal: 13m 47s\tremaining: 37m 35s\n",
      "2684:\tlearn: 0.0360753\ttest: 0.0389582\tbest: 0.0389582 (2683)\ttotal: 13m 47s\tremaining: 37m 35s\n",
      "2685:\tlearn: 0.0360753\ttest: 0.0389582\tbest: 0.0389582 (2685)\ttotal: 13m 48s\tremaining: 37m 35s\n",
      "2686:\tlearn: 0.0360753\ttest: 0.0389582\tbest: 0.0389582 (2686)\ttotal: 13m 48s\tremaining: 37m 34s\n",
      "2687:\tlearn: 0.0360712\ttest: 0.0389574\tbest: 0.0389574 (2687)\ttotal: 13m 48s\tremaining: 37m 34s\n",
      "2688:\tlearn: 0.0360712\ttest: 0.0389574\tbest: 0.0389574 (2687)\ttotal: 13m 49s\tremaining: 37m 34s\n",
      "2689:\tlearn: 0.0360712\ttest: 0.0389574\tbest: 0.0389574 (2689)\ttotal: 13m 49s\tremaining: 37m 33s\n",
      "2690:\tlearn: 0.0360646\ttest: 0.0389547\tbest: 0.0389547 (2690)\ttotal: 13m 49s\tremaining: 37m 33s\n",
      "2691:\tlearn: 0.0360646\ttest: 0.0389547\tbest: 0.0389547 (2690)\ttotal: 13m 49s\tremaining: 37m 32s\n",
      "2692:\tlearn: 0.0360645\ttest: 0.0389547\tbest: 0.0389547 (2692)\ttotal: 13m 50s\tremaining: 37m 32s\n",
      "2693:\tlearn: 0.0360610\ttest: 0.0389526\tbest: 0.0389526 (2693)\ttotal: 13m 50s\tremaining: 37m 32s\n",
      "2694:\tlearn: 0.0360576\ttest: 0.0389507\tbest: 0.0389507 (2694)\ttotal: 13m 50s\tremaining: 37m 31s\n",
      "2695:\tlearn: 0.0360576\ttest: 0.0389507\tbest: 0.0389507 (2694)\ttotal: 13m 50s\tremaining: 37m 31s\n",
      "2696:\tlearn: 0.0360524\ttest: 0.0389488\tbest: 0.0389488 (2696)\ttotal: 13m 51s\tremaining: 37m 31s\n",
      "2697:\tlearn: 0.0360524\ttest: 0.0389488\tbest: 0.0389488 (2697)\ttotal: 13m 51s\tremaining: 37m 30s\n",
      "2698:\tlearn: 0.0360524\ttest: 0.0389488\tbest: 0.0389488 (2698)\ttotal: 13m 51s\tremaining: 37m 30s\n",
      "2699:\tlearn: 0.0360524\ttest: 0.0389488\tbest: 0.0389488 (2699)\ttotal: 13m 52s\tremaining: 37m 29s\n",
      "2700:\tlearn: 0.0360524\ttest: 0.0389488\tbest: 0.0389488 (2699)\ttotal: 13m 52s\tremaining: 37m 29s\n",
      "2701:\tlearn: 0.0360524\ttest: 0.0389488\tbest: 0.0389488 (2701)\ttotal: 13m 52s\tremaining: 37m 28s\n",
      "2702:\tlearn: 0.0360524\ttest: 0.0389488\tbest: 0.0389488 (2702)\ttotal: 13m 52s\tremaining: 37m 28s\n",
      "2703:\tlearn: 0.0360524\ttest: 0.0389488\tbest: 0.0389488 (2703)\ttotal: 13m 53s\tremaining: 37m 27s\n",
      "2704:\tlearn: 0.0360484\ttest: 0.0389482\tbest: 0.0389482 (2704)\ttotal: 13m 53s\tremaining: 37m 27s\n",
      "2705:\tlearn: 0.0360484\ttest: 0.0389482\tbest: 0.0389482 (2705)\ttotal: 13m 53s\tremaining: 37m 26s\n",
      "2706:\tlearn: 0.0360484\ttest: 0.0389482\tbest: 0.0389482 (2705)\ttotal: 13m 53s\tremaining: 37m 26s\n",
      "2707:\tlearn: 0.0360484\ttest: 0.0389482\tbest: 0.0389482 (2705)\ttotal: 13m 54s\tremaining: 37m 26s\n",
      "2708:\tlearn: 0.0360484\ttest: 0.0389482\tbest: 0.0389482 (2705)\ttotal: 13m 54s\tremaining: 37m 25s\n",
      "2709:\tlearn: 0.0360444\ttest: 0.0389460\tbest: 0.0389460 (2709)\ttotal: 13m 54s\tremaining: 37m 25s\n",
      "2710:\tlearn: 0.0360444\ttest: 0.0389460\tbest: 0.0389460 (2710)\ttotal: 13m 54s\tremaining: 37m 24s\n",
      "2711:\tlearn: 0.0360444\ttest: 0.0389460\tbest: 0.0389460 (2711)\ttotal: 13m 55s\tremaining: 37m 24s\n",
      "2712:\tlearn: 0.0360444\ttest: 0.0389460\tbest: 0.0389460 (2712)\ttotal: 13m 55s\tremaining: 37m 24s\n",
      "2713:\tlearn: 0.0360444\ttest: 0.0389460\tbest: 0.0389460 (2712)\ttotal: 13m 55s\tremaining: 37m 23s\n",
      "2714:\tlearn: 0.0360444\ttest: 0.0389460\tbest: 0.0389460 (2714)\ttotal: 13m 55s\tremaining: 37m 23s\n",
      "2715:\tlearn: 0.0360444\ttest: 0.0389460\tbest: 0.0389460 (2715)\ttotal: 13m 56s\tremaining: 37m 22s\n",
      "2716:\tlearn: 0.0360445\ttest: 0.0389460\tbest: 0.0389460 (2716)\ttotal: 13m 56s\tremaining: 37m 22s\n",
      "2717:\tlearn: 0.0360445\ttest: 0.0389460\tbest: 0.0389460 (2716)\ttotal: 13m 56s\tremaining: 37m 21s\n",
      "2718:\tlearn: 0.0360445\ttest: 0.0389460\tbest: 0.0389460 (2716)\ttotal: 13m 56s\tremaining: 37m 21s\n",
      "2719:\tlearn: 0.0360397\ttest: 0.0389457\tbest: 0.0389457 (2719)\ttotal: 13m 57s\tremaining: 37m 20s\n",
      "2720:\tlearn: 0.0360331\ttest: 0.0389431\tbest: 0.0389431 (2720)\ttotal: 13m 57s\tremaining: 37m 20s\n",
      "2721:\tlearn: 0.0360332\ttest: 0.0389431\tbest: 0.0389431 (2721)\ttotal: 13m 57s\tremaining: 37m 20s\n",
      "2722:\tlearn: 0.0360332\ttest: 0.0389431\tbest: 0.0389431 (2722)\ttotal: 13m 58s\tremaining: 37m 19s\n",
      "2723:\tlearn: 0.0360331\ttest: 0.0389431\tbest: 0.0389431 (2723)\ttotal: 13m 58s\tremaining: 37m 19s\n",
      "2724:\tlearn: 0.0360331\ttest: 0.0389431\tbest: 0.0389431 (2724)\ttotal: 13m 58s\tremaining: 37m 19s\n",
      "2725:\tlearn: 0.0360331\ttest: 0.0389431\tbest: 0.0389431 (2724)\ttotal: 13m 59s\tremaining: 37m 19s\n",
      "2726:\tlearn: 0.0360331\ttest: 0.0389431\tbest: 0.0389431 (2726)\ttotal: 13m 59s\tremaining: 37m 19s\n",
      "2727:\tlearn: 0.0360331\ttest: 0.0389431\tbest: 0.0389431 (2726)\ttotal: 14m\tremaining: 37m 19s\n",
      "2728:\tlearn: 0.0360298\ttest: 0.0389417\tbest: 0.0389417 (2728)\ttotal: 14m\tremaining: 37m 20s\n",
      "2729:\tlearn: 0.0360277\ttest: 0.0389414\tbest: 0.0389414 (2729)\ttotal: 14m 1s\tremaining: 37m 20s\n",
      "2730:\tlearn: 0.0360277\ttest: 0.0389414\tbest: 0.0389414 (2729)\ttotal: 14m 1s\tremaining: 37m 20s\n",
      "2731:\tlearn: 0.0360202\ttest: 0.0389385\tbest: 0.0389385 (2731)\ttotal: 14m 2s\tremaining: 37m 20s\n",
      "2732:\tlearn: 0.0360202\ttest: 0.0389385\tbest: 0.0389385 (2732)\ttotal: 14m 2s\tremaining: 37m 20s\n",
      "2733:\tlearn: 0.0360158\ttest: 0.0389346\tbest: 0.0389346 (2733)\ttotal: 14m 2s\tremaining: 37m 19s\n",
      "2734:\tlearn: 0.0360158\ttest: 0.0389346\tbest: 0.0389346 (2733)\ttotal: 14m 3s\tremaining: 37m 19s\n",
      "2735:\tlearn: 0.0360158\ttest: 0.0389346\tbest: 0.0389346 (2735)\ttotal: 14m 3s\tremaining: 37m 18s\n",
      "2736:\tlearn: 0.0360082\ttest: 0.0389319\tbest: 0.0389319 (2736)\ttotal: 14m 3s\tremaining: 37m 18s\n",
      "2737:\tlearn: 0.0360082\ttest: 0.0389319\tbest: 0.0389319 (2737)\ttotal: 14m 3s\tremaining: 37m 18s\n",
      "2738:\tlearn: 0.0360082\ttest: 0.0389319\tbest: 0.0389319 (2738)\ttotal: 14m 4s\tremaining: 37m 17s\n",
      "2739:\tlearn: 0.0360082\ttest: 0.0389319\tbest: 0.0389319 (2738)\ttotal: 14m 4s\tremaining: 37m 17s\n",
      "2740:\tlearn: 0.0360082\ttest: 0.0389319\tbest: 0.0389319 (2740)\ttotal: 14m 4s\tremaining: 37m 16s\n",
      "2741:\tlearn: 0.0360082\ttest: 0.0389319\tbest: 0.0389319 (2740)\ttotal: 14m 4s\tremaining: 37m 16s\n",
      "2742:\tlearn: 0.0360082\ttest: 0.0389319\tbest: 0.0389319 (2742)\ttotal: 14m 5s\tremaining: 37m 15s\n",
      "2743:\tlearn: 0.0360082\ttest: 0.0389319\tbest: 0.0389319 (2743)\ttotal: 14m 5s\tremaining: 37m 15s\n",
      "2744:\tlearn: 0.0360082\ttest: 0.0389319\tbest: 0.0389319 (2743)\ttotal: 14m 5s\tremaining: 37m 14s\n",
      "2745:\tlearn: 0.0360082\ttest: 0.0389319\tbest: 0.0389319 (2743)\ttotal: 14m 5s\tremaining: 37m 14s\n",
      "2746:\tlearn: 0.0360047\ttest: 0.0389309\tbest: 0.0389309 (2746)\ttotal: 14m 6s\tremaining: 37m 14s\n",
      "2747:\tlearn: 0.0360047\ttest: 0.0389309\tbest: 0.0389309 (2746)\ttotal: 14m 6s\tremaining: 37m 13s\n",
      "2748:\tlearn: 0.0360047\ttest: 0.0389309\tbest: 0.0389309 (2746)\ttotal: 14m 6s\tremaining: 37m 13s\n",
      "2749:\tlearn: 0.0360047\ttest: 0.0389309\tbest: 0.0389309 (2746)\ttotal: 14m 6s\tremaining: 37m 12s\n",
      "2750:\tlearn: 0.0360047\ttest: 0.0389309\tbest: 0.0389309 (2750)\ttotal: 14m 7s\tremaining: 37m 12s\n",
      "2751:\tlearn: 0.0360047\ttest: 0.0389309\tbest: 0.0389309 (2750)\ttotal: 14m 7s\tremaining: 37m 11s\n",
      "2752:\tlearn: 0.0360047\ttest: 0.0389309\tbest: 0.0389309 (2752)\ttotal: 14m 7s\tremaining: 37m 11s\n",
      "2753:\tlearn: 0.0360002\ttest: 0.0389285\tbest: 0.0389285 (2753)\ttotal: 14m 7s\tremaining: 37m 11s\n",
      "2754:\tlearn: 0.0360002\ttest: 0.0389285\tbest: 0.0389285 (2754)\ttotal: 14m 8s\tremaining: 37m 10s\n",
      "2755:\tlearn: 0.0360002\ttest: 0.0389285\tbest: 0.0389285 (2755)\ttotal: 14m 8s\tremaining: 37m 10s\n",
      "2756:\tlearn: 0.0359956\ttest: 0.0389277\tbest: 0.0389277 (2756)\ttotal: 14m 8s\tremaining: 37m 9s\n",
      "2757:\tlearn: 0.0359956\ttest: 0.0389277\tbest: 0.0389277 (2756)\ttotal: 14m 9s\tremaining: 37m 9s\n",
      "2758:\tlearn: 0.0359956\ttest: 0.0389277\tbest: 0.0389277 (2758)\ttotal: 14m 9s\tremaining: 37m 9s\n",
      "2759:\tlearn: 0.0359878\ttest: 0.0389239\tbest: 0.0389239 (2759)\ttotal: 14m 9s\tremaining: 37m 8s\n",
      "2760:\tlearn: 0.0359878\ttest: 0.0389239\tbest: 0.0389239 (2760)\ttotal: 14m 9s\tremaining: 37m 8s\n",
      "2761:\tlearn: 0.0359878\ttest: 0.0389239\tbest: 0.0389239 (2761)\ttotal: 14m 10s\tremaining: 37m 7s\n",
      "2762:\tlearn: 0.0359878\ttest: 0.0389239\tbest: 0.0389239 (2762)\ttotal: 14m 10s\tremaining: 37m 7s\n",
      "2763:\tlearn: 0.0359825\ttest: 0.0389212\tbest: 0.0389212 (2763)\ttotal: 14m 10s\tremaining: 37m 7s\n",
      "2764:\tlearn: 0.0359825\ttest: 0.0389212\tbest: 0.0389212 (2764)\ttotal: 14m 10s\tremaining: 37m 6s\n",
      "2765:\tlearn: 0.0359788\ttest: 0.0389195\tbest: 0.0389195 (2765)\ttotal: 14m 11s\tremaining: 37m 6s\n",
      "2766:\tlearn: 0.0359788\ttest: 0.0389195\tbest: 0.0389195 (2766)\ttotal: 14m 11s\tremaining: 37m 5s\n",
      "2767:\tlearn: 0.0359788\ttest: 0.0389195\tbest: 0.0389195 (2766)\ttotal: 14m 11s\tremaining: 37m 5s\n",
      "2768:\tlearn: 0.0359788\ttest: 0.0389195\tbest: 0.0389195 (2766)\ttotal: 14m 12s\tremaining: 37m 5s\n",
      "2769:\tlearn: 0.0359788\ttest: 0.0389195\tbest: 0.0389195 (2769)\ttotal: 14m 12s\tremaining: 37m 4s\n",
      "2770:\tlearn: 0.0359788\ttest: 0.0389195\tbest: 0.0389195 (2770)\ttotal: 14m 12s\tremaining: 37m 4s\n",
      "2771:\tlearn: 0.0359788\ttest: 0.0389194\tbest: 0.0389194 (2771)\ttotal: 14m 13s\tremaining: 37m 4s\n",
      "2772:\tlearn: 0.0359788\ttest: 0.0389194\tbest: 0.0389194 (2772)\ttotal: 14m 13s\tremaining: 37m 5s\n",
      "2773:\tlearn: 0.0359739\ttest: 0.0389180\tbest: 0.0389180 (2773)\ttotal: 14m 14s\tremaining: 37m 5s\n",
      "2774:\tlearn: 0.0359739\ttest: 0.0389180\tbest: 0.0389180 (2774)\ttotal: 14m 14s\tremaining: 37m 5s\n",
      "2775:\tlearn: 0.0359739\ttest: 0.0389179\tbest: 0.0389179 (2775)\ttotal: 14m 15s\tremaining: 37m 5s\n",
      "2776:\tlearn: 0.0359717\ttest: 0.0389169\tbest: 0.0389169 (2776)\ttotal: 14m 15s\tremaining: 37m 5s\n",
      "2777:\tlearn: 0.0359667\ttest: 0.0389144\tbest: 0.0389144 (2777)\ttotal: 14m 16s\tremaining: 37m 6s\n",
      "2778:\tlearn: 0.0359614\ttest: 0.0389125\tbest: 0.0389125 (2778)\ttotal: 14m 16s\tremaining: 37m 5s\n",
      "2779:\tlearn: 0.0359566\ttest: 0.0389108\tbest: 0.0389108 (2779)\ttotal: 14m 16s\tremaining: 37m 5s\n",
      "2780:\tlearn: 0.0359566\ttest: 0.0389108\tbest: 0.0389108 (2779)\ttotal: 14m 17s\tremaining: 37m 5s\n",
      "2781:\tlearn: 0.0359566\ttest: 0.0389108\tbest: 0.0389108 (2781)\ttotal: 14m 17s\tremaining: 37m 4s\n",
      "2782:\tlearn: 0.0359510\ttest: 0.0389074\tbest: 0.0389074 (2782)\ttotal: 14m 17s\tremaining: 37m 4s\n",
      "2783:\tlearn: 0.0359447\ttest: 0.0389030\tbest: 0.0389030 (2783)\ttotal: 14m 18s\tremaining: 37m 4s\n",
      "2784:\tlearn: 0.0359447\ttest: 0.0389029\tbest: 0.0389029 (2784)\ttotal: 14m 18s\tremaining: 37m 3s\n",
      "2785:\tlearn: 0.0359447\ttest: 0.0389029\tbest: 0.0389029 (2785)\ttotal: 14m 18s\tremaining: 37m 3s\n",
      "2786:\tlearn: 0.0359447\ttest: 0.0389029\tbest: 0.0389029 (2786)\ttotal: 14m 18s\tremaining: 37m 2s\n",
      "2787:\tlearn: 0.0359446\ttest: 0.0389029\tbest: 0.0389029 (2787)\ttotal: 14m 19s\tremaining: 37m 2s\n",
      "2788:\tlearn: 0.0359446\ttest: 0.0389029\tbest: 0.0389029 (2788)\ttotal: 14m 19s\tremaining: 37m 2s\n",
      "2789:\tlearn: 0.0359446\ttest: 0.0389029\tbest: 0.0389029 (2788)\ttotal: 14m 19s\tremaining: 37m 1s\n",
      "2790:\tlearn: 0.0359446\ttest: 0.0389029\tbest: 0.0389029 (2790)\ttotal: 14m 19s\tremaining: 37m 1s\n",
      "2791:\tlearn: 0.0359412\ttest: 0.0389020\tbest: 0.0389020 (2791)\ttotal: 14m 20s\tremaining: 37m\n",
      "2792:\tlearn: 0.0359355\ttest: 0.0389000\tbest: 0.0389000 (2792)\ttotal: 14m 20s\tremaining: 37m\n",
      "2793:\tlearn: 0.0359355\ttest: 0.0389000\tbest: 0.0389000 (2793)\ttotal: 14m 20s\tremaining: 36m 59s\n",
      "2794:\tlearn: 0.0359278\ttest: 0.0388981\tbest: 0.0388981 (2794)\ttotal: 14m 21s\tremaining: 36m 59s\n",
      "2795:\tlearn: 0.0359237\ttest: 0.0388978\tbest: 0.0388978 (2795)\ttotal: 14m 21s\tremaining: 36m 59s\n",
      "2796:\tlearn: 0.0359237\ttest: 0.0388978\tbest: 0.0388978 (2796)\ttotal: 14m 21s\tremaining: 36m 58s\n",
      "2797:\tlearn: 0.0359237\ttest: 0.0388978\tbest: 0.0388978 (2797)\ttotal: 14m 21s\tremaining: 36m 58s\n",
      "2798:\tlearn: 0.0359237\ttest: 0.0388978\tbest: 0.0388978 (2798)\ttotal: 14m 22s\tremaining: 36m 57s\n",
      "2799:\tlearn: 0.0359237\ttest: 0.0388978\tbest: 0.0388978 (2799)\ttotal: 14m 22s\tremaining: 36m 57s\n",
      "2800:\tlearn: 0.0359202\ttest: 0.0388958\tbest: 0.0388958 (2800)\ttotal: 14m 22s\tremaining: 36m 57s\n",
      "2801:\tlearn: 0.0359201\ttest: 0.0388958\tbest: 0.0388958 (2801)\ttotal: 14m 22s\tremaining: 36m 56s\n",
      "2802:\tlearn: 0.0359159\ttest: 0.0388936\tbest: 0.0388936 (2802)\ttotal: 14m 23s\tremaining: 36m 56s\n",
      "2803:\tlearn: 0.0359114\ttest: 0.0388909\tbest: 0.0388909 (2803)\ttotal: 14m 23s\tremaining: 36m 56s\n",
      "2804:\tlearn: 0.0359089\ttest: 0.0388905\tbest: 0.0388905 (2804)\ttotal: 14m 23s\tremaining: 36m 55s\n",
      "2805:\tlearn: 0.0359089\ttest: 0.0388905\tbest: 0.0388905 (2805)\ttotal: 14m 24s\tremaining: 36m 55s\n",
      "2806:\tlearn: 0.0359034\ttest: 0.0388878\tbest: 0.0388878 (2806)\ttotal: 14m 24s\tremaining: 36m 55s\n",
      "2807:\tlearn: 0.0359034\ttest: 0.0388878\tbest: 0.0388878 (2807)\ttotal: 14m 24s\tremaining: 36m 54s\n",
      "2808:\tlearn: 0.0359034\ttest: 0.0388878\tbest: 0.0388878 (2808)\ttotal: 14m 24s\tremaining: 36m 54s\n",
      "2809:\tlearn: 0.0358987\ttest: 0.0388862\tbest: 0.0388862 (2809)\ttotal: 14m 25s\tremaining: 36m 54s\n",
      "2810:\tlearn: 0.0358987\ttest: 0.0388862\tbest: 0.0388862 (2810)\ttotal: 14m 25s\tremaining: 36m 53s\n",
      "2811:\tlearn: 0.0358952\ttest: 0.0388849\tbest: 0.0388849 (2811)\ttotal: 14m 25s\tremaining: 36m 53s\n",
      "2812:\tlearn: 0.0358952\ttest: 0.0388849\tbest: 0.0388849 (2812)\ttotal: 14m 26s\tremaining: 36m 52s\n",
      "2813:\tlearn: 0.0358952\ttest: 0.0388849\tbest: 0.0388849 (2813)\ttotal: 14m 26s\tremaining: 36m 52s\n",
      "2814:\tlearn: 0.0358919\ttest: 0.0388843\tbest: 0.0388843 (2814)\ttotal: 14m 26s\tremaining: 36m 52s\n",
      "2815:\tlearn: 0.0358919\ttest: 0.0388843\tbest: 0.0388843 (2814)\ttotal: 14m 27s\tremaining: 36m 52s\n",
      "2816:\tlearn: 0.0358919\ttest: 0.0388843\tbest: 0.0388843 (2816)\ttotal: 14m 27s\tremaining: 36m 52s\n",
      "2817:\tlearn: 0.0358919\ttest: 0.0388843\tbest: 0.0388843 (2817)\ttotal: 14m 28s\tremaining: 36m 52s\n",
      "2818:\tlearn: 0.0358919\ttest: 0.0388843\tbest: 0.0388843 (2817)\ttotal: 14m 28s\tremaining: 36m 52s\n",
      "2819:\tlearn: 0.0358867\ttest: 0.0388832\tbest: 0.0388832 (2819)\ttotal: 14m 29s\tremaining: 36m 53s\n",
      "2820:\tlearn: 0.0358867\ttest: 0.0388832\tbest: 0.0388832 (2819)\ttotal: 14m 29s\tremaining: 36m 53s\n",
      "2821:\tlearn: 0.0358866\ttest: 0.0388832\tbest: 0.0388832 (2821)\ttotal: 14m 30s\tremaining: 36m 53s\n",
      "2822:\tlearn: 0.0358866\ttest: 0.0388832\tbest: 0.0388832 (2822)\ttotal: 14m 30s\tremaining: 36m 52s\n",
      "2823:\tlearn: 0.0358802\ttest: 0.0388808\tbest: 0.0388808 (2823)\ttotal: 14m 30s\tremaining: 36m 52s\n",
      "2824:\tlearn: 0.0358802\ttest: 0.0388808\tbest: 0.0388808 (2824)\ttotal: 14m 30s\tremaining: 36m 51s\n",
      "2825:\tlearn: 0.0358802\ttest: 0.0388808\tbest: 0.0388808 (2825)\ttotal: 14m 31s\tremaining: 36m 51s\n",
      "2826:\tlearn: 0.0358802\ttest: 0.0388808\tbest: 0.0388808 (2826)\ttotal: 14m 31s\tremaining: 36m 51s\n",
      "2827:\tlearn: 0.0358754\ttest: 0.0388805\tbest: 0.0388805 (2827)\ttotal: 14m 31s\tremaining: 36m 50s\n",
      "2828:\tlearn: 0.0358697\ttest: 0.0388784\tbest: 0.0388784 (2828)\ttotal: 14m 32s\tremaining: 36m 50s\n",
      "2829:\tlearn: 0.0358697\ttest: 0.0388784\tbest: 0.0388784 (2829)\ttotal: 14m 32s\tremaining: 36m 50s\n",
      "2830:\tlearn: 0.0358697\ttest: 0.0388784\tbest: 0.0388784 (2830)\ttotal: 14m 32s\tremaining: 36m 49s\n",
      "2831:\tlearn: 0.0358696\ttest: 0.0388784\tbest: 0.0388784 (2830)\ttotal: 14m 32s\tremaining: 36m 49s\n",
      "2832:\tlearn: 0.0358697\ttest: 0.0388784\tbest: 0.0388784 (2830)\ttotal: 14m 33s\tremaining: 36m 48s\n",
      "2833:\tlearn: 0.0358697\ttest: 0.0388784\tbest: 0.0388784 (2830)\ttotal: 14m 33s\tremaining: 36m 48s\n",
      "2834:\tlearn: 0.0358697\ttest: 0.0388784\tbest: 0.0388784 (2830)\ttotal: 14m 33s\tremaining: 36m 47s\n",
      "2835:\tlearn: 0.0358696\ttest: 0.0388784\tbest: 0.0388784 (2835)\ttotal: 14m 33s\tremaining: 36m 47s\n",
      "2836:\tlearn: 0.0358696\ttest: 0.0388784\tbest: 0.0388784 (2835)\ttotal: 14m 34s\tremaining: 36m 46s\n",
      "2837:\tlearn: 0.0358696\ttest: 0.0388784\tbest: 0.0388784 (2837)\ttotal: 14m 34s\tremaining: 36m 46s\n",
      "2838:\tlearn: 0.0358602\ttest: 0.0388749\tbest: 0.0388749 (2838)\ttotal: 14m 34s\tremaining: 36m 46s\n",
      "2839:\tlearn: 0.0358564\ttest: 0.0388726\tbest: 0.0388726 (2839)\ttotal: 14m 34s\tremaining: 36m 45s\n",
      "2840:\tlearn: 0.0358545\ttest: 0.0388729\tbest: 0.0388726 (2839)\ttotal: 14m 35s\tremaining: 36m 45s\n",
      "2841:\tlearn: 0.0358545\ttest: 0.0388729\tbest: 0.0388726 (2839)\ttotal: 14m 35s\tremaining: 36m 44s\n",
      "2842:\tlearn: 0.0358545\ttest: 0.0388729\tbest: 0.0388726 (2839)\ttotal: 14m 35s\tremaining: 36m 44s\n",
      "2843:\tlearn: 0.0358449\ttest: 0.0388663\tbest: 0.0388663 (2843)\ttotal: 14m 36s\tremaining: 36m 44s\n",
      "2844:\tlearn: 0.0358448\ttest: 0.0388663\tbest: 0.0388663 (2843)\ttotal: 14m 36s\tremaining: 36m 43s\n",
      "2845:\tlearn: 0.0358448\ttest: 0.0388663\tbest: 0.0388663 (2845)\ttotal: 14m 36s\tremaining: 36m 43s\n",
      "2846:\tlearn: 0.0358448\ttest: 0.0388663\tbest: 0.0388663 (2846)\ttotal: 14m 36s\tremaining: 36m 42s\n",
      "2847:\tlearn: 0.0358421\ttest: 0.0388649\tbest: 0.0388649 (2847)\ttotal: 14m 37s\tremaining: 36m 42s\n",
      "2848:\tlearn: 0.0358421\ttest: 0.0388649\tbest: 0.0388649 (2848)\ttotal: 14m 37s\tremaining: 36m 42s\n",
      "2849:\tlearn: 0.0358421\ttest: 0.0388649\tbest: 0.0388649 (2848)\ttotal: 14m 37s\tremaining: 36m 41s\n",
      "2850:\tlearn: 0.0358421\ttest: 0.0388649\tbest: 0.0388649 (2850)\ttotal: 14m 37s\tremaining: 36m 41s\n",
      "2851:\tlearn: 0.0358421\ttest: 0.0388649\tbest: 0.0388649 (2851)\ttotal: 14m 38s\tremaining: 36m 40s\n",
      "2852:\tlearn: 0.0358421\ttest: 0.0388649\tbest: 0.0388649 (2852)\ttotal: 14m 38s\tremaining: 36m 40s\n",
      "2853:\tlearn: 0.0358421\ttest: 0.0388649\tbest: 0.0388649 (2852)\ttotal: 14m 38s\tremaining: 36m 39s\n",
      "2854:\tlearn: 0.0358421\ttest: 0.0388649\tbest: 0.0388649 (2854)\ttotal: 14m 38s\tremaining: 36m 39s\n",
      "2855:\tlearn: 0.0358421\ttest: 0.0388649\tbest: 0.0388649 (2854)\ttotal: 14m 39s\tremaining: 36m 39s\n",
      "2856:\tlearn: 0.0358328\ttest: 0.0388608\tbest: 0.0388608 (2856)\ttotal: 14m 39s\tremaining: 36m 38s\n",
      "2857:\tlearn: 0.0358305\ttest: 0.0388601\tbest: 0.0388601 (2857)\ttotal: 14m 39s\tremaining: 36m 38s\n",
      "2858:\tlearn: 0.0358305\ttest: 0.0388601\tbest: 0.0388601 (2857)\ttotal: 14m 40s\tremaining: 36m 38s\n",
      "2859:\tlearn: 0.0358304\ttest: 0.0388601\tbest: 0.0388601 (2859)\ttotal: 14m 40s\tremaining: 36m 38s\n",
      "2860:\tlearn: 0.0358304\ttest: 0.0388601\tbest: 0.0388601 (2860)\ttotal: 14m 40s\tremaining: 36m 38s\n",
      "2861:\tlearn: 0.0358212\ttest: 0.0388542\tbest: 0.0388542 (2861)\ttotal: 14m 41s\tremaining: 36m 38s\n",
      "2862:\tlearn: 0.0358158\ttest: 0.0388505\tbest: 0.0388505 (2862)\ttotal: 14m 41s\tremaining: 36m 38s\n",
      "2863:\tlearn: 0.0358116\ttest: 0.0388499\tbest: 0.0388499 (2863)\ttotal: 14m 42s\tremaining: 36m 38s\n",
      "2864:\tlearn: 0.0358116\ttest: 0.0388499\tbest: 0.0388499 (2864)\ttotal: 14m 42s\tremaining: 36m 38s\n",
      "2865:\tlearn: 0.0358116\ttest: 0.0388499\tbest: 0.0388499 (2865)\ttotal: 14m 43s\tremaining: 36m 38s\n",
      "2866:\tlearn: 0.0358116\ttest: 0.0388499\tbest: 0.0388499 (2866)\ttotal: 14m 43s\tremaining: 36m 38s\n",
      "2867:\tlearn: 0.0358066\ttest: 0.0388493\tbest: 0.0388493 (2867)\ttotal: 14m 44s\tremaining: 36m 39s\n",
      "2868:\tlearn: 0.0358066\ttest: 0.0388493\tbest: 0.0388493 (2868)\ttotal: 14m 44s\tremaining: 36m 38s\n",
      "2869:\tlearn: 0.0358025\ttest: 0.0388473\tbest: 0.0388473 (2869)\ttotal: 14m 44s\tremaining: 36m 38s\n",
      "2870:\tlearn: 0.0358024\ttest: 0.0388473\tbest: 0.0388473 (2869)\ttotal: 14m 45s\tremaining: 36m 37s\n",
      "2871:\tlearn: 0.0357930\ttest: 0.0388428\tbest: 0.0388428 (2871)\ttotal: 14m 45s\tremaining: 36m 37s\n",
      "2872:\tlearn: 0.0357930\ttest: 0.0388428\tbest: 0.0388428 (2871)\ttotal: 14m 45s\tremaining: 36m 37s\n",
      "2873:\tlearn: 0.0357930\ttest: 0.0388428\tbest: 0.0388428 (2873)\ttotal: 14m 45s\tremaining: 36m 36s\n",
      "2874:\tlearn: 0.0357930\ttest: 0.0388428\tbest: 0.0388428 (2873)\ttotal: 14m 46s\tremaining: 36m 36s\n",
      "2875:\tlearn: 0.0357929\ttest: 0.0388428\tbest: 0.0388428 (2875)\ttotal: 14m 46s\tremaining: 36m 35s\n",
      "2876:\tlearn: 0.0357929\ttest: 0.0388428\tbest: 0.0388428 (2876)\ttotal: 14m 46s\tremaining: 36m 35s\n",
      "2877:\tlearn: 0.0357929\ttest: 0.0388428\tbest: 0.0388428 (2876)\ttotal: 14m 46s\tremaining: 36m 34s\n",
      "2878:\tlearn: 0.0357929\ttest: 0.0388428\tbest: 0.0388428 (2878)\ttotal: 14m 47s\tremaining: 36m 34s\n",
      "2879:\tlearn: 0.0357929\ttest: 0.0388428\tbest: 0.0388428 (2879)\ttotal: 14m 47s\tremaining: 36m 34s\n",
      "2880:\tlearn: 0.0357929\ttest: 0.0388428\tbest: 0.0388428 (2879)\ttotal: 14m 47s\tremaining: 36m 33s\n",
      "2881:\tlearn: 0.0357929\ttest: 0.0388428\tbest: 0.0388428 (2881)\ttotal: 14m 47s\tremaining: 36m 33s\n",
      "2882:\tlearn: 0.0357929\ttest: 0.0388427\tbest: 0.0388427 (2882)\ttotal: 14m 48s\tremaining: 36m 32s\n",
      "2883:\tlearn: 0.0357929\ttest: 0.0388427\tbest: 0.0388427 (2882)\ttotal: 14m 48s\tremaining: 36m 32s\n",
      "2884:\tlearn: 0.0357929\ttest: 0.0388427\tbest: 0.0388427 (2884)\ttotal: 14m 48s\tremaining: 36m 31s\n",
      "2885:\tlearn: 0.0357929\ttest: 0.0388427\tbest: 0.0388427 (2885)\ttotal: 14m 48s\tremaining: 36m 31s\n",
      "2886:\tlearn: 0.0357929\ttest: 0.0388427\tbest: 0.0388427 (2885)\ttotal: 14m 49s\tremaining: 36m 30s\n",
      "2887:\tlearn: 0.0357929\ttest: 0.0388427\tbest: 0.0388427 (2887)\ttotal: 14m 49s\tremaining: 36m 30s\n",
      "2888:\tlearn: 0.0357929\ttest: 0.0388427\tbest: 0.0388427 (2888)\ttotal: 14m 49s\tremaining: 36m 30s\n",
      "2889:\tlearn: 0.0357929\ttest: 0.0388427\tbest: 0.0388427 (2889)\ttotal: 14m 50s\tremaining: 36m 29s\n",
      "2890:\tlearn: 0.0357929\ttest: 0.0388427\tbest: 0.0388427 (2890)\ttotal: 14m 50s\tremaining: 36m 29s\n",
      "2891:\tlearn: 0.0357929\ttest: 0.0388427\tbest: 0.0388427 (2890)\ttotal: 14m 50s\tremaining: 36m 28s\n",
      "2892:\tlearn: 0.0357929\ttest: 0.0388427\tbest: 0.0388427 (2890)\ttotal: 14m 50s\tremaining: 36m 28s\n",
      "2893:\tlearn: 0.0357929\ttest: 0.0388427\tbest: 0.0388427 (2890)\ttotal: 14m 51s\tremaining: 36m 27s\n",
      "2894:\tlearn: 0.0357929\ttest: 0.0388427\tbest: 0.0388427 (2890)\ttotal: 14m 51s\tremaining: 36m 27s\n",
      "2895:\tlearn: 0.0357929\ttest: 0.0388427\tbest: 0.0388427 (2890)\ttotal: 14m 51s\tremaining: 36m 27s\n",
      "2896:\tlearn: 0.0357929\ttest: 0.0388427\tbest: 0.0388427 (2896)\ttotal: 14m 51s\tremaining: 36m 26s\n",
      "2897:\tlearn: 0.0357929\ttest: 0.0388427\tbest: 0.0388427 (2897)\ttotal: 14m 52s\tremaining: 36m 26s\n",
      "2898:\tlearn: 0.0357929\ttest: 0.0388427\tbest: 0.0388427 (2897)\ttotal: 14m 52s\tremaining: 36m 25s\n",
      "2899:\tlearn: 0.0357929\ttest: 0.0388427\tbest: 0.0388427 (2899)\ttotal: 14m 52s\tremaining: 36m 25s\n",
      "2900:\tlearn: 0.0357929\ttest: 0.0388427\tbest: 0.0388427 (2900)\ttotal: 14m 52s\tremaining: 36m 24s\n",
      "2901:\tlearn: 0.0357929\ttest: 0.0388427\tbest: 0.0388427 (2901)\ttotal: 14m 53s\tremaining: 36m 24s\n",
      "2902:\tlearn: 0.0357929\ttest: 0.0388427\tbest: 0.0388427 (2902)\ttotal: 14m 53s\tremaining: 36m 23s\n",
      "2903:\tlearn: 0.0357929\ttest: 0.0388427\tbest: 0.0388427 (2902)\ttotal: 14m 53s\tremaining: 36m 23s\n",
      "2904:\tlearn: 0.0357929\ttest: 0.0388427\tbest: 0.0388427 (2902)\ttotal: 14m 53s\tremaining: 36m 22s\n",
      "2905:\tlearn: 0.0357929\ttest: 0.0388427\tbest: 0.0388427 (2905)\ttotal: 14m 54s\tremaining: 36m 22s\n",
      "2906:\tlearn: 0.0357929\ttest: 0.0388427\tbest: 0.0388427 (2906)\ttotal: 14m 54s\tremaining: 36m 22s\n",
      "2907:\tlearn: 0.0357929\ttest: 0.0388427\tbest: 0.0388427 (2907)\ttotal: 14m 54s\tremaining: 36m 22s\n",
      "2908:\tlearn: 0.0357929\ttest: 0.0388427\tbest: 0.0388427 (2908)\ttotal: 14m 55s\tremaining: 36m 22s\n",
      "2909:\tlearn: 0.0357929\ttest: 0.0388427\tbest: 0.0388427 (2908)\ttotal: 14m 55s\tremaining: 36m 22s\n",
      "2910:\tlearn: 0.0357877\ttest: 0.0388419\tbest: 0.0388419 (2910)\ttotal: 14m 56s\tremaining: 36m 22s\n",
      "2911:\tlearn: 0.0357877\ttest: 0.0388419\tbest: 0.0388419 (2911)\ttotal: 14m 56s\tremaining: 36m 22s\n",
      "2912:\tlearn: 0.0357877\ttest: 0.0388419\tbest: 0.0388419 (2912)\ttotal: 14m 57s\tremaining: 36m 22s\n",
      "2913:\tlearn: 0.0357877\ttest: 0.0388419\tbest: 0.0388419 (2913)\ttotal: 14m 57s\tremaining: 36m 22s\n",
      "2914:\tlearn: 0.0357818\ttest: 0.0388391\tbest: 0.0388391 (2914)\ttotal: 14m 58s\tremaining: 36m 23s\n",
      "2915:\tlearn: 0.0357818\ttest: 0.0388391\tbest: 0.0388391 (2915)\ttotal: 14m 58s\tremaining: 36m 23s\n",
      "2916:\tlearn: 0.0357756\ttest: 0.0388348\tbest: 0.0388348 (2916)\ttotal: 14m 58s\tremaining: 36m 22s\n",
      "2917:\tlearn: 0.0357756\ttest: 0.0388348\tbest: 0.0388348 (2916)\ttotal: 14m 59s\tremaining: 36m 22s\n",
      "2918:\tlearn: 0.0357756\ttest: 0.0388348\tbest: 0.0388348 (2916)\ttotal: 14m 59s\tremaining: 36m 21s\n",
      "2919:\tlearn: 0.0357757\ttest: 0.0388348\tbest: 0.0388348 (2919)\ttotal: 14m 59s\tremaining: 36m 21s\n",
      "2920:\tlearn: 0.0357756\ttest: 0.0388348\tbest: 0.0388348 (2920)\ttotal: 14m 59s\tremaining: 36m 21s\n",
      "2921:\tlearn: 0.0357756\ttest: 0.0388348\tbest: 0.0388348 (2920)\ttotal: 15m\tremaining: 36m 20s\n",
      "2922:\tlearn: 0.0357756\ttest: 0.0388348\tbest: 0.0388348 (2920)\ttotal: 15m\tremaining: 36m 20s\n",
      "2923:\tlearn: 0.0357756\ttest: 0.0388348\tbest: 0.0388348 (2923)\ttotal: 15m\tremaining: 36m 19s\n",
      "2924:\tlearn: 0.0357756\ttest: 0.0388348\tbest: 0.0388348 (2924)\ttotal: 15m\tremaining: 36m 19s\n",
      "2925:\tlearn: 0.0357756\ttest: 0.0388348\tbest: 0.0388348 (2924)\ttotal: 15m 1s\tremaining: 36m 18s\n",
      "2926:\tlearn: 0.0357756\ttest: 0.0388348\tbest: 0.0388348 (2924)\ttotal: 15m 1s\tremaining: 36m 18s\n",
      "2927:\tlearn: 0.0357756\ttest: 0.0388348\tbest: 0.0388348 (2927)\ttotal: 15m 1s\tremaining: 36m 18s\n",
      "2928:\tlearn: 0.0357756\ttest: 0.0388348\tbest: 0.0388348 (2927)\ttotal: 15m 2s\tremaining: 36m 17s\n",
      "2929:\tlearn: 0.0357756\ttest: 0.0388348\tbest: 0.0388348 (2929)\ttotal: 15m 2s\tremaining: 36m 17s\n",
      "2930:\tlearn: 0.0357756\ttest: 0.0388348\tbest: 0.0388348 (2930)\ttotal: 15m 2s\tremaining: 36m 16s\n",
      "2931:\tlearn: 0.0357756\ttest: 0.0388348\tbest: 0.0388348 (2930)\ttotal: 15m 2s\tremaining: 36m 16s\n",
      "2932:\tlearn: 0.0357756\ttest: 0.0388348\tbest: 0.0388348 (2932)\ttotal: 15m 3s\tremaining: 36m 15s\n",
      "2933:\tlearn: 0.0357756\ttest: 0.0388348\tbest: 0.0388348 (2933)\ttotal: 15m 3s\tremaining: 36m 15s\n",
      "2934:\tlearn: 0.0357756\ttest: 0.0388348\tbest: 0.0388348 (2934)\ttotal: 15m 3s\tremaining: 36m 15s\n",
      "2935:\tlearn: 0.0357756\ttest: 0.0388348\tbest: 0.0388348 (2935)\ttotal: 15m 3s\tremaining: 36m 14s\n",
      "2936:\tlearn: 0.0357756\ttest: 0.0388348\tbest: 0.0388348 (2936)\ttotal: 15m 4s\tremaining: 36m 14s\n",
      "2937:\tlearn: 0.0357671\ttest: 0.0388299\tbest: 0.0388299 (2937)\ttotal: 15m 4s\tremaining: 36m 13s\n",
      "2938:\tlearn: 0.0357558\ttest: 0.0388232\tbest: 0.0388232 (2938)\ttotal: 15m 4s\tremaining: 36m 13s\n",
      "2939:\tlearn: 0.0357558\ttest: 0.0388232\tbest: 0.0388232 (2938)\ttotal: 15m 5s\tremaining: 36m 13s\n",
      "2940:\tlearn: 0.0357558\ttest: 0.0388232\tbest: 0.0388232 (2938)\ttotal: 15m 5s\tremaining: 36m 12s\n",
      "2941:\tlearn: 0.0357558\ttest: 0.0388232\tbest: 0.0388232 (2938)\ttotal: 15m 5s\tremaining: 36m 12s\n",
      "2942:\tlearn: 0.0357558\ttest: 0.0388232\tbest: 0.0388232 (2942)\ttotal: 15m 5s\tremaining: 36m 11s\n",
      "2943:\tlearn: 0.0357558\ttest: 0.0388232\tbest: 0.0388232 (2943)\ttotal: 15m 5s\tremaining: 36m 11s\n",
      "2944:\tlearn: 0.0357558\ttest: 0.0388232\tbest: 0.0388232 (2944)\ttotal: 15m 6s\tremaining: 36m 10s\n",
      "2945:\tlearn: 0.0357511\ttest: 0.0388229\tbest: 0.0388229 (2945)\ttotal: 15m 6s\tremaining: 36m 10s\n",
      "2946:\tlearn: 0.0357511\ttest: 0.0388229\tbest: 0.0388229 (2946)\ttotal: 15m 6s\tremaining: 36m 10s\n",
      "2947:\tlearn: 0.0357511\ttest: 0.0388229\tbest: 0.0388229 (2947)\ttotal: 15m 7s\tremaining: 36m 9s\n",
      "2948:\tlearn: 0.0357511\ttest: 0.0388229\tbest: 0.0388229 (2947)\ttotal: 15m 7s\tremaining: 36m 9s\n",
      "2949:\tlearn: 0.0357464\ttest: 0.0388216\tbest: 0.0388216 (2949)\ttotal: 15m 7s\tremaining: 36m 9s\n",
      "2950:\tlearn: 0.0357464\ttest: 0.0388216\tbest: 0.0388216 (2949)\ttotal: 15m 7s\tremaining: 36m 8s\n",
      "2951:\tlearn: 0.0357464\ttest: 0.0388216\tbest: 0.0388216 (2951)\ttotal: 15m 8s\tremaining: 36m 8s\n",
      "2952:\tlearn: 0.0357464\ttest: 0.0388216\tbest: 0.0388216 (2951)\ttotal: 15m 8s\tremaining: 36m 7s\n",
      "2953:\tlearn: 0.0357464\ttest: 0.0388216\tbest: 0.0388216 (2953)\ttotal: 15m 8s\tremaining: 36m 7s\n",
      "2954:\tlearn: 0.0357464\ttest: 0.0388216\tbest: 0.0388216 (2954)\ttotal: 15m 9s\tremaining: 36m 7s\n",
      "2955:\tlearn: 0.0357464\ttest: 0.0388216\tbest: 0.0388216 (2954)\ttotal: 15m 9s\tremaining: 36m 7s\n",
      "2956:\tlearn: 0.0357464\ttest: 0.0388216\tbest: 0.0388216 (2956)\ttotal: 15m 9s\tremaining: 36m 7s\n",
      "2957:\tlearn: 0.0357464\ttest: 0.0388216\tbest: 0.0388216 (2957)\ttotal: 15m 10s\tremaining: 36m 7s\n",
      "2958:\tlearn: 0.0357419\ttest: 0.0388208\tbest: 0.0388208 (2958)\ttotal: 15m 11s\tremaining: 36m 7s\n",
      "2959:\tlearn: 0.0357419\ttest: 0.0388208\tbest: 0.0388208 (2959)\ttotal: 15m 11s\tremaining: 36m 7s\n",
      "2960:\tlearn: 0.0357419\ttest: 0.0388208\tbest: 0.0388208 (2959)\ttotal: 15m 12s\tremaining: 36m 8s\n",
      "2961:\tlearn: 0.0357419\ttest: 0.0388208\tbest: 0.0388208 (2961)\ttotal: 15m 12s\tremaining: 36m 8s\n",
      "2962:\tlearn: 0.0357419\ttest: 0.0388208\tbest: 0.0388208 (2961)\ttotal: 15m 12s\tremaining: 36m 8s\n",
      "2963:\tlearn: 0.0357419\ttest: 0.0388208\tbest: 0.0388208 (2961)\ttotal: 15m 13s\tremaining: 36m 8s\n",
      "2964:\tlearn: 0.0357374\ttest: 0.0388207\tbest: 0.0388207 (2964)\ttotal: 15m 13s\tremaining: 36m 8s\n",
      "2965:\tlearn: 0.0357374\ttest: 0.0388207\tbest: 0.0388207 (2965)\ttotal: 15m 14s\tremaining: 36m 8s\n",
      "2966:\tlearn: 0.0357373\ttest: 0.0388207\tbest: 0.0388207 (2966)\ttotal: 15m 14s\tremaining: 36m 8s\n",
      "2967:\tlearn: 0.0357374\ttest: 0.0388207\tbest: 0.0388207 (2967)\ttotal: 15m 15s\tremaining: 36m 8s\n",
      "2968:\tlearn: 0.0357373\ttest: 0.0388207\tbest: 0.0388207 (2968)\ttotal: 15m 15s\tremaining: 36m 8s\n",
      "2969:\tlearn: 0.0357373\ttest: 0.0388207\tbest: 0.0388207 (2969)\ttotal: 15m 16s\tremaining: 36m 8s\n",
      "2970:\tlearn: 0.0357373\ttest: 0.0388207\tbest: 0.0388207 (2970)\ttotal: 15m 16s\tremaining: 36m 8s\n",
      "2971:\tlearn: 0.0357373\ttest: 0.0388207\tbest: 0.0388207 (2970)\ttotal: 15m 16s\tremaining: 36m 7s\n",
      "2972:\tlearn: 0.0357373\ttest: 0.0388207\tbest: 0.0388207 (2970)\ttotal: 15m 16s\tremaining: 36m 7s\n",
      "2973:\tlearn: 0.0357373\ttest: 0.0388207\tbest: 0.0388207 (2973)\ttotal: 15m 17s\tremaining: 36m 6s\n",
      "2974:\tlearn: 0.0357373\ttest: 0.0388207\tbest: 0.0388207 (2973)\ttotal: 15m 17s\tremaining: 36m 6s\n",
      "2975:\tlearn: 0.0357373\ttest: 0.0388207\tbest: 0.0388207 (2975)\ttotal: 15m 17s\tremaining: 36m 5s\n",
      "2976:\tlearn: 0.0357373\ttest: 0.0388207\tbest: 0.0388207 (2976)\ttotal: 15m 17s\tremaining: 36m 5s\n",
      "2977:\tlearn: 0.0357328\ttest: 0.0388189\tbest: 0.0388189 (2977)\ttotal: 15m 18s\tremaining: 36m 4s\n",
      "2978:\tlearn: 0.0357328\ttest: 0.0388189\tbest: 0.0388189 (2978)\ttotal: 15m 18s\tremaining: 36m 4s\n",
      "2979:\tlearn: 0.0357328\ttest: 0.0388189\tbest: 0.0388189 (2979)\ttotal: 15m 18s\tremaining: 36m 4s\n",
      "2980:\tlearn: 0.0357328\ttest: 0.0388189\tbest: 0.0388189 (2979)\ttotal: 15m 18s\tremaining: 36m 3s\n",
      "2981:\tlearn: 0.0357328\ttest: 0.0388189\tbest: 0.0388189 (2979)\ttotal: 15m 19s\tremaining: 36m 3s\n",
      "2982:\tlearn: 0.0357320\ttest: 0.0388191\tbest: 0.0388189 (2979)\ttotal: 15m 19s\tremaining: 36m 2s\n",
      "2983:\tlearn: 0.0357255\ttest: 0.0388164\tbest: 0.0388164 (2983)\ttotal: 15m 19s\tremaining: 36m 2s\n",
      "2984:\tlearn: 0.0357255\ttest: 0.0388164\tbest: 0.0388164 (2984)\ttotal: 15m 19s\tremaining: 36m 2s\n",
      "2985:\tlearn: 0.0357255\ttest: 0.0388164\tbest: 0.0388164 (2984)\ttotal: 15m 20s\tremaining: 36m 1s\n",
      "2986:\tlearn: 0.0357255\ttest: 0.0388164\tbest: 0.0388164 (2986)\ttotal: 15m 20s\tremaining: 36m 1s\n",
      "2987:\tlearn: 0.0357255\ttest: 0.0388164\tbest: 0.0388164 (2986)\ttotal: 15m 20s\tremaining: 36m\n",
      "2988:\tlearn: 0.0357255\ttest: 0.0388164\tbest: 0.0388164 (2988)\ttotal: 15m 20s\tremaining: 36m\n",
      "2989:\tlearn: 0.0357237\ttest: 0.0388159\tbest: 0.0388159 (2989)\ttotal: 15m 21s\tremaining: 35m 59s\n",
      "2990:\tlearn: 0.0357237\ttest: 0.0388159\tbest: 0.0388159 (2990)\ttotal: 15m 21s\tremaining: 35m 59s\n",
      "2991:\tlearn: 0.0357237\ttest: 0.0388159\tbest: 0.0388159 (2991)\ttotal: 15m 21s\tremaining: 35m 59s\n",
      "2992:\tlearn: 0.0357197\ttest: 0.0388154\tbest: 0.0388154 (2992)\ttotal: 15m 22s\tremaining: 35m 58s\n",
      "2993:\tlearn: 0.0357197\ttest: 0.0388154\tbest: 0.0388154 (2992)\ttotal: 15m 22s\tremaining: 35m 58s\n",
      "2994:\tlearn: 0.0357197\ttest: 0.0388154\tbest: 0.0388154 (2992)\ttotal: 15m 22s\tremaining: 35m 57s\n",
      "2995:\tlearn: 0.0357197\ttest: 0.0388154\tbest: 0.0388154 (2995)\ttotal: 15m 22s\tremaining: 35m 57s\n",
      "2996:\tlearn: 0.0357197\ttest: 0.0388154\tbest: 0.0388154 (2996)\ttotal: 15m 23s\tremaining: 35m 56s\n",
      "2997:\tlearn: 0.0357135\ttest: 0.0388145\tbest: 0.0388145 (2997)\ttotal: 15m 23s\tremaining: 35m 56s\n",
      "2998:\tlearn: 0.0357135\ttest: 0.0388145\tbest: 0.0388145 (2997)\ttotal: 15m 23s\tremaining: 35m 56s\n",
      "2999:\tlearn: 0.0357134\ttest: 0.0388144\tbest: 0.0388144 (2999)\ttotal: 15m 23s\tremaining: 35m 55s\n",
      "3000:\tlearn: 0.0357134\ttest: 0.0388144\tbest: 0.0388144 (2999)\ttotal: 15m 24s\tremaining: 35m 55s\n",
      "3001:\tlearn: 0.0357134\ttest: 0.0388144\tbest: 0.0388144 (3001)\ttotal: 15m 24s\tremaining: 35m 55s\n",
      "3002:\tlearn: 0.0357134\ttest: 0.0388144\tbest: 0.0388144 (3002)\ttotal: 15m 25s\tremaining: 35m 55s\n",
      "3003:\tlearn: 0.0357134\ttest: 0.0388144\tbest: 0.0388144 (3003)\ttotal: 15m 25s\tremaining: 35m 56s\n",
      "3004:\tlearn: 0.0357084\ttest: 0.0388128\tbest: 0.0388128 (3004)\ttotal: 15m 26s\tremaining: 35m 56s\n",
      "3005:\tlearn: 0.0357084\ttest: 0.0388128\tbest: 0.0388128 (3005)\ttotal: 15m 26s\tremaining: 35m 56s\n",
      "3006:\tlearn: 0.0357084\ttest: 0.0388128\tbest: 0.0388128 (3005)\ttotal: 15m 27s\tremaining: 35m 56s\n",
      "3007:\tlearn: 0.0357050\ttest: 0.0388119\tbest: 0.0388119 (3007)\ttotal: 15m 27s\tremaining: 35m 56s\n",
      "3008:\tlearn: 0.0357050\ttest: 0.0388119\tbest: 0.0388119 (3007)\ttotal: 15m 28s\tremaining: 35m 56s\n",
      "3009:\tlearn: 0.0357051\ttest: 0.0388119\tbest: 0.0388119 (3009)\ttotal: 15m 28s\tremaining: 35m 55s\n",
      "3010:\tlearn: 0.0357051\ttest: 0.0388119\tbest: 0.0388119 (3010)\ttotal: 15m 28s\tremaining: 35m 55s\n",
      "3011:\tlearn: 0.0357050\ttest: 0.0388119\tbest: 0.0388119 (3011)\ttotal: 15m 28s\tremaining: 35m 55s\n",
      "3012:\tlearn: 0.0357050\ttest: 0.0388118\tbest: 0.0388118 (3012)\ttotal: 15m 29s\tremaining: 35m 54s\n",
      "3013:\tlearn: 0.0357018\ttest: 0.0388110\tbest: 0.0388110 (3013)\ttotal: 15m 29s\tremaining: 35m 54s\n",
      "3014:\tlearn: 0.0357018\ttest: 0.0388110\tbest: 0.0388110 (3014)\ttotal: 15m 29s\tremaining: 35m 53s\n",
      "3015:\tlearn: 0.0356957\ttest: 0.0388081\tbest: 0.0388081 (3015)\ttotal: 15m 30s\tremaining: 35m 53s\n",
      "3016:\tlearn: 0.0356957\ttest: 0.0388081\tbest: 0.0388081 (3016)\ttotal: 15m 30s\tremaining: 35m 53s\n",
      "3017:\tlearn: 0.0356957\ttest: 0.0388081\tbest: 0.0388081 (3017)\ttotal: 15m 30s\tremaining: 35m 52s\n",
      "3018:\tlearn: 0.0356957\ttest: 0.0388081\tbest: 0.0388081 (3017)\ttotal: 15m 30s\tremaining: 35m 52s\n",
      "3019:\tlearn: 0.0356957\ttest: 0.0388081\tbest: 0.0388081 (3017)\ttotal: 15m 31s\tremaining: 35m 51s\n",
      "3020:\tlearn: 0.0356919\ttest: 0.0388075\tbest: 0.0388075 (3020)\ttotal: 15m 31s\tremaining: 35m 51s\n",
      "3021:\tlearn: 0.0356894\ttest: 0.0388063\tbest: 0.0388063 (3021)\ttotal: 15m 31s\tremaining: 35m 51s\n",
      "3022:\tlearn: 0.0356894\ttest: 0.0388062\tbest: 0.0388062 (3022)\ttotal: 15m 31s\tremaining: 35m 50s\n",
      "3023:\tlearn: 0.0356894\ttest: 0.0388062\tbest: 0.0388062 (3022)\ttotal: 15m 32s\tremaining: 35m 50s\n",
      "3024:\tlearn: 0.0356864\ttest: 0.0388049\tbest: 0.0388049 (3024)\ttotal: 15m 32s\tremaining: 35m 49s\n",
      "3025:\tlearn: 0.0356865\ttest: 0.0388049\tbest: 0.0388049 (3025)\ttotal: 15m 32s\tremaining: 35m 49s\n",
      "3026:\tlearn: 0.0356864\ttest: 0.0388049\tbest: 0.0388049 (3026)\ttotal: 15m 32s\tremaining: 35m 49s\n",
      "3027:\tlearn: 0.0356820\ttest: 0.0388029\tbest: 0.0388029 (3027)\ttotal: 15m 33s\tremaining: 35m 48s\n",
      "3028:\tlearn: 0.0356820\ttest: 0.0388029\tbest: 0.0388029 (3028)\ttotal: 15m 33s\tremaining: 35m 48s\n",
      "3029:\tlearn: 0.0356735\ttest: 0.0388009\tbest: 0.0388009 (3029)\ttotal: 15m 33s\tremaining: 35m 48s\n",
      "3030:\tlearn: 0.0356657\ttest: 0.0387973\tbest: 0.0387973 (3030)\ttotal: 15m 34s\tremaining: 35m 47s\n",
      "3031:\tlearn: 0.0356657\ttest: 0.0387973\tbest: 0.0387973 (3031)\ttotal: 15m 34s\tremaining: 35m 47s\n",
      "3032:\tlearn: 0.0356657\ttest: 0.0387973\tbest: 0.0387973 (3032)\ttotal: 15m 34s\tremaining: 35m 46s\n",
      "3033:\tlearn: 0.0356657\ttest: 0.0387973\tbest: 0.0387973 (3033)\ttotal: 15m 34s\tremaining: 35m 46s\n",
      "3034:\tlearn: 0.0356657\ttest: 0.0387973\tbest: 0.0387973 (3033)\ttotal: 15m 35s\tremaining: 35m 46s\n",
      "3035:\tlearn: 0.0356657\ttest: 0.0387973\tbest: 0.0387973 (3035)\ttotal: 15m 35s\tremaining: 35m 45s\n",
      "3036:\tlearn: 0.0356657\ttest: 0.0387973\tbest: 0.0387973 (3036)\ttotal: 15m 35s\tremaining: 35m 45s\n",
      "3037:\tlearn: 0.0356657\ttest: 0.0387973\tbest: 0.0387973 (3037)\ttotal: 15m 35s\tremaining: 35m 44s\n",
      "3038:\tlearn: 0.0356657\ttest: 0.0387973\tbest: 0.0387973 (3037)\ttotal: 15m 36s\tremaining: 35m 44s\n",
      "3039:\tlearn: 0.0356657\ttest: 0.0387973\tbest: 0.0387973 (3039)\ttotal: 15m 36s\tremaining: 35m 44s\n",
      "3040:\tlearn: 0.0356657\ttest: 0.0387973\tbest: 0.0387973 (3040)\ttotal: 15m 36s\tremaining: 35m 43s\n",
      "3041:\tlearn: 0.0356657\ttest: 0.0387973\tbest: 0.0387973 (3040)\ttotal: 15m 36s\tremaining: 35m 43s\n",
      "3042:\tlearn: 0.0356628\ttest: 0.0387963\tbest: 0.0387963 (3042)\ttotal: 15m 37s\tremaining: 35m 42s\n",
      "3043:\tlearn: 0.0356628\ttest: 0.0387963\tbest: 0.0387963 (3043)\ttotal: 15m 37s\tremaining: 35m 42s\n",
      "3044:\tlearn: 0.0356607\ttest: 0.0387961\tbest: 0.0387961 (3044)\ttotal: 15m 37s\tremaining: 35m 42s\n",
      "3045:\tlearn: 0.0356607\ttest: 0.0387961\tbest: 0.0387961 (3045)\ttotal: 15m 38s\tremaining: 35m 41s\n",
      "3046:\tlearn: 0.0356607\ttest: 0.0387961\tbest: 0.0387961 (3045)\ttotal: 15m 38s\tremaining: 35m 42s\n",
      "3047:\tlearn: 0.0356607\ttest: 0.0387961\tbest: 0.0387961 (3047)\ttotal: 15m 39s\tremaining: 35m 42s\n",
      "3048:\tlearn: 0.0356607\ttest: 0.0387961\tbest: 0.0387961 (3048)\ttotal: 15m 39s\tremaining: 35m 42s\n",
      "3049:\tlearn: 0.0356607\ttest: 0.0387961\tbest: 0.0387961 (3048)\ttotal: 15m 40s\tremaining: 35m 42s\n",
      "3050:\tlearn: 0.0356607\ttest: 0.0387961\tbest: 0.0387961 (3050)\ttotal: 15m 40s\tremaining: 35m 42s\n",
      "3051:\tlearn: 0.0356567\ttest: 0.0387951\tbest: 0.0387951 (3051)\ttotal: 15m 41s\tremaining: 35m 42s\n",
      "3052:\tlearn: 0.0356567\ttest: 0.0387951\tbest: 0.0387951 (3052)\ttotal: 15m 41s\tremaining: 35m 42s\n",
      "3053:\tlearn: 0.0356567\ttest: 0.0387951\tbest: 0.0387951 (3053)\ttotal: 15m 42s\tremaining: 35m 42s\n",
      "3054:\tlearn: 0.0356567\ttest: 0.0387951\tbest: 0.0387951 (3054)\ttotal: 15m 42s\tremaining: 35m 42s\n",
      "3055:\tlearn: 0.0356567\ttest: 0.0387951\tbest: 0.0387951 (3055)\ttotal: 15m 42s\tremaining: 35m 41s\n",
      "3056:\tlearn: 0.0356567\ttest: 0.0387951\tbest: 0.0387951 (3056)\ttotal: 15m 42s\tremaining: 35m 41s\n",
      "3057:\tlearn: 0.0356567\ttest: 0.0387951\tbest: 0.0387951 (3057)\ttotal: 15m 43s\tremaining: 35m 40s\n",
      "3058:\tlearn: 0.0356567\ttest: 0.0387951\tbest: 0.0387951 (3058)\ttotal: 15m 43s\tremaining: 35m 40s\n",
      "3059:\tlearn: 0.0356567\ttest: 0.0387951\tbest: 0.0387951 (3059)\ttotal: 15m 43s\tremaining: 35m 40s\n",
      "3060:\tlearn: 0.0356481\ttest: 0.0387895\tbest: 0.0387895 (3060)\ttotal: 15m 43s\tremaining: 35m 39s\n",
      "3061:\tlearn: 0.0356481\ttest: 0.0387895\tbest: 0.0387895 (3060)\ttotal: 15m 44s\tremaining: 35m 39s\n",
      "3062:\tlearn: 0.0356436\ttest: 0.0387875\tbest: 0.0387875 (3062)\ttotal: 15m 44s\tremaining: 35m 39s\n",
      "3063:\tlearn: 0.0356436\ttest: 0.0387875\tbest: 0.0387875 (3063)\ttotal: 15m 44s\tremaining: 35m 38s\n",
      "3064:\tlearn: 0.0356436\ttest: 0.0387875\tbest: 0.0387875 (3063)\ttotal: 15m 45s\tremaining: 35m 38s\n",
      "3065:\tlearn: 0.0356436\ttest: 0.0387875\tbest: 0.0387875 (3065)\ttotal: 15m 45s\tremaining: 35m 37s\n",
      "3066:\tlearn: 0.0356436\ttest: 0.0387875\tbest: 0.0387875 (3066)\ttotal: 15m 45s\tremaining: 35m 37s\n",
      "3067:\tlearn: 0.0356436\ttest: 0.0387875\tbest: 0.0387875 (3067)\ttotal: 15m 45s\tremaining: 35m 36s\n",
      "3068:\tlearn: 0.0356408\ttest: 0.0387860\tbest: 0.0387860 (3068)\ttotal: 15m 46s\tremaining: 35m 36s\n",
      "3069:\tlearn: 0.0356368\ttest: 0.0387847\tbest: 0.0387847 (3069)\ttotal: 15m 46s\tremaining: 35m 36s\n",
      "3070:\tlearn: 0.0356368\ttest: 0.0387847\tbest: 0.0387847 (3069)\ttotal: 15m 46s\tremaining: 35m 35s\n",
      "3071:\tlearn: 0.0356368\ttest: 0.0387847\tbest: 0.0387847 (3071)\ttotal: 15m 46s\tremaining: 35m 35s\n",
      "3072:\tlearn: 0.0356368\ttest: 0.0387846\tbest: 0.0387846 (3072)\ttotal: 15m 47s\tremaining: 35m 34s\n",
      "3073:\tlearn: 0.0356368\ttest: 0.0387846\tbest: 0.0387846 (3073)\ttotal: 15m 47s\tremaining: 35m 34s\n",
      "3074:\tlearn: 0.0356306\ttest: 0.0387819\tbest: 0.0387819 (3074)\ttotal: 15m 47s\tremaining: 35m 34s\n",
      "3075:\tlearn: 0.0356306\ttest: 0.0387819\tbest: 0.0387819 (3074)\ttotal: 15m 47s\tremaining: 35m 33s\n",
      "3076:\tlearn: 0.0356306\ttest: 0.0387819\tbest: 0.0387819 (3074)\ttotal: 15m 48s\tremaining: 35m 33s\n",
      "3077:\tlearn: 0.0356263\ttest: 0.0387796\tbest: 0.0387796 (3077)\ttotal: 15m 48s\tremaining: 35m 33s\n",
      "3078:\tlearn: 0.0356263\ttest: 0.0387796\tbest: 0.0387796 (3078)\ttotal: 15m 48s\tremaining: 35m 32s\n",
      "3079:\tlearn: 0.0356194\ttest: 0.0387771\tbest: 0.0387771 (3079)\ttotal: 15m 49s\tremaining: 35m 32s\n",
      "3080:\tlearn: 0.0356147\ttest: 0.0387736\tbest: 0.0387736 (3080)\ttotal: 15m 49s\tremaining: 35m 32s\n",
      "3081:\tlearn: 0.0356147\ttest: 0.0387736\tbest: 0.0387736 (3081)\ttotal: 15m 49s\tremaining: 35m 31s\n",
      "3082:\tlearn: 0.0356147\ttest: 0.0387736\tbest: 0.0387736 (3082)\ttotal: 15m 49s\tremaining: 35m 31s\n",
      "3083:\tlearn: 0.0356092\ttest: 0.0387716\tbest: 0.0387716 (3083)\ttotal: 15m 50s\tremaining: 35m 31s\n",
      "3084:\tlearn: 0.0356092\ttest: 0.0387716\tbest: 0.0387716 (3083)\ttotal: 15m 50s\tremaining: 35m 30s\n",
      "3085:\tlearn: 0.0356090\ttest: 0.0387716\tbest: 0.0387716 (3083)\ttotal: 15m 50s\tremaining: 35m 30s\n",
      "3086:\tlearn: 0.0356090\ttest: 0.0387716\tbest: 0.0387716 (3083)\ttotal: 15m 51s\tremaining: 35m 29s\n",
      "3087:\tlearn: 0.0356090\ttest: 0.0387716\tbest: 0.0387716 (3083)\ttotal: 15m 51s\tremaining: 35m 29s\n",
      "3088:\tlearn: 0.0356090\ttest: 0.0387717\tbest: 0.0387716 (3083)\ttotal: 15m 51s\tremaining: 35m 29s\n",
      "3089:\tlearn: 0.0356090\ttest: 0.0387717\tbest: 0.0387716 (3083)\ttotal: 15m 51s\tremaining: 35m 28s\n",
      "3090:\tlearn: 0.0356043\ttest: 0.0387706\tbest: 0.0387706 (3090)\ttotal: 15m 52s\tremaining: 35m 28s\n",
      "3091:\tlearn: 0.0356000\ttest: 0.0387702\tbest: 0.0387702 (3091)\ttotal: 15m 52s\tremaining: 35m 28s\n",
      "3092:\tlearn: 0.0356000\ttest: 0.0387702\tbest: 0.0387702 (3092)\ttotal: 15m 53s\tremaining: 35m 28s\n",
      "3093:\tlearn: 0.0355999\ttest: 0.0387702\tbest: 0.0387702 (3093)\ttotal: 15m 53s\tremaining: 35m 28s\n",
      "3094:\tlearn: 0.0355941\ttest: 0.0387677\tbest: 0.0387677 (3094)\ttotal: 15m 54s\tremaining: 35m 29s\n",
      "3095:\tlearn: 0.0355941\ttest: 0.0387677\tbest: 0.0387677 (3095)\ttotal: 15m 54s\tremaining: 35m 29s\n",
      "3096:\tlearn: 0.0355941\ttest: 0.0387677\tbest: 0.0387677 (3095)\ttotal: 15m 55s\tremaining: 35m 29s\n",
      "3097:\tlearn: 0.0355913\ttest: 0.0387673\tbest: 0.0387673 (3097)\ttotal: 15m 55s\tremaining: 35m 29s\n",
      "3098:\tlearn: 0.0355913\ttest: 0.0387673\tbest: 0.0387673 (3098)\ttotal: 15m 56s\tremaining: 35m 29s\n",
      "3099:\tlearn: 0.0355913\ttest: 0.0387673\tbest: 0.0387673 (3099)\ttotal: 15m 56s\tremaining: 35m 28s\n",
      "3100:\tlearn: 0.0355854\ttest: 0.0387646\tbest: 0.0387646 (3100)\ttotal: 15m 56s\tremaining: 35m 28s\n",
      "3101:\tlearn: 0.0355854\ttest: 0.0387646\tbest: 0.0387646 (3100)\ttotal: 15m 57s\tremaining: 35m 28s\n",
      "3102:\tlearn: 0.0355854\ttest: 0.0387646\tbest: 0.0387646 (3102)\ttotal: 15m 57s\tremaining: 35m 27s\n",
      "3103:\tlearn: 0.0355799\ttest: 0.0387642\tbest: 0.0387642 (3103)\ttotal: 15m 57s\tremaining: 35m 27s\n",
      "3104:\tlearn: 0.0355799\ttest: 0.0387642\tbest: 0.0387642 (3104)\ttotal: 15m 57s\tremaining: 35m 27s\n",
      "3105:\tlearn: 0.0355748\ttest: 0.0387632\tbest: 0.0387632 (3105)\ttotal: 15m 58s\tremaining: 35m 26s\n",
      "3106:\tlearn: 0.0355748\ttest: 0.0387632\tbest: 0.0387632 (3106)\ttotal: 15m 58s\tremaining: 35m 26s\n",
      "3107:\tlearn: 0.0355748\ttest: 0.0387632\tbest: 0.0387632 (3107)\ttotal: 15m 58s\tremaining: 35m 25s\n",
      "3108:\tlearn: 0.0355748\ttest: 0.0387632\tbest: 0.0387632 (3108)\ttotal: 15m 58s\tremaining: 35m 25s\n",
      "3109:\tlearn: 0.0355695\ttest: 0.0387611\tbest: 0.0387611 (3109)\ttotal: 15m 59s\tremaining: 35m 25s\n",
      "3110:\tlearn: 0.0355695\ttest: 0.0387611\tbest: 0.0387611 (3110)\ttotal: 15m 59s\tremaining: 35m 24s\n",
      "3111:\tlearn: 0.0355695\ttest: 0.0387611\tbest: 0.0387611 (3110)\ttotal: 15m 59s\tremaining: 35m 24s\n",
      "3112:\tlearn: 0.0355635\ttest: 0.0387591\tbest: 0.0387591 (3112)\ttotal: 16m\tremaining: 35m 24s\n",
      "3113:\tlearn: 0.0355635\ttest: 0.0387591\tbest: 0.0387591 (3112)\ttotal: 16m\tremaining: 35m 23s\n",
      "3114:\tlearn: 0.0355635\ttest: 0.0387591\tbest: 0.0387591 (3112)\ttotal: 16m\tremaining: 35m 23s\n",
      "3115:\tlearn: 0.0355635\ttest: 0.0387591\tbest: 0.0387591 (3112)\ttotal: 16m\tremaining: 35m 22s\n",
      "3116:\tlearn: 0.0355635\ttest: 0.0387590\tbest: 0.0387590 (3116)\ttotal: 16m 1s\tremaining: 35m 22s\n",
      "3117:\tlearn: 0.0355635\ttest: 0.0387590\tbest: 0.0387590 (3117)\ttotal: 16m 1s\tremaining: 35m 21s\n",
      "3118:\tlearn: 0.0355603\ttest: 0.0387587\tbest: 0.0387587 (3118)\ttotal: 16m 1s\tremaining: 35m 21s\n",
      "3119:\tlearn: 0.0355603\ttest: 0.0387587\tbest: 0.0387587 (3119)\ttotal: 16m 1s\tremaining: 35m 21s\n",
      "3120:\tlearn: 0.0355603\ttest: 0.0387587\tbest: 0.0387587 (3120)\ttotal: 16m 2s\tremaining: 35m 20s\n",
      "3121:\tlearn: 0.0355603\ttest: 0.0387587\tbest: 0.0387587 (3120)\ttotal: 16m 2s\tremaining: 35m 20s\n",
      "3122:\tlearn: 0.0355603\ttest: 0.0387587\tbest: 0.0387587 (3120)\ttotal: 16m 2s\tremaining: 35m 19s\n",
      "3123:\tlearn: 0.0355549\ttest: 0.0387573\tbest: 0.0387573 (3123)\ttotal: 16m 3s\tremaining: 35m 19s\n",
      "3124:\tlearn: 0.0355513\ttest: 0.0387566\tbest: 0.0387566 (3124)\ttotal: 16m 3s\tremaining: 35m 19s\n",
      "3125:\tlearn: 0.0355513\ttest: 0.0387566\tbest: 0.0387566 (3125)\ttotal: 16m 3s\tremaining: 35m 18s\n",
      "3126:\tlearn: 0.0355513\ttest: 0.0387566\tbest: 0.0387566 (3125)\ttotal: 16m 3s\tremaining: 35m 18s\n",
      "3127:\tlearn: 0.0355513\ttest: 0.0387566\tbest: 0.0387566 (3125)\ttotal: 16m 4s\tremaining: 35m 18s\n",
      "3128:\tlearn: 0.0355464\ttest: 0.0387548\tbest: 0.0387548 (3128)\ttotal: 16m 4s\tremaining: 35m 17s\n",
      "3129:\tlearn: 0.0355464\ttest: 0.0387548\tbest: 0.0387548 (3128)\ttotal: 16m 4s\tremaining: 35m 17s\n",
      "3130:\tlearn: 0.0355464\ttest: 0.0387548\tbest: 0.0387548 (3128)\ttotal: 16m 4s\tremaining: 35m 16s\n",
      "3131:\tlearn: 0.0355447\ttest: 0.0387545\tbest: 0.0387545 (3131)\ttotal: 16m 5s\tremaining: 35m 16s\n",
      "3132:\tlearn: 0.0355407\ttest: 0.0387540\tbest: 0.0387540 (3132)\ttotal: 16m 5s\tremaining: 35m 16s\n",
      "3133:\tlearn: 0.0355407\ttest: 0.0387540\tbest: 0.0387540 (3133)\ttotal: 16m 5s\tremaining: 35m 15s\n",
      "3134:\tlearn: 0.0355407\ttest: 0.0387540\tbest: 0.0387540 (3134)\ttotal: 16m 5s\tremaining: 35m 15s\n",
      "3135:\tlearn: 0.0355407\ttest: 0.0387540\tbest: 0.0387540 (3135)\ttotal: 16m 6s\tremaining: 35m 14s\n",
      "3136:\tlearn: 0.0355407\ttest: 0.0387540\tbest: 0.0387540 (3135)\ttotal: 16m 6s\tremaining: 35m 14s\n",
      "3137:\tlearn: 0.0355407\ttest: 0.0387540\tbest: 0.0387540 (3137)\ttotal: 16m 7s\tremaining: 35m 14s\n",
      "3138:\tlearn: 0.0355407\ttest: 0.0387540\tbest: 0.0387540 (3138)\ttotal: 16m 7s\tremaining: 35m 14s\n",
      "3139:\tlearn: 0.0355407\ttest: 0.0387540\tbest: 0.0387540 (3138)\ttotal: 16m 8s\tremaining: 35m 14s\n",
      "3140:\tlearn: 0.0355351\ttest: 0.0387530\tbest: 0.0387530 (3140)\ttotal: 16m 8s\tremaining: 35m 15s\n",
      "3141:\tlearn: 0.0355351\ttest: 0.0387530\tbest: 0.0387530 (3141)\ttotal: 16m 9s\tremaining: 35m 15s\n",
      "3142:\tlearn: 0.0355351\ttest: 0.0387530\tbest: 0.0387530 (3141)\ttotal: 16m 9s\tremaining: 35m 15s\n",
      "3143:\tlearn: 0.0355351\ttest: 0.0387530\tbest: 0.0387530 (3143)\ttotal: 16m 9s\tremaining: 35m 15s\n",
      "3144:\tlearn: 0.0355326\ttest: 0.0387530\tbest: 0.0387530 (3143)\ttotal: 16m 10s\tremaining: 35m 14s\n",
      "3145:\tlearn: 0.0355326\ttest: 0.0387530\tbest: 0.0387530 (3143)\ttotal: 16m 10s\tremaining: 35m 14s\n",
      "3146:\tlearn: 0.0355326\ttest: 0.0387530\tbest: 0.0387530 (3143)\ttotal: 16m 10s\tremaining: 35m 14s\n",
      "3147:\tlearn: 0.0355326\ttest: 0.0387530\tbest: 0.0387530 (3143)\ttotal: 16m 11s\tremaining: 35m 13s\n",
      "3148:\tlearn: 0.0355326\ttest: 0.0387530\tbest: 0.0387530 (3143)\ttotal: 16m 11s\tremaining: 35m 13s\n",
      "3149:\tlearn: 0.0355326\ttest: 0.0387530\tbest: 0.0387530 (3143)\ttotal: 16m 11s\tremaining: 35m 12s\n",
      "3150:\tlearn: 0.0355325\ttest: 0.0387530\tbest: 0.0387530 (3143)\ttotal: 16m 11s\tremaining: 35m 12s\n",
      "3151:\tlearn: 0.0355325\ttest: 0.0387530\tbest: 0.0387530 (3143)\ttotal: 16m 12s\tremaining: 35m 12s\n",
      "3152:\tlearn: 0.0355278\ttest: 0.0387524\tbest: 0.0387524 (3152)\ttotal: 16m 12s\tremaining: 35m 11s\n",
      "3153:\tlearn: 0.0355278\ttest: 0.0387524\tbest: 0.0387524 (3153)\ttotal: 16m 12s\tremaining: 35m 11s\n",
      "3154:\tlearn: 0.0355278\ttest: 0.0387524\tbest: 0.0387524 (3154)\ttotal: 16m 12s\tremaining: 35m 10s\n",
      "3155:\tlearn: 0.0355278\ttest: 0.0387524\tbest: 0.0387524 (3154)\ttotal: 16m 13s\tremaining: 35m 10s\n",
      "3156:\tlearn: 0.0355278\ttest: 0.0387524\tbest: 0.0387524 (3156)\ttotal: 16m 13s\tremaining: 35m 10s\n",
      "3157:\tlearn: 0.0355278\ttest: 0.0387524\tbest: 0.0387524 (3157)\ttotal: 16m 13s\tremaining: 35m 9s\n",
      "3158:\tlearn: 0.0355278\ttest: 0.0387524\tbest: 0.0387524 (3157)\ttotal: 16m 14s\tremaining: 35m 9s\n",
      "3159:\tlearn: 0.0355263\ttest: 0.0387521\tbest: 0.0387521 (3159)\ttotal: 16m 14s\tremaining: 35m 8s\n",
      "3160:\tlearn: 0.0355209\ttest: 0.0387494\tbest: 0.0387494 (3160)\ttotal: 16m 14s\tremaining: 35m 8s\n",
      "3161:\tlearn: 0.0355209\ttest: 0.0387494\tbest: 0.0387494 (3161)\ttotal: 16m 14s\tremaining: 35m 8s\n",
      "3162:\tlearn: 0.0355209\ttest: 0.0387494\tbest: 0.0387494 (3161)\ttotal: 16m 15s\tremaining: 35m 7s\n",
      "3163:\tlearn: 0.0355208\ttest: 0.0387493\tbest: 0.0387493 (3163)\ttotal: 16m 15s\tremaining: 35m 7s\n",
      "3164:\tlearn: 0.0355208\ttest: 0.0387493\tbest: 0.0387493 (3163)\ttotal: 16m 15s\tremaining: 35m 6s\n",
      "3165:\tlearn: 0.0355207\ttest: 0.0387493\tbest: 0.0387493 (3165)\ttotal: 16m 15s\tremaining: 35m 6s\n",
      "3166:\tlearn: 0.0355207\ttest: 0.0387493\tbest: 0.0387493 (3166)\ttotal: 16m 16s\tremaining: 35m 6s\n",
      "3167:\tlearn: 0.0355163\ttest: 0.0387468\tbest: 0.0387468 (3167)\ttotal: 16m 16s\tremaining: 35m 5s\n",
      "3168:\tlearn: 0.0355096\ttest: 0.0387447\tbest: 0.0387447 (3168)\ttotal: 16m 16s\tremaining: 35m 5s\n",
      "3169:\tlearn: 0.0355096\ttest: 0.0387447\tbest: 0.0387447 (3169)\ttotal: 16m 17s\tremaining: 35m 5s\n",
      "3170:\tlearn: 0.0355096\ttest: 0.0387447\tbest: 0.0387447 (3170)\ttotal: 16m 17s\tremaining: 35m 4s\n",
      "3171:\tlearn: 0.0355096\ttest: 0.0387447\tbest: 0.0387447 (3170)\ttotal: 16m 17s\tremaining: 35m 4s\n",
      "3172:\tlearn: 0.0355096\ttest: 0.0387447\tbest: 0.0387447 (3172)\ttotal: 16m 17s\tremaining: 35m 3s\n",
      "3173:\tlearn: 0.0355096\ttest: 0.0387447\tbest: 0.0387447 (3172)\ttotal: 16m 18s\tremaining: 35m 3s\n",
      "3174:\tlearn: 0.0355095\ttest: 0.0387447\tbest: 0.0387447 (3172)\ttotal: 16m 18s\tremaining: 35m 3s\n",
      "3175:\tlearn: 0.0355095\ttest: 0.0387447\tbest: 0.0387447 (3172)\ttotal: 16m 18s\tremaining: 35m 2s\n",
      "3176:\tlearn: 0.0355095\ttest: 0.0387447\tbest: 0.0387447 (3176)\ttotal: 16m 18s\tremaining: 35m 2s\n",
      "3177:\tlearn: 0.0355079\ttest: 0.0387443\tbest: 0.0387443 (3177)\ttotal: 16m 19s\tremaining: 35m 1s\n",
      "3178:\tlearn: 0.0355055\ttest: 0.0387436\tbest: 0.0387436 (3178)\ttotal: 16m 19s\tremaining: 35m 1s\n",
      "3179:\tlearn: 0.0355055\ttest: 0.0387436\tbest: 0.0387436 (3179)\ttotal: 16m 19s\tremaining: 35m 1s\n",
      "3180:\tlearn: 0.0355055\ttest: 0.0387436\tbest: 0.0387436 (3180)\ttotal: 16m 19s\tremaining: 35m\n",
      "3181:\tlearn: 0.0354982\ttest: 0.0387397\tbest: 0.0387397 (3181)\ttotal: 16m 20s\tremaining: 35m\n",
      "3182:\tlearn: 0.0354950\ttest: 0.0387382\tbest: 0.0387382 (3182)\ttotal: 16m 20s\tremaining: 35m\n",
      "3183:\tlearn: 0.0354950\ttest: 0.0387382\tbest: 0.0387382 (3182)\ttotal: 16m 21s\tremaining: 35m\n",
      "3184:\tlearn: 0.0354900\ttest: 0.0387369\tbest: 0.0387369 (3184)\ttotal: 16m 21s\tremaining: 35m\n",
      "3185:\tlearn: 0.0354900\ttest: 0.0387369\tbest: 0.0387369 (3185)\ttotal: 16m 22s\tremaining: 35m\n",
      "3186:\tlearn: 0.0354900\ttest: 0.0387369\tbest: 0.0387369 (3185)\ttotal: 16m 22s\tremaining: 35m\n",
      "3187:\tlearn: 0.0354900\ttest: 0.0387369\tbest: 0.0387369 (3185)\ttotal: 16m 23s\tremaining: 35m\n",
      "3188:\tlearn: 0.0354860\ttest: 0.0387347\tbest: 0.0387347 (3188)\ttotal: 16m 23s\tremaining: 35m\n",
      "3189:\tlearn: 0.0354860\ttest: 0.0387347\tbest: 0.0387347 (3188)\ttotal: 16m 24s\tremaining: 35m\n",
      "3190:\tlearn: 0.0354860\ttest: 0.0387347\tbest: 0.0387347 (3188)\ttotal: 16m 24s\tremaining: 35m\n",
      "3191:\tlearn: 0.0354814\ttest: 0.0387311\tbest: 0.0387311 (3191)\ttotal: 16m 24s\tremaining: 35m\n",
      "3192:\tlearn: 0.0354814\ttest: 0.0387311\tbest: 0.0387311 (3192)\ttotal: 16m 24s\tremaining: 34m 59s\n",
      "3193:\tlearn: 0.0354814\ttest: 0.0387311\tbest: 0.0387311 (3193)\ttotal: 16m 25s\tremaining: 34m 59s\n",
      "3194:\tlearn: 0.0354814\ttest: 0.0387311\tbest: 0.0387311 (3194)\ttotal: 16m 25s\tremaining: 34m 59s\n",
      "3195:\tlearn: 0.0354813\ttest: 0.0387311\tbest: 0.0387311 (3195)\ttotal: 16m 25s\tremaining: 34m 58s\n",
      "3196:\tlearn: 0.0354813\ttest: 0.0387311\tbest: 0.0387311 (3196)\ttotal: 16m 26s\tremaining: 34m 58s\n",
      "3197:\tlearn: 0.0354813\ttest: 0.0387311\tbest: 0.0387311 (3196)\ttotal: 16m 26s\tremaining: 34m 57s\n",
      "3198:\tlearn: 0.0354813\ttest: 0.0387311\tbest: 0.0387311 (3198)\ttotal: 16m 26s\tremaining: 34m 57s\n",
      "3199:\tlearn: 0.0354776\ttest: 0.0387308\tbest: 0.0387308 (3199)\ttotal: 16m 26s\tremaining: 34m 57s\n",
      "3200:\tlearn: 0.0354776\ttest: 0.0387308\tbest: 0.0387308 (3199)\ttotal: 16m 27s\tremaining: 34m 56s\n",
      "3201:\tlearn: 0.0354776\ttest: 0.0387308\tbest: 0.0387308 (3201)\ttotal: 16m 27s\tremaining: 34m 56s\n",
      "3202:\tlearn: 0.0354776\ttest: 0.0387308\tbest: 0.0387308 (3201)\ttotal: 16m 27s\tremaining: 34m 55s\n",
      "3203:\tlearn: 0.0354776\ttest: 0.0387308\tbest: 0.0387308 (3201)\ttotal: 16m 27s\tremaining: 34m 55s\n",
      "3204:\tlearn: 0.0354724\ttest: 0.0387271\tbest: 0.0387271 (3204)\ttotal: 16m 28s\tremaining: 34m 55s\n",
      "3205:\tlearn: 0.0354724\ttest: 0.0387271\tbest: 0.0387271 (3205)\ttotal: 16m 28s\tremaining: 34m 54s\n",
      "3206:\tlearn: 0.0354689\ttest: 0.0387257\tbest: 0.0387257 (3206)\ttotal: 16m 28s\tremaining: 34m 54s\n",
      "3207:\tlearn: 0.0354689\ttest: 0.0387257\tbest: 0.0387257 (3207)\ttotal: 16m 29s\tremaining: 34m 54s\n",
      "3208:\tlearn: 0.0354689\ttest: 0.0387257\tbest: 0.0387257 (3208)\ttotal: 16m 29s\tremaining: 34m 53s\n",
      "3209:\tlearn: 0.0354689\ttest: 0.0387257\tbest: 0.0387257 (3209)\ttotal: 16m 29s\tremaining: 34m 53s\n",
      "3210:\tlearn: 0.0354689\ttest: 0.0387257\tbest: 0.0387257 (3210)\ttotal: 16m 29s\tremaining: 34m 52s\n",
      "3211:\tlearn: 0.0354689\ttest: 0.0387257\tbest: 0.0387257 (3211)\ttotal: 16m 30s\tremaining: 34m 52s\n",
      "3212:\tlearn: 0.0354688\ttest: 0.0387257\tbest: 0.0387257 (3212)\ttotal: 16m 30s\tremaining: 34m 52s\n",
      "3213:\tlearn: 0.0354619\ttest: 0.0387230\tbest: 0.0387230 (3213)\ttotal: 16m 30s\tremaining: 34m 51s\n",
      "3214:\tlearn: 0.0354619\ttest: 0.0387230\tbest: 0.0387230 (3214)\ttotal: 16m 30s\tremaining: 34m 51s\n",
      "3215:\tlearn: 0.0354619\ttest: 0.0387230\tbest: 0.0387230 (3214)\ttotal: 16m 31s\tremaining: 34m 50s\n",
      "3216:\tlearn: 0.0354619\ttest: 0.0387230\tbest: 0.0387230 (3216)\ttotal: 16m 31s\tremaining: 34m 50s\n",
      "3217:\tlearn: 0.0354619\ttest: 0.0387230\tbest: 0.0387230 (3217)\ttotal: 16m 31s\tremaining: 34m 50s\n",
      "3218:\tlearn: 0.0354589\ttest: 0.0387206\tbest: 0.0387206 (3218)\ttotal: 16m 32s\tremaining: 34m 49s\n",
      "3219:\tlearn: 0.0354522\ttest: 0.0387182\tbest: 0.0387182 (3219)\ttotal: 16m 32s\tremaining: 34m 49s\n",
      "3220:\tlearn: 0.0354442\ttest: 0.0387126\tbest: 0.0387126 (3220)\ttotal: 16m 32s\tremaining: 34m 49s\n",
      "3221:\tlearn: 0.0354442\ttest: 0.0387126\tbest: 0.0387126 (3220)\ttotal: 16m 32s\tremaining: 34m 48s\n",
      "3222:\tlearn: 0.0354442\ttest: 0.0387126\tbest: 0.0387126 (3220)\ttotal: 16m 33s\tremaining: 34m 48s\n",
      "3223:\tlearn: 0.0354442\ttest: 0.0387126\tbest: 0.0387126 (3223)\ttotal: 16m 33s\tremaining: 34m 48s\n",
      "3224:\tlearn: 0.0354442\ttest: 0.0387126\tbest: 0.0387126 (3224)\ttotal: 16m 33s\tremaining: 34m 47s\n",
      "3225:\tlearn: 0.0354442\ttest: 0.0387126\tbest: 0.0387126 (3224)\ttotal: 16m 33s\tremaining: 34m 47s\n",
      "3226:\tlearn: 0.0354442\ttest: 0.0387126\tbest: 0.0387126 (3226)\ttotal: 16m 34s\tremaining: 34m 46s\n",
      "3227:\tlearn: 0.0354442\ttest: 0.0387126\tbest: 0.0387126 (3226)\ttotal: 16m 34s\tremaining: 34m 46s\n",
      "3228:\tlearn: 0.0354442\ttest: 0.0387125\tbest: 0.0387125 (3228)\ttotal: 16m 35s\tremaining: 34m 46s\n",
      "3229:\tlearn: 0.0354442\ttest: 0.0387125\tbest: 0.0387125 (3228)\ttotal: 16m 35s\tremaining: 34m 46s\n",
      "3230:\tlearn: 0.0354442\ttest: 0.0387125\tbest: 0.0387125 (3228)\ttotal: 16m 36s\tremaining: 34m 46s\n",
      "3231:\tlearn: 0.0354405\ttest: 0.0387105\tbest: 0.0387105 (3231)\ttotal: 16m 36s\tremaining: 34m 46s\n",
      "3232:\tlearn: 0.0354405\ttest: 0.0387105\tbest: 0.0387105 (3232)\ttotal: 16m 37s\tremaining: 34m 46s\n",
      "3233:\tlearn: 0.0354405\ttest: 0.0387105\tbest: 0.0387105 (3233)\ttotal: 16m 37s\tremaining: 34m 46s\n",
      "3234:\tlearn: 0.0354405\ttest: 0.0387105\tbest: 0.0387105 (3234)\ttotal: 16m 37s\tremaining: 34m 46s\n",
      "3235:\tlearn: 0.0354358\ttest: 0.0387090\tbest: 0.0387090 (3235)\ttotal: 16m 38s\tremaining: 34m 46s\n",
      "3236:\tlearn: 0.0354358\ttest: 0.0387090\tbest: 0.0387090 (3236)\ttotal: 16m 38s\tremaining: 34m 46s\n",
      "3237:\tlearn: 0.0354291\ttest: 0.0387064\tbest: 0.0387064 (3237)\ttotal: 16m 38s\tremaining: 34m 46s\n",
      "3238:\tlearn: 0.0354291\ttest: 0.0387064\tbest: 0.0387064 (3238)\ttotal: 16m 39s\tremaining: 34m 45s\n",
      "3239:\tlearn: 0.0354291\ttest: 0.0387064\tbest: 0.0387064 (3238)\ttotal: 16m 39s\tremaining: 34m 45s\n",
      "3240:\tlearn: 0.0354291\ttest: 0.0387064\tbest: 0.0387064 (3240)\ttotal: 16m 39s\tremaining: 34m 45s\n",
      "3241:\tlearn: 0.0354291\ttest: 0.0387064\tbest: 0.0387064 (3241)\ttotal: 16m 40s\tremaining: 34m 44s\n",
      "3242:\tlearn: 0.0354227\ttest: 0.0387041\tbest: 0.0387041 (3242)\ttotal: 16m 40s\tremaining: 34m 44s\n",
      "3243:\tlearn: 0.0354193\ttest: 0.0387037\tbest: 0.0387037 (3243)\ttotal: 16m 40s\tremaining: 34m 44s\n",
      "3244:\tlearn: 0.0354171\ttest: 0.0387025\tbest: 0.0387025 (3244)\ttotal: 16m 41s\tremaining: 34m 43s\n",
      "3245:\tlearn: 0.0354171\ttest: 0.0387025\tbest: 0.0387025 (3244)\ttotal: 16m 41s\tremaining: 34m 43s\n",
      "3246:\tlearn: 0.0354171\ttest: 0.0387025\tbest: 0.0387025 (3244)\ttotal: 16m 41s\tremaining: 34m 42s\n",
      "3247:\tlearn: 0.0354127\ttest: 0.0387017\tbest: 0.0387017 (3247)\ttotal: 16m 41s\tremaining: 34m 42s\n",
      "3248:\tlearn: 0.0354127\ttest: 0.0387017\tbest: 0.0387017 (3247)\ttotal: 16m 42s\tremaining: 34m 42s\n",
      "3249:\tlearn: 0.0354098\ttest: 0.0387016\tbest: 0.0387016 (3249)\ttotal: 16m 42s\tremaining: 34m 41s\n",
      "3250:\tlearn: 0.0354098\ttest: 0.0387016\tbest: 0.0387016 (3250)\ttotal: 16m 42s\tremaining: 34m 41s\n",
      "3251:\tlearn: 0.0354098\ttest: 0.0387016\tbest: 0.0387016 (3250)\ttotal: 16m 42s\tremaining: 34m 41s\n",
      "3252:\tlearn: 0.0354045\ttest: 0.0387004\tbest: 0.0387004 (3252)\ttotal: 16m 43s\tremaining: 34m 40s\n",
      "3253:\tlearn: 0.0354007\ttest: 0.0386990\tbest: 0.0386990 (3253)\ttotal: 16m 43s\tremaining: 34m 40s\n",
      "3254:\tlearn: 0.0354006\ttest: 0.0386990\tbest: 0.0386990 (3254)\ttotal: 16m 43s\tremaining: 34m 40s\n",
      "3255:\tlearn: 0.0354006\ttest: 0.0386990\tbest: 0.0386990 (3255)\ttotal: 16m 44s\tremaining: 34m 39s\n",
      "3256:\tlearn: 0.0353960\ttest: 0.0386980\tbest: 0.0386980 (3256)\ttotal: 16m 44s\tremaining: 34m 39s\n",
      "3257:\tlearn: 0.0353960\ttest: 0.0386980\tbest: 0.0386980 (3257)\ttotal: 16m 44s\tremaining: 34m 39s\n",
      "3258:\tlearn: 0.0353960\ttest: 0.0386980\tbest: 0.0386980 (3257)\ttotal: 16m 44s\tremaining: 34m 38s\n",
      "3259:\tlearn: 0.0353960\ttest: 0.0386980\tbest: 0.0386980 (3259)\ttotal: 16m 45s\tremaining: 34m 38s\n",
      "3260:\tlearn: 0.0353960\ttest: 0.0386979\tbest: 0.0386979 (3260)\ttotal: 16m 45s\tremaining: 34m 37s\n",
      "3261:\tlearn: 0.0353943\ttest: 0.0386979\tbest: 0.0386979 (3261)\ttotal: 16m 45s\tremaining: 34m 37s\n",
      "3262:\tlearn: 0.0353943\ttest: 0.0386979\tbest: 0.0386979 (3262)\ttotal: 16m 45s\tremaining: 34m 36s\n",
      "3263:\tlearn: 0.0353898\ttest: 0.0386955\tbest: 0.0386955 (3263)\ttotal: 16m 46s\tremaining: 34m 36s\n",
      "3264:\tlearn: 0.0353898\ttest: 0.0386955\tbest: 0.0386955 (3264)\ttotal: 16m 46s\tremaining: 34m 36s\n",
      "3265:\tlearn: 0.0353858\ttest: 0.0386933\tbest: 0.0386933 (3265)\ttotal: 16m 46s\tremaining: 34m 35s\n",
      "3266:\tlearn: 0.0353858\ttest: 0.0386933\tbest: 0.0386933 (3266)\ttotal: 16m 47s\tremaining: 34m 35s\n",
      "3267:\tlearn: 0.0353858\ttest: 0.0386933\tbest: 0.0386933 (3266)\ttotal: 16m 47s\tremaining: 34m 35s\n",
      "3268:\tlearn: 0.0353858\ttest: 0.0386933\tbest: 0.0386933 (3268)\ttotal: 16m 47s\tremaining: 34m 34s\n",
      "3269:\tlearn: 0.0353816\ttest: 0.0386909\tbest: 0.0386909 (3269)\ttotal: 16m 47s\tremaining: 34m 34s\n",
      "3270:\tlearn: 0.0353816\ttest: 0.0386909\tbest: 0.0386909 (3269)\ttotal: 16m 48s\tremaining: 34m 34s\n",
      "3271:\tlearn: 0.0353772\ttest: 0.0386889\tbest: 0.0386889 (3271)\ttotal: 16m 48s\tremaining: 34m 33s\n",
      "3272:\tlearn: 0.0353772\ttest: 0.0386889\tbest: 0.0386889 (3271)\ttotal: 16m 48s\tremaining: 34m 33s\n",
      "3273:\tlearn: 0.0353722\ttest: 0.0386884\tbest: 0.0386884 (3273)\ttotal: 16m 49s\tremaining: 34m 33s\n",
      "3274:\tlearn: 0.0353722\ttest: 0.0386884\tbest: 0.0386884 (3274)\ttotal: 16m 49s\tremaining: 34m 33s\n",
      "3275:\tlearn: 0.0353683\ttest: 0.0386880\tbest: 0.0386880 (3275)\ttotal: 16m 50s\tremaining: 34m 34s\n",
      "3276:\tlearn: 0.0353683\ttest: 0.0386880\tbest: 0.0386880 (3276)\ttotal: 16m 50s\tremaining: 34m 34s\n",
      "3277:\tlearn: 0.0353683\ttest: 0.0386880\tbest: 0.0386880 (3277)\ttotal: 16m 51s\tremaining: 34m 34s\n",
      "3278:\tlearn: 0.0353683\ttest: 0.0386880\tbest: 0.0386880 (3278)\ttotal: 16m 51s\tremaining: 34m 34s\n",
      "3279:\tlearn: 0.0353651\ttest: 0.0386874\tbest: 0.0386874 (3279)\ttotal: 16m 52s\tremaining: 34m 34s\n",
      "3280:\tlearn: 0.0353651\ttest: 0.0386874\tbest: 0.0386874 (3280)\ttotal: 16m 52s\tremaining: 34m 33s\n",
      "3281:\tlearn: 0.0353651\ttest: 0.0386874\tbest: 0.0386874 (3281)\ttotal: 16m 52s\tremaining: 34m 33s\n",
      "3282:\tlearn: 0.0353602\ttest: 0.0386861\tbest: 0.0386861 (3282)\ttotal: 16m 53s\tremaining: 34m 33s\n",
      "3283:\tlearn: 0.0353602\ttest: 0.0386861\tbest: 0.0386861 (3283)\ttotal: 16m 53s\tremaining: 34m 32s\n",
      "3284:\tlearn: 0.0353602\ttest: 0.0386861\tbest: 0.0386861 (3284)\ttotal: 16m 53s\tremaining: 34m 32s\n",
      "3285:\tlearn: 0.0353602\ttest: 0.0386861\tbest: 0.0386861 (3284)\ttotal: 16m 54s\tremaining: 34m 31s\n",
      "3286:\tlearn: 0.0353602\ttest: 0.0386861\tbest: 0.0386861 (3286)\ttotal: 16m 54s\tremaining: 34m 31s\n",
      "3287:\tlearn: 0.0353602\ttest: 0.0386861\tbest: 0.0386861 (3286)\ttotal: 16m 54s\tremaining: 34m 31s\n",
      "3288:\tlearn: 0.0353588\ttest: 0.0386858\tbest: 0.0386858 (3288)\ttotal: 16m 54s\tremaining: 34m 30s\n",
      "3289:\tlearn: 0.0353588\ttest: 0.0386858\tbest: 0.0386858 (3289)\ttotal: 16m 55s\tremaining: 34m 30s\n",
      "3290:\tlearn: 0.0353537\ttest: 0.0386857\tbest: 0.0386857 (3290)\ttotal: 16m 55s\tremaining: 34m 29s\n",
      "3291:\tlearn: 0.0353537\ttest: 0.0386857\tbest: 0.0386857 (3291)\ttotal: 16m 55s\tremaining: 34m 29s\n",
      "3292:\tlearn: 0.0353537\ttest: 0.0386857\tbest: 0.0386857 (3292)\ttotal: 16m 55s\tremaining: 34m 29s\n",
      "3293:\tlearn: 0.0353537\ttest: 0.0386857\tbest: 0.0386857 (3293)\ttotal: 16m 56s\tremaining: 34m 28s\n",
      "3294:\tlearn: 0.0353537\ttest: 0.0386857\tbest: 0.0386857 (3294)\ttotal: 16m 56s\tremaining: 34m 28s\n",
      "3295:\tlearn: 0.0353537\ttest: 0.0386857\tbest: 0.0386857 (3295)\ttotal: 16m 56s\tremaining: 34m 27s\n",
      "3296:\tlearn: 0.0353537\ttest: 0.0386857\tbest: 0.0386857 (3296)\ttotal: 16m 56s\tremaining: 34m 27s\n",
      "3297:\tlearn: 0.0353481\ttest: 0.0386849\tbest: 0.0386849 (3297)\ttotal: 16m 57s\tremaining: 34m 27s\n",
      "3298:\tlearn: 0.0353481\ttest: 0.0386849\tbest: 0.0386849 (3297)\ttotal: 16m 57s\tremaining: 34m 26s\n",
      "3299:\tlearn: 0.0353481\ttest: 0.0386849\tbest: 0.0386849 (3297)\ttotal: 16m 57s\tremaining: 34m 26s\n",
      "3300:\tlearn: 0.0353481\ttest: 0.0386849\tbest: 0.0386849 (3297)\ttotal: 16m 57s\tremaining: 34m 25s\n",
      "3301:\tlearn: 0.0353481\ttest: 0.0386849\tbest: 0.0386849 (3301)\ttotal: 16m 58s\tremaining: 34m 25s\n",
      "3302:\tlearn: 0.0353481\ttest: 0.0386849\tbest: 0.0386849 (3302)\ttotal: 16m 58s\tremaining: 34m 25s\n",
      "3303:\tlearn: 0.0353446\ttest: 0.0386833\tbest: 0.0386833 (3303)\ttotal: 16m 58s\tremaining: 34m 24s\n",
      "3304:\tlearn: 0.0353446\ttest: 0.0386833\tbest: 0.0386833 (3304)\ttotal: 16m 59s\tremaining: 34m 24s\n",
      "3305:\tlearn: 0.0353400\ttest: 0.0386804\tbest: 0.0386804 (3305)\ttotal: 16m 59s\tremaining: 34m 24s\n",
      "3306:\tlearn: 0.0353365\ttest: 0.0386791\tbest: 0.0386791 (3306)\ttotal: 16m 59s\tremaining: 34m 23s\n",
      "3307:\tlearn: 0.0353288\ttest: 0.0386771\tbest: 0.0386771 (3307)\ttotal: 16m 59s\tremaining: 34m 23s\n",
      "3308:\tlearn: 0.0353288\ttest: 0.0386771\tbest: 0.0386771 (3308)\ttotal: 17m\tremaining: 34m 23s\n",
      "3309:\tlearn: 0.0353288\ttest: 0.0386771\tbest: 0.0386771 (3309)\ttotal: 17m\tremaining: 34m 22s\n",
      "3310:\tlearn: 0.0353288\ttest: 0.0386771\tbest: 0.0386771 (3309)\ttotal: 17m\tremaining: 34m 22s\n",
      "3311:\tlearn: 0.0353288\ttest: 0.0386771\tbest: 0.0386771 (3309)\ttotal: 17m 1s\tremaining: 34m 21s\n",
      "3312:\tlearn: 0.0353288\ttest: 0.0386771\tbest: 0.0386771 (3312)\ttotal: 17m 1s\tremaining: 34m 21s\n",
      "3313:\tlearn: 0.0353220\ttest: 0.0386751\tbest: 0.0386751 (3313)\ttotal: 17m 1s\tremaining: 34m 21s\n",
      "3314:\tlearn: 0.0353220\ttest: 0.0386751\tbest: 0.0386751 (3314)\ttotal: 17m 1s\tremaining: 34m 20s\n",
      "3315:\tlearn: 0.0353220\ttest: 0.0386751\tbest: 0.0386751 (3315)\ttotal: 17m 2s\tremaining: 34m 20s\n",
      "3316:\tlearn: 0.0353220\ttest: 0.0386751\tbest: 0.0386751 (3315)\ttotal: 17m 2s\tremaining: 34m 19s\n",
      "3317:\tlearn: 0.0353220\ttest: 0.0386751\tbest: 0.0386751 (3315)\ttotal: 17m 2s\tremaining: 34m 19s\n",
      "3318:\tlearn: 0.0353220\ttest: 0.0386751\tbest: 0.0386751 (3315)\ttotal: 17m 2s\tremaining: 34m 19s\n",
      "3319:\tlearn: 0.0353220\ttest: 0.0386751\tbest: 0.0386751 (3319)\ttotal: 17m 3s\tremaining: 34m 19s\n",
      "3320:\tlearn: 0.0353193\ttest: 0.0386747\tbest: 0.0386747 (3320)\ttotal: 17m 3s\tremaining: 34m 19s\n",
      "3321:\tlearn: 0.0353143\ttest: 0.0386728\tbest: 0.0386728 (3321)\ttotal: 17m 4s\tremaining: 34m 19s\n",
      "3322:\tlearn: 0.0353143\ttest: 0.0386728\tbest: 0.0386728 (3322)\ttotal: 17m 4s\tremaining: 34m 19s\n",
      "3323:\tlearn: 0.0353108\ttest: 0.0386719\tbest: 0.0386719 (3323)\ttotal: 17m 5s\tremaining: 34m 19s\n",
      "3324:\tlearn: 0.0353108\ttest: 0.0386719\tbest: 0.0386719 (3324)\ttotal: 17m 5s\tremaining: 34m 19s\n",
      "3325:\tlearn: 0.0353107\ttest: 0.0386719\tbest: 0.0386719 (3325)\ttotal: 17m 6s\tremaining: 34m 19s\n",
      "3326:\tlearn: 0.0353107\ttest: 0.0386719\tbest: 0.0386719 (3326)\ttotal: 17m 6s\tremaining: 34m 19s\n",
      "3327:\tlearn: 0.0353107\ttest: 0.0386719\tbest: 0.0386719 (3327)\ttotal: 17m 6s\tremaining: 34m 18s\n",
      "3328:\tlearn: 0.0353107\ttest: 0.0386719\tbest: 0.0386719 (3327)\ttotal: 17m 7s\tremaining: 34m 18s\n",
      "3329:\tlearn: 0.0353107\ttest: 0.0386719\tbest: 0.0386719 (3327)\ttotal: 17m 7s\tremaining: 34m 17s\n",
      "3330:\tlearn: 0.0353107\ttest: 0.0386719\tbest: 0.0386719 (3330)\ttotal: 17m 7s\tremaining: 34m 17s\n",
      "3331:\tlearn: 0.0353107\ttest: 0.0386719\tbest: 0.0386719 (3330)\ttotal: 17m 7s\tremaining: 34m 17s\n",
      "3332:\tlearn: 0.0353107\ttest: 0.0386718\tbest: 0.0386718 (3332)\ttotal: 17m 8s\tremaining: 34m 16s\n",
      "3333:\tlearn: 0.0353077\ttest: 0.0386696\tbest: 0.0386696 (3333)\ttotal: 17m 8s\tremaining: 34m 16s\n",
      "3334:\tlearn: 0.0353077\ttest: 0.0386696\tbest: 0.0386696 (3334)\ttotal: 17m 8s\tremaining: 34m 15s\n",
      "3335:\tlearn: 0.0353077\ttest: 0.0386696\tbest: 0.0386696 (3334)\ttotal: 17m 9s\tremaining: 34m 15s\n",
      "3336:\tlearn: 0.0353027\ttest: 0.0386682\tbest: 0.0386682 (3336)\ttotal: 17m 9s\tremaining: 34m 15s\n",
      "3337:\tlearn: 0.0353027\ttest: 0.0386682\tbest: 0.0386682 (3337)\ttotal: 17m 9s\tremaining: 34m 14s\n",
      "3338:\tlearn: 0.0353027\ttest: 0.0386682\tbest: 0.0386682 (3338)\ttotal: 17m 9s\tremaining: 34m 14s\n",
      "3339:\tlearn: 0.0353027\ttest: 0.0386682\tbest: 0.0386682 (3339)\ttotal: 17m 10s\tremaining: 34m 14s\n",
      "3340:\tlearn: 0.0353026\ttest: 0.0386682\tbest: 0.0386682 (3340)\ttotal: 17m 10s\tremaining: 34m 13s\n",
      "3341:\tlearn: 0.0353026\ttest: 0.0386682\tbest: 0.0386682 (3340)\ttotal: 17m 10s\tremaining: 34m 13s\n",
      "3342:\tlearn: 0.0353026\ttest: 0.0386682\tbest: 0.0386682 (3342)\ttotal: 17m 10s\tremaining: 34m 12s\n",
      "3343:\tlearn: 0.0353026\ttest: 0.0386682\tbest: 0.0386682 (3343)\ttotal: 17m 11s\tremaining: 34m 12s\n",
      "3344:\tlearn: 0.0353026\ttest: 0.0386682\tbest: 0.0386682 (3344)\ttotal: 17m 11s\tremaining: 34m 12s\n",
      "3345:\tlearn: 0.0353026\ttest: 0.0386682\tbest: 0.0386682 (3344)\ttotal: 17m 11s\tremaining: 34m 11s\n",
      "3346:\tlearn: 0.0353026\ttest: 0.0386682\tbest: 0.0386682 (3344)\ttotal: 17m 11s\tremaining: 34m 11s\n",
      "3347:\tlearn: 0.0353026\ttest: 0.0386682\tbest: 0.0386682 (3347)\ttotal: 17m 12s\tremaining: 34m 10s\n",
      "3348:\tlearn: 0.0353004\ttest: 0.0386675\tbest: 0.0386675 (3348)\ttotal: 17m 12s\tremaining: 34m 10s\n",
      "3349:\tlearn: 0.0353004\ttest: 0.0386675\tbest: 0.0386675 (3349)\ttotal: 17m 12s\tremaining: 34m 10s\n",
      "3350:\tlearn: 0.0352932\ttest: 0.0386636\tbest: 0.0386636 (3350)\ttotal: 17m 13s\tremaining: 34m 9s\n",
      "3351:\tlearn: 0.0352932\ttest: 0.0386636\tbest: 0.0386636 (3351)\ttotal: 17m 13s\tremaining: 34m 9s\n",
      "3352:\tlearn: 0.0352932\ttest: 0.0386636\tbest: 0.0386636 (3352)\ttotal: 17m 13s\tremaining: 34m 8s\n",
      "3353:\tlearn: 0.0352932\ttest: 0.0386636\tbest: 0.0386636 (3353)\ttotal: 17m 13s\tremaining: 34m 8s\n",
      "3354:\tlearn: 0.0352887\ttest: 0.0386625\tbest: 0.0386625 (3354)\ttotal: 17m 14s\tremaining: 34m 8s\n",
      "3355:\tlearn: 0.0352887\ttest: 0.0386625\tbest: 0.0386625 (3355)\ttotal: 17m 14s\tremaining: 34m 7s\n",
      "3356:\tlearn: 0.0352886\ttest: 0.0386625\tbest: 0.0386625 (3356)\ttotal: 17m 14s\tremaining: 34m 7s\n",
      "3357:\tlearn: 0.0352886\ttest: 0.0386625\tbest: 0.0386625 (3356)\ttotal: 17m 14s\tremaining: 34m 7s\n",
      "3358:\tlearn: 0.0352886\ttest: 0.0386625\tbest: 0.0386625 (3358)\ttotal: 17m 15s\tremaining: 34m 6s\n",
      "3359:\tlearn: 0.0352886\ttest: 0.0386625\tbest: 0.0386625 (3358)\ttotal: 17m 15s\tremaining: 34m 6s\n",
      "3360:\tlearn: 0.0352886\ttest: 0.0386625\tbest: 0.0386625 (3358)\ttotal: 17m 15s\tremaining: 34m 5s\n",
      "3361:\tlearn: 0.0352841\ttest: 0.0386624\tbest: 0.0386624 (3361)\ttotal: 17m 16s\tremaining: 34m 5s\n",
      "3362:\tlearn: 0.0352841\ttest: 0.0386624\tbest: 0.0386624 (3362)\ttotal: 17m 16s\tremaining: 34m 5s\n",
      "3363:\tlearn: 0.0352841\ttest: 0.0386624\tbest: 0.0386624 (3363)\ttotal: 17m 16s\tremaining: 34m 4s\n",
      "3364:\tlearn: 0.0352841\ttest: 0.0386624\tbest: 0.0386624 (3364)\ttotal: 17m 17s\tremaining: 34m 4s\n",
      "3365:\tlearn: 0.0352841\ttest: 0.0386624\tbest: 0.0386624 (3364)\ttotal: 17m 17s\tremaining: 34m 4s\n",
      "3366:\tlearn: 0.0352815\ttest: 0.0386620\tbest: 0.0386620 (3366)\ttotal: 17m 18s\tremaining: 34m 4s\n",
      "3367:\tlearn: 0.0352815\ttest: 0.0386620\tbest: 0.0386620 (3367)\ttotal: 17m 18s\tremaining: 34m 4s\n",
      "3368:\tlearn: 0.0352776\ttest: 0.0386610\tbest: 0.0386610 (3368)\ttotal: 17m 19s\tremaining: 34m 5s\n",
      "3369:\tlearn: 0.0352776\ttest: 0.0386610\tbest: 0.0386610 (3368)\ttotal: 17m 19s\tremaining: 34m 5s\n",
      "3370:\tlearn: 0.0352776\ttest: 0.0386610\tbest: 0.0386610 (3370)\ttotal: 17m 19s\tremaining: 34m 5s\n",
      "3371:\tlearn: 0.0352776\ttest: 0.0386610\tbest: 0.0386610 (3371)\ttotal: 17m 20s\tremaining: 34m 5s\n",
      "3372:\tlearn: 0.0352776\ttest: 0.0386610\tbest: 0.0386610 (3372)\ttotal: 17m 20s\tremaining: 34m 4s\n",
      "3373:\tlearn: 0.0352776\ttest: 0.0386610\tbest: 0.0386610 (3373)\ttotal: 17m 20s\tremaining: 34m 4s\n",
      "3374:\tlearn: 0.0352776\ttest: 0.0386610\tbest: 0.0386610 (3373)\ttotal: 17m 21s\tremaining: 34m 3s\n",
      "3375:\tlearn: 0.0352740\ttest: 0.0386611\tbest: 0.0386610 (3373)\ttotal: 17m 21s\tremaining: 34m 3s\n",
      "3376:\tlearn: 0.0352740\ttest: 0.0386611\tbest: 0.0386610 (3373)\ttotal: 17m 21s\tremaining: 34m 3s\n",
      "3377:\tlearn: 0.0352740\ttest: 0.0386611\tbest: 0.0386610 (3373)\ttotal: 17m 22s\tremaining: 34m 2s\n",
      "3378:\tlearn: 0.0352740\ttest: 0.0386610\tbest: 0.0386610 (3373)\ttotal: 17m 22s\tremaining: 34m 2s\n",
      "3379:\tlearn: 0.0352740\ttest: 0.0386610\tbest: 0.0386610 (3373)\ttotal: 17m 22s\tremaining: 34m 1s\n",
      "3380:\tlearn: 0.0352664\ttest: 0.0386567\tbest: 0.0386567 (3380)\ttotal: 17m 22s\tremaining: 34m 1s\n",
      "3381:\tlearn: 0.0352664\ttest: 0.0386567\tbest: 0.0386567 (3381)\ttotal: 17m 23s\tremaining: 34m 1s\n",
      "3382:\tlearn: 0.0352664\ttest: 0.0386567\tbest: 0.0386567 (3382)\ttotal: 17m 23s\tremaining: 34m\n",
      "3383:\tlearn: 0.0352664\ttest: 0.0386567\tbest: 0.0386567 (3383)\ttotal: 17m 23s\tremaining: 34m\n",
      "3384:\tlearn: 0.0352664\ttest: 0.0386567\tbest: 0.0386567 (3384)\ttotal: 17m 23s\tremaining: 34m\n",
      "3385:\tlearn: 0.0352664\ttest: 0.0386567\tbest: 0.0386567 (3384)\ttotal: 17m 24s\tremaining: 33m 59s\n",
      "3386:\tlearn: 0.0352664\ttest: 0.0386567\tbest: 0.0386567 (3384)\ttotal: 17m 24s\tremaining: 33m 59s\n",
      "3387:\tlearn: 0.0352664\ttest: 0.0386567\tbest: 0.0386567 (3384)\ttotal: 17m 24s\tremaining: 33m 58s\n",
      "3388:\tlearn: 0.0352664\ttest: 0.0386567\tbest: 0.0386567 (3384)\ttotal: 17m 24s\tremaining: 33m 58s\n",
      "3389:\tlearn: 0.0352664\ttest: 0.0386567\tbest: 0.0386567 (3384)\ttotal: 17m 25s\tremaining: 33m 57s\n",
      "3390:\tlearn: 0.0352664\ttest: 0.0386567\tbest: 0.0386567 (3384)\ttotal: 17m 25s\tremaining: 33m 57s\n",
      "3391:\tlearn: 0.0352664\ttest: 0.0386567\tbest: 0.0386567 (3391)\ttotal: 17m 25s\tremaining: 33m 57s\n",
      "3392:\tlearn: 0.0352664\ttest: 0.0386567\tbest: 0.0386567 (3391)\ttotal: 17m 25s\tremaining: 33m 56s\n",
      "3393:\tlearn: 0.0352664\ttest: 0.0386567\tbest: 0.0386567 (3391)\ttotal: 17m 26s\tremaining: 33m 56s\n",
      "3394:\tlearn: 0.0352630\ttest: 0.0386568\tbest: 0.0386567 (3391)\ttotal: 17m 26s\tremaining: 33m 56s\n",
      "3395:\tlearn: 0.0352630\ttest: 0.0386568\tbest: 0.0386567 (3391)\ttotal: 17m 26s\tremaining: 33m 55s\n",
      "3396:\tlearn: 0.0352630\ttest: 0.0386568\tbest: 0.0386567 (3391)\ttotal: 17m 27s\tremaining: 33m 55s\n",
      "3397:\tlearn: 0.0352630\ttest: 0.0386568\tbest: 0.0386567 (3391)\ttotal: 17m 27s\tremaining: 33m 54s\n",
      "3398:\tlearn: 0.0352630\ttest: 0.0386568\tbest: 0.0386567 (3391)\ttotal: 17m 27s\tremaining: 33m 54s\n",
      "3399:\tlearn: 0.0352630\ttest: 0.0386568\tbest: 0.0386567 (3391)\ttotal: 17m 27s\tremaining: 33m 54s\n",
      "3400:\tlearn: 0.0352630\ttest: 0.0386568\tbest: 0.0386567 (3391)\ttotal: 17m 28s\tremaining: 33m 53s\n",
      "3401:\tlearn: 0.0352630\ttest: 0.0386568\tbest: 0.0386567 (3391)\ttotal: 17m 28s\tremaining: 33m 53s\n",
      "3402:\tlearn: 0.0352630\ttest: 0.0386568\tbest: 0.0386567 (3391)\ttotal: 17m 28s\tremaining: 33m 52s\n",
      "3403:\tlearn: 0.0352629\ttest: 0.0386568\tbest: 0.0386567 (3391)\ttotal: 17m 28s\tremaining: 33m 52s\n",
      "3404:\tlearn: 0.0352629\ttest: 0.0386567\tbest: 0.0386567 (3391)\ttotal: 17m 29s\tremaining: 33m 51s\n",
      "3405:\tlearn: 0.0352629\ttest: 0.0386567\tbest: 0.0386567 (3391)\ttotal: 17m 29s\tremaining: 33m 51s\n",
      "3406:\tlearn: 0.0352629\ttest: 0.0386567\tbest: 0.0386567 (3391)\ttotal: 17m 29s\tremaining: 33m 51s\n",
      "3407:\tlearn: 0.0352628\ttest: 0.0386567\tbest: 0.0386567 (3391)\ttotal: 17m 29s\tremaining: 33m 50s\n",
      "3408:\tlearn: 0.0352628\ttest: 0.0386567\tbest: 0.0386567 (3391)\ttotal: 17m 30s\tremaining: 33m 50s\n",
      "3409:\tlearn: 0.0352628\ttest: 0.0386567\tbest: 0.0386567 (3391)\ttotal: 17m 30s\tremaining: 33m 49s\n",
      "3410:\tlearn: 0.0352628\ttest: 0.0386567\tbest: 0.0386567 (3391)\ttotal: 17m 30s\tremaining: 33m 49s\n",
      "3411:\tlearn: 0.0352561\ttest: 0.0386532\tbest: 0.0386532 (3411)\ttotal: 17m 31s\tremaining: 33m 49s\n",
      "3412:\tlearn: 0.0352561\ttest: 0.0386532\tbest: 0.0386532 (3411)\ttotal: 17m 31s\tremaining: 33m 49s\n",
      "3413:\tlearn: 0.0352514\ttest: 0.0386532\tbest: 0.0386532 (3413)\ttotal: 17m 32s\tremaining: 33m 49s\n",
      "3414:\tlearn: 0.0352514\ttest: 0.0386532\tbest: 0.0386532 (3414)\ttotal: 17m 32s\tremaining: 33m 49s\n",
      "3415:\tlearn: 0.0352514\ttest: 0.0386532\tbest: 0.0386532 (3415)\ttotal: 17m 33s\tremaining: 33m 49s\n",
      "3416:\tlearn: 0.0352514\ttest: 0.0386532\tbest: 0.0386532 (3416)\ttotal: 17m 33s\tremaining: 33m 49s\n",
      "3417:\tlearn: 0.0352514\ttest: 0.0386532\tbest: 0.0386532 (3417)\ttotal: 17m 33s\tremaining: 33m 49s\n",
      "3418:\tlearn: 0.0352514\ttest: 0.0386532\tbest: 0.0386532 (3417)\ttotal: 17m 34s\tremaining: 33m 49s\n",
      "3419:\tlearn: 0.0352514\ttest: 0.0386532\tbest: 0.0386532 (3419)\ttotal: 17m 34s\tremaining: 33m 49s\n",
      "3420:\tlearn: 0.0352514\ttest: 0.0386532\tbest: 0.0386532 (3420)\ttotal: 17m 35s\tremaining: 33m 49s\n",
      "3421:\tlearn: 0.0352514\ttest: 0.0386532\tbest: 0.0386532 (3421)\ttotal: 17m 35s\tremaining: 33m 48s\n",
      "3422:\tlearn: 0.0352514\ttest: 0.0386532\tbest: 0.0386532 (3421)\ttotal: 17m 35s\tremaining: 33m 48s\n",
      "3423:\tlearn: 0.0352514\ttest: 0.0386532\tbest: 0.0386532 (3421)\ttotal: 17m 35s\tremaining: 33m 47s\n",
      "3424:\tlearn: 0.0352514\ttest: 0.0386532\tbest: 0.0386532 (3424)\ttotal: 17m 36s\tremaining: 33m 47s\n",
      "3425:\tlearn: 0.0352513\ttest: 0.0386532\tbest: 0.0386532 (3424)\ttotal: 17m 36s\tremaining: 33m 47s\n",
      "3426:\tlearn: 0.0352479\ttest: 0.0386524\tbest: 0.0386524 (3426)\ttotal: 17m 36s\tremaining: 33m 46s\n",
      "3427:\tlearn: 0.0352479\ttest: 0.0386524\tbest: 0.0386524 (3427)\ttotal: 17m 36s\tremaining: 33m 46s\n",
      "3428:\tlearn: 0.0352479\ttest: 0.0386524\tbest: 0.0386524 (3428)\ttotal: 17m 37s\tremaining: 33m 45s\n",
      "3429:\tlearn: 0.0352479\ttest: 0.0386524\tbest: 0.0386524 (3429)\ttotal: 17m 37s\tremaining: 33m 45s\n",
      "3430:\tlearn: 0.0352479\ttest: 0.0386524\tbest: 0.0386524 (3429)\ttotal: 17m 37s\tremaining: 33m 45s\n",
      "3431:\tlearn: 0.0352479\ttest: 0.0386524\tbest: 0.0386524 (3431)\ttotal: 17m 37s\tremaining: 33m 44s\n",
      "3432:\tlearn: 0.0352479\ttest: 0.0386524\tbest: 0.0386524 (3431)\ttotal: 17m 38s\tremaining: 33m 44s\n",
      "3433:\tlearn: 0.0352479\ttest: 0.0386524\tbest: 0.0386524 (3433)\ttotal: 17m 38s\tremaining: 33m 43s\n",
      "3434:\tlearn: 0.0352478\ttest: 0.0386524\tbest: 0.0386524 (3434)\ttotal: 17m 38s\tremaining: 33m 43s\n",
      "3435:\tlearn: 0.0352478\ttest: 0.0386524\tbest: 0.0386524 (3434)\ttotal: 17m 39s\tremaining: 33m 43s\n",
      "3436:\tlearn: 0.0352478\ttest: 0.0386524\tbest: 0.0386524 (3436)\ttotal: 17m 39s\tremaining: 33m 42s\n",
      "3437:\tlearn: 0.0352478\ttest: 0.0386523\tbest: 0.0386523 (3437)\ttotal: 17m 39s\tremaining: 33m 42s\n",
      "3438:\tlearn: 0.0352479\ttest: 0.0386523\tbest: 0.0386523 (3438)\ttotal: 17m 39s\tremaining: 33m 41s\n",
      "3439:\tlearn: 0.0352478\ttest: 0.0386523\tbest: 0.0386523 (3439)\ttotal: 17m 40s\tremaining: 33m 41s\n",
      "3440:\tlearn: 0.0352478\ttest: 0.0386523\tbest: 0.0386523 (3439)\ttotal: 17m 40s\tremaining: 33m 41s\n",
      "3441:\tlearn: 0.0352478\ttest: 0.0386523\tbest: 0.0386523 (3439)\ttotal: 17m 40s\tremaining: 33m 40s\n",
      "3442:\tlearn: 0.0352478\ttest: 0.0386523\tbest: 0.0386523 (3442)\ttotal: 17m 40s\tremaining: 33m 40s\n",
      "3443:\tlearn: 0.0352478\ttest: 0.0386523\tbest: 0.0386523 (3443)\ttotal: 17m 41s\tremaining: 33m 39s\n",
      "3444:\tlearn: 0.0352478\ttest: 0.0386523\tbest: 0.0386523 (3444)\ttotal: 17m 41s\tremaining: 33m 39s\n",
      "3445:\tlearn: 0.0352418\ttest: 0.0386522\tbest: 0.0386522 (3445)\ttotal: 17m 41s\tremaining: 33m 39s\n",
      "3446:\tlearn: 0.0352376\ttest: 0.0386508\tbest: 0.0386508 (3446)\ttotal: 17m 42s\tremaining: 33m 38s\n",
      "3447:\tlearn: 0.0352376\ttest: 0.0386508\tbest: 0.0386508 (3447)\ttotal: 17m 42s\tremaining: 33m 38s\n",
      "3448:\tlearn: 0.0352376\ttest: 0.0386508\tbest: 0.0386508 (3448)\ttotal: 17m 42s\tremaining: 33m 38s\n",
      "3449:\tlearn: 0.0352315\ttest: 0.0386482\tbest: 0.0386482 (3449)\ttotal: 17m 42s\tremaining: 33m 37s\n",
      "3450:\tlearn: 0.0352315\ttest: 0.0386481\tbest: 0.0386481 (3450)\ttotal: 17m 43s\tremaining: 33m 37s\n",
      "3451:\tlearn: 0.0352315\ttest: 0.0386481\tbest: 0.0386481 (3450)\ttotal: 17m 43s\tremaining: 33m 37s\n",
      "3452:\tlearn: 0.0352315\ttest: 0.0386481\tbest: 0.0386481 (3452)\ttotal: 17m 43s\tremaining: 33m 36s\n",
      "3453:\tlearn: 0.0352315\ttest: 0.0386481\tbest: 0.0386481 (3453)\ttotal: 17m 43s\tremaining: 33m 36s\n",
      "3454:\tlearn: 0.0352315\ttest: 0.0386481\tbest: 0.0386481 (3453)\ttotal: 17m 44s\tremaining: 33m 35s\n",
      "3455:\tlearn: 0.0352315\ttest: 0.0386481\tbest: 0.0386481 (3453)\ttotal: 17m 44s\tremaining: 33m 35s\n",
      "3456:\tlearn: 0.0352283\ttest: 0.0386473\tbest: 0.0386473 (3456)\ttotal: 17m 44s\tremaining: 33m 35s\n",
      "3457:\tlearn: 0.0352283\ttest: 0.0386473\tbest: 0.0386473 (3457)\ttotal: 17m 45s\tremaining: 33m 35s\n",
      "3458:\tlearn: 0.0352283\ttest: 0.0386473\tbest: 0.0386473 (3457)\ttotal: 17m 45s\tremaining: 33m 34s\n",
      "3459:\tlearn: 0.0352239\ttest: 0.0386464\tbest: 0.0386464 (3459)\ttotal: 17m 46s\tremaining: 33m 35s\n",
      "3460:\tlearn: 0.0352203\ttest: 0.0386453\tbest: 0.0386453 (3460)\ttotal: 17m 46s\tremaining: 33m 35s\n",
      "3461:\tlearn: 0.0352203\ttest: 0.0386453\tbest: 0.0386453 (3461)\ttotal: 17m 47s\tremaining: 33m 35s\n",
      "3462:\tlearn: 0.0352164\ttest: 0.0386453\tbest: 0.0386453 (3461)\ttotal: 17m 47s\tremaining: 33m 35s\n",
      "3463:\tlearn: 0.0352121\ttest: 0.0386451\tbest: 0.0386451 (3463)\ttotal: 17m 48s\tremaining: 33m 35s\n",
      "3464:\tlearn: 0.0352063\ttest: 0.0386414\tbest: 0.0386414 (3464)\ttotal: 17m 48s\tremaining: 33m 35s\n",
      "3465:\tlearn: 0.0352063\ttest: 0.0386414\tbest: 0.0386414 (3465)\ttotal: 17m 49s\tremaining: 33m 35s\n",
      "3466:\tlearn: 0.0352063\ttest: 0.0386414\tbest: 0.0386414 (3465)\ttotal: 17m 49s\tremaining: 33m 35s\n",
      "3467:\tlearn: 0.0352063\ttest: 0.0386414\tbest: 0.0386414 (3467)\ttotal: 17m 49s\tremaining: 33m 34s\n",
      "3468:\tlearn: 0.0352063\ttest: 0.0386414\tbest: 0.0386414 (3468)\ttotal: 17m 49s\tremaining: 33m 34s\n",
      "3469:\tlearn: 0.0352063\ttest: 0.0386414\tbest: 0.0386414 (3468)\ttotal: 17m 50s\tremaining: 33m 33s\n",
      "3470:\tlearn: 0.0352063\ttest: 0.0386414\tbest: 0.0386414 (3470)\ttotal: 17m 50s\tremaining: 33m 33s\n",
      "3471:\tlearn: 0.0352063\ttest: 0.0386414\tbest: 0.0386414 (3470)\ttotal: 17m 50s\tremaining: 33m 32s\n",
      "3472:\tlearn: 0.0352063\ttest: 0.0386414\tbest: 0.0386414 (3470)\ttotal: 17m 50s\tremaining: 33m 32s\n",
      "3473:\tlearn: 0.0352063\ttest: 0.0386414\tbest: 0.0386414 (3473)\ttotal: 17m 51s\tremaining: 33m 32s\n",
      "3474:\tlearn: 0.0352063\ttest: 0.0386414\tbest: 0.0386414 (3473)\ttotal: 17m 51s\tremaining: 33m 31s\n",
      "3475:\tlearn: 0.0352019\ttest: 0.0386401\tbest: 0.0386401 (3475)\ttotal: 17m 51s\tremaining: 33m 31s\n",
      "3476:\tlearn: 0.0352019\ttest: 0.0386401\tbest: 0.0386401 (3476)\ttotal: 17m 51s\tremaining: 33m 31s\n",
      "3477:\tlearn: 0.0352019\ttest: 0.0386401\tbest: 0.0386401 (3477)\ttotal: 17m 52s\tremaining: 33m 31s\n",
      "3478:\tlearn: 0.0352019\ttest: 0.0386401\tbest: 0.0386401 (3478)\ttotal: 17m 52s\tremaining: 33m 30s\n",
      "3479:\tlearn: 0.0351973\ttest: 0.0386367\tbest: 0.0386367 (3479)\ttotal: 17m 53s\tremaining: 33m 31s\n",
      "3480:\tlearn: 0.0351973\ttest: 0.0386367\tbest: 0.0386367 (3480)\ttotal: 17m 53s\tremaining: 33m 30s\n",
      "3481:\tlearn: 0.0351973\ttest: 0.0386367\tbest: 0.0386367 (3481)\ttotal: 17m 54s\tremaining: 33m 30s\n",
      "3482:\tlearn: 0.0351942\ttest: 0.0386362\tbest: 0.0386362 (3482)\ttotal: 17m 54s\tremaining: 33m 31s\n",
      "3483:\tlearn: 0.0351942\ttest: 0.0386362\tbest: 0.0386362 (3482)\ttotal: 17m 55s\tremaining: 33m 31s\n",
      "3484:\tlearn: 0.0351942\ttest: 0.0386362\tbest: 0.0386362 (3484)\ttotal: 17m 55s\tremaining: 33m 31s\n",
      "3485:\tlearn: 0.0351942\ttest: 0.0386362\tbest: 0.0386362 (3484)\ttotal: 17m 56s\tremaining: 33m 30s\n",
      "3486:\tlearn: 0.0351904\ttest: 0.0386346\tbest: 0.0386346 (3486)\ttotal: 17m 56s\tremaining: 33m 30s\n",
      "3487:\tlearn: 0.0351904\ttest: 0.0386346\tbest: 0.0386346 (3486)\ttotal: 17m 56s\tremaining: 33m 30s\n",
      "3488:\tlearn: 0.0351904\ttest: 0.0386346\tbest: 0.0386346 (3488)\ttotal: 17m 56s\tremaining: 33m 29s\n",
      "3489:\tlearn: 0.0351904\ttest: 0.0386346\tbest: 0.0386346 (3488)\ttotal: 17m 57s\tremaining: 33m 29s\n",
      "3490:\tlearn: 0.0351904\ttest: 0.0386346\tbest: 0.0386346 (3490)\ttotal: 17m 57s\tremaining: 33m 28s\n",
      "3491:\tlearn: 0.0351862\ttest: 0.0386335\tbest: 0.0386335 (3491)\ttotal: 17m 57s\tremaining: 33m 28s\n",
      "3492:\tlearn: 0.0351862\ttest: 0.0386335\tbest: 0.0386335 (3492)\ttotal: 17m 58s\tremaining: 33m 28s\n",
      "3493:\tlearn: 0.0351862\ttest: 0.0386335\tbest: 0.0386335 (3492)\ttotal: 17m 58s\tremaining: 33m 27s\n",
      "3494:\tlearn: 0.0351862\ttest: 0.0386335\tbest: 0.0386335 (3494)\ttotal: 17m 58s\tremaining: 33m 27s\n",
      "3495:\tlearn: 0.0351862\ttest: 0.0386335\tbest: 0.0386335 (3495)\ttotal: 17m 58s\tremaining: 33m 27s\n",
      "3496:\tlearn: 0.0351862\ttest: 0.0386335\tbest: 0.0386335 (3495)\ttotal: 17m 59s\tremaining: 33m 26s\n",
      "3497:\tlearn: 0.0351827\ttest: 0.0386328\tbest: 0.0386328 (3497)\ttotal: 17m 59s\tremaining: 33m 27s\n",
      "3498:\tlearn: 0.0351827\ttest: 0.0386328\tbest: 0.0386328 (3498)\ttotal: 18m\tremaining: 33m 27s\n",
      "3499:\tlearn: 0.0351827\ttest: 0.0386328\tbest: 0.0386328 (3499)\ttotal: 18m\tremaining: 33m 27s\n",
      "3500:\tlearn: 0.0351827\ttest: 0.0386328\tbest: 0.0386328 (3500)\ttotal: 18m 1s\tremaining: 33m 26s\n",
      "3501:\tlearn: 0.0351827\ttest: 0.0386328\tbest: 0.0386328 (3501)\ttotal: 18m 1s\tremaining: 33m 26s\n",
      "3502:\tlearn: 0.0351827\ttest: 0.0386328\tbest: 0.0386328 (3501)\ttotal: 18m 2s\tremaining: 33m 26s\n",
      "3503:\tlearn: 0.0351827\ttest: 0.0386328\tbest: 0.0386328 (3503)\ttotal: 18m 2s\tremaining: 33m 26s\n",
      "3504:\tlearn: 0.0351827\ttest: 0.0386328\tbest: 0.0386328 (3503)\ttotal: 18m 2s\tremaining: 33m 26s\n",
      "3505:\tlearn: 0.0351827\ttest: 0.0386328\tbest: 0.0386328 (3503)\ttotal: 18m 2s\tremaining: 33m 25s\n",
      "3506:\tlearn: 0.0351827\ttest: 0.0386328\tbest: 0.0386328 (3503)\ttotal: 18m 3s\tremaining: 33m 25s\n",
      "3507:\tlearn: 0.0351789\ttest: 0.0386318\tbest: 0.0386318 (3507)\ttotal: 18m 3s\tremaining: 33m 25s\n",
      "3508:\tlearn: 0.0351789\ttest: 0.0386318\tbest: 0.0386318 (3508)\ttotal: 18m 3s\tremaining: 33m 24s\n",
      "3509:\tlearn: 0.0351790\ttest: 0.0386318\tbest: 0.0386318 (3509)\ttotal: 18m 3s\tremaining: 33m 24s\n",
      "3510:\tlearn: 0.0351790\ttest: 0.0386318\tbest: 0.0386318 (3509)\ttotal: 18m 4s\tremaining: 33m 23s\n",
      "3511:\tlearn: 0.0351789\ttest: 0.0386318\tbest: 0.0386318 (3511)\ttotal: 18m 4s\tremaining: 33m 23s\n",
      "3512:\tlearn: 0.0351752\ttest: 0.0386306\tbest: 0.0386306 (3512)\ttotal: 18m 4s\tremaining: 33m 23s\n",
      "3513:\tlearn: 0.0351752\ttest: 0.0386306\tbest: 0.0386306 (3513)\ttotal: 18m 5s\tremaining: 33m 22s\n",
      "3514:\tlearn: 0.0351752\ttest: 0.0386306\tbest: 0.0386306 (3513)\ttotal: 18m 5s\tremaining: 33m 22s\n",
      "3515:\tlearn: 0.0351752\ttest: 0.0386306\tbest: 0.0386306 (3513)\ttotal: 18m 5s\tremaining: 33m 21s\n",
      "3516:\tlearn: 0.0351713\ttest: 0.0386303\tbest: 0.0386303 (3516)\ttotal: 18m 5s\tremaining: 33m 21s\n",
      "3517:\tlearn: 0.0351713\ttest: 0.0386303\tbest: 0.0386303 (3517)\ttotal: 18m 6s\tremaining: 33m 21s\n",
      "3518:\tlearn: 0.0351667\ttest: 0.0386295\tbest: 0.0386295 (3518)\ttotal: 18m 6s\tremaining: 33m 20s\n",
      "3519:\tlearn: 0.0351595\ttest: 0.0386271\tbest: 0.0386271 (3519)\ttotal: 18m 6s\tremaining: 33m 20s\n",
      "3520:\tlearn: 0.0351595\ttest: 0.0386271\tbest: 0.0386271 (3519)\ttotal: 18m 6s\tremaining: 33m 20s\n",
      "3521:\tlearn: 0.0351595\ttest: 0.0386271\tbest: 0.0386271 (3519)\ttotal: 18m 7s\tremaining: 33m 19s\n",
      "3522:\tlearn: 0.0351595\ttest: 0.0386271\tbest: 0.0386271 (3519)\ttotal: 18m 7s\tremaining: 33m 19s\n",
      "3523:\tlearn: 0.0351595\ttest: 0.0386271\tbest: 0.0386271 (3519)\ttotal: 18m 7s\tremaining: 33m 18s\n",
      "3524:\tlearn: 0.0351595\ttest: 0.0386271\tbest: 0.0386271 (3524)\ttotal: 18m 7s\tremaining: 33m 18s\n",
      "3525:\tlearn: 0.0351595\ttest: 0.0386271\tbest: 0.0386271 (3525)\ttotal: 18m 8s\tremaining: 33m 18s\n",
      "3526:\tlearn: 0.0351595\ttest: 0.0386271\tbest: 0.0386271 (3526)\ttotal: 18m 8s\tremaining: 33m 17s\n",
      "3527:\tlearn: 0.0351595\ttest: 0.0386271\tbest: 0.0386271 (3526)\ttotal: 18m 8s\tremaining: 33m 17s\n",
      "3528:\tlearn: 0.0351595\ttest: 0.0386271\tbest: 0.0386271 (3528)\ttotal: 18m 8s\tremaining: 33m 16s\n",
      "3529:\tlearn: 0.0351552\ttest: 0.0386258\tbest: 0.0386258 (3529)\ttotal: 18m 9s\tremaining: 33m 16s\n",
      "3530:\tlearn: 0.0351552\ttest: 0.0386258\tbest: 0.0386258 (3530)\ttotal: 18m 9s\tremaining: 33m 16s\n",
      "3531:\tlearn: 0.0351552\ttest: 0.0386258\tbest: 0.0386258 (3530)\ttotal: 18m 9s\tremaining: 33m 15s\n",
      "3532:\tlearn: 0.0351514\ttest: 0.0386241\tbest: 0.0386241 (3532)\ttotal: 18m 10s\tremaining: 33m 15s\n",
      "3533:\tlearn: 0.0351514\ttest: 0.0386241\tbest: 0.0386241 (3533)\ttotal: 18m 10s\tremaining: 33m 14s\n",
      "3534:\tlearn: 0.0351514\ttest: 0.0386241\tbest: 0.0386241 (3534)\ttotal: 18m 10s\tremaining: 33m 14s\n",
      "3535:\tlearn: 0.0351514\ttest: 0.0386241\tbest: 0.0386241 (3535)\ttotal: 18m 10s\tremaining: 33m 14s\n",
      "3536:\tlearn: 0.0351465\ttest: 0.0386201\tbest: 0.0386201 (3536)\ttotal: 18m 11s\tremaining: 33m 13s\n",
      "3537:\tlearn: 0.0351465\ttest: 0.0386201\tbest: 0.0386201 (3537)\ttotal: 18m 11s\tremaining: 33m 13s\n",
      "3538:\tlearn: 0.0351465\ttest: 0.0386201\tbest: 0.0386201 (3538)\ttotal: 18m 11s\tremaining: 33m 13s\n",
      "3539:\tlearn: 0.0351465\ttest: 0.0386201\tbest: 0.0386201 (3539)\ttotal: 18m 11s\tremaining: 33m 12s\n",
      "3540:\tlearn: 0.0351464\ttest: 0.0386201\tbest: 0.0386201 (3540)\ttotal: 18m 12s\tremaining: 33m 12s\n",
      "3541:\tlearn: 0.0351464\ttest: 0.0386201\tbest: 0.0386201 (3541)\ttotal: 18m 12s\tremaining: 33m 11s\n",
      "3542:\tlearn: 0.0351464\ttest: 0.0386201\tbest: 0.0386201 (3542)\ttotal: 18m 12s\tremaining: 33m 11s\n",
      "3543:\tlearn: 0.0351464\ttest: 0.0386201\tbest: 0.0386201 (3543)\ttotal: 18m 13s\tremaining: 33m 11s\n",
      "3544:\tlearn: 0.0351421\ttest: 0.0386204\tbest: 0.0386201 (3543)\ttotal: 18m 13s\tremaining: 33m 11s\n",
      "3545:\tlearn: 0.0351381\ttest: 0.0386202\tbest: 0.0386201 (3543)\ttotal: 18m 14s\tremaining: 33m 11s\n",
      "3546:\tlearn: 0.0351342\ttest: 0.0386198\tbest: 0.0386198 (3546)\ttotal: 18m 15s\tremaining: 33m 12s\n",
      "3547:\tlearn: 0.0351342\ttest: 0.0386198\tbest: 0.0386198 (3546)\ttotal: 18m 15s\tremaining: 33m 12s\n",
      "3548:\tlearn: 0.0351342\ttest: 0.0386198\tbest: 0.0386198 (3548)\ttotal: 18m 15s\tremaining: 33m 12s\n",
      "3549:\tlearn: 0.0351306\ttest: 0.0386189\tbest: 0.0386189 (3549)\ttotal: 18m 16s\tremaining: 33m 12s\n",
      "3550:\tlearn: 0.0351273\ttest: 0.0386178\tbest: 0.0386178 (3550)\ttotal: 18m 16s\tremaining: 33m 12s\n",
      "3551:\tlearn: 0.0351233\ttest: 0.0386172\tbest: 0.0386172 (3551)\ttotal: 18m 17s\tremaining: 33m 11s\n",
      "3552:\tlearn: 0.0351232\ttest: 0.0386172\tbest: 0.0386172 (3552)\ttotal: 18m 17s\tremaining: 33m 11s\n",
      "3553:\tlearn: 0.0351232\ttest: 0.0386172\tbest: 0.0386172 (3553)\ttotal: 18m 17s\tremaining: 33m 10s\n",
      "3554:\tlearn: 0.0351232\ttest: 0.0386172\tbest: 0.0386172 (3554)\ttotal: 18m 17s\tremaining: 33m 10s\n",
      "3555:\tlearn: 0.0351232\ttest: 0.0386172\tbest: 0.0386172 (3554)\ttotal: 18m 18s\tremaining: 33m 10s\n",
      "3556:\tlearn: 0.0351232\ttest: 0.0386172\tbest: 0.0386172 (3554)\ttotal: 18m 18s\tremaining: 33m 9s\n",
      "3557:\tlearn: 0.0351189\ttest: 0.0386172\tbest: 0.0386172 (3557)\ttotal: 18m 18s\tremaining: 33m 9s\n",
      "3558:\tlearn: 0.0351142\ttest: 0.0386149\tbest: 0.0386149 (3558)\ttotal: 18m 19s\tremaining: 33m 9s\n",
      "3559:\tlearn: 0.0351105\ttest: 0.0386135\tbest: 0.0386135 (3559)\ttotal: 18m 19s\tremaining: 33m 8s\n",
      "3560:\tlearn: 0.0351105\ttest: 0.0386135\tbest: 0.0386135 (3560)\ttotal: 18m 19s\tremaining: 33m 8s\n",
      "3561:\tlearn: 0.0351105\ttest: 0.0386135\tbest: 0.0386135 (3561)\ttotal: 18m 19s\tremaining: 33m 8s\n",
      "3562:\tlearn: 0.0351105\ttest: 0.0386135\tbest: 0.0386135 (3561)\ttotal: 18m 20s\tremaining: 33m 7s\n",
      "3563:\tlearn: 0.0351068\ttest: 0.0386122\tbest: 0.0386122 (3563)\ttotal: 18m 20s\tremaining: 33m 7s\n",
      "3564:\tlearn: 0.0351068\ttest: 0.0386122\tbest: 0.0386122 (3564)\ttotal: 18m 20s\tremaining: 33m 6s\n",
      "3565:\tlearn: 0.0351068\ttest: 0.0386122\tbest: 0.0386122 (3565)\ttotal: 18m 21s\tremaining: 33m 6s\n",
      "3566:\tlearn: 0.0351015\ttest: 0.0386088\tbest: 0.0386088 (3566)\ttotal: 18m 21s\tremaining: 33m 6s\n",
      "3567:\tlearn: 0.0351015\ttest: 0.0386088\tbest: 0.0386088 (3567)\ttotal: 18m 21s\tremaining: 33m 5s\n",
      "3568:\tlearn: 0.0351015\ttest: 0.0386088\tbest: 0.0386088 (3568)\ttotal: 18m 21s\tremaining: 33m 5s\n",
      "3569:\tlearn: 0.0351015\ttest: 0.0386088\tbest: 0.0386088 (3569)\ttotal: 18m 22s\tremaining: 33m 5s\n",
      "3570:\tlearn: 0.0351015\ttest: 0.0386088\tbest: 0.0386088 (3570)\ttotal: 18m 22s\tremaining: 33m 4s\n",
      "3571:\tlearn: 0.0350970\ttest: 0.0386083\tbest: 0.0386083 (3571)\ttotal: 18m 22s\tremaining: 33m 4s\n",
      "3572:\tlearn: 0.0350933\ttest: 0.0386083\tbest: 0.0386083 (3572)\ttotal: 18m 22s\tremaining: 33m 4s\n",
      "3573:\tlearn: 0.0350933\ttest: 0.0386083\tbest: 0.0386083 (3573)\ttotal: 18m 23s\tremaining: 33m 3s\n",
      "3574:\tlearn: 0.0350933\ttest: 0.0386082\tbest: 0.0386082 (3574)\ttotal: 18m 23s\tremaining: 33m 3s\n",
      "3575:\tlearn: 0.0350911\ttest: 0.0386081\tbest: 0.0386081 (3575)\ttotal: 18m 23s\tremaining: 33m 3s\n",
      "3576:\tlearn: 0.0350911\ttest: 0.0386081\tbest: 0.0386081 (3576)\ttotal: 18m 24s\tremaining: 33m 2s\n",
      "3577:\tlearn: 0.0350911\ttest: 0.0386081\tbest: 0.0386081 (3577)\ttotal: 18m 24s\tremaining: 33m 2s\n",
      "3578:\tlearn: 0.0350873\ttest: 0.0386085\tbest: 0.0386081 (3577)\ttotal: 18m 24s\tremaining: 33m 1s\n",
      "3579:\tlearn: 0.0350873\ttest: 0.0386085\tbest: 0.0386081 (3577)\ttotal: 18m 24s\tremaining: 33m 1s\n",
      "3580:\tlearn: 0.0350816\ttest: 0.0386065\tbest: 0.0386065 (3580)\ttotal: 18m 25s\tremaining: 33m 1s\n",
      "3581:\tlearn: 0.0350816\ttest: 0.0386065\tbest: 0.0386065 (3581)\ttotal: 18m 25s\tremaining: 33m\n",
      "3582:\tlearn: 0.0350772\ttest: 0.0386044\tbest: 0.0386044 (3582)\ttotal: 18m 25s\tremaining: 33m\n",
      "3583:\tlearn: 0.0350772\ttest: 0.0386044\tbest: 0.0386044 (3582)\ttotal: 18m 26s\tremaining: 33m\n",
      "3584:\tlearn: 0.0350772\ttest: 0.0386044\tbest: 0.0386044 (3584)\ttotal: 18m 26s\tremaining: 32m 59s\n",
      "3585:\tlearn: 0.0350772\ttest: 0.0386044\tbest: 0.0386044 (3584)\ttotal: 18m 26s\tremaining: 32m 59s\n",
      "3586:\tlearn: 0.0350772\ttest: 0.0386044\tbest: 0.0386044 (3586)\ttotal: 18m 27s\tremaining: 32m 59s\n",
      "3587:\tlearn: 0.0350726\ttest: 0.0386022\tbest: 0.0386022 (3587)\ttotal: 18m 27s\tremaining: 32m 59s\n",
      "3588:\tlearn: 0.0350726\ttest: 0.0386022\tbest: 0.0386022 (3587)\ttotal: 18m 27s\tremaining: 32m 59s\n",
      "3589:\tlearn: 0.0350726\ttest: 0.0386022\tbest: 0.0386022 (3587)\ttotal: 18m 28s\tremaining: 32m 59s\n",
      "3590:\tlearn: 0.0350726\ttest: 0.0386022\tbest: 0.0386022 (3587)\ttotal: 18m 28s\tremaining: 32m 59s\n",
      "3591:\tlearn: 0.0350726\ttest: 0.0386022\tbest: 0.0386022 (3587)\ttotal: 18m 29s\tremaining: 32m 59s\n",
      "3592:\tlearn: 0.0350701\ttest: 0.0386018\tbest: 0.0386018 (3592)\ttotal: 18m 29s\tremaining: 32m 59s\n",
      "3593:\tlearn: 0.0350701\ttest: 0.0386017\tbest: 0.0386017 (3593)\ttotal: 18m 30s\tremaining: 32m 59s\n",
      "3594:\tlearn: 0.0350701\ttest: 0.0386017\tbest: 0.0386017 (3593)\ttotal: 18m 30s\tremaining: 32m 58s\n",
      "3595:\tlearn: 0.0350637\ttest: 0.0385983\tbest: 0.0385983 (3595)\ttotal: 18m 31s\tremaining: 32m 58s\n",
      "3596:\tlearn: 0.0350637\ttest: 0.0385983\tbest: 0.0385983 (3595)\ttotal: 18m 31s\tremaining: 32m 58s\n",
      "3597:\tlearn: 0.0350637\ttest: 0.0385983\tbest: 0.0385983 (3597)\ttotal: 18m 31s\tremaining: 32m 57s\n",
      "3598:\tlearn: 0.0350619\ttest: 0.0385984\tbest: 0.0385983 (3597)\ttotal: 18m 31s\tremaining: 32m 57s\n",
      "3599:\tlearn: 0.0350618\ttest: 0.0385984\tbest: 0.0385983 (3597)\ttotal: 18m 32s\tremaining: 32m 57s\n",
      "3600:\tlearn: 0.0350618\ttest: 0.0385984\tbest: 0.0385983 (3597)\ttotal: 18m 32s\tremaining: 32m 56s\n",
      "3601:\tlearn: 0.0350618\ttest: 0.0385984\tbest: 0.0385983 (3597)\ttotal: 18m 32s\tremaining: 32m 56s\n",
      "3602:\tlearn: 0.0350618\ttest: 0.0385984\tbest: 0.0385983 (3597)\ttotal: 18m 32s\tremaining: 32m 55s\n",
      "3603:\tlearn: 0.0350618\ttest: 0.0385984\tbest: 0.0385983 (3597)\ttotal: 18m 33s\tremaining: 32m 55s\n",
      "3604:\tlearn: 0.0350618\ttest: 0.0385984\tbest: 0.0385983 (3597)\ttotal: 18m 33s\tremaining: 32m 55s\n",
      "3605:\tlearn: 0.0350618\ttest: 0.0385984\tbest: 0.0385983 (3597)\ttotal: 18m 33s\tremaining: 32m 54s\n",
      "3606:\tlearn: 0.0350570\ttest: 0.0385966\tbest: 0.0385966 (3606)\ttotal: 18m 33s\tremaining: 32m 54s\n",
      "3607:\tlearn: 0.0350570\ttest: 0.0385966\tbest: 0.0385966 (3607)\ttotal: 18m 34s\tremaining: 32m 53s\n",
      "3608:\tlearn: 0.0350570\ttest: 0.0385966\tbest: 0.0385966 (3608)\ttotal: 18m 34s\tremaining: 32m 53s\n",
      "3609:\tlearn: 0.0350570\ttest: 0.0385966\tbest: 0.0385966 (3609)\ttotal: 18m 34s\tremaining: 32m 53s\n",
      "3610:\tlearn: 0.0350570\ttest: 0.0385966\tbest: 0.0385966 (3610)\ttotal: 18m 34s\tremaining: 32m 52s\n",
      "3611:\tlearn: 0.0350570\ttest: 0.0385966\tbest: 0.0385966 (3610)\ttotal: 18m 35s\tremaining: 32m 52s\n",
      "3612:\tlearn: 0.0350570\ttest: 0.0385966\tbest: 0.0385966 (3610)\ttotal: 18m 35s\tremaining: 32m 51s\n",
      "3613:\tlearn: 0.0350570\ttest: 0.0385966\tbest: 0.0385966 (3613)\ttotal: 18m 35s\tremaining: 32m 51s\n",
      "3614:\tlearn: 0.0350514\ttest: 0.0385947\tbest: 0.0385947 (3614)\ttotal: 18m 36s\tremaining: 32m 51s\n",
      "3615:\tlearn: 0.0350474\ttest: 0.0385937\tbest: 0.0385937 (3615)\ttotal: 18m 36s\tremaining: 32m 51s\n",
      "3616:\tlearn: 0.0350436\ttest: 0.0385928\tbest: 0.0385928 (3616)\ttotal: 18m 36s\tremaining: 32m 50s\n",
      "3617:\tlearn: 0.0350436\ttest: 0.0385928\tbest: 0.0385928 (3617)\ttotal: 18m 36s\tremaining: 32m 50s\n",
      "3618:\tlearn: 0.0350436\ttest: 0.0385928\tbest: 0.0385928 (3618)\ttotal: 18m 37s\tremaining: 32m 49s\n",
      "3619:\tlearn: 0.0350373\ttest: 0.0385896\tbest: 0.0385896 (3619)\ttotal: 18m 37s\tremaining: 32m 49s\n",
      "3620:\tlearn: 0.0350373\ttest: 0.0385896\tbest: 0.0385896 (3619)\ttotal: 18m 37s\tremaining: 32m 49s\n",
      "3621:\tlearn: 0.0350372\ttest: 0.0385896\tbest: 0.0385896 (3621)\ttotal: 18m 38s\tremaining: 32m 48s\n",
      "3622:\tlearn: 0.0350372\ttest: 0.0385896\tbest: 0.0385896 (3621)\ttotal: 18m 38s\tremaining: 32m 48s\n",
      "3623:\tlearn: 0.0350372\ttest: 0.0385896\tbest: 0.0385896 (3623)\ttotal: 18m 38s\tremaining: 32m 48s\n",
      "3624:\tlearn: 0.0350372\ttest: 0.0385896\tbest: 0.0385896 (3624)\ttotal: 18m 38s\tremaining: 32m 47s\n",
      "3625:\tlearn: 0.0350372\ttest: 0.0385896\tbest: 0.0385896 (3625)\ttotal: 18m 39s\tremaining: 32m 47s\n",
      "3626:\tlearn: 0.0350372\ttest: 0.0385896\tbest: 0.0385896 (3626)\ttotal: 18m 39s\tremaining: 32m 46s\n",
      "3627:\tlearn: 0.0350372\ttest: 0.0385896\tbest: 0.0385896 (3627)\ttotal: 18m 39s\tremaining: 32m 46s\n",
      "3628:\tlearn: 0.0350372\ttest: 0.0385896\tbest: 0.0385896 (3628)\ttotal: 18m 39s\tremaining: 32m 46s\n",
      "3629:\tlearn: 0.0350324\ttest: 0.0385872\tbest: 0.0385872 (3629)\ttotal: 18m 40s\tremaining: 32m 45s\n",
      "3630:\tlearn: 0.0350324\ttest: 0.0385871\tbest: 0.0385871 (3630)\ttotal: 18m 40s\tremaining: 32m 45s\n",
      "3631:\tlearn: 0.0350324\ttest: 0.0385871\tbest: 0.0385871 (3630)\ttotal: 18m 40s\tremaining: 32m 45s\n",
      "3632:\tlearn: 0.0350281\ttest: 0.0385840\tbest: 0.0385840 (3632)\ttotal: 18m 41s\tremaining: 32m 45s\n",
      "3633:\tlearn: 0.0350249\ttest: 0.0385841\tbest: 0.0385840 (3632)\ttotal: 18m 41s\tremaining: 32m 45s\n",
      "3634:\tlearn: 0.0350249\ttest: 0.0385841\tbest: 0.0385840 (3632)\ttotal: 18m 42s\tremaining: 32m 45s\n",
      "3635:\tlearn: 0.0350249\ttest: 0.0385841\tbest: 0.0385840 (3632)\ttotal: 18m 42s\tremaining: 32m 45s\n",
      "3636:\tlearn: 0.0350249\ttest: 0.0385841\tbest: 0.0385840 (3632)\ttotal: 18m 43s\tremaining: 32m 45s\n",
      "3637:\tlearn: 0.0350249\ttest: 0.0385841\tbest: 0.0385840 (3632)\ttotal: 18m 43s\tremaining: 32m 45s\n",
      "3638:\tlearn: 0.0350249\ttest: 0.0385841\tbest: 0.0385840 (3632)\ttotal: 18m 44s\tremaining: 32m 44s\n",
      "3639:\tlearn: 0.0350249\ttest: 0.0385841\tbest: 0.0385840 (3632)\ttotal: 18m 44s\tremaining: 32m 44s\n",
      "3640:\tlearn: 0.0350249\ttest: 0.0385841\tbest: 0.0385840 (3632)\ttotal: 18m 44s\tremaining: 32m 44s\n",
      "3641:\tlearn: 0.0350249\ttest: 0.0385841\tbest: 0.0385840 (3632)\ttotal: 18m 45s\tremaining: 32m 44s\n",
      "3642:\tlearn: 0.0350249\ttest: 0.0385841\tbest: 0.0385840 (3632)\ttotal: 18m 45s\tremaining: 32m 43s\n",
      "3643:\tlearn: 0.0350249\ttest: 0.0385841\tbest: 0.0385840 (3632)\ttotal: 18m 45s\tremaining: 32m 43s\n",
      "3644:\tlearn: 0.0350249\ttest: 0.0385841\tbest: 0.0385840 (3632)\ttotal: 18m 45s\tremaining: 32m 43s\n",
      "3645:\tlearn: 0.0350249\ttest: 0.0385841\tbest: 0.0385840 (3632)\ttotal: 18m 46s\tremaining: 32m 42s\n",
      "3646:\tlearn: 0.0350180\ttest: 0.0385834\tbest: 0.0385834 (3646)\ttotal: 18m 46s\tremaining: 32m 42s\n",
      "3647:\tlearn: 0.0350180\ttest: 0.0385834\tbest: 0.0385834 (3647)\ttotal: 18m 46s\tremaining: 32m 42s\n",
      "3648:\tlearn: 0.0350180\ttest: 0.0385834\tbest: 0.0385834 (3648)\ttotal: 18m 47s\tremaining: 32m 41s\n",
      "3649:\tlearn: 0.0350180\ttest: 0.0385834\tbest: 0.0385834 (3649)\ttotal: 18m 47s\tremaining: 32m 41s\n",
      "3650:\tlearn: 0.0350180\ttest: 0.0385834\tbest: 0.0385834 (3650)\ttotal: 18m 47s\tremaining: 32m 40s\n",
      "3651:\tlearn: 0.0350180\ttest: 0.0385834\tbest: 0.0385834 (3651)\ttotal: 18m 47s\tremaining: 32m 40s\n",
      "3652:\tlearn: 0.0350180\ttest: 0.0385834\tbest: 0.0385834 (3652)\ttotal: 18m 48s\tremaining: 32m 40s\n",
      "3653:\tlearn: 0.0350180\ttest: 0.0385834\tbest: 0.0385834 (3652)\ttotal: 18m 48s\tremaining: 32m 39s\n",
      "3654:\tlearn: 0.0350091\ttest: 0.0385760\tbest: 0.0385760 (3654)\ttotal: 18m 48s\tremaining: 32m 39s\n",
      "3655:\tlearn: 0.0350063\ttest: 0.0385762\tbest: 0.0385760 (3654)\ttotal: 18m 48s\tremaining: 32m 39s\n",
      "3656:\tlearn: 0.0350063\ttest: 0.0385762\tbest: 0.0385760 (3654)\ttotal: 18m 49s\tremaining: 32m 38s\n",
      "3657:\tlearn: 0.0350063\ttest: 0.0385762\tbest: 0.0385760 (3654)\ttotal: 18m 49s\tremaining: 32m 38s\n",
      "3658:\tlearn: 0.0350022\ttest: 0.0385752\tbest: 0.0385752 (3658)\ttotal: 18m 49s\tremaining: 32m 37s\n",
      "3659:\tlearn: 0.0350022\ttest: 0.0385752\tbest: 0.0385752 (3659)\ttotal: 18m 50s\tremaining: 32m 37s\n",
      "3660:\tlearn: 0.0350022\ttest: 0.0385752\tbest: 0.0385752 (3659)\ttotal: 18m 50s\tremaining: 32m 37s\n",
      "3661:\tlearn: 0.0350022\ttest: 0.0385752\tbest: 0.0385752 (3661)\ttotal: 18m 50s\tremaining: 32m 36s\n",
      "3662:\tlearn: 0.0350022\ttest: 0.0385752\tbest: 0.0385752 (3662)\ttotal: 18m 50s\tremaining: 32m 36s\n",
      "3663:\tlearn: 0.0350022\ttest: 0.0385752\tbest: 0.0385752 (3662)\ttotal: 18m 51s\tremaining: 32m 35s\n",
      "3664:\tlearn: 0.0350022\ttest: 0.0385752\tbest: 0.0385752 (3664)\ttotal: 18m 51s\tremaining: 32m 35s\n",
      "3665:\tlearn: 0.0350022\ttest: 0.0385752\tbest: 0.0385752 (3665)\ttotal: 18m 51s\tremaining: 32m 35s\n",
      "3666:\tlearn: 0.0350022\ttest: 0.0385752\tbest: 0.0385752 (3666)\ttotal: 18m 51s\tremaining: 32m 34s\n",
      "3667:\tlearn: 0.0350022\ttest: 0.0385752\tbest: 0.0385752 (3666)\ttotal: 18m 52s\tremaining: 32m 34s\n",
      "3668:\tlearn: 0.0350021\ttest: 0.0385752\tbest: 0.0385752 (3668)\ttotal: 18m 52s\tremaining: 32m 33s\n",
      "3669:\tlearn: 0.0350021\ttest: 0.0385752\tbest: 0.0385752 (3669)\ttotal: 18m 52s\tremaining: 32m 33s\n",
      "3670:\tlearn: 0.0349988\ttest: 0.0385738\tbest: 0.0385738 (3670)\ttotal: 18m 52s\tremaining: 32m 33s\n",
      "3671:\tlearn: 0.0349988\ttest: 0.0385738\tbest: 0.0385738 (3671)\ttotal: 18m 53s\tremaining: 32m 32s\n",
      "3672:\tlearn: 0.0349988\ttest: 0.0385738\tbest: 0.0385738 (3672)\ttotal: 18m 53s\tremaining: 32m 32s\n",
      "3673:\tlearn: 0.0349988\ttest: 0.0385738\tbest: 0.0385738 (3672)\ttotal: 18m 53s\tremaining: 32m 32s\n",
      "3674:\tlearn: 0.0349988\ttest: 0.0385738\tbest: 0.0385738 (3674)\ttotal: 18m 53s\tremaining: 32m 31s\n",
      "3675:\tlearn: 0.0349988\ttest: 0.0385738\tbest: 0.0385738 (3674)\ttotal: 18m 54s\tremaining: 32m 31s\n",
      "3676:\tlearn: 0.0349988\ttest: 0.0385738\tbest: 0.0385738 (3674)\ttotal: 18m 54s\tremaining: 32m 30s\n",
      "3677:\tlearn: 0.0349988\ttest: 0.0385738\tbest: 0.0385738 (3677)\ttotal: 18m 54s\tremaining: 32m 30s\n",
      "3678:\tlearn: 0.0349988\ttest: 0.0385738\tbest: 0.0385738 (3678)\ttotal: 18m 55s\tremaining: 32m 30s\n",
      "3679:\tlearn: 0.0349988\ttest: 0.0385738\tbest: 0.0385738 (3679)\ttotal: 18m 55s\tremaining: 32m 30s\n",
      "3680:\tlearn: 0.0349918\ttest: 0.0385719\tbest: 0.0385719 (3680)\ttotal: 18m 56s\tremaining: 32m 30s\n",
      "3681:\tlearn: 0.0349918\ttest: 0.0385719\tbest: 0.0385719 (3681)\ttotal: 18m 56s\tremaining: 32m 30s\n",
      "3682:\tlearn: 0.0349918\ttest: 0.0385719\tbest: 0.0385719 (3682)\ttotal: 18m 57s\tremaining: 32m 30s\n",
      "3683:\tlearn: 0.0349918\ttest: 0.0385719\tbest: 0.0385719 (3683)\ttotal: 18m 57s\tremaining: 32m 30s\n",
      "3684:\tlearn: 0.0349918\ttest: 0.0385719\tbest: 0.0385719 (3684)\ttotal: 18m 57s\tremaining: 32m 30s\n",
      "3685:\tlearn: 0.0349918\ttest: 0.0385719\tbest: 0.0385719 (3685)\ttotal: 18m 58s\tremaining: 32m 30s\n",
      "3686:\tlearn: 0.0349918\ttest: 0.0385719\tbest: 0.0385719 (3685)\ttotal: 18m 58s\tremaining: 32m 30s\n",
      "3687:\tlearn: 0.0349918\ttest: 0.0385719\tbest: 0.0385719 (3687)\ttotal: 18m 59s\tremaining: 32m 29s\n",
      "3688:\tlearn: 0.0349918\ttest: 0.0385718\tbest: 0.0385718 (3688)\ttotal: 18m 59s\tremaining: 32m 29s\n",
      "3689:\tlearn: 0.0349918\ttest: 0.0385718\tbest: 0.0385718 (3689)\ttotal: 18m 59s\tremaining: 32m 28s\n",
      "3690:\tlearn: 0.0349918\ttest: 0.0385718\tbest: 0.0385718 (3690)\ttotal: 18m 59s\tremaining: 32m 28s\n",
      "3691:\tlearn: 0.0349918\ttest: 0.0385718\tbest: 0.0385718 (3691)\ttotal: 19m\tremaining: 32m 28s\n",
      "3692:\tlearn: 0.0349917\ttest: 0.0385718\tbest: 0.0385718 (3692)\ttotal: 19m\tremaining: 32m 27s\n",
      "3693:\tlearn: 0.0349865\ttest: 0.0385678\tbest: 0.0385678 (3693)\ttotal: 19m\tremaining: 32m 27s\n",
      "3694:\tlearn: 0.0349865\ttest: 0.0385678\tbest: 0.0385678 (3694)\ttotal: 19m 1s\tremaining: 32m 27s\n",
      "3695:\tlearn: 0.0349865\ttest: 0.0385678\tbest: 0.0385678 (3695)\ttotal: 19m 1s\tremaining: 32m 26s\n",
      "3696:\tlearn: 0.0349821\ttest: 0.0385663\tbest: 0.0385663 (3696)\ttotal: 19m 1s\tremaining: 32m 26s\n",
      "3697:\tlearn: 0.0349795\ttest: 0.0385664\tbest: 0.0385663 (3696)\ttotal: 19m 2s\tremaining: 32m 26s\n",
      "3698:\tlearn: 0.0349796\ttest: 0.0385664\tbest: 0.0385663 (3696)\ttotal: 19m 2s\tremaining: 32m 25s\n",
      "3699:\tlearn: 0.0349796\ttest: 0.0385664\tbest: 0.0385663 (3696)\ttotal: 19m 2s\tremaining: 32m 25s\n",
      "3700:\tlearn: 0.0349795\ttest: 0.0385664\tbest: 0.0385663 (3696)\ttotal: 19m 2s\tremaining: 32m 24s\n",
      "3701:\tlearn: 0.0349795\ttest: 0.0385664\tbest: 0.0385663 (3696)\ttotal: 19m 3s\tremaining: 32m 24s\n",
      "3702:\tlearn: 0.0349795\ttest: 0.0385664\tbest: 0.0385663 (3696)\ttotal: 19m 3s\tremaining: 32m 24s\n",
      "3703:\tlearn: 0.0349795\ttest: 0.0385664\tbest: 0.0385663 (3696)\ttotal: 19m 3s\tremaining: 32m 23s\n",
      "3704:\tlearn: 0.0349795\ttest: 0.0385664\tbest: 0.0385663 (3696)\ttotal: 19m 3s\tremaining: 32m 23s\n",
      "3705:\tlearn: 0.0349795\ttest: 0.0385664\tbest: 0.0385663 (3696)\ttotal: 19m 4s\tremaining: 32m 23s\n",
      "3706:\tlearn: 0.0349795\ttest: 0.0385664\tbest: 0.0385663 (3696)\ttotal: 19m 4s\tremaining: 32m 22s\n",
      "3707:\tlearn: 0.0349795\ttest: 0.0385664\tbest: 0.0385663 (3696)\ttotal: 19m 4s\tremaining: 32m 22s\n",
      "3708:\tlearn: 0.0349766\ttest: 0.0385664\tbest: 0.0385663 (3696)\ttotal: 19m 4s\tremaining: 32m 21s\n",
      "3709:\tlearn: 0.0349766\ttest: 0.0385664\tbest: 0.0385663 (3696)\ttotal: 19m 5s\tremaining: 32m 21s\n",
      "3710:\tlearn: 0.0349714\ttest: 0.0385642\tbest: 0.0385642 (3710)\ttotal: 19m 5s\tremaining: 32m 21s\n",
      "3711:\tlearn: 0.0349714\ttest: 0.0385642\tbest: 0.0385642 (3710)\ttotal: 19m 5s\tremaining: 32m 20s\n",
      "3712:\tlearn: 0.0349698\ttest: 0.0385642\tbest: 0.0385642 (3710)\ttotal: 19m 6s\tremaining: 32m 20s\n",
      "3713:\tlearn: 0.0349698\ttest: 0.0385642\tbest: 0.0385642 (3710)\ttotal: 19m 6s\tremaining: 32m 20s\n",
      "3714:\tlearn: 0.0349652\ttest: 0.0385612\tbest: 0.0385612 (3714)\ttotal: 19m 6s\tremaining: 32m 19s\n",
      "3715:\tlearn: 0.0349629\ttest: 0.0385613\tbest: 0.0385612 (3714)\ttotal: 19m 6s\tremaining: 32m 19s\n",
      "3716:\tlearn: 0.0349591\ttest: 0.0385602\tbest: 0.0385602 (3716)\ttotal: 19m 7s\tremaining: 32m 19s\n",
      "3717:\tlearn: 0.0349591\ttest: 0.0385602\tbest: 0.0385602 (3717)\ttotal: 19m 7s\tremaining: 32m 18s\n",
      "3718:\tlearn: 0.0349591\ttest: 0.0385602\tbest: 0.0385602 (3717)\ttotal: 19m 7s\tremaining: 32m 18s\n",
      "3719:\tlearn: 0.0349591\ttest: 0.0385602\tbest: 0.0385602 (3717)\ttotal: 19m 8s\tremaining: 32m 18s\n",
      "3720:\tlearn: 0.0349591\ttest: 0.0385602\tbest: 0.0385602 (3720)\ttotal: 19m 8s\tremaining: 32m 17s\n",
      "3721:\tlearn: 0.0349591\ttest: 0.0385602\tbest: 0.0385602 (3721)\ttotal: 19m 8s\tremaining: 32m 17s\n",
      "3722:\tlearn: 0.0349591\ttest: 0.0385602\tbest: 0.0385602 (3722)\ttotal: 19m 8s\tremaining: 32m 16s\n",
      "3723:\tlearn: 0.0349591\ttest: 0.0385602\tbest: 0.0385602 (3722)\ttotal: 19m 9s\tremaining: 32m 16s\n",
      "3724:\tlearn: 0.0349590\ttest: 0.0385602\tbest: 0.0385602 (3724)\ttotal: 19m 9s\tremaining: 32m 16s\n",
      "3725:\tlearn: 0.0349590\ttest: 0.0385602\tbest: 0.0385602 (3724)\ttotal: 19m 10s\tremaining: 32m 16s\n",
      "3726:\tlearn: 0.0349590\ttest: 0.0385602\tbest: 0.0385602 (3726)\ttotal: 19m 10s\tremaining: 32m 16s\n",
      "3727:\tlearn: 0.0349554\ttest: 0.0385599\tbest: 0.0385599 (3727)\ttotal: 19m 11s\tremaining: 32m 16s\n",
      "3728:\tlearn: 0.0349553\ttest: 0.0385599\tbest: 0.0385599 (3728)\ttotal: 19m 11s\tremaining: 32m 16s\n",
      "3729:\tlearn: 0.0349554\ttest: 0.0385599\tbest: 0.0385599 (3729)\ttotal: 19m 12s\tremaining: 32m 16s\n",
      "3730:\tlearn: 0.0349554\ttest: 0.0385599\tbest: 0.0385599 (3730)\ttotal: 19m 12s\tremaining: 32m 16s\n",
      "3731:\tlearn: 0.0349553\ttest: 0.0385599\tbest: 0.0385599 (3731)\ttotal: 19m 12s\tremaining: 32m 16s\n",
      "3732:\tlearn: 0.0349553\ttest: 0.0385599\tbest: 0.0385599 (3732)\ttotal: 19m 13s\tremaining: 32m 16s\n",
      "3733:\tlearn: 0.0349553\ttest: 0.0385599\tbest: 0.0385599 (3732)\ttotal: 19m 13s\tremaining: 32m 15s\n",
      "3734:\tlearn: 0.0349553\ttest: 0.0385599\tbest: 0.0385599 (3732)\ttotal: 19m 13s\tremaining: 32m 15s\n",
      "3735:\tlearn: 0.0349534\ttest: 0.0385594\tbest: 0.0385594 (3735)\ttotal: 19m 14s\tremaining: 32m 15s\n",
      "3736:\tlearn: 0.0349507\ttest: 0.0385580\tbest: 0.0385580 (3736)\ttotal: 19m 14s\tremaining: 32m 14s\n",
      "3737:\tlearn: 0.0349507\ttest: 0.0385580\tbest: 0.0385580 (3737)\ttotal: 19m 14s\tremaining: 32m 14s\n",
      "3738:\tlearn: 0.0349507\ttest: 0.0385580\tbest: 0.0385580 (3738)\ttotal: 19m 14s\tremaining: 32m 14s\n",
      "3739:\tlearn: 0.0349507\ttest: 0.0385580\tbest: 0.0385580 (3739)\ttotal: 19m 15s\tremaining: 32m 13s\n",
      "3740:\tlearn: 0.0349507\ttest: 0.0385580\tbest: 0.0385580 (3740)\ttotal: 19m 15s\tremaining: 32m 13s\n",
      "3741:\tlearn: 0.0349507\ttest: 0.0385580\tbest: 0.0385580 (3741)\ttotal: 19m 15s\tremaining: 32m 12s\n",
      "3742:\tlearn: 0.0349507\ttest: 0.0385580\tbest: 0.0385580 (3742)\ttotal: 19m 16s\tremaining: 32m 12s\n",
      "3743:\tlearn: 0.0349507\ttest: 0.0385580\tbest: 0.0385580 (3743)\ttotal: 19m 16s\tremaining: 32m 12s\n",
      "3744:\tlearn: 0.0349507\ttest: 0.0385580\tbest: 0.0385580 (3743)\ttotal: 19m 16s\tremaining: 32m 11s\n",
      "3745:\tlearn: 0.0349507\ttest: 0.0385580\tbest: 0.0385580 (3745)\ttotal: 19m 16s\tremaining: 32m 11s\n",
      "3746:\tlearn: 0.0349507\ttest: 0.0385580\tbest: 0.0385580 (3746)\ttotal: 19m 17s\tremaining: 32m 10s\n",
      "3747:\tlearn: 0.0349507\ttest: 0.0385580\tbest: 0.0385580 (3746)\ttotal: 19m 17s\tremaining: 32m 10s\n",
      "3748:\tlearn: 0.0349507\ttest: 0.0385580\tbest: 0.0385580 (3748)\ttotal: 19m 17s\tremaining: 32m 10s\n",
      "3749:\tlearn: 0.0349507\ttest: 0.0385580\tbest: 0.0385580 (3749)\ttotal: 19m 17s\tremaining: 32m 9s\n",
      "3750:\tlearn: 0.0349507\ttest: 0.0385580\tbest: 0.0385580 (3749)\ttotal: 19m 18s\tremaining: 32m 9s\n",
      "3751:\tlearn: 0.0349506\ttest: 0.0385580\tbest: 0.0385580 (3751)\ttotal: 19m 18s\tremaining: 32m 8s\n",
      "3752:\tlearn: 0.0349462\ttest: 0.0385568\tbest: 0.0385568 (3752)\ttotal: 19m 18s\tremaining: 32m 8s\n",
      "3753:\tlearn: 0.0349461\ttest: 0.0385568\tbest: 0.0385568 (3753)\ttotal: 19m 18s\tremaining: 32m 8s\n",
      "3754:\tlearn: 0.0349461\ttest: 0.0385568\tbest: 0.0385568 (3754)\ttotal: 19m 19s\tremaining: 32m 7s\n",
      "3755:\tlearn: 0.0349461\ttest: 0.0385568\tbest: 0.0385568 (3755)\ttotal: 19m 19s\tremaining: 32m 7s\n",
      "3756:\tlearn: 0.0349461\ttest: 0.0385568\tbest: 0.0385568 (3755)\ttotal: 19m 19s\tremaining: 32m 7s\n",
      "3757:\tlearn: 0.0349461\ttest: 0.0385568\tbest: 0.0385568 (3755)\ttotal: 19m 19s\tremaining: 32m 6s\n",
      "3758:\tlearn: 0.0349461\ttest: 0.0385568\tbest: 0.0385568 (3755)\ttotal: 19m 20s\tremaining: 32m 6s\n",
      "3759:\tlearn: 0.0349461\ttest: 0.0385568\tbest: 0.0385568 (3755)\ttotal: 19m 20s\tremaining: 32m 5s\n",
      "3760:\tlearn: 0.0349461\ttest: 0.0385568\tbest: 0.0385568 (3760)\ttotal: 19m 20s\tremaining: 32m 5s\n",
      "3761:\tlearn: 0.0349461\ttest: 0.0385568\tbest: 0.0385568 (3761)\ttotal: 19m 20s\tremaining: 32m 5s\n",
      "3762:\tlearn: 0.0349461\ttest: 0.0385568\tbest: 0.0385568 (3761)\ttotal: 19m 21s\tremaining: 32m 4s\n",
      "3763:\tlearn: 0.0349437\ttest: 0.0385567\tbest: 0.0385567 (3763)\ttotal: 19m 21s\tremaining: 32m 4s\n",
      "3764:\tlearn: 0.0349437\ttest: 0.0385567\tbest: 0.0385567 (3763)\ttotal: 19m 21s\tremaining: 32m 4s\n",
      "3765:\tlearn: 0.0349393\ttest: 0.0385560\tbest: 0.0385560 (3765)\ttotal: 19m 22s\tremaining: 32m 3s\n",
      "3766:\tlearn: 0.0349380\ttest: 0.0385556\tbest: 0.0385556 (3766)\ttotal: 19m 22s\tremaining: 32m 3s\n",
      "3767:\tlearn: 0.0349380\ttest: 0.0385556\tbest: 0.0385556 (3767)\ttotal: 19m 22s\tremaining: 32m 3s\n",
      "3768:\tlearn: 0.0349380\ttest: 0.0385556\tbest: 0.0385556 (3768)\ttotal: 19m 22s\tremaining: 32m 2s\n",
      "3769:\tlearn: 0.0349380\ttest: 0.0385556\tbest: 0.0385556 (3769)\ttotal: 19m 23s\tremaining: 32m 2s\n",
      "3770:\tlearn: 0.0349380\ttest: 0.0385556\tbest: 0.0385556 (3769)\ttotal: 19m 23s\tremaining: 32m 2s\n",
      "3771:\tlearn: 0.0349319\ttest: 0.0385531\tbest: 0.0385531 (3771)\ttotal: 19m 24s\tremaining: 32m 2s\n",
      "3772:\tlearn: 0.0349319\ttest: 0.0385531\tbest: 0.0385531 (3772)\ttotal: 19m 24s\tremaining: 32m 2s\n",
      "3773:\tlearn: 0.0349279\ttest: 0.0385523\tbest: 0.0385523 (3773)\ttotal: 19m 25s\tremaining: 32m 2s\n",
      "3774:\tlearn: 0.0349279\ttest: 0.0385523\tbest: 0.0385523 (3773)\ttotal: 19m 25s\tremaining: 32m 2s\n",
      "3775:\tlearn: 0.0349279\ttest: 0.0385523\tbest: 0.0385523 (3775)\ttotal: 19m 26s\tremaining: 32m 2s\n",
      "3776:\tlearn: 0.0349279\ttest: 0.0385523\tbest: 0.0385523 (3776)\ttotal: 19m 26s\tremaining: 32m 2s\n",
      "3777:\tlearn: 0.0349237\ttest: 0.0385484\tbest: 0.0385484 (3777)\ttotal: 19m 27s\tremaining: 32m 2s\n",
      "3778:\tlearn: 0.0349237\ttest: 0.0385484\tbest: 0.0385484 (3778)\ttotal: 19m 27s\tremaining: 32m 1s\n",
      "3779:\tlearn: 0.0349201\ttest: 0.0385475\tbest: 0.0385475 (3779)\ttotal: 19m 27s\tremaining: 32m 1s\n",
      "3780:\tlearn: 0.0349167\ttest: 0.0385457\tbest: 0.0385457 (3780)\ttotal: 19m 27s\tremaining: 32m 1s\n",
      "3781:\tlearn: 0.0349128\ttest: 0.0385446\tbest: 0.0385446 (3781)\ttotal: 19m 28s\tremaining: 32m\n",
      "3782:\tlearn: 0.0349128\ttest: 0.0385446\tbest: 0.0385446 (3782)\ttotal: 19m 28s\tremaining: 32m\n",
      "3783:\tlearn: 0.0349128\ttest: 0.0385446\tbest: 0.0385446 (3782)\ttotal: 19m 28s\tremaining: 32m\n",
      "3784:\tlearn: 0.0349127\ttest: 0.0385445\tbest: 0.0385445 (3784)\ttotal: 19m 29s\tremaining: 31m 59s\n",
      "3785:\tlearn: 0.0349127\ttest: 0.0385445\tbest: 0.0385445 (3785)\ttotal: 19m 29s\tremaining: 31m 59s\n",
      "3786:\tlearn: 0.0349080\ttest: 0.0385432\tbest: 0.0385432 (3786)\ttotal: 19m 29s\tremaining: 31m 59s\n",
      "3787:\tlearn: 0.0349080\ttest: 0.0385432\tbest: 0.0385432 (3786)\ttotal: 19m 29s\tremaining: 31m 58s\n",
      "3788:\tlearn: 0.0349080\ttest: 0.0385432\tbest: 0.0385432 (3786)\ttotal: 19m 30s\tremaining: 31m 58s\n",
      "3789:\tlearn: 0.0349041\ttest: 0.0385418\tbest: 0.0385418 (3789)\ttotal: 19m 30s\tremaining: 31m 57s\n",
      "3790:\tlearn: 0.0348997\ttest: 0.0385411\tbest: 0.0385411 (3790)\ttotal: 19m 30s\tremaining: 31m 57s\n",
      "3791:\tlearn: 0.0348997\ttest: 0.0385411\tbest: 0.0385411 (3790)\ttotal: 19m 31s\tremaining: 31m 57s\n",
      "3792:\tlearn: 0.0348997\ttest: 0.0385411\tbest: 0.0385411 (3792)\ttotal: 19m 31s\tremaining: 31m 56s\n",
      "3793:\tlearn: 0.0348997\ttest: 0.0385411\tbest: 0.0385411 (3793)\ttotal: 19m 31s\tremaining: 31m 56s\n",
      "3794:\tlearn: 0.0348957\ttest: 0.0385414\tbest: 0.0385411 (3793)\ttotal: 19m 31s\tremaining: 31m 56s\n",
      "3795:\tlearn: 0.0348957\ttest: 0.0385414\tbest: 0.0385411 (3793)\ttotal: 19m 32s\tremaining: 31m 55s\n",
      "3796:\tlearn: 0.0348956\ttest: 0.0385415\tbest: 0.0385411 (3793)\ttotal: 19m 32s\tremaining: 31m 55s\n",
      "3797:\tlearn: 0.0348956\ttest: 0.0385414\tbest: 0.0385411 (3793)\ttotal: 19m 32s\tremaining: 31m 55s\n",
      "3798:\tlearn: 0.0348909\ttest: 0.0385409\tbest: 0.0385409 (3798)\ttotal: 19m 33s\tremaining: 31m 54s\n",
      "3799:\tlearn: 0.0348909\ttest: 0.0385409\tbest: 0.0385409 (3799)\ttotal: 19m 33s\tremaining: 31m 54s\n",
      "3800:\tlearn: 0.0348909\ttest: 0.0385409\tbest: 0.0385409 (3799)\ttotal: 19m 33s\tremaining: 31m 53s\n",
      "3801:\tlearn: 0.0348909\ttest: 0.0385409\tbest: 0.0385409 (3801)\ttotal: 19m 33s\tremaining: 31m 53s\n",
      "3802:\tlearn: 0.0348909\ttest: 0.0385409\tbest: 0.0385409 (3801)\ttotal: 19m 34s\tremaining: 31m 53s\n",
      "3803:\tlearn: 0.0348909\ttest: 0.0385409\tbest: 0.0385409 (3803)\ttotal: 19m 34s\tremaining: 31m 52s\n",
      "3804:\tlearn: 0.0348883\ttest: 0.0385406\tbest: 0.0385406 (3804)\ttotal: 19m 34s\tremaining: 31m 52s\n",
      "3805:\tlearn: 0.0348883\ttest: 0.0385406\tbest: 0.0385406 (3805)\ttotal: 19m 34s\tremaining: 31m 52s\n",
      "3806:\tlearn: 0.0348883\ttest: 0.0385406\tbest: 0.0385406 (3805)\ttotal: 19m 35s\tremaining: 31m 51s\n",
      "3807:\tlearn: 0.0348883\ttest: 0.0385406\tbest: 0.0385406 (3805)\ttotal: 19m 35s\tremaining: 31m 51s\n",
      "3808:\tlearn: 0.0348883\ttest: 0.0385406\tbest: 0.0385406 (3808)\ttotal: 19m 35s\tremaining: 31m 50s\n",
      "3809:\tlearn: 0.0348882\ttest: 0.0385405\tbest: 0.0385405 (3809)\ttotal: 19m 35s\tremaining: 31m 50s\n",
      "3810:\tlearn: 0.0348882\ttest: 0.0385405\tbest: 0.0385405 (3810)\ttotal: 19m 36s\tremaining: 31m 50s\n",
      "3811:\tlearn: 0.0348882\ttest: 0.0385405\tbest: 0.0385405 (3811)\ttotal: 19m 36s\tremaining: 31m 49s\n",
      "3812:\tlearn: 0.0348882\ttest: 0.0385405\tbest: 0.0385405 (3811)\ttotal: 19m 36s\tremaining: 31m 49s\n",
      "3813:\tlearn: 0.0348882\ttest: 0.0385405\tbest: 0.0385405 (3813)\ttotal: 19m 36s\tremaining: 31m 48s\n",
      "3814:\tlearn: 0.0348882\ttest: 0.0385405\tbest: 0.0385405 (3814)\ttotal: 19m 37s\tremaining: 31m 48s\n",
      "3815:\tlearn: 0.0348882\ttest: 0.0385405\tbest: 0.0385405 (3815)\ttotal: 19m 37s\tremaining: 31m 48s\n",
      "3816:\tlearn: 0.0348861\ttest: 0.0385404\tbest: 0.0385404 (3816)\ttotal: 19m 38s\tremaining: 31m 48s\n",
      "3817:\tlearn: 0.0348819\ttest: 0.0385390\tbest: 0.0385390 (3817)\ttotal: 19m 38s\tremaining: 31m 48s\n",
      "3818:\tlearn: 0.0348819\ttest: 0.0385390\tbest: 0.0385390 (3817)\ttotal: 19m 39s\tremaining: 31m 48s\n",
      "3819:\tlearn: 0.0348804\ttest: 0.0385390\tbest: 0.0385390 (3817)\ttotal: 19m 39s\tremaining: 31m 48s\n",
      "3820:\tlearn: 0.0348804\ttest: 0.0385390\tbest: 0.0385390 (3817)\ttotal: 19m 40s\tremaining: 31m 48s\n",
      "3821:\tlearn: 0.0348804\ttest: 0.0385390\tbest: 0.0385390 (3817)\ttotal: 19m 40s\tremaining: 31m 48s\n",
      "3822:\tlearn: 0.0348804\ttest: 0.0385390\tbest: 0.0385390 (3817)\ttotal: 19m 41s\tremaining: 31m 48s\n",
      "3823:\tlearn: 0.0348804\ttest: 0.0385390\tbest: 0.0385390 (3823)\ttotal: 19m 41s\tremaining: 31m 47s\n",
      "3824:\tlearn: 0.0348761\ttest: 0.0385391\tbest: 0.0385390 (3823)\ttotal: 19m 41s\tremaining: 31m 47s\n",
      "3825:\tlearn: 0.0348761\ttest: 0.0385391\tbest: 0.0385390 (3823)\ttotal: 19m 41s\tremaining: 31m 47s\n",
      "3826:\tlearn: 0.0348761\ttest: 0.0385391\tbest: 0.0385390 (3823)\ttotal: 19m 42s\tremaining: 31m 46s\n",
      "3827:\tlearn: 0.0348761\ttest: 0.0385391\tbest: 0.0385390 (3823)\ttotal: 19m 42s\tremaining: 31m 46s\n",
      "3828:\tlearn: 0.0348710\ttest: 0.0385372\tbest: 0.0385372 (3828)\ttotal: 19m 42s\tremaining: 31m 46s\n",
      "3829:\tlearn: 0.0348636\ttest: 0.0385325\tbest: 0.0385325 (3829)\ttotal: 19m 43s\tremaining: 31m 45s\n",
      "3830:\tlearn: 0.0348636\ttest: 0.0385325\tbest: 0.0385325 (3829)\ttotal: 19m 43s\tremaining: 31m 45s\n",
      "3831:\tlearn: 0.0348636\ttest: 0.0385325\tbest: 0.0385325 (3831)\ttotal: 19m 43s\tremaining: 31m 45s\n",
      "3832:\tlearn: 0.0348636\ttest: 0.0385325\tbest: 0.0385325 (3832)\ttotal: 19m 43s\tremaining: 31m 44s\n",
      "3833:\tlearn: 0.0348573\ttest: 0.0385301\tbest: 0.0385301 (3833)\ttotal: 19m 44s\tremaining: 31m 44s\n",
      "3834:\tlearn: 0.0348573\ttest: 0.0385301\tbest: 0.0385301 (3833)\ttotal: 19m 44s\tremaining: 31m 44s\n",
      "3835:\tlearn: 0.0348573\ttest: 0.0385301\tbest: 0.0385301 (3835)\ttotal: 19m 44s\tremaining: 31m 43s\n",
      "3836:\tlearn: 0.0348573\ttest: 0.0385301\tbest: 0.0385301 (3835)\ttotal: 19m 45s\tremaining: 31m 43s\n",
      "3837:\tlearn: 0.0348573\ttest: 0.0385301\tbest: 0.0385301 (3835)\ttotal: 19m 45s\tremaining: 31m 43s\n",
      "3838:\tlearn: 0.0348573\ttest: 0.0385301\tbest: 0.0385301 (3838)\ttotal: 19m 45s\tremaining: 31m 42s\n",
      "3839:\tlearn: 0.0348573\ttest: 0.0385301\tbest: 0.0385301 (3839)\ttotal: 19m 45s\tremaining: 31m 42s\n",
      "3840:\tlearn: 0.0348573\ttest: 0.0385301\tbest: 0.0385301 (3839)\ttotal: 19m 46s\tremaining: 31m 41s\n",
      "3841:\tlearn: 0.0348573\ttest: 0.0385301\tbest: 0.0385301 (3841)\ttotal: 19m 46s\tremaining: 31m 41s\n",
      "3842:\tlearn: 0.0348531\ttest: 0.0385281\tbest: 0.0385281 (3842)\ttotal: 19m 46s\tremaining: 31m 41s\n",
      "3843:\tlearn: 0.0348482\ttest: 0.0385260\tbest: 0.0385260 (3843)\ttotal: 19m 46s\tremaining: 31m 40s\n",
      "3844:\tlearn: 0.0348423\ttest: 0.0385225\tbest: 0.0385225 (3844)\ttotal: 19m 47s\tremaining: 31m 40s\n",
      "3845:\tlearn: 0.0348423\ttest: 0.0385225\tbest: 0.0385225 (3844)\ttotal: 19m 47s\tremaining: 31m 40s\n",
      "3846:\tlearn: 0.0348423\ttest: 0.0385225\tbest: 0.0385225 (3846)\ttotal: 19m 47s\tremaining: 31m 39s\n",
      "3847:\tlearn: 0.0348423\ttest: 0.0385225\tbest: 0.0385225 (3847)\ttotal: 19m 48s\tremaining: 31m 39s\n",
      "3848:\tlearn: 0.0348423\ttest: 0.0385225\tbest: 0.0385225 (3848)\ttotal: 19m 48s\tremaining: 31m 39s\n",
      "3849:\tlearn: 0.0348423\ttest: 0.0385225\tbest: 0.0385225 (3849)\ttotal: 19m 48s\tremaining: 31m 38s\n",
      "3850:\tlearn: 0.0348423\ttest: 0.0385225\tbest: 0.0385225 (3850)\ttotal: 19m 48s\tremaining: 31m 38s\n",
      "3851:\tlearn: 0.0348423\ttest: 0.0385225\tbest: 0.0385225 (3850)\ttotal: 19m 49s\tremaining: 31m 37s\n",
      "3852:\tlearn: 0.0348423\ttest: 0.0385225\tbest: 0.0385225 (3852)\ttotal: 19m 49s\tremaining: 31m 37s\n",
      "3853:\tlearn: 0.0348422\ttest: 0.0385225\tbest: 0.0385225 (3852)\ttotal: 19m 49s\tremaining: 31m 37s\n",
      "3854:\tlearn: 0.0348422\ttest: 0.0385225\tbest: 0.0385225 (3852)\ttotal: 19m 49s\tremaining: 31m 36s\n",
      "3855:\tlearn: 0.0348422\ttest: 0.0385225\tbest: 0.0385225 (3852)\ttotal: 19m 50s\tremaining: 31m 36s\n",
      "3856:\tlearn: 0.0348406\ttest: 0.0385219\tbest: 0.0385219 (3856)\ttotal: 19m 50s\tremaining: 31m 36s\n",
      "3857:\tlearn: 0.0348372\ttest: 0.0385204\tbest: 0.0385204 (3857)\ttotal: 19m 50s\tremaining: 31m 35s\n",
      "3858:\tlearn: 0.0348372\ttest: 0.0385204\tbest: 0.0385204 (3858)\ttotal: 19m 51s\tremaining: 31m 35s\n",
      "3859:\tlearn: 0.0348372\ttest: 0.0385204\tbest: 0.0385204 (3858)\ttotal: 19m 51s\tremaining: 31m 35s\n",
      "3860:\tlearn: 0.0348319\ttest: 0.0385194\tbest: 0.0385194 (3860)\ttotal: 19m 52s\tremaining: 31m 35s\n",
      "3861:\tlearn: 0.0348319\ttest: 0.0385194\tbest: 0.0385194 (3861)\ttotal: 19m 52s\tremaining: 31m 35s\n",
      "3862:\tlearn: 0.0348319\ttest: 0.0385193\tbest: 0.0385193 (3862)\ttotal: 19m 53s\tremaining: 31m 35s\n",
      "3863:\tlearn: 0.0348299\ttest: 0.0385193\tbest: 0.0385193 (3863)\ttotal: 19m 53s\tremaining: 31m 35s\n",
      "3864:\tlearn: 0.0348299\ttest: 0.0385193\tbest: 0.0385193 (3864)\ttotal: 19m 54s\tremaining: 31m 35s\n",
      "3865:\tlearn: 0.0348252\ttest: 0.0385169\tbest: 0.0385169 (3865)\ttotal: 19m 54s\tremaining: 31m 35s\n",
      "3866:\tlearn: 0.0348252\ttest: 0.0385169\tbest: 0.0385169 (3865)\ttotal: 19m 55s\tremaining: 31m 35s\n",
      "3867:\tlearn: 0.0348252\ttest: 0.0385169\tbest: 0.0385169 (3867)\ttotal: 19m 55s\tremaining: 31m 35s\n",
      "3868:\tlearn: 0.0348252\ttest: 0.0385169\tbest: 0.0385169 (3867)\ttotal: 19m 55s\tremaining: 31m 34s\n",
      "3869:\tlearn: 0.0348224\ttest: 0.0385166\tbest: 0.0385166 (3869)\ttotal: 19m 56s\tremaining: 31m 34s\n",
      "3870:\tlearn: 0.0348225\ttest: 0.0385166\tbest: 0.0385166 (3870)\ttotal: 19m 56s\tremaining: 31m 34s\n",
      "3871:\tlearn: 0.0348225\ttest: 0.0385166\tbest: 0.0385166 (3871)\ttotal: 19m 56s\tremaining: 31m 33s\n",
      "3872:\tlearn: 0.0348224\ttest: 0.0385166\tbest: 0.0385166 (3872)\ttotal: 19m 56s\tremaining: 31m 33s\n",
      "3873:\tlearn: 0.0348183\ttest: 0.0385154\tbest: 0.0385154 (3873)\ttotal: 19m 57s\tremaining: 31m 32s\n",
      "3874:\tlearn: 0.0348183\ttest: 0.0385154\tbest: 0.0385154 (3873)\ttotal: 19m 57s\tremaining: 31m 32s\n",
      "3875:\tlearn: 0.0348183\ttest: 0.0385154\tbest: 0.0385154 (3875)\ttotal: 19m 57s\tremaining: 31m 32s\n",
      "3876:\tlearn: 0.0348183\ttest: 0.0385154\tbest: 0.0385154 (3875)\ttotal: 19m 57s\tremaining: 31m 31s\n",
      "3877:\tlearn: 0.0348183\ttest: 0.0385154\tbest: 0.0385154 (3877)\ttotal: 19m 58s\tremaining: 31m 31s\n",
      "3878:\tlearn: 0.0348183\ttest: 0.0385154\tbest: 0.0385154 (3878)\ttotal: 19m 58s\tremaining: 31m 31s\n",
      "3879:\tlearn: 0.0348183\ttest: 0.0385154\tbest: 0.0385154 (3879)\ttotal: 19m 58s\tremaining: 31m 30s\n",
      "3880:\tlearn: 0.0348183\ttest: 0.0385154\tbest: 0.0385154 (3879)\ttotal: 19m 58s\tremaining: 31m 30s\n",
      "3881:\tlearn: 0.0348183\ttest: 0.0385154\tbest: 0.0385154 (3881)\ttotal: 19m 59s\tremaining: 31m 29s\n",
      "3882:\tlearn: 0.0348183\ttest: 0.0385154\tbest: 0.0385154 (3882)\ttotal: 19m 59s\tremaining: 31m 29s\n",
      "3883:\tlearn: 0.0348182\ttest: 0.0385154\tbest: 0.0385154 (3883)\ttotal: 19m 59s\tremaining: 31m 29s\n",
      "3884:\tlearn: 0.0348182\ttest: 0.0385154\tbest: 0.0385154 (3883)\ttotal: 19m 59s\tremaining: 31m 28s\n",
      "3885:\tlearn: 0.0348182\ttest: 0.0385154\tbest: 0.0385154 (3885)\ttotal: 20m\tremaining: 31m 28s\n",
      "3886:\tlearn: 0.0348182\ttest: 0.0385154\tbest: 0.0385154 (3886)\ttotal: 20m\tremaining: 31m 27s\n",
      "3887:\tlearn: 0.0348182\ttest: 0.0385154\tbest: 0.0385154 (3887)\ttotal: 20m\tremaining: 31m 27s\n",
      "3888:\tlearn: 0.0348182\ttest: 0.0385154\tbest: 0.0385154 (3887)\ttotal: 20m\tremaining: 31m 27s\n",
      "3889:\tlearn: 0.0348182\ttest: 0.0385154\tbest: 0.0385154 (3889)\ttotal: 20m 1s\tremaining: 31m 26s\n",
      "3890:\tlearn: 0.0348131\ttest: 0.0385137\tbest: 0.0385137 (3890)\ttotal: 20m 1s\tremaining: 31m 26s\n",
      "3891:\tlearn: 0.0348082\ttest: 0.0385117\tbest: 0.0385117 (3891)\ttotal: 20m 1s\tremaining: 31m 26s\n",
      "3892:\tlearn: 0.0348082\ttest: 0.0385117\tbest: 0.0385117 (3892)\ttotal: 20m 2s\tremaining: 31m 25s\n",
      "3893:\tlearn: 0.0348048\ttest: 0.0385101\tbest: 0.0385101 (3893)\ttotal: 20m 2s\tremaining: 31m 25s\n",
      "3894:\tlearn: 0.0348048\ttest: 0.0385101\tbest: 0.0385101 (3893)\ttotal: 20m 2s\tremaining: 31m 25s\n",
      "3895:\tlearn: 0.0348048\ttest: 0.0385101\tbest: 0.0385101 (3895)\ttotal: 20m 2s\tremaining: 31m 24s\n",
      "3896:\tlearn: 0.0348048\ttest: 0.0385101\tbest: 0.0385101 (3896)\ttotal: 20m 3s\tremaining: 31m 24s\n",
      "3897:\tlearn: 0.0348048\ttest: 0.0385101\tbest: 0.0385101 (3896)\ttotal: 20m 3s\tremaining: 31m 24s\n",
      "3898:\tlearn: 0.0348048\ttest: 0.0385101\tbest: 0.0385101 (3898)\ttotal: 20m 3s\tremaining: 31m 23s\n",
      "3899:\tlearn: 0.0348048\ttest: 0.0385101\tbest: 0.0385101 (3899)\ttotal: 20m 4s\tremaining: 31m 23s\n",
      "3900:\tlearn: 0.0348029\ttest: 0.0385097\tbest: 0.0385097 (3900)\ttotal: 20m 4s\tremaining: 31m 22s\n",
      "3901:\tlearn: 0.0348029\ttest: 0.0385097\tbest: 0.0385097 (3900)\ttotal: 20m 4s\tremaining: 31m 22s\n",
      "3902:\tlearn: 0.0348029\ttest: 0.0385097\tbest: 0.0385097 (3902)\ttotal: 20m 4s\tremaining: 31m 22s\n",
      "3903:\tlearn: 0.0348029\ttest: 0.0385097\tbest: 0.0385097 (3903)\ttotal: 20m 5s\tremaining: 31m 21s\n",
      "3904:\tlearn: 0.0348028\ttest: 0.0385097\tbest: 0.0385097 (3904)\ttotal: 20m 5s\tremaining: 31m 21s\n",
      "3905:\tlearn: 0.0348028\ttest: 0.0385097\tbest: 0.0385097 (3904)\ttotal: 20m 6s\tremaining: 31m 21s\n",
      "3906:\tlearn: 0.0348029\ttest: 0.0385097\tbest: 0.0385097 (3906)\ttotal: 20m 6s\tremaining: 31m 21s\n",
      "3907:\tlearn: 0.0348029\ttest: 0.0385097\tbest: 0.0385097 (3907)\ttotal: 20m 6s\tremaining: 31m 21s\n",
      "3908:\tlearn: 0.0348029\ttest: 0.0385097\tbest: 0.0385097 (3908)\ttotal: 20m 7s\tremaining: 31m 21s\n",
      "3909:\tlearn: 0.0348028\ttest: 0.0385097\tbest: 0.0385097 (3909)\ttotal: 20m 7s\tremaining: 31m 21s\n",
      "3910:\tlearn: 0.0347990\ttest: 0.0385090\tbest: 0.0385090 (3910)\ttotal: 20m 8s\tremaining: 31m 21s\n",
      "3911:\tlearn: 0.0347990\ttest: 0.0385090\tbest: 0.0385090 (3911)\ttotal: 20m 8s\tremaining: 31m 21s\n",
      "3912:\tlearn: 0.0347990\ttest: 0.0385090\tbest: 0.0385090 (3911)\ttotal: 20m 9s\tremaining: 31m 20s\n",
      "3913:\tlearn: 0.0347990\ttest: 0.0385090\tbest: 0.0385090 (3911)\ttotal: 20m 9s\tremaining: 31m 20s\n",
      "3914:\tlearn: 0.0347990\ttest: 0.0385090\tbest: 0.0385090 (3914)\ttotal: 20m 9s\tremaining: 31m 20s\n",
      "3915:\tlearn: 0.0347990\ttest: 0.0385090\tbest: 0.0385090 (3915)\ttotal: 20m 9s\tremaining: 31m 19s\n",
      "3916:\tlearn: 0.0347990\ttest: 0.0385090\tbest: 0.0385090 (3916)\ttotal: 20m 10s\tremaining: 31m 19s\n",
      "3917:\tlearn: 0.0347990\ttest: 0.0385090\tbest: 0.0385090 (3916)\ttotal: 20m 10s\tremaining: 31m 18s\n",
      "3918:\tlearn: 0.0347932\ttest: 0.0385068\tbest: 0.0385068 (3918)\ttotal: 20m 10s\tremaining: 31m 18s\n",
      "3919:\tlearn: 0.0347932\ttest: 0.0385068\tbest: 0.0385068 (3919)\ttotal: 20m 10s\tremaining: 31m 18s\n",
      "3920:\tlearn: 0.0347881\ttest: 0.0385056\tbest: 0.0385056 (3920)\ttotal: 20m 11s\tremaining: 31m 17s\n",
      "3921:\tlearn: 0.0347881\ttest: 0.0385056\tbest: 0.0385056 (3921)\ttotal: 20m 11s\tremaining: 31m 17s\n",
      "3922:\tlearn: 0.0347881\ttest: 0.0385056\tbest: 0.0385056 (3921)\ttotal: 20m 11s\tremaining: 31m 17s\n",
      "3923:\tlearn: 0.0347881\ttest: 0.0385056\tbest: 0.0385056 (3923)\ttotal: 20m 12s\tremaining: 31m 16s\n",
      "3924:\tlearn: 0.0347881\ttest: 0.0385056\tbest: 0.0385056 (3923)\ttotal: 20m 12s\tremaining: 31m 16s\n",
      "3925:\tlearn: 0.0347881\ttest: 0.0385056\tbest: 0.0385056 (3925)\ttotal: 20m 12s\tremaining: 31m 16s\n",
      "3926:\tlearn: 0.0347881\ttest: 0.0385056\tbest: 0.0385056 (3925)\ttotal: 20m 12s\tremaining: 31m 15s\n",
      "3927:\tlearn: 0.0347881\ttest: 0.0385056\tbest: 0.0385056 (3927)\ttotal: 20m 13s\tremaining: 31m 15s\n",
      "3928:\tlearn: 0.0347881\ttest: 0.0385056\tbest: 0.0385056 (3928)\ttotal: 20m 13s\tremaining: 31m 14s\n",
      "3929:\tlearn: 0.0347881\ttest: 0.0385056\tbest: 0.0385056 (3928)\ttotal: 20m 13s\tremaining: 31m 14s\n",
      "3930:\tlearn: 0.0347881\ttest: 0.0385056\tbest: 0.0385056 (3930)\ttotal: 20m 13s\tremaining: 31m 14s\n",
      "3931:\tlearn: 0.0347881\ttest: 0.0385056\tbest: 0.0385056 (3930)\ttotal: 20m 14s\tremaining: 31m 13s\n",
      "3932:\tlearn: 0.0347881\ttest: 0.0385056\tbest: 0.0385056 (3930)\ttotal: 20m 14s\tremaining: 31m 13s\n",
      "3933:\tlearn: 0.0347881\ttest: 0.0385056\tbest: 0.0385056 (3933)\ttotal: 20m 14s\tremaining: 31m 13s\n",
      "3934:\tlearn: 0.0347881\ttest: 0.0385056\tbest: 0.0385056 (3934)\ttotal: 20m 14s\tremaining: 31m 12s\n",
      "3935:\tlearn: 0.0347881\ttest: 0.0385056\tbest: 0.0385056 (3935)\ttotal: 20m 15s\tremaining: 31m 12s\n",
      "3936:\tlearn: 0.0347881\ttest: 0.0385056\tbest: 0.0385056 (3936)\ttotal: 20m 15s\tremaining: 31m 11s\n",
      "3937:\tlearn: 0.0347881\ttest: 0.0385056\tbest: 0.0385056 (3936)\ttotal: 20m 15s\tremaining: 31m 11s\n",
      "3938:\tlearn: 0.0347880\ttest: 0.0385056\tbest: 0.0385056 (3938)\ttotal: 20m 16s\tremaining: 31m 11s\n",
      "3939:\tlearn: 0.0347880\ttest: 0.0385056\tbest: 0.0385056 (3939)\ttotal: 20m 16s\tremaining: 31m 10s\n",
      "3940:\tlearn: 0.0347880\ttest: 0.0385056\tbest: 0.0385056 (3939)\ttotal: 20m 16s\tremaining: 31m 10s\n",
      "3941:\tlearn: 0.0347880\ttest: 0.0385056\tbest: 0.0385056 (3939)\ttotal: 20m 16s\tremaining: 31m 10s\n",
      "3942:\tlearn: 0.0347880\ttest: 0.0385056\tbest: 0.0385056 (3942)\ttotal: 20m 17s\tremaining: 31m 9s\n",
      "3943:\tlearn: 0.0347880\ttest: 0.0385055\tbest: 0.0385055 (3943)\ttotal: 20m 17s\tremaining: 31m 9s\n",
      "3944:\tlearn: 0.0347880\ttest: 0.0385055\tbest: 0.0385055 (3944)\ttotal: 20m 17s\tremaining: 31m 8s\n",
      "3945:\tlearn: 0.0347880\ttest: 0.0385055\tbest: 0.0385055 (3945)\ttotal: 20m 17s\tremaining: 31m 8s\n",
      "3946:\tlearn: 0.0347880\ttest: 0.0385055\tbest: 0.0385055 (3945)\ttotal: 20m 18s\tremaining: 31m 8s\n",
      "3947:\tlearn: 0.0347880\ttest: 0.0385055\tbest: 0.0385055 (3947)\ttotal: 20m 18s\tremaining: 31m 7s\n",
      "3948:\tlearn: 0.0347880\ttest: 0.0385056\tbest: 0.0385055 (3947)\ttotal: 20m 18s\tremaining: 31m 7s\n",
      "3949:\tlearn: 0.0347808\ttest: 0.0385035\tbest: 0.0385035 (3949)\ttotal: 20m 19s\tremaining: 31m 7s\n",
      "3950:\tlearn: 0.0347808\ttest: 0.0385035\tbest: 0.0385035 (3950)\ttotal: 20m 19s\tremaining: 31m 7s\n",
      "3951:\tlearn: 0.0347808\ttest: 0.0385035\tbest: 0.0385035 (3950)\ttotal: 20m 19s\tremaining: 31m 6s\n",
      "3952:\tlearn: 0.0347808\ttest: 0.0385035\tbest: 0.0385035 (3950)\ttotal: 20m 20s\tremaining: 31m 6s\n",
      "3953:\tlearn: 0.0347808\ttest: 0.0385035\tbest: 0.0385035 (3950)\ttotal: 20m 20s\tremaining: 31m 6s\n",
      "3954:\tlearn: 0.0347772\ttest: 0.0385028\tbest: 0.0385028 (3954)\ttotal: 20m 21s\tremaining: 31m 6s\n",
      "3955:\tlearn: 0.0347772\ttest: 0.0385028\tbest: 0.0385028 (3954)\ttotal: 20m 21s\tremaining: 31m 6s\n",
      "3956:\tlearn: 0.0347772\ttest: 0.0385028\tbest: 0.0385028 (3956)\ttotal: 20m 22s\tremaining: 31m 6s\n",
      "3957:\tlearn: 0.0347772\ttest: 0.0385028\tbest: 0.0385028 (3957)\ttotal: 20m 22s\tremaining: 31m 6s\n",
      "3958:\tlearn: 0.0347772\ttest: 0.0385028\tbest: 0.0385028 (3957)\ttotal: 20m 23s\tremaining: 31m 6s\n",
      "3959:\tlearn: 0.0347772\ttest: 0.0385028\tbest: 0.0385028 (3959)\ttotal: 20m 23s\tremaining: 31m 5s\n",
      "3960:\tlearn: 0.0347771\ttest: 0.0385028\tbest: 0.0385028 (3960)\ttotal: 20m 23s\tremaining: 31m 5s\n",
      "3961:\tlearn: 0.0347771\ttest: 0.0385028\tbest: 0.0385028 (3961)\ttotal: 20m 23s\tremaining: 31m 5s\n",
      "3962:\tlearn: 0.0347771\ttest: 0.0385028\tbest: 0.0385028 (3961)\ttotal: 20m 24s\tremaining: 31m 4s\n",
      "3963:\tlearn: 0.0347771\ttest: 0.0385028\tbest: 0.0385028 (3963)\ttotal: 20m 24s\tremaining: 31m 4s\n",
      "3964:\tlearn: 0.0347771\ttest: 0.0385028\tbest: 0.0385028 (3964)\ttotal: 20m 24s\tremaining: 31m 3s\n",
      "3965:\tlearn: 0.0347771\ttest: 0.0385027\tbest: 0.0385027 (3965)\ttotal: 20m 24s\tremaining: 31m 3s\n",
      "3966:\tlearn: 0.0347771\ttest: 0.0385027\tbest: 0.0385027 (3966)\ttotal: 20m 25s\tremaining: 31m 3s\n",
      "3967:\tlearn: 0.0347771\ttest: 0.0385027\tbest: 0.0385027 (3967)\ttotal: 20m 25s\tremaining: 31m 2s\n",
      "3968:\tlearn: 0.0347771\ttest: 0.0385027\tbest: 0.0385027 (3967)\ttotal: 20m 25s\tremaining: 31m 2s\n",
      "3969:\tlearn: 0.0347771\ttest: 0.0385027\tbest: 0.0385027 (3969)\ttotal: 20m 25s\tremaining: 31m 2s\n",
      "3970:\tlearn: 0.0347738\ttest: 0.0385019\tbest: 0.0385019 (3970)\ttotal: 20m 26s\tremaining: 31m 1s\n",
      "3971:\tlearn: 0.0347697\ttest: 0.0385011\tbest: 0.0385011 (3971)\ttotal: 20m 26s\tremaining: 31m 1s\n",
      "3972:\tlearn: 0.0347697\ttest: 0.0385011\tbest: 0.0385011 (3972)\ttotal: 20m 26s\tremaining: 31m 1s\n",
      "3973:\tlearn: 0.0347697\ttest: 0.0385011\tbest: 0.0385011 (3973)\ttotal: 20m 27s\tremaining: 31m\n",
      "3974:\tlearn: 0.0347656\ttest: 0.0385000\tbest: 0.0385000 (3974)\ttotal: 20m 27s\tremaining: 31m\n",
      "3975:\tlearn: 0.0347656\ttest: 0.0385000\tbest: 0.0385000 (3974)\ttotal: 20m 27s\tremaining: 30m 59s\n",
      "3976:\tlearn: 0.0347656\ttest: 0.0385000\tbest: 0.0385000 (3976)\ttotal: 20m 27s\tremaining: 30m 59s\n",
      "3977:\tlearn: 0.0347655\ttest: 0.0385000\tbest: 0.0385000 (3977)\ttotal: 20m 28s\tremaining: 30m 59s\n",
      "3978:\tlearn: 0.0347655\ttest: 0.0385000\tbest: 0.0385000 (3978)\ttotal: 20m 28s\tremaining: 30m 58s\n",
      "3979:\tlearn: 0.0347610\ttest: 0.0384994\tbest: 0.0384994 (3979)\ttotal: 20m 28s\tremaining: 30m 58s\n",
      "3980:\tlearn: 0.0347610\ttest: 0.0384994\tbest: 0.0384994 (3979)\ttotal: 20m 29s\tremaining: 30m 58s\n",
      "3981:\tlearn: 0.0347541\ttest: 0.0384981\tbest: 0.0384981 (3981)\ttotal: 20m 29s\tremaining: 30m 57s\n",
      "3982:\tlearn: 0.0347541\ttest: 0.0384981\tbest: 0.0384981 (3981)\ttotal: 20m 29s\tremaining: 30m 57s\n",
      "3983:\tlearn: 0.0347541\ttest: 0.0384981\tbest: 0.0384981 (3983)\ttotal: 20m 29s\tremaining: 30m 57s\n",
      "3984:\tlearn: 0.0347541\ttest: 0.0384981\tbest: 0.0384981 (3984)\ttotal: 20m 30s\tremaining: 30m 56s\n",
      "3985:\tlearn: 0.0347541\ttest: 0.0384981\tbest: 0.0384981 (3985)\ttotal: 20m 30s\tremaining: 30m 56s\n",
      "3986:\tlearn: 0.0347541\ttest: 0.0384981\tbest: 0.0384981 (3985)\ttotal: 20m 30s\tremaining: 30m 56s\n",
      "3987:\tlearn: 0.0347541\ttest: 0.0384981\tbest: 0.0384981 (3987)\ttotal: 20m 30s\tremaining: 30m 55s\n",
      "3988:\tlearn: 0.0347541\ttest: 0.0384981\tbest: 0.0384981 (3988)\ttotal: 20m 31s\tremaining: 30m 55s\n",
      "3989:\tlearn: 0.0347541\ttest: 0.0384981\tbest: 0.0384981 (3989)\ttotal: 20m 31s\tremaining: 30m 54s\n",
      "3990:\tlearn: 0.0347541\ttest: 0.0384981\tbest: 0.0384981 (3990)\ttotal: 20m 31s\tremaining: 30m 54s\n",
      "3991:\tlearn: 0.0347541\ttest: 0.0384981\tbest: 0.0384981 (3991)\ttotal: 20m 31s\tremaining: 30m 54s\n",
      "3992:\tlearn: 0.0347541\ttest: 0.0384981\tbest: 0.0384981 (3992)\ttotal: 20m 32s\tremaining: 30m 53s\n",
      "3993:\tlearn: 0.0347541\ttest: 0.0384981\tbest: 0.0384981 (3992)\ttotal: 20m 32s\tremaining: 30m 53s\n",
      "3994:\tlearn: 0.0347499\ttest: 0.0384970\tbest: 0.0384970 (3994)\ttotal: 20m 32s\tremaining: 30m 53s\n",
      "3995:\tlearn: 0.0347499\ttest: 0.0384970\tbest: 0.0384970 (3994)\ttotal: 20m 33s\tremaining: 30m 53s\n",
      "3996:\tlearn: 0.0347498\ttest: 0.0384970\tbest: 0.0384970 (3996)\ttotal: 20m 33s\tremaining: 30m 53s\n",
      "3997:\tlearn: 0.0347498\ttest: 0.0384970\tbest: 0.0384970 (3996)\ttotal: 20m 34s\tremaining: 30m 53s\n",
      "3998:\tlearn: 0.0347499\ttest: 0.0384970\tbest: 0.0384970 (3998)\ttotal: 20m 34s\tremaining: 30m 53s\n",
      "3999:\tlearn: 0.0347499\ttest: 0.0384970\tbest: 0.0384970 (3999)\ttotal: 20m 35s\tremaining: 30m 53s\n",
      "4000:\tlearn: 0.0347498\ttest: 0.0384970\tbest: 0.0384970 (4000)\ttotal: 20m 35s\tremaining: 30m 52s\n",
      "4001:\tlearn: 0.0347498\ttest: 0.0384970\tbest: 0.0384970 (4001)\ttotal: 20m 36s\tremaining: 30m 52s\n",
      "4002:\tlearn: 0.0347451\ttest: 0.0384970\tbest: 0.0384970 (4001)\ttotal: 20m 36s\tremaining: 30m 53s\n",
      "4003:\tlearn: 0.0347451\ttest: 0.0384970\tbest: 0.0384970 (4001)\ttotal: 20m 37s\tremaining: 30m 52s\n",
      "4004:\tlearn: 0.0347451\ttest: 0.0384970\tbest: 0.0384970 (4001)\ttotal: 20m 37s\tremaining: 30m 52s\n",
      "4005:\tlearn: 0.0347401\ttest: 0.0384963\tbest: 0.0384963 (4005)\ttotal: 20m 38s\tremaining: 30m 52s\n",
      "4006:\tlearn: 0.0347401\ttest: 0.0384963\tbest: 0.0384963 (4006)\ttotal: 20m 38s\tremaining: 30m 52s\n",
      "4007:\tlearn: 0.0347401\ttest: 0.0384963\tbest: 0.0384963 (4006)\ttotal: 20m 39s\tremaining: 30m 52s\n",
      "4008:\tlearn: 0.0347401\ttest: 0.0384963\tbest: 0.0384963 (4008)\ttotal: 20m 39s\tremaining: 30m 52s\n",
      "4009:\tlearn: 0.0347401\ttest: 0.0384963\tbest: 0.0384963 (4009)\ttotal: 20m 40s\tremaining: 30m 52s\n",
      "4010:\tlearn: 0.0347401\ttest: 0.0384963\tbest: 0.0384963 (4009)\ttotal: 20m 40s\tremaining: 30m 52s\n",
      "4011:\tlearn: 0.0347401\ttest: 0.0384963\tbest: 0.0384963 (4009)\ttotal: 20m 40s\tremaining: 30m 51s\n",
      "4012:\tlearn: 0.0347401\ttest: 0.0384963\tbest: 0.0384963 (4012)\ttotal: 20m 40s\tremaining: 30m 51s\n",
      "4013:\tlearn: 0.0347360\ttest: 0.0384965\tbest: 0.0384963 (4012)\ttotal: 20m 41s\tremaining: 30m 50s\n",
      "4014:\tlearn: 0.0347360\ttest: 0.0384965\tbest: 0.0384963 (4012)\ttotal: 20m 41s\tremaining: 30m 50s\n",
      "4015:\tlearn: 0.0347360\ttest: 0.0384965\tbest: 0.0384963 (4012)\ttotal: 20m 41s\tremaining: 30m 50s\n",
      "4016:\tlearn: 0.0347360\ttest: 0.0384965\tbest: 0.0384963 (4012)\ttotal: 20m 42s\tremaining: 30m 49s\n",
      "4017:\tlearn: 0.0347360\ttest: 0.0384965\tbest: 0.0384963 (4012)\ttotal: 20m 42s\tremaining: 30m 49s\n",
      "4018:\tlearn: 0.0347322\ttest: 0.0384944\tbest: 0.0384944 (4018)\ttotal: 20m 42s\tremaining: 30m 49s\n",
      "4019:\tlearn: 0.0347322\ttest: 0.0384944\tbest: 0.0384944 (4018)\ttotal: 20m 42s\tremaining: 30m 48s\n",
      "4020:\tlearn: 0.0347322\ttest: 0.0384944\tbest: 0.0384944 (4020)\ttotal: 20m 43s\tremaining: 30m 48s\n",
      "4021:\tlearn: 0.0347322\ttest: 0.0384944\tbest: 0.0384944 (4021)\ttotal: 20m 43s\tremaining: 30m 48s\n",
      "4022:\tlearn: 0.0347272\ttest: 0.0384922\tbest: 0.0384922 (4022)\ttotal: 20m 43s\tremaining: 30m 47s\n",
      "4023:\tlearn: 0.0347272\ttest: 0.0384922\tbest: 0.0384922 (4023)\ttotal: 20m 43s\tremaining: 30m 47s\n",
      "4024:\tlearn: 0.0347272\ttest: 0.0384922\tbest: 0.0384922 (4024)\ttotal: 20m 44s\tremaining: 30m 46s\n",
      "4025:\tlearn: 0.0347213\ttest: 0.0384904\tbest: 0.0384904 (4025)\ttotal: 20m 44s\tremaining: 30m 46s\n",
      "4026:\tlearn: 0.0347213\ttest: 0.0384904\tbest: 0.0384904 (4025)\ttotal: 20m 44s\tremaining: 30m 46s\n",
      "4027:\tlearn: 0.0347213\ttest: 0.0384904\tbest: 0.0384904 (4027)\ttotal: 20m 45s\tremaining: 30m 45s\n",
      "4028:\tlearn: 0.0347190\ttest: 0.0384895\tbest: 0.0384895 (4028)\ttotal: 20m 45s\tremaining: 30m 45s\n",
      "4029:\tlearn: 0.0347190\ttest: 0.0384895\tbest: 0.0384895 (4029)\ttotal: 20m 45s\tremaining: 30m 45s\n",
      "4030:\tlearn: 0.0347190\ttest: 0.0384895\tbest: 0.0384895 (4029)\ttotal: 20m 45s\tremaining: 30m 44s\n",
      "4031:\tlearn: 0.0347190\ttest: 0.0384895\tbest: 0.0384895 (4031)\ttotal: 20m 46s\tremaining: 30m 44s\n",
      "4032:\tlearn: 0.0347190\ttest: 0.0384895\tbest: 0.0384895 (4031)\ttotal: 20m 46s\tremaining: 30m 43s\n",
      "4033:\tlearn: 0.0347190\ttest: 0.0384895\tbest: 0.0384895 (4033)\ttotal: 20m 46s\tremaining: 30m 43s\n",
      "4034:\tlearn: 0.0347154\ttest: 0.0384878\tbest: 0.0384878 (4034)\ttotal: 20m 46s\tremaining: 30m 43s\n",
      "4035:\tlearn: 0.0347154\ttest: 0.0384878\tbest: 0.0384878 (4035)\ttotal: 20m 47s\tremaining: 30m 42s\n",
      "4036:\tlearn: 0.0347154\ttest: 0.0384878\tbest: 0.0384878 (4035)\ttotal: 20m 47s\tremaining: 30m 42s\n",
      "4037:\tlearn: 0.0347154\ttest: 0.0384878\tbest: 0.0384878 (4037)\ttotal: 20m 47s\tremaining: 30m 42s\n",
      "4038:\tlearn: 0.0347154\ttest: 0.0384878\tbest: 0.0384878 (4038)\ttotal: 20m 47s\tremaining: 30m 41s\n",
      "4039:\tlearn: 0.0347154\ttest: 0.0384878\tbest: 0.0384878 (4039)\ttotal: 20m 48s\tremaining: 30m 41s\n",
      "4040:\tlearn: 0.0347153\ttest: 0.0384878\tbest: 0.0384878 (4040)\ttotal: 20m 48s\tremaining: 30m 40s\n",
      "4041:\tlearn: 0.0347153\ttest: 0.0384878\tbest: 0.0384878 (4040)\ttotal: 20m 48s\tremaining: 30m 40s\n",
      "4042:\tlearn: 0.0347153\ttest: 0.0384878\tbest: 0.0384878 (4042)\ttotal: 20m 48s\tremaining: 30m 40s\n",
      "4043:\tlearn: 0.0347153\ttest: 0.0384878\tbest: 0.0384878 (4042)\ttotal: 20m 49s\tremaining: 30m 39s\n",
      "4044:\tlearn: 0.0347153\ttest: 0.0384878\tbest: 0.0384878 (4044)\ttotal: 20m 49s\tremaining: 30m 39s\n",
      "4045:\tlearn: 0.0347153\ttest: 0.0384878\tbest: 0.0384878 (4045)\ttotal: 20m 49s\tremaining: 30m 39s\n",
      "4046:\tlearn: 0.0347153\ttest: 0.0384878\tbest: 0.0384878 (4046)\ttotal: 20m 50s\tremaining: 30m 38s\n",
      "4047:\tlearn: 0.0347153\ttest: 0.0384878\tbest: 0.0384878 (4047)\ttotal: 20m 50s\tremaining: 30m 38s\n",
      "4048:\tlearn: 0.0347153\ttest: 0.0384878\tbest: 0.0384878 (4047)\ttotal: 20m 50s\tremaining: 30m 38s\n",
      "4049:\tlearn: 0.0347153\ttest: 0.0384877\tbest: 0.0384877 (4049)\ttotal: 20m 51s\tremaining: 30m 38s\n",
      "4050:\tlearn: 0.0347124\ttest: 0.0384869\tbest: 0.0384869 (4050)\ttotal: 20m 51s\tremaining: 30m 38s\n",
      "4051:\tlearn: 0.0347124\ttest: 0.0384869\tbest: 0.0384869 (4050)\ttotal: 20m 52s\tremaining: 30m 38s\n",
      "4052:\tlearn: 0.0347124\ttest: 0.0384869\tbest: 0.0384869 (4052)\ttotal: 20m 52s\tremaining: 30m 38s\n",
      "4053:\tlearn: 0.0347124\ttest: 0.0384869\tbest: 0.0384869 (4053)\ttotal: 20m 53s\tremaining: 30m 38s\n",
      "4054:\tlearn: 0.0347124\ttest: 0.0384869\tbest: 0.0384869 (4054)\ttotal: 20m 53s\tremaining: 30m 37s\n",
      "4055:\tlearn: 0.0347124\ttest: 0.0384869\tbest: 0.0384869 (4055)\ttotal: 20m 54s\tremaining: 30m 37s\n",
      "4056:\tlearn: 0.0347069\ttest: 0.0384857\tbest: 0.0384857 (4056)\ttotal: 20m 54s\tremaining: 30m 37s\n",
      "4057:\tlearn: 0.0347069\ttest: 0.0384857\tbest: 0.0384857 (4057)\ttotal: 20m 54s\tremaining: 30m 37s\n",
      "4058:\tlearn: 0.0347069\ttest: 0.0384857\tbest: 0.0384857 (4057)\ttotal: 20m 54s\tremaining: 30m 36s\n",
      "4059:\tlearn: 0.0347069\ttest: 0.0384856\tbest: 0.0384856 (4059)\ttotal: 20m 55s\tremaining: 30m 36s\n",
      "4060:\tlearn: 0.0347069\ttest: 0.0384856\tbest: 0.0384856 (4060)\ttotal: 20m 55s\tremaining: 30m 35s\n",
      "4061:\tlearn: 0.0347069\ttest: 0.0384856\tbest: 0.0384856 (4061)\ttotal: 20m 55s\tremaining: 30m 35s\n",
      "4062:\tlearn: 0.0347069\ttest: 0.0384856\tbest: 0.0384856 (4062)\ttotal: 20m 55s\tremaining: 30m 35s\n",
      "4063:\tlearn: 0.0347069\ttest: 0.0384856\tbest: 0.0384856 (4063)\ttotal: 20m 56s\tremaining: 30m 34s\n",
      "4064:\tlearn: 0.0347069\ttest: 0.0384856\tbest: 0.0384856 (4064)\ttotal: 20m 56s\tremaining: 30m 34s\n",
      "4065:\tlearn: 0.0347069\ttest: 0.0384856\tbest: 0.0384856 (4065)\ttotal: 20m 56s\tremaining: 30m 33s\n",
      "4066:\tlearn: 0.0347069\ttest: 0.0384856\tbest: 0.0384856 (4066)\ttotal: 20m 56s\tremaining: 30m 33s\n",
      "4067:\tlearn: 0.0347069\ttest: 0.0384856\tbest: 0.0384856 (4067)\ttotal: 20m 57s\tremaining: 30m 33s\n",
      "4068:\tlearn: 0.0347069\ttest: 0.0384856\tbest: 0.0384856 (4068)\ttotal: 20m 57s\tremaining: 30m 32s\n",
      "4069:\tlearn: 0.0347024\ttest: 0.0384848\tbest: 0.0384848 (4069)\ttotal: 20m 57s\tremaining: 30m 32s\n",
      "4070:\tlearn: 0.0347024\ttest: 0.0384848\tbest: 0.0384848 (4070)\ttotal: 20m 57s\tremaining: 30m 32s\n",
      "4071:\tlearn: 0.0347024\ttest: 0.0384848\tbest: 0.0384848 (4070)\ttotal: 20m 58s\tremaining: 30m 31s\n",
      "4072:\tlearn: 0.0347024\ttest: 0.0384848\tbest: 0.0384848 (4070)\ttotal: 20m 58s\tremaining: 30m 31s\n",
      "4073:\tlearn: 0.0347024\ttest: 0.0384848\tbest: 0.0384848 (4073)\ttotal: 20m 58s\tremaining: 30m 30s\n",
      "4074:\tlearn: 0.0347024\ttest: 0.0384848\tbest: 0.0384848 (4074)\ttotal: 20m 59s\tremaining: 30m 30s\n",
      "4075:\tlearn: 0.0347024\ttest: 0.0384848\tbest: 0.0384848 (4075)\ttotal: 20m 59s\tremaining: 30m 30s\n",
      "4076:\tlearn: 0.0347024\ttest: 0.0384848\tbest: 0.0384848 (4076)\ttotal: 20m 59s\tremaining: 30m 29s\n",
      "4077:\tlearn: 0.0347023\ttest: 0.0384848\tbest: 0.0384848 (4077)\ttotal: 20m 59s\tremaining: 30m 29s\n",
      "4078:\tlearn: 0.0347023\ttest: 0.0384848\tbest: 0.0384848 (4077)\ttotal: 21m\tremaining: 30m 29s\n",
      "4079:\tlearn: 0.0347023\ttest: 0.0384848\tbest: 0.0384848 (4079)\ttotal: 21m\tremaining: 30m 28s\n",
      "4080:\tlearn: 0.0346989\ttest: 0.0384841\tbest: 0.0384841 (4080)\ttotal: 21m\tremaining: 30m 28s\n",
      "4081:\tlearn: 0.0346929\ttest: 0.0384816\tbest: 0.0384816 (4081)\ttotal: 21m\tremaining: 30m 28s\n",
      "4082:\tlearn: 0.0346929\ttest: 0.0384816\tbest: 0.0384816 (4082)\ttotal: 21m 1s\tremaining: 30m 27s\n",
      "4083:\tlearn: 0.0346929\ttest: 0.0384816\tbest: 0.0384816 (4083)\ttotal: 21m 1s\tremaining: 30m 27s\n",
      "4084:\tlearn: 0.0346929\ttest: 0.0384816\tbest: 0.0384816 (4084)\ttotal: 21m 1s\tremaining: 30m 26s\n",
      "4085:\tlearn: 0.0346929\ttest: 0.0384816\tbest: 0.0384816 (4084)\ttotal: 21m 2s\tremaining: 30m 26s\n",
      "4086:\tlearn: 0.0346929\ttest: 0.0384816\tbest: 0.0384816 (4084)\ttotal: 21m 2s\tremaining: 30m 26s\n",
      "4087:\tlearn: 0.0346929\ttest: 0.0384816\tbest: 0.0384816 (4087)\ttotal: 21m 2s\tremaining: 30m 25s\n",
      "4088:\tlearn: 0.0346929\ttest: 0.0384816\tbest: 0.0384816 (4087)\ttotal: 21m 2s\tremaining: 30m 25s\n",
      "4089:\tlearn: 0.0346929\ttest: 0.0384816\tbest: 0.0384816 (4089)\ttotal: 21m 3s\tremaining: 30m 25s\n",
      "4090:\tlearn: 0.0346929\ttest: 0.0384816\tbest: 0.0384816 (4090)\ttotal: 21m 3s\tremaining: 30m 24s\n",
      "4091:\tlearn: 0.0346913\ttest: 0.0384814\tbest: 0.0384814 (4091)\ttotal: 21m 3s\tremaining: 30m 24s\n",
      "4092:\tlearn: 0.0346913\ttest: 0.0384814\tbest: 0.0384814 (4092)\ttotal: 21m 3s\tremaining: 30m 23s\n",
      "4093:\tlearn: 0.0346913\ttest: 0.0384814\tbest: 0.0384814 (4092)\ttotal: 21m 4s\tremaining: 30m 23s\n",
      "4094:\tlearn: 0.0346913\ttest: 0.0384813\tbest: 0.0384813 (4094)\ttotal: 21m 4s\tremaining: 30m 23s\n",
      "4095:\tlearn: 0.0346886\ttest: 0.0384799\tbest: 0.0384799 (4095)\ttotal: 21m 5s\tremaining: 30m 23s\n",
      "4096:\tlearn: 0.0346885\ttest: 0.0384799\tbest: 0.0384799 (4095)\ttotal: 21m 5s\tremaining: 30m 23s\n",
      "4097:\tlearn: 0.0346885\ttest: 0.0384799\tbest: 0.0384799 (4095)\ttotal: 21m 6s\tremaining: 30m 23s\n",
      "4098:\tlearn: 0.0346885\ttest: 0.0384799\tbest: 0.0384799 (4098)\ttotal: 21m 6s\tremaining: 30m 23s\n",
      "4099:\tlearn: 0.0346885\ttest: 0.0384799\tbest: 0.0384799 (4098)\ttotal: 21m 7s\tremaining: 30m 23s\n",
      "4100:\tlearn: 0.0346885\ttest: 0.0384799\tbest: 0.0384799 (4100)\ttotal: 21m 7s\tremaining: 30m 23s\n",
      "4101:\tlearn: 0.0346885\ttest: 0.0384799\tbest: 0.0384799 (4101)\ttotal: 21m 7s\tremaining: 30m 23s\n",
      "4102:\tlearn: 0.0346885\ttest: 0.0384799\tbest: 0.0384799 (4102)\ttotal: 21m 8s\tremaining: 30m 22s\n",
      "4103:\tlearn: 0.0346885\ttest: 0.0384799\tbest: 0.0384799 (4103)\ttotal: 21m 8s\tremaining: 30m 22s\n",
      "4104:\tlearn: 0.0346885\ttest: 0.0384799\tbest: 0.0384799 (4103)\ttotal: 21m 8s\tremaining: 30m 22s\n",
      "4105:\tlearn: 0.0346850\ttest: 0.0384788\tbest: 0.0384788 (4105)\ttotal: 21m 9s\tremaining: 30m 21s\n",
      "4106:\tlearn: 0.0346850\ttest: 0.0384788\tbest: 0.0384788 (4105)\ttotal: 21m 9s\tremaining: 30m 21s\n",
      "4107:\tlearn: 0.0346795\ttest: 0.0384771\tbest: 0.0384771 (4107)\ttotal: 21m 9s\tremaining: 30m 21s\n",
      "4108:\tlearn: 0.0346795\ttest: 0.0384771\tbest: 0.0384771 (4108)\ttotal: 21m 9s\tremaining: 30m 20s\n",
      "4109:\tlearn: 0.0346794\ttest: 0.0384771\tbest: 0.0384771 (4109)\ttotal: 21m 10s\tremaining: 30m 20s\n",
      "4110:\tlearn: 0.0346794\ttest: 0.0384771\tbest: 0.0384771 (4110)\ttotal: 21m 10s\tremaining: 30m 19s\n",
      "4111:\tlearn: 0.0346794\ttest: 0.0384771\tbest: 0.0384771 (4111)\ttotal: 21m 10s\tremaining: 30m 19s\n",
      "4112:\tlearn: 0.0346747\ttest: 0.0384755\tbest: 0.0384755 (4112)\ttotal: 21m 11s\tremaining: 30m 19s\n",
      "4113:\tlearn: 0.0346747\ttest: 0.0384755\tbest: 0.0384755 (4113)\ttotal: 21m 11s\tremaining: 30m 18s\n",
      "4114:\tlearn: 0.0346747\ttest: 0.0384755\tbest: 0.0384755 (4114)\ttotal: 21m 11s\tremaining: 30m 18s\n",
      "4115:\tlearn: 0.0346747\ttest: 0.0384755\tbest: 0.0384755 (4114)\ttotal: 21m 11s\tremaining: 30m 18s\n",
      "4116:\tlearn: 0.0346747\ttest: 0.0384755\tbest: 0.0384755 (4116)\ttotal: 21m 12s\tremaining: 30m 17s\n",
      "4117:\tlearn: 0.0346747\ttest: 0.0384755\tbest: 0.0384755 (4117)\ttotal: 21m 12s\tremaining: 30m 17s\n",
      "4118:\tlearn: 0.0346697\ttest: 0.0384740\tbest: 0.0384740 (4118)\ttotal: 21m 12s\tremaining: 30m 17s\n",
      "4119:\tlearn: 0.0346697\ttest: 0.0384740\tbest: 0.0384740 (4118)\ttotal: 21m 12s\tremaining: 30m 16s\n",
      "4120:\tlearn: 0.0346697\ttest: 0.0384740\tbest: 0.0384740 (4120)\ttotal: 21m 13s\tremaining: 30m 16s\n",
      "4121:\tlearn: 0.0346697\ttest: 0.0384740\tbest: 0.0384740 (4121)\ttotal: 21m 13s\tremaining: 30m 15s\n",
      "4122:\tlearn: 0.0346697\ttest: 0.0384740\tbest: 0.0384740 (4122)\ttotal: 21m 13s\tremaining: 30m 15s\n",
      "4123:\tlearn: 0.0346656\ttest: 0.0384731\tbest: 0.0384731 (4123)\ttotal: 21m 13s\tremaining: 30m 15s\n",
      "4124:\tlearn: 0.0346656\ttest: 0.0384731\tbest: 0.0384731 (4124)\ttotal: 21m 14s\tremaining: 30m 14s\n",
      "4125:\tlearn: 0.0346656\ttest: 0.0384731\tbest: 0.0384731 (4124)\ttotal: 21m 14s\tremaining: 30m 14s\n",
      "4126:\tlearn: 0.0346656\ttest: 0.0384731\tbest: 0.0384731 (4126)\ttotal: 21m 14s\tremaining: 30m 14s\n",
      "4127:\tlearn: 0.0346656\ttest: 0.0384731\tbest: 0.0384731 (4126)\ttotal: 21m 15s\tremaining: 30m 13s\n",
      "4128:\tlearn: 0.0346656\ttest: 0.0384731\tbest: 0.0384731 (4128)\ttotal: 21m 15s\tremaining: 30m 13s\n",
      "4129:\tlearn: 0.0346656\ttest: 0.0384731\tbest: 0.0384731 (4129)\ttotal: 21m 15s\tremaining: 30m 12s\n",
      "4130:\tlearn: 0.0346656\ttest: 0.0384731\tbest: 0.0384731 (4130)\ttotal: 21m 15s\tremaining: 30m 12s\n",
      "4131:\tlearn: 0.0346656\ttest: 0.0384731\tbest: 0.0384731 (4131)\ttotal: 21m 16s\tremaining: 30m 12s\n",
      "4132:\tlearn: 0.0346656\ttest: 0.0384731\tbest: 0.0384731 (4131)\ttotal: 21m 16s\tremaining: 30m 11s\n",
      "4133:\tlearn: 0.0346656\ttest: 0.0384731\tbest: 0.0384731 (4133)\ttotal: 21m 16s\tremaining: 30m 11s\n",
      "4134:\tlearn: 0.0346656\ttest: 0.0384731\tbest: 0.0384731 (4134)\ttotal: 21m 16s\tremaining: 30m 11s\n",
      "4135:\tlearn: 0.0346656\ttest: 0.0384731\tbest: 0.0384731 (4135)\ttotal: 21m 17s\tremaining: 30m 10s\n",
      "4136:\tlearn: 0.0346656\ttest: 0.0384731\tbest: 0.0384731 (4136)\ttotal: 21m 17s\tremaining: 30m 10s\n",
      "4137:\tlearn: 0.0346656\ttest: 0.0384731\tbest: 0.0384731 (4137)\ttotal: 21m 17s\tremaining: 30m 9s\n",
      "4138:\tlearn: 0.0346656\ttest: 0.0384731\tbest: 0.0384731 (4138)\ttotal: 21m 17s\tremaining: 30m 9s\n",
      "4139:\tlearn: 0.0346656\ttest: 0.0384731\tbest: 0.0384731 (4138)\ttotal: 21m 18s\tremaining: 30m 9s\n",
      "4140:\tlearn: 0.0346656\ttest: 0.0384731\tbest: 0.0384731 (4140)\ttotal: 21m 18s\tremaining: 30m 9s\n",
      "4141:\tlearn: 0.0346656\ttest: 0.0384731\tbest: 0.0384731 (4141)\ttotal: 21m 19s\tremaining: 30m 9s\n",
      "4142:\tlearn: 0.0346656\ttest: 0.0384731\tbest: 0.0384731 (4142)\ttotal: 21m 19s\tremaining: 30m 8s\n",
      "4143:\tlearn: 0.0346656\ttest: 0.0384731\tbest: 0.0384731 (4143)\ttotal: 21m 20s\tremaining: 30m 8s\n",
      "4144:\tlearn: 0.0346656\ttest: 0.0384731\tbest: 0.0384731 (4144)\ttotal: 21m 20s\tremaining: 30m 8s\n",
      "4145:\tlearn: 0.0346656\ttest: 0.0384731\tbest: 0.0384731 (4145)\ttotal: 21m 20s\tremaining: 30m 8s\n",
      "4146:\tlearn: 0.0346656\ttest: 0.0384731\tbest: 0.0384731 (4145)\ttotal: 21m 21s\tremaining: 30m 8s\n",
      "4147:\tlearn: 0.0346625\ttest: 0.0384728\tbest: 0.0384728 (4147)\ttotal: 21m 21s\tremaining: 30m 8s\n",
      "4148:\tlearn: 0.0346625\ttest: 0.0384728\tbest: 0.0384728 (4148)\ttotal: 21m 22s\tremaining: 30m 8s\n",
      "4149:\tlearn: 0.0346625\ttest: 0.0384728\tbest: 0.0384728 (4148)\ttotal: 21m 22s\tremaining: 30m 7s\n",
      "4150:\tlearn: 0.0346587\ttest: 0.0384700\tbest: 0.0384700 (4150)\ttotal: 21m 22s\tremaining: 30m 7s\n",
      "4151:\tlearn: 0.0346569\ttest: 0.0384698\tbest: 0.0384698 (4151)\ttotal: 21m 23s\tremaining: 30m 7s\n",
      "4152:\tlearn: 0.0346501\ttest: 0.0384691\tbest: 0.0384691 (4152)\ttotal: 21m 23s\tremaining: 30m 6s\n",
      "4153:\tlearn: 0.0346501\ttest: 0.0384691\tbest: 0.0384691 (4152)\ttotal: 21m 23s\tremaining: 30m 6s\n",
      "4154:\tlearn: 0.0346500\ttest: 0.0384691\tbest: 0.0384691 (4154)\ttotal: 21m 23s\tremaining: 30m 6s\n",
      "4155:\tlearn: 0.0346500\ttest: 0.0384691\tbest: 0.0384691 (4154)\ttotal: 21m 24s\tremaining: 30m 5s\n",
      "4156:\tlearn: 0.0346449\ttest: 0.0384684\tbest: 0.0384684 (4156)\ttotal: 21m 24s\tremaining: 30m 5s\n",
      "4157:\tlearn: 0.0346399\ttest: 0.0384680\tbest: 0.0384680 (4157)\ttotal: 21m 24s\tremaining: 30m 5s\n",
      "4158:\tlearn: 0.0346399\ttest: 0.0384680\tbest: 0.0384680 (4158)\ttotal: 21m 25s\tremaining: 30m 4s\n",
      "4159:\tlearn: 0.0346399\ttest: 0.0384680\tbest: 0.0384680 (4159)\ttotal: 21m 25s\tremaining: 30m 4s\n",
      "4160:\tlearn: 0.0346399\ttest: 0.0384680\tbest: 0.0384680 (4159)\ttotal: 21m 25s\tremaining: 30m 3s\n",
      "4161:\tlearn: 0.0346399\ttest: 0.0384680\tbest: 0.0384680 (4159)\ttotal: 21m 25s\tremaining: 30m 3s\n",
      "4162:\tlearn: 0.0346399\ttest: 0.0384680\tbest: 0.0384680 (4162)\ttotal: 21m 26s\tremaining: 30m 3s\n",
      "4163:\tlearn: 0.0346399\ttest: 0.0384680\tbest: 0.0384680 (4163)\ttotal: 21m 26s\tremaining: 30m 2s\n",
      "4164:\tlearn: 0.0346399\ttest: 0.0384680\tbest: 0.0384680 (4164)\ttotal: 21m 26s\tremaining: 30m 2s\n",
      "4165:\tlearn: 0.0346365\ttest: 0.0384670\tbest: 0.0384670 (4165)\ttotal: 21m 26s\tremaining: 30m 2s\n",
      "4166:\tlearn: 0.0346365\ttest: 0.0384670\tbest: 0.0384670 (4166)\ttotal: 21m 27s\tremaining: 30m 1s\n",
      "4167:\tlearn: 0.0346365\ttest: 0.0384670\tbest: 0.0384670 (4167)\ttotal: 21m 27s\tremaining: 30m 1s\n",
      "4168:\tlearn: 0.0346365\ttest: 0.0384670\tbest: 0.0384670 (4167)\ttotal: 21m 27s\tremaining: 30m 1s\n",
      "4169:\tlearn: 0.0346365\ttest: 0.0384670\tbest: 0.0384670 (4169)\ttotal: 21m 27s\tremaining: 30m\n",
      "4170:\tlearn: 0.0346343\ttest: 0.0384670\tbest: 0.0384670 (4170)\ttotal: 21m 28s\tremaining: 30m\n",
      "4171:\tlearn: 0.0346342\ttest: 0.0384670\tbest: 0.0384670 (4170)\ttotal: 21m 28s\tremaining: 29m 59s\n",
      "4172:\tlearn: 0.0346342\ttest: 0.0384670\tbest: 0.0384670 (4170)\ttotal: 21m 28s\tremaining: 29m 59s\n",
      "4173:\tlearn: 0.0346342\ttest: 0.0384670\tbest: 0.0384670 (4170)\ttotal: 21m 28s\tremaining: 29m 59s\n",
      "4174:\tlearn: 0.0346308\ttest: 0.0384667\tbest: 0.0384667 (4174)\ttotal: 21m 29s\tremaining: 29m 58s\n",
      "4175:\tlearn: 0.0346308\ttest: 0.0384667\tbest: 0.0384667 (4175)\ttotal: 21m 29s\tremaining: 29m 58s\n",
      "4176:\tlearn: 0.0346308\ttest: 0.0384667\tbest: 0.0384667 (4176)\ttotal: 21m 29s\tremaining: 29m 58s\n",
      "4177:\tlearn: 0.0346308\ttest: 0.0384667\tbest: 0.0384667 (4176)\ttotal: 21m 30s\tremaining: 29m 57s\n",
      "4178:\tlearn: 0.0346308\ttest: 0.0384667\tbest: 0.0384667 (4178)\ttotal: 21m 30s\tremaining: 29m 57s\n",
      "4179:\tlearn: 0.0346308\ttest: 0.0384667\tbest: 0.0384667 (4178)\ttotal: 21m 30s\tremaining: 29m 56s\n",
      "4180:\tlearn: 0.0346308\ttest: 0.0384667\tbest: 0.0384667 (4180)\ttotal: 21m 30s\tremaining: 29m 56s\n",
      "4181:\tlearn: 0.0346308\ttest: 0.0384667\tbest: 0.0384667 (4181)\ttotal: 21m 31s\tremaining: 29m 56s\n",
      "4182:\tlearn: 0.0346307\ttest: 0.0384667\tbest: 0.0384667 (4182)\ttotal: 21m 31s\tremaining: 29m 55s\n",
      "4183:\tlearn: 0.0346307\ttest: 0.0384667\tbest: 0.0384667 (4183)\ttotal: 21m 31s\tremaining: 29m 55s\n",
      "4184:\tlearn: 0.0346278\ttest: 0.0384655\tbest: 0.0384655 (4184)\ttotal: 21m 31s\tremaining: 29m 55s\n",
      "4185:\tlearn: 0.0346278\ttest: 0.0384655\tbest: 0.0384655 (4185)\ttotal: 21m 32s\tremaining: 29m 54s\n",
      "4186:\tlearn: 0.0346278\ttest: 0.0384655\tbest: 0.0384655 (4185)\ttotal: 21m 32s\tremaining: 29m 54s\n",
      "4187:\tlearn: 0.0346278\ttest: 0.0384655\tbest: 0.0384655 (4185)\ttotal: 21m 33s\tremaining: 29m 54s\n",
      "4188:\tlearn: 0.0346236\ttest: 0.0384643\tbest: 0.0384643 (4188)\ttotal: 21m 33s\tremaining: 29m 54s\n",
      "4189:\tlearn: 0.0346236\ttest: 0.0384643\tbest: 0.0384643 (4189)\ttotal: 21m 34s\tremaining: 29m 54s\n",
      "4190:\tlearn: 0.0346192\ttest: 0.0384645\tbest: 0.0384643 (4189)\ttotal: 21m 34s\tremaining: 29m 54s\n",
      "4191:\tlearn: 0.0346192\ttest: 0.0384645\tbest: 0.0384643 (4189)\ttotal: 21m 35s\tremaining: 29m 54s\n",
      "4192:\tlearn: 0.0346192\ttest: 0.0384645\tbest: 0.0384643 (4189)\ttotal: 21m 35s\tremaining: 29m 54s\n",
      "4193:\tlearn: 0.0346192\ttest: 0.0384645\tbest: 0.0384643 (4189)\ttotal: 21m 35s\tremaining: 29m 53s\n",
      "4194:\tlearn: 0.0346192\ttest: 0.0384645\tbest: 0.0384643 (4189)\ttotal: 21m 36s\tremaining: 29m 53s\n",
      "4195:\tlearn: 0.0346192\ttest: 0.0384645\tbest: 0.0384643 (4189)\ttotal: 21m 36s\tremaining: 29m 53s\n",
      "4196:\tlearn: 0.0346192\ttest: 0.0384645\tbest: 0.0384643 (4189)\ttotal: 21m 36s\tremaining: 29m 52s\n",
      "4197:\tlearn: 0.0346192\ttest: 0.0384645\tbest: 0.0384643 (4189)\ttotal: 21m 36s\tremaining: 29m 52s\n",
      "4198:\tlearn: 0.0346192\ttest: 0.0384645\tbest: 0.0384643 (4189)\ttotal: 21m 37s\tremaining: 29m 51s\n",
      "4199:\tlearn: 0.0346192\ttest: 0.0384645\tbest: 0.0384643 (4189)\ttotal: 21m 37s\tremaining: 29m 51s\n",
      "4200:\tlearn: 0.0346192\ttest: 0.0384645\tbest: 0.0384643 (4189)\ttotal: 21m 37s\tremaining: 29m 51s\n",
      "4201:\tlearn: 0.0346192\ttest: 0.0384645\tbest: 0.0384643 (4189)\ttotal: 21m 37s\tremaining: 29m 50s\n",
      "4202:\tlearn: 0.0346192\ttest: 0.0384645\tbest: 0.0384643 (4189)\ttotal: 21m 38s\tremaining: 29m 50s\n",
      "4203:\tlearn: 0.0346192\ttest: 0.0384645\tbest: 0.0384643 (4189)\ttotal: 21m 38s\tremaining: 29m 50s\n",
      "4204:\tlearn: 0.0346192\ttest: 0.0384645\tbest: 0.0384643 (4189)\ttotal: 21m 38s\tremaining: 29m 49s\n",
      "4205:\tlearn: 0.0346192\ttest: 0.0384645\tbest: 0.0384643 (4189)\ttotal: 21m 38s\tremaining: 29m 49s\n",
      "4206:\tlearn: 0.0346192\ttest: 0.0384645\tbest: 0.0384643 (4189)\ttotal: 21m 39s\tremaining: 29m 49s\n",
      "4207:\tlearn: 0.0346192\ttest: 0.0384645\tbest: 0.0384643 (4189)\ttotal: 21m 39s\tremaining: 29m 48s\n",
      "4208:\tlearn: 0.0346192\ttest: 0.0384645\tbest: 0.0384643 (4189)\ttotal: 21m 39s\tremaining: 29m 48s\n",
      "4209:\tlearn: 0.0346192\ttest: 0.0384645\tbest: 0.0384643 (4189)\ttotal: 21m 39s\tremaining: 29m 47s\n",
      "4210:\tlearn: 0.0346154\ttest: 0.0384626\tbest: 0.0384626 (4210)\ttotal: 21m 40s\tremaining: 29m 47s\n",
      "4211:\tlearn: 0.0346120\ttest: 0.0384637\tbest: 0.0384626 (4210)\ttotal: 21m 40s\tremaining: 29m 47s\n",
      "4212:\tlearn: 0.0346120\ttest: 0.0384637\tbest: 0.0384626 (4210)\ttotal: 21m 40s\tremaining: 29m 46s\n",
      "4213:\tlearn: 0.0346078\ttest: 0.0384642\tbest: 0.0384626 (4210)\ttotal: 21m 41s\tremaining: 29m 46s\n",
      "4214:\tlearn: 0.0346078\ttest: 0.0384641\tbest: 0.0384626 (4210)\ttotal: 21m 41s\tremaining: 29m 46s\n",
      "4215:\tlearn: 0.0346078\ttest: 0.0384641\tbest: 0.0384626 (4210)\ttotal: 21m 41s\tremaining: 29m 45s\n",
      "4216:\tlearn: 0.0346077\ttest: 0.0384641\tbest: 0.0384626 (4210)\ttotal: 21m 41s\tremaining: 29m 45s\n",
      "4217:\tlearn: 0.0346077\ttest: 0.0384641\tbest: 0.0384626 (4210)\ttotal: 21m 42s\tremaining: 29m 45s\n",
      "4218:\tlearn: 0.0346077\ttest: 0.0384641\tbest: 0.0384626 (4210)\ttotal: 21m 42s\tremaining: 29m 44s\n",
      "4219:\tlearn: 0.0346044\ttest: 0.0384639\tbest: 0.0384626 (4210)\ttotal: 21m 42s\tremaining: 29m 44s\n",
      "4220:\tlearn: 0.0346040\ttest: 0.0384636\tbest: 0.0384626 (4210)\ttotal: 21m 43s\tremaining: 29m 44s\n",
      "4221:\tlearn: 0.0346040\ttest: 0.0384636\tbest: 0.0384626 (4210)\ttotal: 21m 43s\tremaining: 29m 43s\n",
      "4222:\tlearn: 0.0346040\ttest: 0.0384636\tbest: 0.0384626 (4210)\ttotal: 21m 43s\tremaining: 29m 43s\n",
      "4223:\tlearn: 0.0346040\ttest: 0.0384636\tbest: 0.0384626 (4210)\ttotal: 21m 43s\tremaining: 29m 42s\n",
      "4224:\tlearn: 0.0346040\ttest: 0.0384636\tbest: 0.0384626 (4210)\ttotal: 21m 44s\tremaining: 29m 42s\n",
      "4225:\tlearn: 0.0346040\ttest: 0.0384636\tbest: 0.0384626 (4210)\ttotal: 21m 44s\tremaining: 29m 42s\n",
      "4226:\tlearn: 0.0346040\ttest: 0.0384636\tbest: 0.0384626 (4210)\ttotal: 21m 44s\tremaining: 29m 41s\n",
      "4227:\tlearn: 0.0346040\ttest: 0.0384636\tbest: 0.0384626 (4210)\ttotal: 21m 44s\tremaining: 29m 41s\n",
      "4228:\tlearn: 0.0346040\ttest: 0.0384636\tbest: 0.0384626 (4210)\ttotal: 21m 45s\tremaining: 29m 40s\n",
      "4229:\tlearn: 0.0346040\ttest: 0.0384636\tbest: 0.0384626 (4210)\ttotal: 21m 45s\tremaining: 29m 40s\n",
      "4230:\tlearn: 0.0345987\ttest: 0.0384626\tbest: 0.0384626 (4210)\ttotal: 21m 45s\tremaining: 29m 40s\n",
      "4231:\tlearn: 0.0345987\ttest: 0.0384626\tbest: 0.0384626 (4210)\ttotal: 21m 46s\tremaining: 29m 40s\n",
      "4232:\tlearn: 0.0345987\ttest: 0.0384626\tbest: 0.0384626 (4210)\ttotal: 21m 46s\tremaining: 29m 39s\n",
      "4233:\tlearn: 0.0345946\ttest: 0.0384622\tbest: 0.0384622 (4233)\ttotal: 21m 47s\tremaining: 29m 39s\n",
      "4234:\tlearn: 0.0345946\ttest: 0.0384622\tbest: 0.0384622 (4234)\ttotal: 21m 47s\tremaining: 29m 39s\n",
      "4235:\tlearn: 0.0345946\ttest: 0.0384622\tbest: 0.0384622 (4234)\ttotal: 21m 47s\tremaining: 29m 39s\n",
      "4236:\tlearn: 0.0345946\ttest: 0.0384622\tbest: 0.0384622 (4236)\ttotal: 21m 48s\tremaining: 29m 39s\n",
      "4237:\tlearn: 0.0345918\ttest: 0.0384625\tbest: 0.0384622 (4236)\ttotal: 21m 48s\tremaining: 29m 39s\n",
      "4238:\tlearn: 0.0345917\ttest: 0.0384625\tbest: 0.0384622 (4236)\ttotal: 21m 49s\tremaining: 29m 39s\n",
      "4239:\tlearn: 0.0345917\ttest: 0.0384624\tbest: 0.0384622 (4236)\ttotal: 21m 49s\tremaining: 29m 39s\n",
      "4240:\tlearn: 0.0345917\ttest: 0.0384625\tbest: 0.0384622 (4236)\ttotal: 21m 50s\tremaining: 29m 38s\n",
      "4241:\tlearn: 0.0345875\ttest: 0.0384618\tbest: 0.0384618 (4241)\ttotal: 21m 50s\tremaining: 29m 38s\n",
      "4242:\tlearn: 0.0345875\ttest: 0.0384618\tbest: 0.0384618 (4242)\ttotal: 21m 50s\tremaining: 29m 38s\n",
      "4243:\tlearn: 0.0345875\ttest: 0.0384618\tbest: 0.0384618 (4243)\ttotal: 21m 50s\tremaining: 29m 37s\n",
      "4244:\tlearn: 0.0345875\ttest: 0.0384618\tbest: 0.0384618 (4243)\ttotal: 21m 51s\tremaining: 29m 37s\n",
      "4245:\tlearn: 0.0345875\ttest: 0.0384618\tbest: 0.0384618 (4243)\ttotal: 21m 51s\tremaining: 29m 37s\n",
      "4246:\tlearn: 0.0345875\ttest: 0.0384618\tbest: 0.0384618 (4246)\ttotal: 21m 51s\tremaining: 29m 36s\n",
      "4247:\tlearn: 0.0345875\ttest: 0.0384618\tbest: 0.0384618 (4247)\ttotal: 21m 51s\tremaining: 29m 36s\n",
      "4248:\tlearn: 0.0345875\ttest: 0.0384618\tbest: 0.0384618 (4248)\ttotal: 21m 52s\tremaining: 29m 35s\n",
      "4249:\tlearn: 0.0345875\ttest: 0.0384618\tbest: 0.0384618 (4248)\ttotal: 21m 52s\tremaining: 29m 35s\n",
      "4250:\tlearn: 0.0345875\ttest: 0.0384618\tbest: 0.0384618 (4250)\ttotal: 21m 52s\tremaining: 29m 35s\n",
      "4251:\tlearn: 0.0345875\ttest: 0.0384618\tbest: 0.0384618 (4251)\ttotal: 21m 52s\tremaining: 29m 34s\n",
      "4252:\tlearn: 0.0345875\ttest: 0.0384618\tbest: 0.0384618 (4251)\ttotal: 21m 53s\tremaining: 29m 34s\n",
      "4253:\tlearn: 0.0345875\ttest: 0.0384618\tbest: 0.0384618 (4251)\ttotal: 21m 53s\tremaining: 29m 33s\n",
      "4254:\tlearn: 0.0345875\ttest: 0.0384618\tbest: 0.0384618 (4251)\ttotal: 21m 53s\tremaining: 29m 33s\n",
      "4255:\tlearn: 0.0345875\ttest: 0.0384618\tbest: 0.0384618 (4251)\ttotal: 21m 53s\tremaining: 29m 33s\n",
      "4256:\tlearn: 0.0345825\ttest: 0.0384607\tbest: 0.0384607 (4256)\ttotal: 21m 54s\tremaining: 29m 32s\n",
      "4257:\tlearn: 0.0345825\ttest: 0.0384607\tbest: 0.0384607 (4257)\ttotal: 21m 54s\tremaining: 29m 32s\n",
      "4258:\tlearn: 0.0345782\ttest: 0.0384587\tbest: 0.0384587 (4258)\ttotal: 21m 54s\tremaining: 29m 32s\n",
      "4259:\tlearn: 0.0345782\ttest: 0.0384587\tbest: 0.0384587 (4259)\ttotal: 21m 55s\tremaining: 29m 31s\n",
      "4260:\tlearn: 0.0345723\ttest: 0.0384574\tbest: 0.0384574 (4260)\ttotal: 21m 55s\tremaining: 29m 31s\n",
      "4261:\tlearn: 0.0345723\ttest: 0.0384574\tbest: 0.0384574 (4261)\ttotal: 21m 55s\tremaining: 29m 31s\n",
      "4262:\tlearn: 0.0345723\ttest: 0.0384574\tbest: 0.0384574 (4262)\ttotal: 21m 55s\tremaining: 29m 30s\n",
      "4263:\tlearn: 0.0345722\ttest: 0.0384574\tbest: 0.0384574 (4263)\ttotal: 21m 56s\tremaining: 29m 30s\n",
      "4264:\tlearn: 0.0345722\ttest: 0.0384574\tbest: 0.0384574 (4264)\ttotal: 21m 56s\tremaining: 29m 29s\n",
      "4265:\tlearn: 0.0345680\ttest: 0.0384564\tbest: 0.0384564 (4265)\ttotal: 21m 56s\tremaining: 29m 29s\n",
      "4266:\tlearn: 0.0345680\ttest: 0.0384564\tbest: 0.0384564 (4266)\ttotal: 21m 56s\tremaining: 29m 29s\n",
      "4267:\tlearn: 0.0345680\ttest: 0.0384564\tbest: 0.0384564 (4266)\ttotal: 21m 57s\tremaining: 29m 28s\n",
      "4268:\tlearn: 0.0345680\ttest: 0.0384564\tbest: 0.0384564 (4266)\ttotal: 21m 57s\tremaining: 29m 28s\n",
      "4269:\tlearn: 0.0345680\ttest: 0.0384564\tbest: 0.0384564 (4266)\ttotal: 21m 57s\tremaining: 29m 28s\n",
      "4270:\tlearn: 0.0345680\ttest: 0.0384564\tbest: 0.0384564 (4266)\ttotal: 21m 57s\tremaining: 29m 27s\n",
      "4271:\tlearn: 0.0345680\ttest: 0.0384564\tbest: 0.0384564 (4271)\ttotal: 21m 58s\tremaining: 29m 27s\n",
      "4272:\tlearn: 0.0345664\ttest: 0.0384557\tbest: 0.0384557 (4272)\ttotal: 21m 58s\tremaining: 29m 27s\n",
      "4273:\tlearn: 0.0345664\ttest: 0.0384557\tbest: 0.0384557 (4272)\ttotal: 21m 58s\tremaining: 29m 26s\n",
      "4274:\tlearn: 0.0345663\ttest: 0.0384557\tbest: 0.0384557 (4274)\ttotal: 21m 58s\tremaining: 29m 26s\n",
      "4275:\tlearn: 0.0345663\ttest: 0.0384557\tbest: 0.0384557 (4274)\ttotal: 21m 59s\tremaining: 29m 25s\n",
      "4276:\tlearn: 0.0345663\ttest: 0.0384557\tbest: 0.0384557 (4276)\ttotal: 21m 59s\tremaining: 29m 25s\n",
      "4277:\tlearn: 0.0345663\ttest: 0.0384557\tbest: 0.0384557 (4276)\ttotal: 21m 59s\tremaining: 29m 25s\n",
      "4278:\tlearn: 0.0345663\ttest: 0.0384557\tbest: 0.0384557 (4278)\ttotal: 22m\tremaining: 29m 25s\n",
      "4279:\tlearn: 0.0345663\ttest: 0.0384557\tbest: 0.0384557 (4279)\ttotal: 22m\tremaining: 29m 25s\n",
      "4280:\tlearn: 0.0345663\ttest: 0.0384557\tbest: 0.0384557 (4280)\ttotal: 22m 1s\tremaining: 29m 25s\n",
      "4281:\tlearn: 0.0345663\ttest: 0.0384557\tbest: 0.0384557 (4281)\ttotal: 22m 1s\tremaining: 29m 24s\n",
      "4282:\tlearn: 0.0345663\ttest: 0.0384557\tbest: 0.0384557 (4282)\ttotal: 22m 2s\tremaining: 29m 24s\n",
      "4283:\tlearn: 0.0345663\ttest: 0.0384557\tbest: 0.0384557 (4283)\ttotal: 22m 2s\tremaining: 29m 24s\n",
      "4284:\tlearn: 0.0345643\ttest: 0.0384560\tbest: 0.0384557 (4283)\ttotal: 22m 3s\tremaining: 29m 24s\n",
      "4285:\tlearn: 0.0345643\ttest: 0.0384560\tbest: 0.0384557 (4283)\ttotal: 22m 3s\tremaining: 29m 24s\n",
      "4286:\tlearn: 0.0345643\ttest: 0.0384560\tbest: 0.0384557 (4283)\ttotal: 22m 3s\tremaining: 29m 24s\n",
      "4287:\tlearn: 0.0345643\ttest: 0.0384560\tbest: 0.0384557 (4283)\ttotal: 22m 4s\tremaining: 29m 23s\n",
      "4288:\tlearn: 0.0345643\ttest: 0.0384560\tbest: 0.0384557 (4283)\ttotal: 22m 4s\tremaining: 29m 23s\n",
      "4289:\tlearn: 0.0345643\ttest: 0.0384560\tbest: 0.0384557 (4283)\ttotal: 22m 4s\tremaining: 29m 23s\n",
      "4290:\tlearn: 0.0345643\ttest: 0.0384560\tbest: 0.0384557 (4283)\ttotal: 22m 4s\tremaining: 29m 22s\n",
      "4291:\tlearn: 0.0345643\ttest: 0.0384560\tbest: 0.0384557 (4283)\ttotal: 22m 5s\tremaining: 29m 22s\n",
      "4292:\tlearn: 0.0345643\ttest: 0.0384560\tbest: 0.0384557 (4283)\ttotal: 22m 5s\tremaining: 29m 21s\n",
      "4293:\tlearn: 0.0345642\ttest: 0.0384560\tbest: 0.0384557 (4283)\ttotal: 22m 5s\tremaining: 29m 21s\n",
      "4294:\tlearn: 0.0345642\ttest: 0.0384560\tbest: 0.0384557 (4283)\ttotal: 22m 5s\tremaining: 29m 21s\n",
      "4295:\tlearn: 0.0345642\ttest: 0.0384560\tbest: 0.0384557 (4283)\ttotal: 22m 6s\tremaining: 29m 20s\n",
      "4296:\tlearn: 0.0345642\ttest: 0.0384560\tbest: 0.0384557 (4283)\ttotal: 22m 6s\tremaining: 29m 20s\n",
      "4297:\tlearn: 0.0345642\ttest: 0.0384560\tbest: 0.0384557 (4283)\ttotal: 22m 6s\tremaining: 29m 19s\n",
      "4298:\tlearn: 0.0345642\ttest: 0.0384560\tbest: 0.0384557 (4283)\ttotal: 22m 6s\tremaining: 29m 19s\n",
      "4299:\tlearn: 0.0345642\ttest: 0.0384560\tbest: 0.0384557 (4283)\ttotal: 22m 7s\tremaining: 29m 19s\n",
      "4300:\tlearn: 0.0345596\ttest: 0.0384543\tbest: 0.0384543 (4300)\ttotal: 22m 7s\tremaining: 29m 18s\n",
      "4301:\tlearn: 0.0345596\ttest: 0.0384543\tbest: 0.0384543 (4301)\ttotal: 22m 7s\tremaining: 29m 18s\n",
      "4302:\tlearn: 0.0345596\ttest: 0.0384543\tbest: 0.0384543 (4301)\ttotal: 22m 7s\tremaining: 29m 18s\n",
      "4303:\tlearn: 0.0345596\ttest: 0.0384543\tbest: 0.0384543 (4303)\ttotal: 22m 8s\tremaining: 29m 17s\n",
      "4304:\tlearn: 0.0345596\ttest: 0.0384543\tbest: 0.0384543 (4304)\ttotal: 22m 8s\tremaining: 29m 17s\n",
      "4305:\tlearn: 0.0345596\ttest: 0.0384543\tbest: 0.0384543 (4304)\ttotal: 22m 8s\tremaining: 29m 16s\n",
      "4306:\tlearn: 0.0345596\ttest: 0.0384543\tbest: 0.0384543 (4306)\ttotal: 22m 8s\tremaining: 29m 16s\n",
      "4307:\tlearn: 0.0345596\ttest: 0.0384543\tbest: 0.0384543 (4307)\ttotal: 22m 9s\tremaining: 29m 16s\n",
      "4308:\tlearn: 0.0345596\ttest: 0.0384543\tbest: 0.0384543 (4308)\ttotal: 22m 9s\tremaining: 29m 15s\n",
      "4309:\tlearn: 0.0345596\ttest: 0.0384543\tbest: 0.0384543 (4309)\ttotal: 22m 9s\tremaining: 29m 15s\n",
      "4310:\tlearn: 0.0345549\ttest: 0.0384537\tbest: 0.0384537 (4310)\ttotal: 22m 10s\tremaining: 29m 15s\n",
      "4311:\tlearn: 0.0345549\ttest: 0.0384537\tbest: 0.0384537 (4311)\ttotal: 22m 10s\tremaining: 29m 14s\n",
      "4312:\tlearn: 0.0345549\ttest: 0.0384537\tbest: 0.0384537 (4312)\ttotal: 22m 10s\tremaining: 29m 14s\n",
      "4313:\tlearn: 0.0345521\ttest: 0.0384534\tbest: 0.0384534 (4313)\ttotal: 22m 10s\tremaining: 29m 14s\n",
      "4314:\tlearn: 0.0345502\ttest: 0.0384536\tbest: 0.0384534 (4313)\ttotal: 22m 11s\tremaining: 29m 13s\n",
      "4315:\tlearn: 0.0345502\ttest: 0.0384536\tbest: 0.0384534 (4313)\ttotal: 22m 11s\tremaining: 29m 13s\n",
      "4316:\tlearn: 0.0345453\ttest: 0.0384536\tbest: 0.0384534 (4313)\ttotal: 22m 11s\tremaining: 29m 13s\n",
      "4317:\tlearn: 0.0345453\ttest: 0.0384536\tbest: 0.0384534 (4313)\ttotal: 22m 11s\tremaining: 29m 12s\n",
      "4318:\tlearn: 0.0345453\ttest: 0.0384536\tbest: 0.0384534 (4313)\ttotal: 22m 12s\tremaining: 29m 12s\n",
      "4319:\tlearn: 0.0345404\ttest: 0.0384519\tbest: 0.0384519 (4319)\ttotal: 22m 12s\tremaining: 29m 12s\n",
      "4320:\tlearn: 0.0345403\ttest: 0.0384519\tbest: 0.0384519 (4320)\ttotal: 22m 12s\tremaining: 29m 11s\n",
      "4321:\tlearn: 0.0345343\ttest: 0.0384511\tbest: 0.0384511 (4321)\ttotal: 22m 13s\tremaining: 29m 11s\n",
      "4322:\tlearn: 0.0345343\ttest: 0.0384511\tbest: 0.0384511 (4322)\ttotal: 22m 13s\tremaining: 29m 11s\n",
      "4323:\tlearn: 0.0345343\ttest: 0.0384511\tbest: 0.0384511 (4323)\ttotal: 22m 13s\tremaining: 29m 10s\n",
      "4324:\tlearn: 0.0345343\ttest: 0.0384511\tbest: 0.0384511 (4324)\ttotal: 22m 14s\tremaining: 29m 10s\n",
      "4325:\tlearn: 0.0345296\ttest: 0.0384500\tbest: 0.0384500 (4325)\ttotal: 22m 14s\tremaining: 29m 10s\n",
      "4326:\tlearn: 0.0345296\ttest: 0.0384500\tbest: 0.0384500 (4326)\ttotal: 22m 15s\tremaining: 29m 10s\n",
      "4327:\tlearn: 0.0345296\ttest: 0.0384500\tbest: 0.0384500 (4326)\ttotal: 22m 15s\tremaining: 29m 10s\n",
      "4328:\tlearn: 0.0345248\ttest: 0.0384503\tbest: 0.0384500 (4326)\ttotal: 22m 16s\tremaining: 29m 10s\n",
      "4329:\tlearn: 0.0345248\ttest: 0.0384503\tbest: 0.0384500 (4326)\ttotal: 22m 16s\tremaining: 29m 10s\n",
      "4330:\tlearn: 0.0345248\ttest: 0.0384503\tbest: 0.0384500 (4326)\ttotal: 22m 17s\tremaining: 29m 10s\n",
      "4331:\tlearn: 0.0345219\ttest: 0.0384504\tbest: 0.0384500 (4326)\ttotal: 22m 17s\tremaining: 29m 10s\n",
      "4332:\tlearn: 0.0345219\ttest: 0.0384504\tbest: 0.0384500 (4326)\ttotal: 22m 17s\tremaining: 29m 9s\n",
      "4333:\tlearn: 0.0345219\ttest: 0.0384504\tbest: 0.0384500 (4326)\ttotal: 22m 18s\tremaining: 29m 9s\n",
      "4334:\tlearn: 0.0345219\ttest: 0.0384504\tbest: 0.0384500 (4326)\ttotal: 22m 18s\tremaining: 29m 9s\n",
      "4335:\tlearn: 0.0345219\ttest: 0.0384504\tbest: 0.0384500 (4326)\ttotal: 22m 18s\tremaining: 29m 8s\n",
      "4336:\tlearn: 0.0345219\ttest: 0.0384504\tbest: 0.0384500 (4326)\ttotal: 22m 18s\tremaining: 29m 8s\n",
      "4337:\tlearn: 0.0345219\ttest: 0.0384504\tbest: 0.0384500 (4326)\ttotal: 22m 19s\tremaining: 29m 7s\n",
      "4338:\tlearn: 0.0345219\ttest: 0.0384504\tbest: 0.0384500 (4326)\ttotal: 22m 19s\tremaining: 29m 7s\n",
      "4339:\tlearn: 0.0345219\ttest: 0.0384504\tbest: 0.0384500 (4326)\ttotal: 22m 19s\tremaining: 29m 7s\n",
      "4340:\tlearn: 0.0345219\ttest: 0.0384504\tbest: 0.0384500 (4326)\ttotal: 22m 19s\tremaining: 29m 6s\n",
      "4341:\tlearn: 0.0345208\ttest: 0.0384502\tbest: 0.0384500 (4326)\ttotal: 22m 20s\tremaining: 29m 6s\n",
      "4342:\tlearn: 0.0345208\ttest: 0.0384502\tbest: 0.0384500 (4326)\ttotal: 22m 20s\tremaining: 29m 6s\n",
      "4343:\tlearn: 0.0345208\ttest: 0.0384502\tbest: 0.0384500 (4326)\ttotal: 22m 20s\tremaining: 29m 5s\n",
      "4344:\tlearn: 0.0345207\ttest: 0.0384502\tbest: 0.0384500 (4326)\ttotal: 22m 21s\tremaining: 29m 5s\n",
      "4345:\tlearn: 0.0345208\ttest: 0.0384502\tbest: 0.0384500 (4326)\ttotal: 22m 21s\tremaining: 29m 4s\n",
      "4346:\tlearn: 0.0345208\ttest: 0.0384502\tbest: 0.0384500 (4326)\ttotal: 22m 21s\tremaining: 29m 4s\n",
      "4347:\tlearn: 0.0345145\ttest: 0.0384462\tbest: 0.0384462 (4347)\ttotal: 22m 21s\tremaining: 29m 4s\n",
      "4348:\tlearn: 0.0345145\ttest: 0.0384462\tbest: 0.0384462 (4348)\ttotal: 22m 22s\tremaining: 29m 3s\n",
      "4349:\tlearn: 0.0345145\ttest: 0.0384462\tbest: 0.0384462 (4349)\ttotal: 22m 22s\tremaining: 29m 3s\n",
      "4350:\tlearn: 0.0345145\ttest: 0.0384462\tbest: 0.0384462 (4349)\ttotal: 22m 22s\tremaining: 29m 3s\n",
      "4351:\tlearn: 0.0345144\ttest: 0.0384462\tbest: 0.0384462 (4349)\ttotal: 22m 22s\tremaining: 29m 2s\n",
      "4352:\tlearn: 0.0345144\ttest: 0.0384462\tbest: 0.0384462 (4352)\ttotal: 22m 23s\tremaining: 29m 2s\n",
      "4353:\tlearn: 0.0345144\ttest: 0.0384462\tbest: 0.0384462 (4353)\ttotal: 22m 23s\tremaining: 29m 1s\n",
      "4354:\tlearn: 0.0345144\ttest: 0.0384462\tbest: 0.0384462 (4353)\ttotal: 22m 23s\tremaining: 29m 1s\n",
      "4355:\tlearn: 0.0345144\ttest: 0.0384462\tbest: 0.0384462 (4353)\ttotal: 22m 23s\tremaining: 29m 1s\n",
      "4356:\tlearn: 0.0345144\ttest: 0.0384462\tbest: 0.0384462 (4353)\ttotal: 22m 24s\tremaining: 29m\n",
      "4357:\tlearn: 0.0345144\ttest: 0.0384462\tbest: 0.0384462 (4353)\ttotal: 22m 24s\tremaining: 29m\n",
      "4358:\tlearn: 0.0345144\ttest: 0.0384462\tbest: 0.0384462 (4353)\ttotal: 22m 24s\tremaining: 29m\n",
      "4359:\tlearn: 0.0345144\ttest: 0.0384462\tbest: 0.0384462 (4353)\ttotal: 22m 24s\tremaining: 28m 59s\n",
      "4360:\tlearn: 0.0345144\ttest: 0.0384462\tbest: 0.0384462 (4353)\ttotal: 22m 25s\tremaining: 28m 59s\n",
      "4361:\tlearn: 0.0345144\ttest: 0.0384462\tbest: 0.0384462 (4361)\ttotal: 22m 25s\tremaining: 28m 59s\n",
      "4362:\tlearn: 0.0345144\ttest: 0.0384462\tbest: 0.0384462 (4362)\ttotal: 22m 25s\tremaining: 28m 58s\n",
      "4363:\tlearn: 0.0345144\ttest: 0.0384462\tbest: 0.0384462 (4363)\ttotal: 22m 26s\tremaining: 28m 58s\n",
      "4364:\tlearn: 0.0345108\ttest: 0.0384460\tbest: 0.0384460 (4364)\ttotal: 22m 26s\tremaining: 28m 58s\n",
      "4365:\tlearn: 0.0345108\ttest: 0.0384460\tbest: 0.0384460 (4365)\ttotal: 22m 26s\tremaining: 28m 57s\n",
      "4366:\tlearn: 0.0345108\ttest: 0.0384460\tbest: 0.0384460 (4365)\ttotal: 22m 26s\tremaining: 28m 57s\n",
      "4367:\tlearn: 0.0345108\ttest: 0.0384460\tbest: 0.0384460 (4367)\ttotal: 22m 27s\tremaining: 28m 56s\n",
      "4368:\tlearn: 0.0345108\ttest: 0.0384460\tbest: 0.0384460 (4367)\ttotal: 22m 27s\tremaining: 28m 56s\n",
      "4369:\tlearn: 0.0345108\ttest: 0.0384460\tbest: 0.0384460 (4367)\ttotal: 22m 27s\tremaining: 28m 56s\n",
      "4370:\tlearn: 0.0345077\ttest: 0.0384454\tbest: 0.0384454 (4370)\ttotal: 22m 27s\tremaining: 28m 55s\n",
      "4371:\tlearn: 0.0345077\ttest: 0.0384454\tbest: 0.0384454 (4371)\ttotal: 22m 28s\tremaining: 28m 55s\n",
      "4372:\tlearn: 0.0345077\ttest: 0.0384454\tbest: 0.0384454 (4372)\ttotal: 22m 28s\tremaining: 28m 55s\n",
      "4373:\tlearn: 0.0345077\ttest: 0.0384454\tbest: 0.0384454 (4373)\ttotal: 22m 29s\tremaining: 28m 55s\n",
      "4374:\tlearn: 0.0345077\ttest: 0.0384454\tbest: 0.0384454 (4373)\ttotal: 22m 29s\tremaining: 28m 55s\n",
      "4375:\tlearn: 0.0345077\ttest: 0.0384454\tbest: 0.0384454 (4373)\ttotal: 22m 30s\tremaining: 28m 55s\n",
      "4376:\tlearn: 0.0345077\ttest: 0.0384454\tbest: 0.0384454 (4376)\ttotal: 22m 30s\tremaining: 28m 55s\n",
      "4377:\tlearn: 0.0345077\ttest: 0.0384454\tbest: 0.0384454 (4377)\ttotal: 22m 31s\tremaining: 28m 55s\n",
      "4378:\tlearn: 0.0345077\ttest: 0.0384454\tbest: 0.0384454 (4378)\ttotal: 22m 31s\tremaining: 28m 54s\n",
      "4379:\tlearn: 0.0345077\ttest: 0.0384454\tbest: 0.0384454 (4379)\ttotal: 22m 31s\tremaining: 28m 54s\n",
      "4380:\tlearn: 0.0345077\ttest: 0.0384454\tbest: 0.0384454 (4379)\ttotal: 22m 32s\tremaining: 28m 54s\n",
      "4381:\tlearn: 0.0345037\ttest: 0.0384446\tbest: 0.0384446 (4381)\ttotal: 22m 32s\tremaining: 28m 53s\n",
      "4382:\tlearn: 0.0345037\ttest: 0.0384446\tbest: 0.0384446 (4382)\ttotal: 22m 32s\tremaining: 28m 53s\n",
      "4383:\tlearn: 0.0345037\ttest: 0.0384446\tbest: 0.0384446 (4382)\ttotal: 22m 32s\tremaining: 28m 53s\n",
      "4384:\tlearn: 0.0345037\ttest: 0.0384446\tbest: 0.0384446 (4382)\ttotal: 22m 33s\tremaining: 28m 52s\n",
      "4385:\tlearn: 0.0345037\ttest: 0.0384446\tbest: 0.0384446 (4385)\ttotal: 22m 33s\tremaining: 28m 52s\n",
      "4386:\tlearn: 0.0345037\ttest: 0.0384446\tbest: 0.0384446 (4386)\ttotal: 22m 33s\tremaining: 28m 51s\n",
      "4387:\tlearn: 0.0345037\ttest: 0.0384446\tbest: 0.0384446 (4387)\ttotal: 22m 33s\tremaining: 28m 51s\n",
      "4388:\tlearn: 0.0345001\ttest: 0.0384449\tbest: 0.0384446 (4387)\ttotal: 22m 34s\tremaining: 28m 51s\n",
      "4389:\tlearn: 0.0344965\ttest: 0.0384455\tbest: 0.0384446 (4387)\ttotal: 22m 34s\tremaining: 28m 51s\n",
      "4390:\tlearn: 0.0344965\ttest: 0.0384455\tbest: 0.0384446 (4387)\ttotal: 22m 34s\tremaining: 28m 50s\n",
      "4391:\tlearn: 0.0344965\ttest: 0.0384455\tbest: 0.0384446 (4387)\ttotal: 22m 35s\tremaining: 28m 50s\n",
      "4392:\tlearn: 0.0344965\ttest: 0.0384455\tbest: 0.0384446 (4387)\ttotal: 22m 35s\tremaining: 28m 49s\n",
      "4393:\tlearn: 0.0344965\ttest: 0.0384455\tbest: 0.0384446 (4387)\ttotal: 22m 35s\tremaining: 28m 49s\n",
      "4394:\tlearn: 0.0344914\ttest: 0.0384431\tbest: 0.0384431 (4394)\ttotal: 22m 35s\tremaining: 28m 49s\n",
      "4395:\tlearn: 0.0344914\ttest: 0.0384431\tbest: 0.0384431 (4395)\ttotal: 22m 36s\tremaining: 28m 48s\n",
      "4396:\tlearn: 0.0344914\ttest: 0.0384431\tbest: 0.0384431 (4395)\ttotal: 22m 36s\tremaining: 28m 48s\n",
      "4397:\tlearn: 0.0344914\ttest: 0.0384431\tbest: 0.0384431 (4395)\ttotal: 22m 36s\tremaining: 28m 48s\n",
      "4398:\tlearn: 0.0344914\ttest: 0.0384431\tbest: 0.0384431 (4395)\ttotal: 22m 36s\tremaining: 28m 47s\n",
      "4399:\tlearn: 0.0344914\ttest: 0.0384431\tbest: 0.0384431 (4395)\ttotal: 22m 37s\tremaining: 28m 47s\n",
      "4400:\tlearn: 0.0344914\ttest: 0.0384431\tbest: 0.0384431 (4395)\ttotal: 22m 37s\tremaining: 28m 46s\n",
      "4401:\tlearn: 0.0344914\ttest: 0.0384431\tbest: 0.0384431 (4395)\ttotal: 22m 37s\tremaining: 28m 46s\n",
      "4402:\tlearn: 0.0344914\ttest: 0.0384431\tbest: 0.0384431 (4395)\ttotal: 22m 37s\tremaining: 28m 46s\n",
      "4403:\tlearn: 0.0344914\ttest: 0.0384431\tbest: 0.0384431 (4395)\ttotal: 22m 38s\tremaining: 28m 45s\n",
      "4404:\tlearn: 0.0344914\ttest: 0.0384431\tbest: 0.0384431 (4404)\ttotal: 22m 38s\tremaining: 28m 45s\n",
      "4405:\tlearn: 0.0344866\ttest: 0.0384432\tbest: 0.0384431 (4404)\ttotal: 22m 38s\tremaining: 28m 45s\n",
      "4406:\tlearn: 0.0344865\ttest: 0.0384432\tbest: 0.0384431 (4404)\ttotal: 22m 39s\tremaining: 28m 44s\n",
      "4407:\tlearn: 0.0344852\ttest: 0.0384432\tbest: 0.0384431 (4404)\ttotal: 22m 39s\tremaining: 28m 44s\n",
      "4408:\tlearn: 0.0344852\ttest: 0.0384432\tbest: 0.0384431 (4404)\ttotal: 22m 39s\tremaining: 28m 44s\n",
      "4409:\tlearn: 0.0344852\ttest: 0.0384432\tbest: 0.0384431 (4404)\ttotal: 22m 39s\tremaining: 28m 43s\n",
      "4410:\tlearn: 0.0344852\ttest: 0.0384432\tbest: 0.0384431 (4404)\ttotal: 22m 40s\tremaining: 28m 43s\n",
      "4411:\tlearn: 0.0344852\ttest: 0.0384432\tbest: 0.0384431 (4404)\ttotal: 22m 40s\tremaining: 28m 42s\n",
      "4412:\tlearn: 0.0344851\ttest: 0.0384432\tbest: 0.0384431 (4404)\ttotal: 22m 40s\tremaining: 28m 42s\n",
      "4413:\tlearn: 0.0344851\ttest: 0.0384431\tbest: 0.0384431 (4404)\ttotal: 22m 40s\tremaining: 28m 42s\n",
      "4414:\tlearn: 0.0344829\ttest: 0.0384430\tbest: 0.0384430 (4414)\ttotal: 22m 41s\tremaining: 28m 41s\n",
      "4415:\tlearn: 0.0344829\ttest: 0.0384430\tbest: 0.0384430 (4414)\ttotal: 22m 41s\tremaining: 28m 41s\n",
      "4416:\tlearn: 0.0344829\ttest: 0.0384430\tbest: 0.0384430 (4416)\ttotal: 22m 41s\tremaining: 28m 41s\n",
      "4417:\tlearn: 0.0344829\ttest: 0.0384430\tbest: 0.0384430 (4416)\ttotal: 22m 42s\tremaining: 28m 41s\n",
      "4418:\tlearn: 0.0344829\ttest: 0.0384430\tbest: 0.0384430 (4418)\ttotal: 22m 42s\tremaining: 28m 41s\n",
      "4419:\tlearn: 0.0344829\ttest: 0.0384430\tbest: 0.0384430 (4418)\ttotal: 22m 43s\tremaining: 28m 40s\n",
      "4420:\tlearn: 0.0344829\ttest: 0.0384430\tbest: 0.0384430 (4420)\ttotal: 22m 43s\tremaining: 28m 40s\n",
      "4421:\tlearn: 0.0344829\ttest: 0.0384430\tbest: 0.0384430 (4421)\ttotal: 22m 44s\tremaining: 28m 40s\n",
      "4422:\tlearn: 0.0344805\ttest: 0.0384430\tbest: 0.0384430 (4422)\ttotal: 22m 44s\tremaining: 28m 40s\n",
      "4423:\tlearn: 0.0344805\ttest: 0.0384430\tbest: 0.0384430 (4422)\ttotal: 22m 45s\tremaining: 28m 40s\n",
      "4424:\tlearn: 0.0344805\ttest: 0.0384430\tbest: 0.0384430 (4424)\ttotal: 22m 45s\tremaining: 28m 40s\n",
      "4425:\tlearn: 0.0344805\ttest: 0.0384430\tbest: 0.0384430 (4424)\ttotal: 22m 45s\tremaining: 28m 40s\n",
      "4426:\tlearn: 0.0344805\ttest: 0.0384430\tbest: 0.0384430 (4424)\ttotal: 22m 46s\tremaining: 28m 39s\n",
      "4427:\tlearn: 0.0344758\ttest: 0.0384420\tbest: 0.0384420 (4427)\ttotal: 22m 46s\tremaining: 28m 39s\n",
      "4428:\tlearn: 0.0344758\ttest: 0.0384420\tbest: 0.0384420 (4428)\ttotal: 22m 46s\tremaining: 28m 39s\n",
      "4429:\tlearn: 0.0344758\ttest: 0.0384420\tbest: 0.0384420 (4428)\ttotal: 22m 47s\tremaining: 28m 38s\n",
      "4430:\tlearn: 0.0344758\ttest: 0.0384420\tbest: 0.0384420 (4430)\ttotal: 22m 47s\tremaining: 28m 38s\n",
      "4431:\tlearn: 0.0344758\ttest: 0.0384420\tbest: 0.0384420 (4431)\ttotal: 22m 47s\tremaining: 28m 38s\n",
      "4432:\tlearn: 0.0344758\ttest: 0.0384420\tbest: 0.0384420 (4432)\ttotal: 22m 47s\tremaining: 28m 37s\n",
      "4433:\tlearn: 0.0344758\ttest: 0.0384420\tbest: 0.0384420 (4433)\ttotal: 22m 48s\tremaining: 28m 37s\n",
      "4434:\tlearn: 0.0344738\ttest: 0.0384417\tbest: 0.0384417 (4434)\ttotal: 22m 48s\tremaining: 28m 36s\n",
      "4435:\tlearn: 0.0344738\ttest: 0.0384417\tbest: 0.0384417 (4434)\ttotal: 22m 48s\tremaining: 28m 36s\n",
      "4436:\tlearn: 0.0344738\ttest: 0.0384417\tbest: 0.0384417 (4436)\ttotal: 22m 48s\tremaining: 28m 36s\n",
      "4437:\tlearn: 0.0344738\ttest: 0.0384417\tbest: 0.0384417 (4437)\ttotal: 22m 49s\tremaining: 28m 35s\n",
      "4438:\tlearn: 0.0344737\ttest: 0.0384417\tbest: 0.0384417 (4438)\ttotal: 22m 49s\tremaining: 28m 35s\n",
      "4439:\tlearn: 0.0344737\ttest: 0.0384417\tbest: 0.0384417 (4439)\ttotal: 22m 49s\tremaining: 28m 35s\n",
      "4440:\tlearn: 0.0344737\ttest: 0.0384417\tbest: 0.0384417 (4439)\ttotal: 22m 49s\tremaining: 28m 34s\n",
      "4441:\tlearn: 0.0344685\ttest: 0.0384419\tbest: 0.0384417 (4439)\ttotal: 22m 50s\tremaining: 28m 34s\n",
      "4442:\tlearn: 0.0344685\ttest: 0.0384419\tbest: 0.0384417 (4439)\ttotal: 22m 50s\tremaining: 28m 34s\n",
      "4443:\tlearn: 0.0344631\ttest: 0.0384401\tbest: 0.0384401 (4443)\ttotal: 22m 50s\tremaining: 28m 33s\n",
      "4444:\tlearn: 0.0344631\ttest: 0.0384401\tbest: 0.0384401 (4444)\ttotal: 22m 51s\tremaining: 28m 33s\n",
      "4445:\tlearn: 0.0344631\ttest: 0.0384401\tbest: 0.0384401 (4444)\ttotal: 22m 51s\tremaining: 28m 33s\n",
      "4446:\tlearn: 0.0344630\ttest: 0.0384401\tbest: 0.0384401 (4446)\ttotal: 22m 51s\tremaining: 28m 32s\n",
      "4447:\tlearn: 0.0344630\ttest: 0.0384401\tbest: 0.0384401 (4447)\ttotal: 22m 51s\tremaining: 28m 32s\n",
      "4448:\tlearn: 0.0344630\ttest: 0.0384401\tbest: 0.0384401 (4448)\ttotal: 22m 52s\tremaining: 28m 31s\n",
      "4449:\tlearn: 0.0344592\ttest: 0.0384383\tbest: 0.0384383 (4449)\ttotal: 22m 52s\tremaining: 28m 31s\n",
      "4450:\tlearn: 0.0344592\ttest: 0.0384383\tbest: 0.0384383 (4450)\ttotal: 22m 52s\tremaining: 28m 31s\n",
      "4451:\tlearn: 0.0344592\ttest: 0.0384383\tbest: 0.0384383 (4450)\ttotal: 22m 52s\tremaining: 28m 30s\n",
      "4452:\tlearn: 0.0344592\ttest: 0.0384383\tbest: 0.0384383 (4452)\ttotal: 22m 53s\tremaining: 28m 30s\n",
      "4453:\tlearn: 0.0344592\ttest: 0.0384383\tbest: 0.0384383 (4452)\ttotal: 22m 53s\tremaining: 28m 30s\n",
      "4454:\tlearn: 0.0344591\ttest: 0.0384383\tbest: 0.0384383 (4454)\ttotal: 22m 53s\tremaining: 28m 29s\n",
      "4455:\tlearn: 0.0344592\ttest: 0.0384383\tbest: 0.0384383 (4455)\ttotal: 22m 53s\tremaining: 28m 29s\n",
      "4456:\tlearn: 0.0344592\ttest: 0.0384383\tbest: 0.0384383 (4456)\ttotal: 22m 54s\tremaining: 28m 29s\n",
      "4457:\tlearn: 0.0344591\ttest: 0.0384383\tbest: 0.0384383 (4457)\ttotal: 22m 54s\tremaining: 28m 28s\n",
      "4458:\tlearn: 0.0344591\ttest: 0.0384383\tbest: 0.0384383 (4458)\ttotal: 22m 54s\tremaining: 28m 28s\n",
      "4459:\tlearn: 0.0344591\ttest: 0.0384383\tbest: 0.0384383 (4459)\ttotal: 22m 54s\tremaining: 28m 27s\n",
      "4460:\tlearn: 0.0344591\ttest: 0.0384383\tbest: 0.0384383 (4460)\ttotal: 22m 55s\tremaining: 28m 27s\n",
      "4461:\tlearn: 0.0344591\ttest: 0.0384383\tbest: 0.0384383 (4461)\ttotal: 22m 55s\tremaining: 28m 27s\n",
      "4462:\tlearn: 0.0344591\ttest: 0.0384383\tbest: 0.0384383 (4461)\ttotal: 22m 55s\tremaining: 28m 26s\n",
      "4463:\tlearn: 0.0344591\ttest: 0.0384383\tbest: 0.0384383 (4461)\ttotal: 22m 56s\tremaining: 28m 26s\n",
      "4464:\tlearn: 0.0344591\ttest: 0.0384383\tbest: 0.0384383 (4464)\ttotal: 22m 56s\tremaining: 28m 26s\n",
      "4465:\tlearn: 0.0344591\ttest: 0.0384383\tbest: 0.0384383 (4464)\ttotal: 22m 56s\tremaining: 28m 26s\n",
      "4466:\tlearn: 0.0344591\ttest: 0.0384383\tbest: 0.0384383 (4464)\ttotal: 22m 57s\tremaining: 28m 26s\n",
      "4467:\tlearn: 0.0344591\ttest: 0.0384383\tbest: 0.0384383 (4464)\ttotal: 22m 57s\tremaining: 28m 25s\n",
      "4468:\tlearn: 0.0344591\ttest: 0.0384383\tbest: 0.0384383 (4464)\ttotal: 22m 58s\tremaining: 28m 25s\n",
      "4469:\tlearn: 0.0344518\ttest: 0.0384368\tbest: 0.0384368 (4469)\ttotal: 22m 58s\tremaining: 28m 25s\n",
      "4470:\tlearn: 0.0344518\ttest: 0.0384368\tbest: 0.0384368 (4469)\ttotal: 22m 59s\tremaining: 28m 25s\n",
      "4471:\tlearn: 0.0344518\ttest: 0.0384368\tbest: 0.0384368 (4471)\ttotal: 22m 59s\tremaining: 28m 25s\n",
      "4472:\tlearn: 0.0344518\ttest: 0.0384368\tbest: 0.0384368 (4471)\ttotal: 23m\tremaining: 28m 25s\n",
      "4473:\tlearn: 0.0344518\ttest: 0.0384368\tbest: 0.0384368 (4471)\ttotal: 23m\tremaining: 28m 24s\n",
      "4474:\tlearn: 0.0344518\ttest: 0.0384368\tbest: 0.0384368 (4474)\ttotal: 23m\tremaining: 28m 24s\n",
      "4475:\tlearn: 0.0344485\ttest: 0.0384366\tbest: 0.0384366 (4475)\ttotal: 23m\tremaining: 28m 24s\n",
      "4476:\tlearn: 0.0344485\ttest: 0.0384366\tbest: 0.0384366 (4476)\ttotal: 23m 1s\tremaining: 28m 23s\n",
      "4477:\tlearn: 0.0344485\ttest: 0.0384366\tbest: 0.0384366 (4477)\ttotal: 23m 1s\tremaining: 28m 23s\n",
      "4478:\tlearn: 0.0344485\ttest: 0.0384366\tbest: 0.0384366 (4478)\ttotal: 23m 1s\tremaining: 28m 23s\n",
      "4479:\tlearn: 0.0344485\ttest: 0.0384366\tbest: 0.0384366 (4479)\ttotal: 23m 2s\tremaining: 28m 22s\n",
      "4480:\tlearn: 0.0344469\ttest: 0.0384365\tbest: 0.0384365 (4480)\ttotal: 23m 2s\tremaining: 28m 22s\n",
      "4481:\tlearn: 0.0344469\ttest: 0.0384365\tbest: 0.0384365 (4481)\ttotal: 23m 2s\tremaining: 28m 22s\n",
      "4482:\tlearn: 0.0344469\ttest: 0.0384365\tbest: 0.0384365 (4482)\ttotal: 23m 2s\tremaining: 28m 21s\n",
      "4483:\tlearn: 0.0344460\ttest: 0.0384366\tbest: 0.0384365 (4482)\ttotal: 23m 3s\tremaining: 28m 21s\n",
      "4484:\tlearn: 0.0344460\ttest: 0.0384366\tbest: 0.0384365 (4482)\ttotal: 23m 3s\tremaining: 28m 21s\n",
      "4485:\tlearn: 0.0344460\ttest: 0.0384366\tbest: 0.0384365 (4482)\ttotal: 23m 3s\tremaining: 28m 20s\n",
      "4486:\tlearn: 0.0344460\ttest: 0.0384366\tbest: 0.0384365 (4482)\ttotal: 23m 3s\tremaining: 28m 20s\n",
      "4487:\tlearn: 0.0344427\ttest: 0.0384352\tbest: 0.0384352 (4487)\ttotal: 23m 4s\tremaining: 28m 20s\n",
      "4488:\tlearn: 0.0344427\ttest: 0.0384352\tbest: 0.0384352 (4487)\ttotal: 23m 4s\tremaining: 28m 19s\n",
      "4489:\tlearn: 0.0344427\ttest: 0.0384352\tbest: 0.0384352 (4487)\ttotal: 23m 4s\tremaining: 28m 19s\n",
      "4490:\tlearn: 0.0344389\ttest: 0.0384341\tbest: 0.0384341 (4490)\ttotal: 23m 4s\tremaining: 28m 18s\n",
      "4491:\tlearn: 0.0344387\ttest: 0.0384341\tbest: 0.0384341 (4490)\ttotal: 23m 5s\tremaining: 28m 18s\n",
      "4492:\tlearn: 0.0344387\ttest: 0.0384341\tbest: 0.0384341 (4490)\ttotal: 23m 5s\tremaining: 28m 18s\n",
      "4493:\tlearn: 0.0344341\ttest: 0.0384322\tbest: 0.0384322 (4493)\ttotal: 23m 5s\tremaining: 28m 17s\n",
      "4494:\tlearn: 0.0344341\ttest: 0.0384322\tbest: 0.0384322 (4493)\ttotal: 23m 6s\tremaining: 28m 17s\n",
      "4495:\tlearn: 0.0344341\ttest: 0.0384322\tbest: 0.0384322 (4495)\ttotal: 23m 6s\tremaining: 28m 17s\n",
      "4496:\tlearn: 0.0344277\ttest: 0.0384287\tbest: 0.0384287 (4496)\ttotal: 23m 6s\tremaining: 28m 16s\n",
      "4497:\tlearn: 0.0344277\ttest: 0.0384287\tbest: 0.0384287 (4497)\ttotal: 23m 6s\tremaining: 28m 16s\n",
      "4498:\tlearn: 0.0344277\ttest: 0.0384287\tbest: 0.0384287 (4498)\ttotal: 23m 7s\tremaining: 28m 16s\n",
      "4499:\tlearn: 0.0344277\ttest: 0.0384286\tbest: 0.0384286 (4499)\ttotal: 23m 7s\tremaining: 28m 15s\n",
      "4500:\tlearn: 0.0344277\ttest: 0.0384286\tbest: 0.0384286 (4499)\ttotal: 23m 7s\tremaining: 28m 15s\n",
      "4501:\tlearn: 0.0344277\ttest: 0.0384286\tbest: 0.0384286 (4499)\ttotal: 23m 7s\tremaining: 28m 14s\n",
      "4502:\tlearn: 0.0344277\ttest: 0.0384286\tbest: 0.0384286 (4502)\ttotal: 23m 8s\tremaining: 28m 14s\n",
      "4503:\tlearn: 0.0344277\ttest: 0.0384286\tbest: 0.0384286 (4503)\ttotal: 23m 8s\tremaining: 28m 14s\n",
      "4504:\tlearn: 0.0344234\ttest: 0.0384284\tbest: 0.0384284 (4504)\ttotal: 23m 8s\tremaining: 28m 13s\n",
      "4505:\tlearn: 0.0344234\ttest: 0.0384284\tbest: 0.0384284 (4504)\ttotal: 23m 9s\tremaining: 28m 13s\n",
      "4506:\tlearn: 0.0344234\ttest: 0.0384284\tbest: 0.0384284 (4504)\ttotal: 23m 9s\tremaining: 28m 13s\n",
      "4507:\tlearn: 0.0344234\ttest: 0.0384284\tbest: 0.0384284 (4504)\ttotal: 23m 9s\tremaining: 28m 12s\n",
      "4508:\tlearn: 0.0344192\ttest: 0.0384284\tbest: 0.0384284 (4504)\ttotal: 23m 9s\tremaining: 28m 12s\n",
      "4509:\tlearn: 0.0344192\ttest: 0.0384284\tbest: 0.0384284 (4504)\ttotal: 23m 10s\tremaining: 28m 12s\n",
      "4510:\tlearn: 0.0344192\ttest: 0.0384284\tbest: 0.0384284 (4504)\ttotal: 23m 10s\tremaining: 28m 11s\n",
      "4511:\tlearn: 0.0344192\ttest: 0.0384284\tbest: 0.0384284 (4504)\ttotal: 23m 10s\tremaining: 28m 11s\n",
      "4512:\tlearn: 0.0344148\ttest: 0.0384277\tbest: 0.0384277 (4512)\ttotal: 23m 11s\tremaining: 28m 11s\n",
      "4513:\tlearn: 0.0344148\ttest: 0.0384277\tbest: 0.0384277 (4512)\ttotal: 23m 11s\tremaining: 28m 11s\n",
      "4514:\tlearn: 0.0344148\ttest: 0.0384277\tbest: 0.0384277 (4514)\ttotal: 23m 12s\tremaining: 28m 11s\n",
      "4515:\tlearn: 0.0344096\ttest: 0.0384269\tbest: 0.0384269 (4515)\ttotal: 23m 12s\tremaining: 28m 11s\n",
      "4516:\tlearn: 0.0344049\ttest: 0.0384259\tbest: 0.0384259 (4516)\ttotal: 23m 13s\tremaining: 28m 11s\n",
      "4517:\tlearn: 0.0344049\ttest: 0.0384259\tbest: 0.0384259 (4517)\ttotal: 23m 14s\tremaining: 28m 11s\n",
      "4518:\tlearn: 0.0344049\ttest: 0.0384259\tbest: 0.0384259 (4518)\ttotal: 23m 14s\tremaining: 28m 11s\n",
      "4519:\tlearn: 0.0344049\ttest: 0.0384259\tbest: 0.0384259 (4519)\ttotal: 23m 14s\tremaining: 28m 11s\n",
      "4520:\tlearn: 0.0344049\ttest: 0.0384259\tbest: 0.0384259 (4520)\ttotal: 23m 15s\tremaining: 28m 11s\n",
      "4521:\tlearn: 0.0344049\ttest: 0.0384259\tbest: 0.0384259 (4521)\ttotal: 23m 15s\tremaining: 28m 10s\n",
      "4522:\tlearn: 0.0344048\ttest: 0.0384258\tbest: 0.0384258 (4522)\ttotal: 23m 16s\tremaining: 28m 10s\n",
      "4523:\tlearn: 0.0344048\ttest: 0.0384258\tbest: 0.0384258 (4523)\ttotal: 23m 16s\tremaining: 28m 10s\n",
      "4524:\tlearn: 0.0344048\ttest: 0.0384258\tbest: 0.0384258 (4524)\ttotal: 23m 17s\tremaining: 28m 10s\n",
      "4525:\tlearn: 0.0344048\ttest: 0.0384258\tbest: 0.0384258 (4525)\ttotal: 23m 17s\tremaining: 28m 10s\n",
      "4526:\tlearn: 0.0344048\ttest: 0.0384258\tbest: 0.0384258 (4525)\ttotal: 23m 18s\tremaining: 28m 10s\n",
      "4527:\tlearn: 0.0344048\ttest: 0.0384258\tbest: 0.0384258 (4527)\ttotal: 23m 18s\tremaining: 28m 9s\n",
      "4528:\tlearn: 0.0344048\ttest: 0.0384258\tbest: 0.0384258 (4528)\ttotal: 23m 18s\tremaining: 28m 9s\n",
      "4529:\tlearn: 0.0344048\ttest: 0.0384258\tbest: 0.0384258 (4529)\ttotal: 23m 18s\tremaining: 28m 9s\n",
      "4530:\tlearn: 0.0344048\ttest: 0.0384258\tbest: 0.0384258 (4529)\ttotal: 23m 19s\tremaining: 28m 8s\n",
      "4531:\tlearn: 0.0344048\ttest: 0.0384258\tbest: 0.0384258 (4531)\ttotal: 23m 19s\tremaining: 28m 8s\n",
      "4532:\tlearn: 0.0344048\ttest: 0.0384258\tbest: 0.0384258 (4532)\ttotal: 23m 19s\tremaining: 28m 7s\n",
      "4533:\tlearn: 0.0343997\ttest: 0.0384246\tbest: 0.0384246 (4533)\ttotal: 23m 19s\tremaining: 28m 7s\n",
      "4534:\tlearn: 0.0343969\ttest: 0.0384240\tbest: 0.0384240 (4534)\ttotal: 23m 20s\tremaining: 28m 7s\n",
      "4535:\tlearn: 0.0343932\ttest: 0.0384233\tbest: 0.0384233 (4535)\ttotal: 23m 20s\tremaining: 28m 7s\n",
      "4536:\tlearn: 0.0343932\ttest: 0.0384233\tbest: 0.0384233 (4536)\ttotal: 23m 20s\tremaining: 28m 6s\n",
      "4537:\tlearn: 0.0343932\ttest: 0.0384233\tbest: 0.0384233 (4537)\ttotal: 23m 21s\tremaining: 28m 6s\n",
      "4538:\tlearn: 0.0343932\ttest: 0.0384233\tbest: 0.0384233 (4538)\ttotal: 23m 21s\tremaining: 28m 5s\n",
      "4539:\tlearn: 0.0343932\ttest: 0.0384233\tbest: 0.0384233 (4539)\ttotal: 23m 21s\tremaining: 28m 5s\n",
      "4540:\tlearn: 0.0343872\ttest: 0.0384214\tbest: 0.0384214 (4540)\ttotal: 23m 21s\tremaining: 28m 5s\n",
      "4541:\tlearn: 0.0343872\ttest: 0.0384213\tbest: 0.0384213 (4541)\ttotal: 23m 22s\tremaining: 28m 4s\n",
      "4542:\tlearn: 0.0343872\ttest: 0.0384213\tbest: 0.0384213 (4542)\ttotal: 23m 22s\tremaining: 28m 4s\n",
      "4543:\tlearn: 0.0343872\ttest: 0.0384213\tbest: 0.0384213 (4542)\ttotal: 23m 22s\tremaining: 28m 4s\n",
      "4544:\tlearn: 0.0343872\ttest: 0.0384213\tbest: 0.0384213 (4544)\ttotal: 23m 22s\tremaining: 28m 3s\n",
      "4545:\tlearn: 0.0343872\ttest: 0.0384213\tbest: 0.0384213 (4545)\ttotal: 23m 23s\tremaining: 28m 3s\n",
      "4546:\tlearn: 0.0343872\ttest: 0.0384213\tbest: 0.0384213 (4545)\ttotal: 23m 23s\tremaining: 28m 2s\n",
      "4547:\tlearn: 0.0343872\ttest: 0.0384213\tbest: 0.0384213 (4547)\ttotal: 23m 23s\tremaining: 28m 2s\n",
      "4548:\tlearn: 0.0343857\ttest: 0.0384212\tbest: 0.0384212 (4548)\ttotal: 23m 23s\tremaining: 28m 2s\n",
      "4549:\tlearn: 0.0343856\ttest: 0.0384212\tbest: 0.0384212 (4549)\ttotal: 23m 24s\tremaining: 28m 1s\n",
      "4550:\tlearn: 0.0343856\ttest: 0.0384212\tbest: 0.0384212 (4549)\ttotal: 23m 24s\tremaining: 28m 1s\n",
      "4551:\tlearn: 0.0343856\ttest: 0.0384212\tbest: 0.0384212 (4549)\ttotal: 23m 25s\tremaining: 28m 1s\n",
      "4552:\tlearn: 0.0343856\ttest: 0.0384212\tbest: 0.0384212 (4549)\ttotal: 23m 25s\tremaining: 28m 1s\n",
      "4553:\tlearn: 0.0343856\ttest: 0.0384212\tbest: 0.0384212 (4553)\ttotal: 23m 25s\tremaining: 28m 1s\n",
      "4554:\tlearn: 0.0343853\ttest: 0.0384212\tbest: 0.0384212 (4553)\ttotal: 23m 26s\tremaining: 28m 1s\n",
      "4555:\tlearn: 0.0343853\ttest: 0.0384212\tbest: 0.0384212 (4553)\ttotal: 23m 26s\tremaining: 28m 1s\n",
      "4556:\tlearn: 0.0343843\ttest: 0.0384213\tbest: 0.0384212 (4553)\ttotal: 23m 27s\tremaining: 28m\n",
      "4557:\tlearn: 0.0343820\ttest: 0.0384205\tbest: 0.0384205 (4557)\ttotal: 23m 27s\tremaining: 28m\n",
      "4558:\tlearn: 0.0343820\ttest: 0.0384205\tbest: 0.0384205 (4558)\ttotal: 23m 28s\tremaining: 28m\n",
      "4559:\tlearn: 0.0343820\ttest: 0.0384205\tbest: 0.0384205 (4558)\ttotal: 23m 28s\tremaining: 28m\n",
      "4560:\tlearn: 0.0343820\ttest: 0.0384205\tbest: 0.0384205 (4558)\ttotal: 23m 28s\tremaining: 28m\n",
      "4561:\tlearn: 0.0343820\ttest: 0.0384205\tbest: 0.0384205 (4561)\ttotal: 23m 29s\tremaining: 27m 59s\n",
      "4562:\tlearn: 0.0343820\ttest: 0.0384205\tbest: 0.0384205 (4561)\ttotal: 23m 29s\tremaining: 27m 59s\n",
      "4563:\tlearn: 0.0343820\ttest: 0.0384205\tbest: 0.0384205 (4561)\ttotal: 23m 29s\tremaining: 27m 58s\n",
      "4564:\tlearn: 0.0343820\ttest: 0.0384205\tbest: 0.0384205 (4564)\ttotal: 23m 29s\tremaining: 27m 58s\n",
      "4565:\tlearn: 0.0343820\ttest: 0.0384205\tbest: 0.0384205 (4564)\ttotal: 23m 30s\tremaining: 27m 58s\n",
      "4566:\tlearn: 0.0343820\ttest: 0.0384205\tbest: 0.0384205 (4566)\ttotal: 23m 30s\tremaining: 27m 57s\n",
      "4567:\tlearn: 0.0343820\ttest: 0.0384205\tbest: 0.0384205 (4567)\ttotal: 23m 30s\tremaining: 27m 57s\n",
      "4568:\tlearn: 0.0343820\ttest: 0.0384205\tbest: 0.0384205 (4568)\ttotal: 23m 30s\tremaining: 27m 57s\n",
      "4569:\tlearn: 0.0343820\ttest: 0.0384205\tbest: 0.0384205 (4568)\ttotal: 23m 31s\tremaining: 27m 56s\n",
      "4570:\tlearn: 0.0343820\ttest: 0.0384205\tbest: 0.0384205 (4568)\ttotal: 23m 31s\tremaining: 27m 56s\n",
      "4571:\tlearn: 0.0343820\ttest: 0.0384205\tbest: 0.0384205 (4571)\ttotal: 23m 31s\tremaining: 27m 55s\n",
      "4572:\tlearn: 0.0343820\ttest: 0.0384205\tbest: 0.0384205 (4572)\ttotal: 23m 31s\tremaining: 27m 55s\n",
      "4573:\tlearn: 0.0343820\ttest: 0.0384205\tbest: 0.0384205 (4572)\ttotal: 23m 32s\tremaining: 27m 55s\n",
      "4574:\tlearn: 0.0343820\ttest: 0.0384205\tbest: 0.0384205 (4574)\ttotal: 23m 32s\tremaining: 27m 54s\n",
      "4575:\tlearn: 0.0343820\ttest: 0.0384205\tbest: 0.0384205 (4575)\ttotal: 23m 32s\tremaining: 27m 54s\n",
      "4576:\tlearn: 0.0343819\ttest: 0.0384205\tbest: 0.0384205 (4576)\ttotal: 23m 32s\tremaining: 27m 54s\n",
      "4577:\tlearn: 0.0343785\ttest: 0.0384187\tbest: 0.0384187 (4577)\ttotal: 23m 33s\tremaining: 27m 53s\n",
      "4578:\tlearn: 0.0343785\ttest: 0.0384187\tbest: 0.0384187 (4578)\ttotal: 23m 33s\tremaining: 27m 53s\n",
      "4579:\tlearn: 0.0343785\ttest: 0.0384187\tbest: 0.0384187 (4579)\ttotal: 23m 33s\tremaining: 27m 53s\n",
      "4580:\tlearn: 0.0343785\ttest: 0.0384187\tbest: 0.0384187 (4579)\ttotal: 23m 34s\tremaining: 27m 52s\n",
      "4581:\tlearn: 0.0343785\ttest: 0.0384187\tbest: 0.0384187 (4581)\ttotal: 23m 34s\tremaining: 27m 52s\n",
      "4582:\tlearn: 0.0343785\ttest: 0.0384187\tbest: 0.0384187 (4582)\ttotal: 23m 34s\tremaining: 27m 51s\n",
      "4583:\tlearn: 0.0343785\ttest: 0.0384187\tbest: 0.0384187 (4583)\ttotal: 23m 34s\tremaining: 27m 51s\n",
      "4584:\tlearn: 0.0343785\ttest: 0.0384187\tbest: 0.0384187 (4584)\ttotal: 23m 35s\tremaining: 27m 51s\n",
      "4585:\tlearn: 0.0343777\ttest: 0.0384190\tbest: 0.0384187 (4584)\ttotal: 23m 35s\tremaining: 27m 50s\n",
      "4586:\tlearn: 0.0343777\ttest: 0.0384190\tbest: 0.0384187 (4584)\ttotal: 23m 35s\tremaining: 27m 50s\n",
      "4587:\tlearn: 0.0343777\ttest: 0.0384190\tbest: 0.0384187 (4584)\ttotal: 23m 35s\tremaining: 27m 50s\n",
      "4588:\tlearn: 0.0343777\ttest: 0.0384190\tbest: 0.0384187 (4584)\ttotal: 23m 36s\tremaining: 27m 49s\n",
      "4589:\tlearn: 0.0343777\ttest: 0.0384190\tbest: 0.0384187 (4584)\ttotal: 23m 36s\tremaining: 27m 49s\n",
      "4590:\tlearn: 0.0343777\ttest: 0.0384190\tbest: 0.0384187 (4584)\ttotal: 23m 36s\tremaining: 27m 49s\n",
      "4591:\tlearn: 0.0343777\ttest: 0.0384190\tbest: 0.0384187 (4584)\ttotal: 23m 36s\tremaining: 27m 48s\n",
      "4592:\tlearn: 0.0343777\ttest: 0.0384190\tbest: 0.0384187 (4584)\ttotal: 23m 37s\tremaining: 27m 48s\n",
      "4593:\tlearn: 0.0343732\ttest: 0.0384180\tbest: 0.0384180 (4593)\ttotal: 23m 37s\tremaining: 27m 48s\n",
      "4594:\tlearn: 0.0343732\ttest: 0.0384180\tbest: 0.0384180 (4593)\ttotal: 23m 37s\tremaining: 27m 47s\n",
      "4595:\tlearn: 0.0343732\ttest: 0.0384180\tbest: 0.0384180 (4593)\ttotal: 23m 37s\tremaining: 27m 47s\n",
      "4596:\tlearn: 0.0343732\ttest: 0.0384180\tbest: 0.0384180 (4593)\ttotal: 23m 38s\tremaining: 27m 46s\n",
      "4597:\tlearn: 0.0343732\ttest: 0.0384180\tbest: 0.0384180 (4593)\ttotal: 23m 38s\tremaining: 27m 46s\n",
      "4598:\tlearn: 0.0343732\ttest: 0.0384180\tbest: 0.0384180 (4593)\ttotal: 23m 38s\tremaining: 27m 46s\n",
      "4599:\tlearn: 0.0343732\ttest: 0.0384180\tbest: 0.0384180 (4599)\ttotal: 23m 39s\tremaining: 27m 46s\n",
      "4600:\tlearn: 0.0343688\ttest: 0.0384166\tbest: 0.0384166 (4600)\ttotal: 23m 39s\tremaining: 27m 46s\n",
      "4601:\tlearn: 0.0343688\ttest: 0.0384166\tbest: 0.0384166 (4601)\ttotal: 23m 40s\tremaining: 27m 46s\n",
      "4602:\tlearn: 0.0343688\ttest: 0.0384166\tbest: 0.0384166 (4601)\ttotal: 23m 40s\tremaining: 27m 45s\n",
      "4603:\tlearn: 0.0343688\ttest: 0.0384166\tbest: 0.0384166 (4603)\ttotal: 23m 41s\tremaining: 27m 45s\n",
      "4604:\tlearn: 0.0343688\ttest: 0.0384166\tbest: 0.0384166 (4604)\ttotal: 23m 41s\tremaining: 27m 45s\n",
      "4605:\tlearn: 0.0343688\ttest: 0.0384166\tbest: 0.0384166 (4605)\ttotal: 23m 42s\tremaining: 27m 45s\n",
      "4606:\tlearn: 0.0343685\ttest: 0.0384166\tbest: 0.0384166 (4606)\ttotal: 23m 42s\tremaining: 27m 45s\n",
      "4607:\tlearn: 0.0343685\ttest: 0.0384166\tbest: 0.0384166 (4607)\ttotal: 23m 42s\tremaining: 27m 45s\n",
      "4608:\tlearn: 0.0343685\ttest: 0.0384166\tbest: 0.0384166 (4607)\ttotal: 23m 43s\tremaining: 27m 44s\n",
      "4609:\tlearn: 0.0343685\ttest: 0.0384166\tbest: 0.0384166 (4609)\ttotal: 23m 43s\tremaining: 27m 44s\n",
      "4610:\tlearn: 0.0343684\ttest: 0.0384166\tbest: 0.0384166 (4610)\ttotal: 23m 43s\tremaining: 27m 43s\n",
      "4611:\tlearn: 0.0343685\ttest: 0.0384166\tbest: 0.0384166 (4611)\ttotal: 23m 43s\tremaining: 27m 43s\n",
      "4612:\tlearn: 0.0343684\ttest: 0.0384165\tbest: 0.0384165 (4612)\ttotal: 23m 44s\tremaining: 27m 43s\n",
      "4613:\tlearn: 0.0343684\ttest: 0.0384165\tbest: 0.0384165 (4612)\ttotal: 23m 44s\tremaining: 27m 42s\n",
      "4614:\tlearn: 0.0343684\ttest: 0.0384165\tbest: 0.0384165 (4612)\ttotal: 23m 44s\tremaining: 27m 42s\n",
      "4615:\tlearn: 0.0343684\ttest: 0.0384165\tbest: 0.0384165 (4612)\ttotal: 23m 45s\tremaining: 27m 42s\n",
      "4616:\tlearn: 0.0343684\ttest: 0.0384165\tbest: 0.0384165 (4616)\ttotal: 23m 45s\tremaining: 27m 41s\n",
      "4617:\tlearn: 0.0343684\ttest: 0.0384165\tbest: 0.0384165 (4616)\ttotal: 23m 45s\tremaining: 27m 41s\n",
      "4618:\tlearn: 0.0343684\ttest: 0.0384165\tbest: 0.0384165 (4618)\ttotal: 23m 45s\tremaining: 27m 40s\n",
      "4619:\tlearn: 0.0343684\ttest: 0.0384165\tbest: 0.0384165 (4618)\ttotal: 23m 46s\tremaining: 27m 40s\n",
      "4620:\tlearn: 0.0343684\ttest: 0.0384165\tbest: 0.0384165 (4620)\ttotal: 23m 46s\tremaining: 27m 40s\n",
      "4621:\tlearn: 0.0343684\ttest: 0.0384165\tbest: 0.0384165 (4621)\ttotal: 23m 46s\tremaining: 27m 39s\n",
      "4622:\tlearn: 0.0343684\ttest: 0.0384165\tbest: 0.0384165 (4622)\ttotal: 23m 46s\tremaining: 27m 39s\n",
      "4623:\tlearn: 0.0343684\ttest: 0.0384165\tbest: 0.0384165 (4622)\ttotal: 23m 47s\tremaining: 27m 39s\n",
      "4624:\tlearn: 0.0343684\ttest: 0.0384165\tbest: 0.0384165 (4624)\ttotal: 23m 47s\tremaining: 27m 38s\n",
      "4625:\tlearn: 0.0343684\ttest: 0.0384165\tbest: 0.0384165 (4624)\ttotal: 23m 47s\tremaining: 27m 38s\n",
      "4626:\tlearn: 0.0343684\ttest: 0.0384165\tbest: 0.0384165 (4624)\ttotal: 23m 47s\tremaining: 27m 38s\n",
      "4627:\tlearn: 0.0343684\ttest: 0.0384165\tbest: 0.0384165 (4624)\ttotal: 23m 48s\tremaining: 27m 37s\n",
      "4628:\tlearn: 0.0343684\ttest: 0.0384165\tbest: 0.0384165 (4628)\ttotal: 23m 48s\tremaining: 27m 37s\n",
      "4629:\tlearn: 0.0343684\ttest: 0.0384165\tbest: 0.0384165 (4628)\ttotal: 23m 48s\tremaining: 27m 36s\n",
      "4630:\tlearn: 0.0343682\ttest: 0.0384165\tbest: 0.0384165 (4630)\ttotal: 23m 48s\tremaining: 27m 36s\n",
      "4631:\tlearn: 0.0343651\ttest: 0.0384168\tbest: 0.0384165 (4630)\ttotal: 23m 49s\tremaining: 27m 36s\n",
      "4632:\tlearn: 0.0343621\ttest: 0.0384170\tbest: 0.0384165 (4630)\ttotal: 23m 49s\tremaining: 27m 35s\n",
      "4633:\tlearn: 0.0343621\ttest: 0.0384170\tbest: 0.0384165 (4630)\ttotal: 23m 49s\tremaining: 27m 35s\n",
      "4634:\tlearn: 0.0343621\ttest: 0.0384170\tbest: 0.0384165 (4630)\ttotal: 23m 49s\tremaining: 27m 35s\n",
      "4635:\tlearn: 0.0343621\ttest: 0.0384170\tbest: 0.0384165 (4630)\ttotal: 23m 50s\tremaining: 27m 34s\n",
      "4636:\tlearn: 0.0343621\ttest: 0.0384170\tbest: 0.0384165 (4630)\ttotal: 23m 50s\tremaining: 27m 34s\n",
      "4637:\tlearn: 0.0343621\ttest: 0.0384170\tbest: 0.0384165 (4630)\ttotal: 23m 50s\tremaining: 27m 34s\n",
      "4638:\tlearn: 0.0343621\ttest: 0.0384170\tbest: 0.0384165 (4630)\ttotal: 23m 50s\tremaining: 27m 33s\n",
      "4639:\tlearn: 0.0343621\ttest: 0.0384170\tbest: 0.0384165 (4630)\ttotal: 23m 51s\tremaining: 27m 33s\n",
      "4640:\tlearn: 0.0343621\ttest: 0.0384170\tbest: 0.0384165 (4630)\ttotal: 23m 51s\tremaining: 27m 32s\n",
      "4641:\tlearn: 0.0343621\ttest: 0.0384170\tbest: 0.0384165 (4630)\ttotal: 23m 51s\tremaining: 27m 32s\n",
      "4642:\tlearn: 0.0343621\ttest: 0.0384170\tbest: 0.0384165 (4630)\ttotal: 23m 51s\tremaining: 27m 32s\n",
      "4643:\tlearn: 0.0343592\ttest: 0.0384159\tbest: 0.0384159 (4643)\ttotal: 23m 52s\tremaining: 27m 31s\n",
      "4644:\tlearn: 0.0343545\ttest: 0.0384151\tbest: 0.0384151 (4644)\ttotal: 23m 52s\tremaining: 27m 31s\n",
      "4645:\tlearn: 0.0343545\ttest: 0.0384151\tbest: 0.0384151 (4645)\ttotal: 23m 53s\tremaining: 27m 31s\n",
      "4646:\tlearn: 0.0343545\ttest: 0.0384151\tbest: 0.0384151 (4646)\ttotal: 23m 53s\tremaining: 27m 31s\n",
      "4647:\tlearn: 0.0343545\ttest: 0.0384151\tbest: 0.0384151 (4646)\ttotal: 23m 54s\tremaining: 27m 31s\n",
      "4648:\tlearn: 0.0343545\ttest: 0.0384151\tbest: 0.0384151 (4646)\ttotal: 23m 54s\tremaining: 27m 31s\n",
      "4649:\tlearn: 0.0343545\ttest: 0.0384151\tbest: 0.0384151 (4646)\ttotal: 23m 54s\tremaining: 27m 30s\n",
      "4650:\tlearn: 0.0343493\ttest: 0.0384129\tbest: 0.0384129 (4650)\ttotal: 23m 55s\tremaining: 27m 30s\n",
      "4651:\tlearn: 0.0343493\ttest: 0.0384129\tbest: 0.0384129 (4650)\ttotal: 23m 55s\tremaining: 27m 30s\n",
      "4652:\tlearn: 0.0343493\ttest: 0.0384129\tbest: 0.0384129 (4652)\ttotal: 23m 56s\tremaining: 27m 30s\n",
      "4653:\tlearn: 0.0343493\ttest: 0.0384129\tbest: 0.0384129 (4652)\ttotal: 23m 56s\tremaining: 27m 30s\n",
      "4654:\tlearn: 0.0343451\ttest: 0.0384130\tbest: 0.0384129 (4652)\ttotal: 23m 56s\tremaining: 27m 29s\n",
      "4655:\tlearn: 0.0343451\ttest: 0.0384130\tbest: 0.0384129 (4652)\ttotal: 23m 57s\tremaining: 27m 29s\n",
      "4656:\tlearn: 0.0343451\ttest: 0.0384130\tbest: 0.0384129 (4652)\ttotal: 23m 57s\tremaining: 27m 29s\n",
      "4657:\tlearn: 0.0343451\ttest: 0.0384130\tbest: 0.0384129 (4652)\ttotal: 23m 57s\tremaining: 27m 28s\n",
      "4658:\tlearn: 0.0343451\ttest: 0.0384130\tbest: 0.0384129 (4652)\ttotal: 23m 57s\tremaining: 27m 28s\n",
      "4659:\tlearn: 0.0343451\ttest: 0.0384130\tbest: 0.0384129 (4652)\ttotal: 23m 58s\tremaining: 27m 28s\n",
      "4660:\tlearn: 0.0343426\ttest: 0.0384134\tbest: 0.0384129 (4652)\ttotal: 23m 58s\tremaining: 27m 27s\n",
      "4661:\tlearn: 0.0343426\ttest: 0.0384134\tbest: 0.0384129 (4652)\ttotal: 23m 58s\tremaining: 27m 27s\n",
      "4662:\tlearn: 0.0343387\ttest: 0.0384115\tbest: 0.0384115 (4662)\ttotal: 23m 59s\tremaining: 27m 27s\n",
      "4663:\tlearn: 0.0343386\ttest: 0.0384115\tbest: 0.0384115 (4663)\ttotal: 23m 59s\tremaining: 27m 26s\n",
      "4664:\tlearn: 0.0343386\ttest: 0.0384115\tbest: 0.0384115 (4664)\ttotal: 23m 59s\tremaining: 27m 26s\n",
      "4665:\tlearn: 0.0343350\ttest: 0.0384104\tbest: 0.0384104 (4665)\ttotal: 24m\tremaining: 27m 26s\n",
      "4666:\tlearn: 0.0343350\ttest: 0.0384104\tbest: 0.0384104 (4666)\ttotal: 24m\tremaining: 27m 25s\n",
      "4667:\tlearn: 0.0343337\ttest: 0.0384103\tbest: 0.0384103 (4667)\ttotal: 24m\tremaining: 27m 25s\n",
      "4668:\tlearn: 0.0343337\ttest: 0.0384103\tbest: 0.0384103 (4668)\ttotal: 24m\tremaining: 27m 25s\n",
      "4669:\tlearn: 0.0343337\ttest: 0.0384103\tbest: 0.0384103 (4669)\ttotal: 24m 1s\tremaining: 27m 24s\n",
      "4670:\tlearn: 0.0343337\ttest: 0.0384103\tbest: 0.0384103 (4669)\ttotal: 24m 1s\tremaining: 27m 24s\n",
      "4671:\tlearn: 0.0343337\ttest: 0.0384103\tbest: 0.0384103 (4669)\ttotal: 24m 1s\tremaining: 27m 24s\n",
      "4672:\tlearn: 0.0343305\ttest: 0.0384094\tbest: 0.0384094 (4672)\ttotal: 24m 1s\tremaining: 27m 23s\n",
      "4673:\tlearn: 0.0343305\ttest: 0.0384094\tbest: 0.0384094 (4673)\ttotal: 24m 2s\tremaining: 27m 23s\n",
      "4674:\tlearn: 0.0343303\ttest: 0.0384093\tbest: 0.0384093 (4674)\ttotal: 24m 2s\tremaining: 27m 23s\n",
      "4675:\tlearn: 0.0343303\ttest: 0.0384093\tbest: 0.0384093 (4674)\ttotal: 24m 2s\tremaining: 27m 22s\n",
      "4676:\tlearn: 0.0343303\ttest: 0.0384093\tbest: 0.0384093 (4676)\ttotal: 24m 3s\tremaining: 27m 22s\n",
      "4677:\tlearn: 0.0343266\ttest: 0.0384084\tbest: 0.0384084 (4677)\ttotal: 24m 3s\tremaining: 27m 22s\n",
      "4678:\tlearn: 0.0343266\ttest: 0.0384084\tbest: 0.0384084 (4678)\ttotal: 24m 3s\tremaining: 27m 21s\n",
      "4679:\tlearn: 0.0343266\ttest: 0.0384084\tbest: 0.0384084 (4679)\ttotal: 24m 3s\tremaining: 27m 21s\n",
      "4680:\tlearn: 0.0343222\ttest: 0.0384064\tbest: 0.0384064 (4680)\ttotal: 24m 4s\tremaining: 27m 20s\n",
      "4681:\tlearn: 0.0343222\ttest: 0.0384064\tbest: 0.0384064 (4680)\ttotal: 24m 4s\tremaining: 27m 20s\n",
      "4682:\tlearn: 0.0343222\ttest: 0.0384064\tbest: 0.0384064 (4682)\ttotal: 24m 4s\tremaining: 27m 20s\n",
      "4683:\tlearn: 0.0343222\ttest: 0.0384064\tbest: 0.0384064 (4683)\ttotal: 24m 4s\tremaining: 27m 19s\n",
      "4684:\tlearn: 0.0343222\ttest: 0.0384064\tbest: 0.0384064 (4684)\ttotal: 24m 5s\tremaining: 27m 19s\n",
      "4685:\tlearn: 0.0343222\ttest: 0.0384064\tbest: 0.0384064 (4685)\ttotal: 24m 5s\tremaining: 27m 19s\n",
      "4686:\tlearn: 0.0343222\ttest: 0.0384064\tbest: 0.0384064 (4686)\ttotal: 24m 5s\tremaining: 27m 18s\n",
      "4687:\tlearn: 0.0343222\ttest: 0.0384064\tbest: 0.0384064 (4686)\ttotal: 24m 5s\tremaining: 27m 18s\n",
      "4688:\tlearn: 0.0343222\ttest: 0.0384064\tbest: 0.0384064 (4686)\ttotal: 24m 6s\tremaining: 27m 18s\n",
      "4689:\tlearn: 0.0343222\ttest: 0.0384064\tbest: 0.0384064 (4689)\ttotal: 24m 6s\tremaining: 27m 17s\n",
      "4690:\tlearn: 0.0343222\ttest: 0.0384064\tbest: 0.0384064 (4690)\ttotal: 24m 6s\tremaining: 27m 17s\n",
      "4691:\tlearn: 0.0343222\ttest: 0.0384064\tbest: 0.0384064 (4690)\ttotal: 24m 7s\tremaining: 27m 17s\n",
      "4692:\tlearn: 0.0343222\ttest: 0.0384064\tbest: 0.0384064 (4690)\ttotal: 24m 7s\tremaining: 27m 17s\n",
      "4693:\tlearn: 0.0343222\ttest: 0.0384064\tbest: 0.0384064 (4690)\ttotal: 24m 8s\tremaining: 27m 17s\n",
      "4694:\tlearn: 0.0343222\ttest: 0.0384064\tbest: 0.0384064 (4694)\ttotal: 24m 8s\tremaining: 27m 16s\n",
      "4695:\tlearn: 0.0343222\ttest: 0.0384063\tbest: 0.0384063 (4695)\ttotal: 24m 9s\tremaining: 27m 16s\n",
      "4696:\tlearn: 0.0343222\ttest: 0.0384063\tbest: 0.0384063 (4696)\ttotal: 24m 9s\tremaining: 27m 16s\n",
      "4697:\tlearn: 0.0343221\ttest: 0.0384063\tbest: 0.0384063 (4697)\ttotal: 24m 10s\tremaining: 27m 16s\n",
      "4698:\tlearn: 0.0343221\ttest: 0.0384063\tbest: 0.0384063 (4698)\ttotal: 24m 10s\tremaining: 27m 16s\n",
      "4699:\tlearn: 0.0343221\ttest: 0.0384063\tbest: 0.0384063 (4699)\ttotal: 24m 10s\tremaining: 27m 15s\n",
      "4700:\tlearn: 0.0343221\ttest: 0.0384063\tbest: 0.0384063 (4699)\ttotal: 24m 11s\tremaining: 27m 15s\n",
      "4701:\tlearn: 0.0343221\ttest: 0.0384063\tbest: 0.0384063 (4699)\ttotal: 24m 11s\tremaining: 27m 15s\n",
      "4702:\tlearn: 0.0343221\ttest: 0.0384063\tbest: 0.0384063 (4699)\ttotal: 24m 11s\tremaining: 27m 14s\n",
      "4703:\tlearn: 0.0343221\ttest: 0.0384063\tbest: 0.0384063 (4699)\ttotal: 24m 11s\tremaining: 27m 14s\n",
      "4704:\tlearn: 0.0343221\ttest: 0.0384063\tbest: 0.0384063 (4699)\ttotal: 24m 12s\tremaining: 27m 14s\n",
      "4705:\tlearn: 0.0343221\ttest: 0.0384063\tbest: 0.0384063 (4705)\ttotal: 24m 12s\tremaining: 27m 13s\n",
      "4706:\tlearn: 0.0343152\ttest: 0.0384039\tbest: 0.0384039 (4706)\ttotal: 24m 12s\tremaining: 27m 13s\n",
      "4707:\tlearn: 0.0343152\ttest: 0.0384038\tbest: 0.0384038 (4707)\ttotal: 24m 13s\tremaining: 27m 13s\n",
      "4708:\tlearn: 0.0343152\ttest: 0.0384038\tbest: 0.0384038 (4708)\ttotal: 24m 13s\tremaining: 27m 12s\n",
      "4709:\tlearn: 0.0343152\ttest: 0.0384038\tbest: 0.0384038 (4709)\ttotal: 24m 13s\tremaining: 27m 12s\n",
      "4710:\tlearn: 0.0343152\ttest: 0.0384038\tbest: 0.0384038 (4709)\ttotal: 24m 13s\tremaining: 27m 12s\n",
      "4711:\tlearn: 0.0343110\ttest: 0.0384022\tbest: 0.0384022 (4711)\ttotal: 24m 14s\tremaining: 27m 11s\n",
      "4712:\tlearn: 0.0343110\ttest: 0.0384022\tbest: 0.0384022 (4712)\ttotal: 24m 14s\tremaining: 27m 11s\n",
      "4713:\tlearn: 0.0343110\ttest: 0.0384022\tbest: 0.0384022 (4712)\ttotal: 24m 14s\tremaining: 27m 11s\n",
      "4714:\tlearn: 0.0343110\ttest: 0.0384022\tbest: 0.0384022 (4712)\ttotal: 24m 14s\tremaining: 27m 10s\n",
      "4715:\tlearn: 0.0343110\ttest: 0.0384022\tbest: 0.0384022 (4712)\ttotal: 24m 15s\tremaining: 27m 10s\n",
      "4716:\tlearn: 0.0343110\ttest: 0.0384022\tbest: 0.0384022 (4716)\ttotal: 24m 15s\tremaining: 27m 10s\n",
      "4717:\tlearn: 0.0343110\ttest: 0.0384022\tbest: 0.0384022 (4716)\ttotal: 24m 15s\tremaining: 27m 9s\n",
      "4718:\tlearn: 0.0343110\ttest: 0.0384022\tbest: 0.0384022 (4716)\ttotal: 24m 15s\tremaining: 27m 9s\n",
      "4719:\tlearn: 0.0343109\ttest: 0.0384022\tbest: 0.0384022 (4719)\ttotal: 24m 16s\tremaining: 27m 8s\n",
      "4720:\tlearn: 0.0343109\ttest: 0.0384022\tbest: 0.0384022 (4720)\ttotal: 24m 16s\tremaining: 27m 8s\n",
      "4721:\tlearn: 0.0343109\ttest: 0.0384022\tbest: 0.0384022 (4720)\ttotal: 24m 16s\tremaining: 27m 8s\n",
      "4722:\tlearn: 0.0343109\ttest: 0.0384022\tbest: 0.0384022 (4720)\ttotal: 24m 16s\tremaining: 27m 7s\n",
      "4723:\tlearn: 0.0343109\ttest: 0.0384022\tbest: 0.0384022 (4720)\ttotal: 24m 17s\tremaining: 27m 7s\n",
      "4724:\tlearn: 0.0343109\ttest: 0.0384022\tbest: 0.0384022 (4720)\ttotal: 24m 17s\tremaining: 27m 7s\n",
      "4725:\tlearn: 0.0343044\ttest: 0.0384014\tbest: 0.0384014 (4725)\ttotal: 24m 17s\tremaining: 27m 6s\n",
      "4726:\tlearn: 0.0343044\ttest: 0.0384014\tbest: 0.0384014 (4725)\ttotal: 24m 18s\tremaining: 27m 6s\n",
      "4727:\tlearn: 0.0343044\ttest: 0.0384014\tbest: 0.0384014 (4725)\ttotal: 24m 18s\tremaining: 27m 6s\n",
      "4728:\tlearn: 0.0343044\ttest: 0.0384014\tbest: 0.0384014 (4725)\ttotal: 24m 18s\tremaining: 27m 5s\n",
      "4729:\tlearn: 0.0343044\ttest: 0.0384013\tbest: 0.0384013 (4729)\ttotal: 24m 18s\tremaining: 27m 5s\n",
      "4730:\tlearn: 0.0343043\ttest: 0.0384013\tbest: 0.0384013 (4729)\ttotal: 24m 19s\tremaining: 27m 4s\n",
      "4731:\tlearn: 0.0343043\ttest: 0.0384013\tbest: 0.0384013 (4729)\ttotal: 24m 19s\tremaining: 27m 4s\n",
      "4732:\tlearn: 0.0343043\ttest: 0.0384013\tbest: 0.0384013 (4729)\ttotal: 24m 19s\tremaining: 27m 4s\n",
      "4733:\tlearn: 0.0343043\ttest: 0.0384013\tbest: 0.0384013 (4733)\ttotal: 24m 19s\tremaining: 27m 3s\n",
      "4734:\tlearn: 0.0343012\ttest: 0.0384005\tbest: 0.0384005 (4734)\ttotal: 24m 20s\tremaining: 27m 3s\n",
      "4735:\tlearn: 0.0342986\ttest: 0.0384006\tbest: 0.0384005 (4734)\ttotal: 24m 20s\tremaining: 27m 3s\n",
      "4736:\tlearn: 0.0342985\ttest: 0.0384006\tbest: 0.0384005 (4734)\ttotal: 24m 20s\tremaining: 27m 2s\n",
      "4737:\tlearn: 0.0342985\ttest: 0.0384006\tbest: 0.0384005 (4734)\ttotal: 24m 21s\tremaining: 27m 2s\n",
      "4738:\tlearn: 0.0342985\ttest: 0.0384006\tbest: 0.0384005 (4734)\ttotal: 24m 21s\tremaining: 27m 2s\n",
      "4739:\tlearn: 0.0342985\ttest: 0.0384005\tbest: 0.0384005 (4734)\ttotal: 24m 22s\tremaining: 27m 2s\n",
      "4740:\tlearn: 0.0342985\ttest: 0.0384005\tbest: 0.0384005 (4734)\ttotal: 24m 22s\tremaining: 27m 2s\n",
      "4741:\tlearn: 0.0342985\ttest: 0.0384005\tbest: 0.0384005 (4734)\ttotal: 24m 23s\tremaining: 27m 2s\n",
      "4742:\tlearn: 0.0342941\ttest: 0.0384008\tbest: 0.0384005 (4734)\ttotal: 24m 23s\tremaining: 27m 2s\n",
      "4743:\tlearn: 0.0342941\ttest: 0.0384008\tbest: 0.0384005 (4734)\ttotal: 24m 24s\tremaining: 27m 2s\n",
      "4744:\tlearn: 0.0342888\ttest: 0.0383994\tbest: 0.0383994 (4744)\ttotal: 24m 24s\tremaining: 27m 1s\n",
      "4745:\tlearn: 0.0342888\ttest: 0.0383994\tbest: 0.0383994 (4745)\ttotal: 24m 24s\tremaining: 27m 1s\n",
      "4746:\tlearn: 0.0342841\ttest: 0.0383979\tbest: 0.0383979 (4746)\ttotal: 24m 25s\tremaining: 27m 1s\n",
      "4747:\tlearn: 0.0342841\ttest: 0.0383979\tbest: 0.0383979 (4747)\ttotal: 24m 25s\tremaining: 27m\n",
      "4748:\tlearn: 0.0342841\ttest: 0.0383979\tbest: 0.0383979 (4748)\ttotal: 24m 25s\tremaining: 27m\n",
      "4749:\tlearn: 0.0342841\ttest: 0.0383979\tbest: 0.0383979 (4748)\ttotal: 24m 25s\tremaining: 27m\n",
      "4750:\tlearn: 0.0342797\ttest: 0.0383970\tbest: 0.0383970 (4750)\ttotal: 24m 26s\tremaining: 26m 59s\n",
      "4751:\tlearn: 0.0342797\ttest: 0.0383970\tbest: 0.0383970 (4750)\ttotal: 24m 26s\tremaining: 26m 59s\n",
      "4752:\tlearn: 0.0342797\ttest: 0.0383970\tbest: 0.0383970 (4750)\ttotal: 24m 26s\tremaining: 26m 59s\n",
      "4753:\tlearn: 0.0342797\ttest: 0.0383970\tbest: 0.0383970 (4750)\ttotal: 24m 27s\tremaining: 26m 58s\n",
      "4754:\tlearn: 0.0342797\ttest: 0.0383970\tbest: 0.0383970 (4754)\ttotal: 24m 27s\tremaining: 26m 58s\n",
      "4755:\tlearn: 0.0342797\ttest: 0.0383970\tbest: 0.0383970 (4754)\ttotal: 24m 27s\tremaining: 26m 58s\n",
      "4756:\tlearn: 0.0342797\ttest: 0.0383970\tbest: 0.0383970 (4754)\ttotal: 24m 27s\tremaining: 26m 57s\n",
      "4757:\tlearn: 0.0342797\ttest: 0.0383970\tbest: 0.0383970 (4757)\ttotal: 24m 28s\tremaining: 26m 57s\n",
      "4758:\tlearn: 0.0342796\ttest: 0.0383970\tbest: 0.0383970 (4758)\ttotal: 24m 28s\tremaining: 26m 57s\n",
      "4759:\tlearn: 0.0342797\ttest: 0.0383970\tbest: 0.0383970 (4759)\ttotal: 24m 28s\tremaining: 26m 56s\n",
      "4760:\tlearn: 0.0342796\ttest: 0.0383970\tbest: 0.0383970 (4760)\ttotal: 24m 28s\tremaining: 26m 56s\n",
      "4761:\tlearn: 0.0342796\ttest: 0.0383970\tbest: 0.0383970 (4761)\ttotal: 24m 29s\tremaining: 26m 55s\n",
      "4762:\tlearn: 0.0342796\ttest: 0.0383970\tbest: 0.0383970 (4761)\ttotal: 24m 29s\tremaining: 26m 55s\n",
      "4763:\tlearn: 0.0342763\ttest: 0.0383968\tbest: 0.0383968 (4763)\ttotal: 24m 29s\tremaining: 26m 55s\n",
      "4764:\tlearn: 0.0342763\ttest: 0.0383968\tbest: 0.0383968 (4763)\ttotal: 24m 29s\tremaining: 26m 54s\n",
      "4765:\tlearn: 0.0342763\ttest: 0.0383968\tbest: 0.0383968 (4765)\ttotal: 24m 30s\tremaining: 26m 54s\n",
      "4766:\tlearn: 0.0342763\ttest: 0.0383968\tbest: 0.0383968 (4765)\ttotal: 24m 30s\tremaining: 26m 54s\n",
      "4767:\tlearn: 0.0342762\ttest: 0.0383968\tbest: 0.0383968 (4767)\ttotal: 24m 30s\tremaining: 26m 53s\n",
      "4768:\tlearn: 0.0342728\ttest: 0.0383961\tbest: 0.0383961 (4768)\ttotal: 24m 30s\tremaining: 26m 53s\n",
      "4769:\tlearn: 0.0342728\ttest: 0.0383961\tbest: 0.0383961 (4768)\ttotal: 24m 31s\tremaining: 26m 53s\n",
      "4770:\tlearn: 0.0342728\ttest: 0.0383961\tbest: 0.0383961 (4768)\ttotal: 24m 31s\tremaining: 26m 52s\n",
      "4771:\tlearn: 0.0342728\ttest: 0.0383961\tbest: 0.0383961 (4771)\ttotal: 24m 31s\tremaining: 26m 52s\n",
      "4772:\tlearn: 0.0342728\ttest: 0.0383961\tbest: 0.0383961 (4772)\ttotal: 24m 31s\tremaining: 26m 51s\n",
      "4773:\tlearn: 0.0342695\ttest: 0.0383949\tbest: 0.0383949 (4773)\ttotal: 24m 32s\tremaining: 26m 51s\n",
      "4774:\tlearn: 0.0342695\ttest: 0.0383949\tbest: 0.0383949 (4773)\ttotal: 24m 32s\tremaining: 26m 51s\n",
      "4775:\tlearn: 0.0342694\ttest: 0.0383949\tbest: 0.0383949 (4773)\ttotal: 24m 32s\tremaining: 26m 50s\n",
      "4776:\tlearn: 0.0342694\ttest: 0.0383949\tbest: 0.0383949 (4773)\ttotal: 24m 33s\tremaining: 26m 50s\n",
      "4777:\tlearn: 0.0342694\ttest: 0.0383949\tbest: 0.0383949 (4773)\ttotal: 24m 33s\tremaining: 26m 50s\n",
      "4778:\tlearn: 0.0342694\ttest: 0.0383949\tbest: 0.0383949 (4773)\ttotal: 24m 33s\tremaining: 26m 49s\n",
      "4779:\tlearn: 0.0342694\ttest: 0.0383949\tbest: 0.0383949 (4773)\ttotal: 24m 33s\tremaining: 26m 49s\n",
      "4780:\tlearn: 0.0342694\ttest: 0.0383949\tbest: 0.0383949 (4773)\ttotal: 24m 34s\tremaining: 26m 49s\n",
      "4781:\tlearn: 0.0342670\ttest: 0.0383946\tbest: 0.0383946 (4781)\ttotal: 24m 34s\tremaining: 26m 48s\n",
      "4782:\tlearn: 0.0342605\ttest: 0.0383922\tbest: 0.0383922 (4782)\ttotal: 24m 34s\tremaining: 26m 48s\n",
      "4783:\tlearn: 0.0342605\ttest: 0.0383922\tbest: 0.0383922 (4783)\ttotal: 24m 35s\tremaining: 26m 48s\n",
      "4784:\tlearn: 0.0342604\ttest: 0.0383922\tbest: 0.0383922 (4784)\ttotal: 24m 35s\tremaining: 26m 48s\n",
      "4785:\tlearn: 0.0342581\ttest: 0.0383921\tbest: 0.0383921 (4785)\ttotal: 24m 36s\tremaining: 26m 48s\n",
      "4786:\tlearn: 0.0342581\ttest: 0.0383921\tbest: 0.0383921 (4786)\ttotal: 24m 36s\tremaining: 26m 48s\n",
      "4787:\tlearn: 0.0342581\ttest: 0.0383921\tbest: 0.0383921 (4787)\ttotal: 24m 37s\tremaining: 26m 48s\n",
      "4788:\tlearn: 0.0342581\ttest: 0.0383921\tbest: 0.0383921 (4788)\ttotal: 24m 37s\tremaining: 26m 47s\n",
      "4789:\tlearn: 0.0342581\ttest: 0.0383921\tbest: 0.0383921 (4789)\ttotal: 24m 38s\tremaining: 26m 47s\n",
      "4790:\tlearn: 0.0342581\ttest: 0.0383921\tbest: 0.0383921 (4790)\ttotal: 24m 38s\tremaining: 26m 47s\n",
      "4791:\tlearn: 0.0342581\ttest: 0.0383921\tbest: 0.0383921 (4790)\ttotal: 24m 38s\tremaining: 26m 47s\n",
      "4792:\tlearn: 0.0342581\ttest: 0.0383921\tbest: 0.0383921 (4792)\ttotal: 24m 39s\tremaining: 26m 46s\n",
      "4793:\tlearn: 0.0342581\ttest: 0.0383921\tbest: 0.0383921 (4792)\ttotal: 24m 39s\tremaining: 26m 46s\n",
      "4794:\tlearn: 0.0342546\ttest: 0.0383915\tbest: 0.0383915 (4794)\ttotal: 24m 39s\tremaining: 26m 46s\n",
      "4795:\tlearn: 0.0342545\ttest: 0.0383915\tbest: 0.0383915 (4795)\ttotal: 24m 39s\tremaining: 26m 45s\n",
      "4796:\tlearn: 0.0342545\ttest: 0.0383915\tbest: 0.0383915 (4796)\ttotal: 24m 40s\tremaining: 26m 45s\n",
      "4797:\tlearn: 0.0342545\ttest: 0.0383915\tbest: 0.0383915 (4796)\ttotal: 24m 40s\tremaining: 26m 45s\n",
      "4798:\tlearn: 0.0342545\ttest: 0.0383915\tbest: 0.0383915 (4798)\ttotal: 24m 40s\tremaining: 26m 44s\n",
      "4799:\tlearn: 0.0342545\ttest: 0.0383915\tbest: 0.0383915 (4799)\ttotal: 24m 41s\tremaining: 26m 44s\n",
      "4800:\tlearn: 0.0342545\ttest: 0.0383915\tbest: 0.0383915 (4800)\ttotal: 24m 41s\tremaining: 26m 44s\n",
      "4801:\tlearn: 0.0342518\ttest: 0.0383903\tbest: 0.0383903 (4801)\ttotal: 24m 41s\tremaining: 26m 43s\n",
      "4802:\tlearn: 0.0342518\ttest: 0.0383903\tbest: 0.0383903 (4801)\ttotal: 24m 41s\tremaining: 26m 43s\n",
      "4803:\tlearn: 0.0342484\ttest: 0.0383900\tbest: 0.0383900 (4803)\ttotal: 24m 42s\tremaining: 26m 43s\n",
      "4804:\tlearn: 0.0342484\ttest: 0.0383900\tbest: 0.0383900 (4804)\ttotal: 24m 42s\tremaining: 26m 42s\n",
      "4805:\tlearn: 0.0342484\ttest: 0.0383900\tbest: 0.0383900 (4805)\ttotal: 24m 42s\tremaining: 26m 42s\n",
      "4806:\tlearn: 0.0342484\ttest: 0.0383900\tbest: 0.0383900 (4806)\ttotal: 24m 42s\tremaining: 26m 42s\n",
      "4807:\tlearn: 0.0342484\ttest: 0.0383900\tbest: 0.0383900 (4807)\ttotal: 24m 43s\tremaining: 26m 41s\n",
      "4808:\tlearn: 0.0342429\ttest: 0.0383894\tbest: 0.0383894 (4808)\ttotal: 24m 43s\tremaining: 26m 41s\n",
      "4809:\tlearn: 0.0342429\ttest: 0.0383894\tbest: 0.0383894 (4809)\ttotal: 24m 43s\tremaining: 26m 41s\n",
      "4810:\tlearn: 0.0342429\ttest: 0.0383894\tbest: 0.0383894 (4809)\ttotal: 24m 44s\tremaining: 26m 40s\n",
      "4811:\tlearn: 0.0342428\ttest: 0.0383894\tbest: 0.0383894 (4809)\ttotal: 24m 44s\tremaining: 26m 40s\n",
      "4812:\tlearn: 0.0342428\ttest: 0.0383894\tbest: 0.0383894 (4812)\ttotal: 24m 44s\tremaining: 26m 40s\n",
      "4813:\tlearn: 0.0342428\ttest: 0.0383894\tbest: 0.0383894 (4812)\ttotal: 24m 44s\tremaining: 26m 39s\n",
      "4814:\tlearn: 0.0342428\ttest: 0.0383894\tbest: 0.0383894 (4812)\ttotal: 24m 45s\tremaining: 26m 39s\n",
      "4815:\tlearn: 0.0342428\ttest: 0.0383894\tbest: 0.0383894 (4815)\ttotal: 24m 45s\tremaining: 26m 38s\n",
      "4816:\tlearn: 0.0342428\ttest: 0.0383894\tbest: 0.0383894 (4816)\ttotal: 24m 45s\tremaining: 26m 38s\n",
      "4817:\tlearn: 0.0342428\ttest: 0.0383894\tbest: 0.0383894 (4816)\ttotal: 24m 45s\tremaining: 26m 38s\n",
      "4818:\tlearn: 0.0342428\ttest: 0.0383894\tbest: 0.0383894 (4816)\ttotal: 24m 46s\tremaining: 26m 37s\n",
      "4819:\tlearn: 0.0342428\ttest: 0.0383894\tbest: 0.0383894 (4819)\ttotal: 24m 46s\tremaining: 26m 37s\n",
      "4820:\tlearn: 0.0342428\ttest: 0.0383894\tbest: 0.0383894 (4820)\ttotal: 24m 46s\tremaining: 26m 37s\n",
      "4821:\tlearn: 0.0342428\ttest: 0.0383894\tbest: 0.0383894 (4820)\ttotal: 24m 46s\tremaining: 26m 36s\n",
      "4822:\tlearn: 0.0342384\ttest: 0.0383885\tbest: 0.0383885 (4822)\ttotal: 24m 47s\tremaining: 26m 36s\n",
      "4823:\tlearn: 0.0342384\ttest: 0.0383885\tbest: 0.0383885 (4823)\ttotal: 24m 47s\tremaining: 26m 36s\n",
      "4824:\tlearn: 0.0342344\ttest: 0.0383878\tbest: 0.0383878 (4824)\ttotal: 24m 47s\tremaining: 26m 35s\n",
      "4825:\tlearn: 0.0342344\ttest: 0.0383878\tbest: 0.0383878 (4825)\ttotal: 24m 48s\tremaining: 26m 35s\n",
      "4826:\tlearn: 0.0342344\ttest: 0.0383878\tbest: 0.0383878 (4825)\ttotal: 24m 48s\tremaining: 26m 35s\n",
      "4827:\tlearn: 0.0342300\ttest: 0.0383879\tbest: 0.0383878 (4825)\ttotal: 24m 48s\tremaining: 26m 34s\n",
      "4828:\tlearn: 0.0342300\ttest: 0.0383878\tbest: 0.0383878 (4825)\ttotal: 24m 49s\tremaining: 26m 34s\n",
      "4829:\tlearn: 0.0342300\ttest: 0.0383878\tbest: 0.0383878 (4825)\ttotal: 24m 49s\tremaining: 26m 34s\n",
      "4830:\tlearn: 0.0342300\ttest: 0.0383878\tbest: 0.0383878 (4825)\ttotal: 24m 50s\tremaining: 26m 34s\n",
      "4831:\tlearn: 0.0342300\ttest: 0.0383878\tbest: 0.0383878 (4825)\ttotal: 24m 50s\tremaining: 26m 34s\n",
      "4832:\tlearn: 0.0342300\ttest: 0.0383878\tbest: 0.0383878 (4825)\ttotal: 24m 51s\tremaining: 26m 34s\n",
      "4833:\tlearn: 0.0342250\ttest: 0.0383870\tbest: 0.0383870 (4833)\ttotal: 24m 51s\tremaining: 26m 33s\n",
      "4834:\tlearn: 0.0342250\ttest: 0.0383870\tbest: 0.0383870 (4834)\ttotal: 24m 51s\tremaining: 26m 33s\n",
      "4835:\tlearn: 0.0342250\ttest: 0.0383870\tbest: 0.0383870 (4835)\ttotal: 24m 52s\tremaining: 26m 33s\n",
      "4836:\tlearn: 0.0342250\ttest: 0.0383870\tbest: 0.0383870 (4836)\ttotal: 24m 52s\tremaining: 26m 33s\n",
      "4837:\tlearn: 0.0342250\ttest: 0.0383870\tbest: 0.0383870 (4836)\ttotal: 24m 52s\tremaining: 26m 32s\n",
      "4838:\tlearn: 0.0342223\ttest: 0.0383864\tbest: 0.0383864 (4838)\ttotal: 24m 53s\tremaining: 26m 32s\n",
      "4839:\tlearn: 0.0342223\ttest: 0.0383864\tbest: 0.0383864 (4838)\ttotal: 24m 53s\tremaining: 26m 32s\n",
      "4840:\tlearn: 0.0342223\ttest: 0.0383864\tbest: 0.0383864 (4840)\ttotal: 24m 53s\tremaining: 26m 31s\n",
      "4841:\tlearn: 0.0342223\ttest: 0.0383864\tbest: 0.0383864 (4840)\ttotal: 24m 53s\tremaining: 26m 31s\n",
      "4842:\tlearn: 0.0342223\ttest: 0.0383864\tbest: 0.0383864 (4842)\ttotal: 24m 54s\tremaining: 26m 30s\n",
      "4843:\tlearn: 0.0342223\ttest: 0.0383864\tbest: 0.0383864 (4843)\ttotal: 24m 54s\tremaining: 26m 30s\n",
      "4844:\tlearn: 0.0342223\ttest: 0.0383864\tbest: 0.0383864 (4844)\ttotal: 24m 54s\tremaining: 26m 30s\n",
      "4845:\tlearn: 0.0342223\ttest: 0.0383864\tbest: 0.0383864 (4845)\ttotal: 24m 54s\tremaining: 26m 29s\n",
      "4846:\tlearn: 0.0342223\ttest: 0.0383864\tbest: 0.0383864 (4845)\ttotal: 24m 55s\tremaining: 26m 29s\n",
      "4847:\tlearn: 0.0342223\ttest: 0.0383864\tbest: 0.0383864 (4847)\ttotal: 24m 55s\tremaining: 26m 29s\n",
      "4848:\tlearn: 0.0342222\ttest: 0.0383864\tbest: 0.0383864 (4848)\ttotal: 24m 55s\tremaining: 26m 28s\n",
      "4849:\tlearn: 0.0342185\ttest: 0.0383843\tbest: 0.0383843 (4849)\ttotal: 24m 55s\tremaining: 26m 28s\n",
      "4850:\tlearn: 0.0342185\ttest: 0.0383843\tbest: 0.0383843 (4849)\ttotal: 24m 56s\tremaining: 26m 28s\n",
      "4851:\tlearn: 0.0342184\ttest: 0.0383843\tbest: 0.0383843 (4849)\ttotal: 24m 56s\tremaining: 26m 27s\n",
      "4852:\tlearn: 0.0342184\ttest: 0.0383843\tbest: 0.0383843 (4849)\ttotal: 24m 56s\tremaining: 26m 27s\n",
      "4853:\tlearn: 0.0342184\ttest: 0.0383843\tbest: 0.0383843 (4849)\ttotal: 24m 56s\tremaining: 26m 27s\n",
      "4854:\tlearn: 0.0342121\ttest: 0.0383795\tbest: 0.0383795 (4854)\ttotal: 24m 57s\tremaining: 26m 26s\n",
      "4855:\tlearn: 0.0342121\ttest: 0.0383795\tbest: 0.0383795 (4854)\ttotal: 24m 57s\tremaining: 26m 26s\n",
      "4856:\tlearn: 0.0342121\ttest: 0.0383795\tbest: 0.0383795 (4854)\ttotal: 24m 57s\tremaining: 26m 25s\n",
      "4857:\tlearn: 0.0342121\ttest: 0.0383795\tbest: 0.0383795 (4857)\ttotal: 24m 58s\tremaining: 26m 25s\n",
      "4858:\tlearn: 0.0342093\ttest: 0.0383787\tbest: 0.0383787 (4858)\ttotal: 24m 58s\tremaining: 26m 25s\n",
      "4859:\tlearn: 0.0342093\ttest: 0.0383787\tbest: 0.0383787 (4859)\ttotal: 24m 58s\tremaining: 26m 25s\n",
      "4860:\tlearn: 0.0342093\ttest: 0.0383787\tbest: 0.0383787 (4859)\ttotal: 24m 58s\tremaining: 26m 24s\n",
      "4861:\tlearn: 0.0342093\ttest: 0.0383787\tbest: 0.0383787 (4859)\ttotal: 24m 59s\tremaining: 26m 24s\n",
      "4862:\tlearn: 0.0342073\ttest: 0.0383792\tbest: 0.0383787 (4859)\ttotal: 24m 59s\tremaining: 26m 23s\n",
      "4863:\tlearn: 0.0342073\ttest: 0.0383792\tbest: 0.0383787 (4859)\ttotal: 24m 59s\tremaining: 26m 23s\n",
      "4864:\tlearn: 0.0342073\ttest: 0.0383792\tbest: 0.0383787 (4859)\ttotal: 24m 59s\tremaining: 26m 23s\n",
      "4865:\tlearn: 0.0342073\ttest: 0.0383792\tbest: 0.0383787 (4859)\ttotal: 25m\tremaining: 26m 22s\n",
      "4866:\tlearn: 0.0342073\ttest: 0.0383792\tbest: 0.0383787 (4859)\ttotal: 25m\tremaining: 26m 22s\n",
      "4867:\tlearn: 0.0342073\ttest: 0.0383792\tbest: 0.0383787 (4859)\ttotal: 25m\tremaining: 26m 22s\n",
      "4868:\tlearn: 0.0342073\ttest: 0.0383792\tbest: 0.0383787 (4859)\ttotal: 25m 1s\tremaining: 26m 21s\n",
      "4869:\tlearn: 0.0342073\ttest: 0.0383792\tbest: 0.0383787 (4859)\ttotal: 25m 1s\tremaining: 26m 21s\n",
      "4870:\tlearn: 0.0342073\ttest: 0.0383792\tbest: 0.0383787 (4859)\ttotal: 25m 1s\tremaining: 26m 21s\n",
      "4871:\tlearn: 0.0342073\ttest: 0.0383792\tbest: 0.0383787 (4859)\ttotal: 25m 1s\tremaining: 26m 20s\n",
      "4872:\tlearn: 0.0342029\ttest: 0.0383772\tbest: 0.0383772 (4872)\ttotal: 25m 2s\tremaining: 26m 20s\n",
      "4873:\tlearn: 0.0341994\ttest: 0.0383766\tbest: 0.0383766 (4873)\ttotal: 25m 2s\tremaining: 26m 20s\n",
      "4874:\tlearn: 0.0341993\ttest: 0.0383766\tbest: 0.0383766 (4873)\ttotal: 25m 3s\tremaining: 26m 20s\n",
      "4875:\tlearn: 0.0341993\ttest: 0.0383766\tbest: 0.0383766 (4873)\ttotal: 25m 3s\tremaining: 26m 19s\n",
      "4876:\tlearn: 0.0341993\ttest: 0.0383766\tbest: 0.0383766 (4873)\ttotal: 25m 4s\tremaining: 26m 19s\n",
      "4877:\tlearn: 0.0341993\ttest: 0.0383766\tbest: 0.0383766 (4873)\ttotal: 25m 4s\tremaining: 26m 19s\n",
      "4878:\tlearn: 0.0341991\ttest: 0.0383766\tbest: 0.0383766 (4873)\ttotal: 25m 4s\tremaining: 26m 19s\n",
      "4879:\tlearn: 0.0341991\ttest: 0.0383766\tbest: 0.0383766 (4873)\ttotal: 25m 5s\tremaining: 26m 19s\n",
      "4880:\tlearn: 0.0341990\ttest: 0.0383766\tbest: 0.0383766 (4873)\ttotal: 25m 5s\tremaining: 26m 19s\n",
      "4881:\tlearn: 0.0341966\ttest: 0.0383769\tbest: 0.0383766 (4873)\ttotal: 25m 6s\tremaining: 26m 19s\n",
      "4882:\tlearn: 0.0341928\ttest: 0.0383745\tbest: 0.0383745 (4882)\ttotal: 25m 6s\tremaining: 26m 18s\n",
      "4883:\tlearn: 0.0341928\ttest: 0.0383745\tbest: 0.0383745 (4883)\ttotal: 25m 6s\tremaining: 26m 18s\n",
      "4884:\tlearn: 0.0341927\ttest: 0.0383746\tbest: 0.0383745 (4883)\ttotal: 25m 7s\tremaining: 26m 18s\n",
      "4885:\tlearn: 0.0341927\ttest: 0.0383746\tbest: 0.0383745 (4883)\ttotal: 25m 7s\tremaining: 26m 17s\n",
      "4886:\tlearn: 0.0341927\ttest: 0.0383746\tbest: 0.0383745 (4883)\ttotal: 25m 7s\tremaining: 26m 17s\n",
      "4887:\tlearn: 0.0341927\ttest: 0.0383746\tbest: 0.0383745 (4883)\ttotal: 25m 7s\tremaining: 26m 16s\n",
      "4888:\tlearn: 0.0341927\ttest: 0.0383746\tbest: 0.0383745 (4883)\ttotal: 25m 8s\tremaining: 26m 16s\n",
      "4889:\tlearn: 0.0341913\ttest: 0.0383747\tbest: 0.0383745 (4883)\ttotal: 25m 8s\tremaining: 26m 16s\n",
      "4890:\tlearn: 0.0341913\ttest: 0.0383747\tbest: 0.0383745 (4883)\ttotal: 25m 8s\tremaining: 26m 15s\n",
      "4891:\tlearn: 0.0341900\ttest: 0.0383751\tbest: 0.0383745 (4883)\ttotal: 25m 8s\tremaining: 26m 15s\n",
      "4892:\tlearn: 0.0341860\ttest: 0.0383743\tbest: 0.0383743 (4892)\ttotal: 25m 9s\tremaining: 26m 15s\n",
      "4893:\tlearn: 0.0341860\ttest: 0.0383743\tbest: 0.0383743 (4892)\ttotal: 25m 9s\tremaining: 26m 14s\n",
      "4894:\tlearn: 0.0341860\ttest: 0.0383743\tbest: 0.0383743 (4894)\ttotal: 25m 9s\tremaining: 26m 14s\n",
      "4895:\tlearn: 0.0341860\ttest: 0.0383743\tbest: 0.0383743 (4895)\ttotal: 25m 10s\tremaining: 26m 14s\n",
      "4896:\tlearn: 0.0341831\ttest: 0.0383739\tbest: 0.0383739 (4896)\ttotal: 25m 10s\tremaining: 26m 13s\n",
      "4897:\tlearn: 0.0341830\ttest: 0.0383739\tbest: 0.0383739 (4897)\ttotal: 25m 10s\tremaining: 26m 13s\n",
      "4898:\tlearn: 0.0341830\ttest: 0.0383739\tbest: 0.0383739 (4898)\ttotal: 25m 10s\tremaining: 26m 13s\n",
      "4899:\tlearn: 0.0341830\ttest: 0.0383739\tbest: 0.0383739 (4899)\ttotal: 25m 11s\tremaining: 26m 12s\n",
      "4900:\tlearn: 0.0341780\ttest: 0.0383730\tbest: 0.0383730 (4900)\ttotal: 25m 11s\tremaining: 26m 12s\n",
      "4901:\tlearn: 0.0341780\ttest: 0.0383730\tbest: 0.0383730 (4900)\ttotal: 25m 11s\tremaining: 26m 12s\n",
      "4902:\tlearn: 0.0341780\ttest: 0.0383730\tbest: 0.0383730 (4902)\ttotal: 25m 11s\tremaining: 26m 11s\n",
      "4903:\tlearn: 0.0341780\ttest: 0.0383730\tbest: 0.0383730 (4903)\ttotal: 25m 12s\tremaining: 26m 11s\n",
      "4904:\tlearn: 0.0341780\ttest: 0.0383730\tbest: 0.0383730 (4904)\ttotal: 25m 12s\tremaining: 26m 11s\n",
      "4905:\tlearn: 0.0341749\ttest: 0.0383725\tbest: 0.0383725 (4905)\ttotal: 25m 12s\tremaining: 26m 10s\n",
      "4906:\tlearn: 0.0341749\ttest: 0.0383725\tbest: 0.0383725 (4906)\ttotal: 25m 13s\tremaining: 26m 10s\n",
      "4907:\tlearn: 0.0341749\ttest: 0.0383725\tbest: 0.0383725 (4906)\ttotal: 25m 13s\tremaining: 26m 10s\n",
      "4908:\tlearn: 0.0341749\ttest: 0.0383725\tbest: 0.0383725 (4908)\ttotal: 25m 13s\tremaining: 26m 9s\n",
      "4909:\tlearn: 0.0341749\ttest: 0.0383725\tbest: 0.0383725 (4909)\ttotal: 25m 13s\tremaining: 26m 9s\n",
      "4910:\tlearn: 0.0341749\ttest: 0.0383725\tbest: 0.0383725 (4910)\ttotal: 25m 14s\tremaining: 26m 8s\n",
      "4911:\tlearn: 0.0341749\ttest: 0.0383725\tbest: 0.0383725 (4910)\ttotal: 25m 14s\tremaining: 26m 8s\n",
      "4912:\tlearn: 0.0341712\ttest: 0.0383716\tbest: 0.0383716 (4912)\ttotal: 25m 14s\tremaining: 26m 8s\n",
      "4913:\tlearn: 0.0341712\ttest: 0.0383716\tbest: 0.0383716 (4912)\ttotal: 25m 14s\tremaining: 26m 7s\n",
      "4914:\tlearn: 0.0341673\ttest: 0.0383713\tbest: 0.0383713 (4914)\ttotal: 25m 15s\tremaining: 26m 7s\n",
      "4915:\tlearn: 0.0341673\ttest: 0.0383713\tbest: 0.0383713 (4914)\ttotal: 25m 15s\tremaining: 26m 7s\n",
      "4916:\tlearn: 0.0341673\ttest: 0.0383713\tbest: 0.0383713 (4916)\ttotal: 25m 15s\tremaining: 26m 6s\n",
      "4917:\tlearn: 0.0341673\ttest: 0.0383713\tbest: 0.0383713 (4917)\ttotal: 25m 15s\tremaining: 26m 6s\n",
      "4918:\tlearn: 0.0341673\ttest: 0.0383713\tbest: 0.0383713 (4918)\ttotal: 25m 16s\tremaining: 26m 6s\n",
      "4919:\tlearn: 0.0341673\ttest: 0.0383713\tbest: 0.0383713 (4919)\ttotal: 25m 16s\tremaining: 26m 6s\n",
      "4920:\tlearn: 0.0341673\ttest: 0.0383713\tbest: 0.0383713 (4920)\ttotal: 25m 17s\tremaining: 26m 5s\n",
      "4921:\tlearn: 0.0341672\ttest: 0.0383713\tbest: 0.0383713 (4921)\ttotal: 25m 17s\tremaining: 26m 5s\n",
      "4922:\tlearn: 0.0341672\ttest: 0.0383713\tbest: 0.0383713 (4921)\ttotal: 25m 18s\tremaining: 26m 5s\n",
      "4923:\tlearn: 0.0341672\ttest: 0.0383713\tbest: 0.0383713 (4921)\ttotal: 25m 18s\tremaining: 26m 5s\n",
      "4924:\tlearn: 0.0341672\ttest: 0.0383713\tbest: 0.0383713 (4924)\ttotal: 25m 19s\tremaining: 26m 5s\n",
      "4925:\tlearn: 0.0341672\ttest: 0.0383713\tbest: 0.0383713 (4924)\ttotal: 25m 19s\tremaining: 26m 5s\n",
      "4926:\tlearn: 0.0341672\ttest: 0.0383713\tbest: 0.0383713 (4924)\ttotal: 25m 20s\tremaining: 26m 5s\n",
      "4927:\tlearn: 0.0341672\ttest: 0.0383713\tbest: 0.0383713 (4927)\ttotal: 25m 20s\tremaining: 26m 4s\n",
      "4928:\tlearn: 0.0341672\ttest: 0.0383713\tbest: 0.0383713 (4928)\ttotal: 25m 20s\tremaining: 26m 4s\n",
      "4929:\tlearn: 0.0341672\ttest: 0.0383713\tbest: 0.0383713 (4928)\ttotal: 25m 20s\tremaining: 26m 4s\n",
      "4930:\tlearn: 0.0341672\ttest: 0.0383713\tbest: 0.0383713 (4930)\ttotal: 25m 21s\tremaining: 26m 3s\n",
      "4931:\tlearn: 0.0341672\ttest: 0.0383713\tbest: 0.0383713 (4931)\ttotal: 25m 21s\tremaining: 26m 3s\n",
      "4932:\tlearn: 0.0341623\ttest: 0.0383712\tbest: 0.0383712 (4932)\ttotal: 25m 21s\tremaining: 26m 2s\n",
      "4933:\tlearn: 0.0341623\ttest: 0.0383712\tbest: 0.0383712 (4933)\ttotal: 25m 21s\tremaining: 26m 2s\n",
      "4934:\tlearn: 0.0341623\ttest: 0.0383712\tbest: 0.0383712 (4933)\ttotal: 25m 22s\tremaining: 26m 2s\n",
      "4935:\tlearn: 0.0341623\ttest: 0.0383712\tbest: 0.0383712 (4935)\ttotal: 25m 22s\tremaining: 26m 1s\n",
      "4936:\tlearn: 0.0341623\ttest: 0.0383712\tbest: 0.0383712 (4935)\ttotal: 25m 22s\tremaining: 26m 1s\n",
      "4937:\tlearn: 0.0341602\ttest: 0.0383714\tbest: 0.0383712 (4935)\ttotal: 25m 22s\tremaining: 26m 1s\n",
      "4938:\tlearn: 0.0341602\ttest: 0.0383714\tbest: 0.0383712 (4935)\ttotal: 25m 23s\tremaining: 26m\n",
      "4939:\tlearn: 0.0341602\ttest: 0.0383714\tbest: 0.0383712 (4935)\ttotal: 25m 23s\tremaining: 26m\n",
      "4940:\tlearn: 0.0341602\ttest: 0.0383714\tbest: 0.0383712 (4935)\ttotal: 25m 23s\tremaining: 26m\n",
      "4941:\tlearn: 0.0341558\ttest: 0.0383702\tbest: 0.0383702 (4941)\ttotal: 25m 24s\tremaining: 25m 59s\n",
      "4942:\tlearn: 0.0341558\ttest: 0.0383702\tbest: 0.0383702 (4942)\ttotal: 25m 24s\tremaining: 25m 59s\n",
      "4943:\tlearn: 0.0341558\ttest: 0.0383702\tbest: 0.0383702 (4943)\ttotal: 25m 24s\tremaining: 25m 59s\n",
      "4944:\tlearn: 0.0341526\ttest: 0.0383695\tbest: 0.0383695 (4944)\ttotal: 25m 24s\tremaining: 25m 58s\n",
      "4945:\tlearn: 0.0341499\ttest: 0.0383694\tbest: 0.0383694 (4945)\ttotal: 25m 25s\tremaining: 25m 58s\n",
      "4946:\tlearn: 0.0341499\ttest: 0.0383694\tbest: 0.0383694 (4946)\ttotal: 25m 25s\tremaining: 25m 58s\n",
      "4947:\tlearn: 0.0341499\ttest: 0.0383694\tbest: 0.0383694 (4947)\ttotal: 25m 25s\tremaining: 25m 57s\n",
      "4948:\tlearn: 0.0341499\ttest: 0.0383694\tbest: 0.0383694 (4947)\ttotal: 25m 25s\tremaining: 25m 57s\n",
      "4949:\tlearn: 0.0341499\ttest: 0.0383694\tbest: 0.0383694 (4947)\ttotal: 25m 26s\tremaining: 25m 57s\n",
      "4950:\tlearn: 0.0341451\ttest: 0.0383697\tbest: 0.0383694 (4947)\ttotal: 25m 26s\tremaining: 25m 56s\n",
      "4951:\tlearn: 0.0341451\ttest: 0.0383697\tbest: 0.0383694 (4947)\ttotal: 25m 26s\tremaining: 25m 56s\n",
      "4952:\tlearn: 0.0341423\ttest: 0.0383698\tbest: 0.0383694 (4947)\ttotal: 25m 27s\tremaining: 25m 56s\n",
      "4953:\tlearn: 0.0341423\ttest: 0.0383698\tbest: 0.0383694 (4947)\ttotal: 25m 27s\tremaining: 25m 55s\n",
      "4954:\tlearn: 0.0341423\ttest: 0.0383698\tbest: 0.0383694 (4947)\ttotal: 25m 27s\tremaining: 25m 55s\n",
      "4955:\tlearn: 0.0341423\ttest: 0.0383698\tbest: 0.0383694 (4947)\ttotal: 25m 27s\tremaining: 25m 54s\n",
      "4956:\tlearn: 0.0341423\ttest: 0.0383698\tbest: 0.0383694 (4947)\ttotal: 25m 28s\tremaining: 25m 54s\n",
      "4957:\tlearn: 0.0341375\ttest: 0.0383685\tbest: 0.0383685 (4957)\ttotal: 25m 28s\tremaining: 25m 54s\n",
      "4958:\tlearn: 0.0341375\ttest: 0.0383686\tbest: 0.0383685 (4957)\ttotal: 25m 28s\tremaining: 25m 53s\n",
      "4959:\tlearn: 0.0341375\ttest: 0.0383686\tbest: 0.0383685 (4957)\ttotal: 25m 28s\tremaining: 25m 53s\n",
      "4960:\tlearn: 0.0341375\ttest: 0.0383686\tbest: 0.0383685 (4957)\ttotal: 25m 29s\tremaining: 25m 53s\n",
      "4961:\tlearn: 0.0341375\ttest: 0.0383686\tbest: 0.0383685 (4957)\ttotal: 25m 29s\tremaining: 25m 52s\n",
      "4962:\tlearn: 0.0341375\ttest: 0.0383686\tbest: 0.0383685 (4957)\ttotal: 25m 29s\tremaining: 25m 52s\n",
      "4963:\tlearn: 0.0341360\ttest: 0.0383681\tbest: 0.0383681 (4963)\ttotal: 25m 30s\tremaining: 25m 52s\n",
      "4964:\tlearn: 0.0341359\ttest: 0.0383681\tbest: 0.0383681 (4964)\ttotal: 25m 30s\tremaining: 25m 52s\n",
      "4965:\tlearn: 0.0341359\ttest: 0.0383681\tbest: 0.0383681 (4965)\ttotal: 25m 30s\tremaining: 25m 51s\n",
      "4966:\tlearn: 0.0341359\ttest: 0.0383681\tbest: 0.0383681 (4966)\ttotal: 25m 31s\tremaining: 25m 51s\n",
      "4967:\tlearn: 0.0341331\ttest: 0.0383675\tbest: 0.0383675 (4967)\ttotal: 25m 31s\tremaining: 25m 51s\n",
      "4968:\tlearn: 0.0341331\ttest: 0.0383675\tbest: 0.0383675 (4967)\ttotal: 25m 32s\tremaining: 25m 51s\n",
      "4969:\tlearn: 0.0341331\ttest: 0.0383675\tbest: 0.0383675 (4967)\ttotal: 25m 32s\tremaining: 25m 51s\n",
      "4970:\tlearn: 0.0341331\ttest: 0.0383675\tbest: 0.0383675 (4967)\ttotal: 25m 33s\tremaining: 25m 51s\n",
      "4971:\tlearn: 0.0341331\ttest: 0.0383675\tbest: 0.0383675 (4967)\ttotal: 25m 33s\tremaining: 25m 50s\n",
      "4972:\tlearn: 0.0341331\ttest: 0.0383675\tbest: 0.0383675 (4967)\ttotal: 25m 33s\tremaining: 25m 50s\n",
      "4973:\tlearn: 0.0341331\ttest: 0.0383675\tbest: 0.0383675 (4967)\ttotal: 25m 34s\tremaining: 25m 50s\n",
      "4974:\tlearn: 0.0341331\ttest: 0.0383675\tbest: 0.0383675 (4974)\ttotal: 25m 34s\tremaining: 25m 49s\n",
      "4975:\tlearn: 0.0341331\ttest: 0.0383675\tbest: 0.0383675 (4974)\ttotal: 25m 34s\tremaining: 25m 49s\n",
      "4976:\tlearn: 0.0341331\ttest: 0.0383675\tbest: 0.0383675 (4976)\ttotal: 25m 34s\tremaining: 25m 49s\n",
      "4977:\tlearn: 0.0341331\ttest: 0.0383675\tbest: 0.0383675 (4976)\ttotal: 25m 35s\tremaining: 25m 48s\n",
      "4978:\tlearn: 0.0341331\ttest: 0.0383675\tbest: 0.0383675 (4978)\ttotal: 25m 35s\tremaining: 25m 48s\n",
      "4979:\tlearn: 0.0341331\ttest: 0.0383675\tbest: 0.0383675 (4978)\ttotal: 25m 35s\tremaining: 25m 48s\n",
      "4980:\tlearn: 0.0341331\ttest: 0.0383675\tbest: 0.0383675 (4980)\ttotal: 25m 35s\tremaining: 25m 47s\n",
      "4981:\tlearn: 0.0341331\ttest: 0.0383675\tbest: 0.0383675 (4980)\ttotal: 25m 36s\tremaining: 25m 47s\n",
      "4982:\tlearn: 0.0341331\ttest: 0.0383675\tbest: 0.0383675 (4980)\ttotal: 25m 36s\tremaining: 25m 46s\n",
      "4983:\tlearn: 0.0341331\ttest: 0.0383675\tbest: 0.0383675 (4983)\ttotal: 25m 36s\tremaining: 25m 46s\n",
      "4984:\tlearn: 0.0341331\ttest: 0.0383675\tbest: 0.0383675 (4984)\ttotal: 25m 37s\tremaining: 25m 46s\n",
      "4985:\tlearn: 0.0341331\ttest: 0.0383675\tbest: 0.0383675 (4984)\ttotal: 25m 37s\tremaining: 25m 45s\n",
      "4986:\tlearn: 0.0341331\ttest: 0.0383675\tbest: 0.0383675 (4984)\ttotal: 25m 37s\tremaining: 25m 45s\n",
      "4987:\tlearn: 0.0341331\ttest: 0.0383675\tbest: 0.0383675 (4984)\ttotal: 25m 37s\tremaining: 25m 45s\n",
      "4988:\tlearn: 0.0341282\ttest: 0.0383663\tbest: 0.0383663 (4988)\ttotal: 25m 38s\tremaining: 25m 44s\n",
      "4989:\tlearn: 0.0341282\ttest: 0.0383663\tbest: 0.0383663 (4988)\ttotal: 25m 38s\tremaining: 25m 44s\n",
      "4990:\tlearn: 0.0341282\ttest: 0.0383663\tbest: 0.0383663 (4990)\ttotal: 25m 38s\tremaining: 25m 44s\n",
      "4991:\tlearn: 0.0341282\ttest: 0.0383663\tbest: 0.0383663 (4990)\ttotal: 25m 38s\tremaining: 25m 43s\n",
      "4992:\tlearn: 0.0341282\ttest: 0.0383663\tbest: 0.0383663 (4990)\ttotal: 25m 39s\tremaining: 25m 43s\n",
      "4993:\tlearn: 0.0341282\ttest: 0.0383663\tbest: 0.0383663 (4993)\ttotal: 25m 39s\tremaining: 25m 43s\n",
      "4994:\tlearn: 0.0341245\ttest: 0.0383658\tbest: 0.0383658 (4994)\ttotal: 25m 39s\tremaining: 25m 42s\n",
      "4995:\tlearn: 0.0341206\ttest: 0.0383647\tbest: 0.0383647 (4995)\ttotal: 25m 40s\tremaining: 25m 42s\n",
      "4996:\tlearn: 0.0341206\ttest: 0.0383647\tbest: 0.0383647 (4996)\ttotal: 25m 40s\tremaining: 25m 42s\n",
      "4997:\tlearn: 0.0341206\ttest: 0.0383647\tbest: 0.0383647 (4997)\ttotal: 25m 40s\tremaining: 25m 41s\n",
      "4998:\tlearn: 0.0341206\ttest: 0.0383647\tbest: 0.0383647 (4997)\ttotal: 25m 40s\tremaining: 25m 41s\n",
      "4999:\tlearn: 0.0341206\ttest: 0.0383647\tbest: 0.0383647 (4997)\ttotal: 25m 41s\tremaining: 25m 41s\n",
      "5000:\tlearn: 0.0341206\ttest: 0.0383647\tbest: 0.0383647 (4997)\ttotal: 25m 41s\tremaining: 25m 40s\n",
      "5001:\tlearn: 0.0341206\ttest: 0.0383647\tbest: 0.0383647 (4997)\ttotal: 25m 41s\tremaining: 25m 40s\n",
      "5002:\tlearn: 0.0341206\ttest: 0.0383647\tbest: 0.0383647 (5002)\ttotal: 25m 41s\tremaining: 25m 39s\n",
      "5003:\tlearn: 0.0341196\ttest: 0.0383645\tbest: 0.0383645 (5003)\ttotal: 25m 42s\tremaining: 25m 39s\n",
      "5004:\tlearn: 0.0341142\ttest: 0.0383643\tbest: 0.0383643 (5004)\ttotal: 25m 42s\tremaining: 25m 39s\n",
      "5005:\tlearn: 0.0341142\ttest: 0.0383643\tbest: 0.0383643 (5005)\ttotal: 25m 42s\tremaining: 25m 38s\n",
      "5006:\tlearn: 0.0341142\ttest: 0.0383643\tbest: 0.0383643 (5005)\ttotal: 25m 42s\tremaining: 25m 38s\n",
      "5007:\tlearn: 0.0341142\ttest: 0.0383643\tbest: 0.0383643 (5005)\ttotal: 25m 43s\tremaining: 25m 38s\n",
      "5008:\tlearn: 0.0341142\ttest: 0.0383643\tbest: 0.0383643 (5005)\ttotal: 25m 43s\tremaining: 25m 37s\n",
      "5009:\tlearn: 0.0341081\ttest: 0.0383631\tbest: 0.0383631 (5009)\ttotal: 25m 43s\tremaining: 25m 37s\n",
      "5010:\tlearn: 0.0341081\ttest: 0.0383631\tbest: 0.0383631 (5010)\ttotal: 25m 44s\tremaining: 25m 37s\n",
      "5011:\tlearn: 0.0341081\ttest: 0.0383631\tbest: 0.0383631 (5010)\ttotal: 25m 44s\tremaining: 25m 37s\n",
      "5012:\tlearn: 0.0341081\ttest: 0.0383631\tbest: 0.0383631 (5010)\ttotal: 25m 45s\tremaining: 25m 37s\n",
      "5013:\tlearn: 0.0341081\ttest: 0.0383631\tbest: 0.0383631 (5013)\ttotal: 25m 45s\tremaining: 25m 36s\n",
      "5014:\tlearn: 0.0341081\ttest: 0.0383631\tbest: 0.0383631 (5014)\ttotal: 25m 45s\tremaining: 25m 36s\n",
      "5015:\tlearn: 0.0341081\ttest: 0.0383631\tbest: 0.0383631 (5014)\ttotal: 25m 46s\tremaining: 25m 36s\n",
      "5016:\tlearn: 0.0341081\ttest: 0.0383631\tbest: 0.0383631 (5014)\ttotal: 25m 46s\tremaining: 25m 36s\n",
      "5017:\tlearn: 0.0341081\ttest: 0.0383631\tbest: 0.0383631 (5014)\ttotal: 25m 47s\tremaining: 25m 36s\n",
      "5018:\tlearn: 0.0341081\ttest: 0.0383631\tbest: 0.0383631 (5014)\ttotal: 25m 47s\tremaining: 25m 36s\n",
      "5019:\tlearn: 0.0341081\ttest: 0.0383631\tbest: 0.0383631 (5014)\ttotal: 25m 47s\tremaining: 25m 35s\n",
      "5020:\tlearn: 0.0341081\ttest: 0.0383631\tbest: 0.0383631 (5020)\ttotal: 25m 48s\tremaining: 25m 35s\n",
      "5021:\tlearn: 0.0341016\ttest: 0.0383628\tbest: 0.0383628 (5021)\ttotal: 25m 48s\tremaining: 25m 34s\n",
      "5022:\tlearn: 0.0341016\ttest: 0.0383628\tbest: 0.0383628 (5021)\ttotal: 25m 48s\tremaining: 25m 34s\n",
      "5023:\tlearn: 0.0340991\ttest: 0.0383634\tbest: 0.0383628 (5021)\ttotal: 25m 49s\tremaining: 25m 34s\n",
      "5024:\tlearn: 0.0340991\ttest: 0.0383634\tbest: 0.0383628 (5021)\ttotal: 25m 49s\tremaining: 25m 33s\n",
      "5025:\tlearn: 0.0340991\ttest: 0.0383634\tbest: 0.0383628 (5021)\ttotal: 25m 49s\tremaining: 25m 33s\n",
      "5026:\tlearn: 0.0340942\ttest: 0.0383631\tbest: 0.0383628 (5021)\ttotal: 25m 49s\tremaining: 25m 33s\n",
      "5027:\tlearn: 0.0340942\ttest: 0.0383631\tbest: 0.0383628 (5021)\ttotal: 25m 50s\tremaining: 25m 32s\n",
      "5028:\tlearn: 0.0340942\ttest: 0.0383631\tbest: 0.0383628 (5021)\ttotal: 25m 50s\tremaining: 25m 32s\n",
      "5029:\tlearn: 0.0340942\ttest: 0.0383631\tbest: 0.0383628 (5021)\ttotal: 25m 50s\tremaining: 25m 32s\n",
      "5030:\tlearn: 0.0340942\ttest: 0.0383631\tbest: 0.0383628 (5021)\ttotal: 25m 50s\tremaining: 25m 31s\n",
      "5031:\tlearn: 0.0340942\ttest: 0.0383631\tbest: 0.0383628 (5021)\ttotal: 25m 51s\tremaining: 25m 31s\n",
      "5032:\tlearn: 0.0340942\ttest: 0.0383631\tbest: 0.0383628 (5021)\ttotal: 25m 51s\tremaining: 25m 31s\n",
      "5033:\tlearn: 0.0340942\ttest: 0.0383631\tbest: 0.0383628 (5021)\ttotal: 25m 51s\tremaining: 25m 30s\n",
      "5034:\tlearn: 0.0340904\ttest: 0.0383623\tbest: 0.0383623 (5034)\ttotal: 25m 52s\tremaining: 25m 30s\n",
      "5035:\tlearn: 0.0340903\ttest: 0.0383623\tbest: 0.0383623 (5034)\ttotal: 25m 52s\tremaining: 25m 30s\n",
      "5036:\tlearn: 0.0340903\ttest: 0.0383623\tbest: 0.0383623 (5034)\ttotal: 25m 52s\tremaining: 25m 29s\n",
      "5037:\tlearn: 0.0340904\ttest: 0.0383623\tbest: 0.0383623 (5034)\ttotal: 25m 52s\tremaining: 25m 29s\n",
      "5038:\tlearn: 0.0340904\ttest: 0.0383623\tbest: 0.0383623 (5034)\ttotal: 25m 53s\tremaining: 25m 29s\n",
      "5039:\tlearn: 0.0340903\ttest: 0.0383622\tbest: 0.0383622 (5039)\ttotal: 25m 53s\tremaining: 25m 28s\n",
      "5040:\tlearn: 0.0340903\ttest: 0.0383622\tbest: 0.0383622 (5040)\ttotal: 25m 53s\tremaining: 25m 28s\n",
      "5041:\tlearn: 0.0340861\ttest: 0.0383598\tbest: 0.0383598 (5041)\ttotal: 25m 53s\tremaining: 25m 28s\n",
      "5042:\tlearn: 0.0340861\ttest: 0.0383598\tbest: 0.0383598 (5041)\ttotal: 25m 54s\tremaining: 25m 27s\n",
      "5043:\tlearn: 0.0340860\ttest: 0.0383598\tbest: 0.0383598 (5043)\ttotal: 25m 54s\tremaining: 25m 27s\n",
      "5044:\tlearn: 0.0340860\ttest: 0.0383598\tbest: 0.0383598 (5044)\ttotal: 25m 54s\tremaining: 25m 26s\n",
      "5045:\tlearn: 0.0340860\ttest: 0.0383598\tbest: 0.0383598 (5045)\ttotal: 25m 54s\tremaining: 25m 26s\n",
      "5046:\tlearn: 0.0340860\ttest: 0.0383598\tbest: 0.0383598 (5045)\ttotal: 25m 55s\tremaining: 25m 26s\n",
      "5047:\tlearn: 0.0340860\ttest: 0.0383598\tbest: 0.0383598 (5045)\ttotal: 25m 55s\tremaining: 25m 25s\n",
      "5048:\tlearn: 0.0340812\ttest: 0.0383584\tbest: 0.0383584 (5048)\ttotal: 25m 56s\tremaining: 25m 25s\n",
      "5049:\tlearn: 0.0340812\ttest: 0.0383584\tbest: 0.0383584 (5049)\ttotal: 25m 56s\tremaining: 25m 25s\n",
      "5050:\tlearn: 0.0340812\ttest: 0.0383583\tbest: 0.0383583 (5050)\ttotal: 25m 56s\tremaining: 25m 25s\n",
      "5051:\tlearn: 0.0340812\ttest: 0.0383583\tbest: 0.0383583 (5050)\ttotal: 25m 57s\tremaining: 25m 25s\n",
      "5052:\tlearn: 0.0340812\ttest: 0.0383583\tbest: 0.0383583 (5052)\ttotal: 25m 57s\tremaining: 25m 25s\n",
      "5053:\tlearn: 0.0340812\ttest: 0.0383583\tbest: 0.0383583 (5052)\ttotal: 25m 58s\tremaining: 25m 25s\n",
      "5054:\tlearn: 0.0340812\ttest: 0.0383583\tbest: 0.0383583 (5052)\ttotal: 25m 58s\tremaining: 25m 24s\n",
      "5055:\tlearn: 0.0340811\ttest: 0.0383583\tbest: 0.0383583 (5055)\ttotal: 25m 59s\tremaining: 25m 24s\n",
      "5056:\tlearn: 0.0340811\ttest: 0.0383583\tbest: 0.0383583 (5056)\ttotal: 25m 59s\tremaining: 25m 24s\n",
      "5057:\tlearn: 0.0340811\ttest: 0.0383583\tbest: 0.0383583 (5057)\ttotal: 26m\tremaining: 25m 24s\n",
      "5058:\tlearn: 0.0340777\ttest: 0.0383582\tbest: 0.0383582 (5058)\ttotal: 26m\tremaining: 25m 24s\n",
      "5059:\tlearn: 0.0340777\ttest: 0.0383582\tbest: 0.0383582 (5059)\ttotal: 26m 1s\tremaining: 25m 24s\n",
      "5060:\tlearn: 0.0340777\ttest: 0.0383582\tbest: 0.0383582 (5059)\ttotal: 26m 1s\tremaining: 25m 24s\n",
      "5061:\tlearn: 0.0340754\ttest: 0.0383582\tbest: 0.0383582 (5059)\ttotal: 26m 2s\tremaining: 25m 24s\n",
      "5062:\tlearn: 0.0340754\ttest: 0.0383582\tbest: 0.0383582 (5059)\ttotal: 26m 2s\tremaining: 25m 23s\n",
      "5063:\tlearn: 0.0340754\ttest: 0.0383582\tbest: 0.0383582 (5059)\ttotal: 26m 3s\tremaining: 25m 23s\n",
      "5064:\tlearn: 0.0340733\ttest: 0.0383585\tbest: 0.0383582 (5059)\ttotal: 26m 3s\tremaining: 25m 23s\n",
      "5065:\tlearn: 0.0340733\ttest: 0.0383585\tbest: 0.0383582 (5059)\ttotal: 26m 3s\tremaining: 25m 22s\n",
      "5066:\tlearn: 0.0340733\ttest: 0.0383585\tbest: 0.0383582 (5059)\ttotal: 26m 4s\tremaining: 25m 22s\n",
      "5067:\tlearn: 0.0340732\ttest: 0.0383585\tbest: 0.0383582 (5059)\ttotal: 26m 4s\tremaining: 25m 22s\n",
      "5068:\tlearn: 0.0340732\ttest: 0.0383585\tbest: 0.0383582 (5059)\ttotal: 26m 4s\tremaining: 25m 21s\n",
      "5069:\tlearn: 0.0340699\ttest: 0.0383587\tbest: 0.0383582 (5059)\ttotal: 26m 4s\tremaining: 25m 21s\n",
      "5070:\tlearn: 0.0340699\ttest: 0.0383587\tbest: 0.0383582 (5059)\ttotal: 26m 5s\tremaining: 25m 21s\n",
      "5071:\tlearn: 0.0340699\ttest: 0.0383587\tbest: 0.0383582 (5059)\ttotal: 26m 5s\tremaining: 25m 20s\n",
      "5072:\tlearn: 0.0340699\ttest: 0.0383587\tbest: 0.0383582 (5059)\ttotal: 26m 5s\tremaining: 25m 20s\n",
      "5073:\tlearn: 0.0340658\ttest: 0.0383579\tbest: 0.0383579 (5073)\ttotal: 26m 5s\tremaining: 25m 20s\n",
      "5074:\tlearn: 0.0340658\ttest: 0.0383579\tbest: 0.0383579 (5073)\ttotal: 26m 6s\tremaining: 25m 19s\n",
      "5075:\tlearn: 0.0340657\ttest: 0.0383579\tbest: 0.0383579 (5073)\ttotal: 26m 6s\tremaining: 25m 19s\n",
      "5076:\tlearn: 0.0340657\ttest: 0.0383579\tbest: 0.0383579 (5073)\ttotal: 26m 6s\tremaining: 25m 19s\n",
      "5077:\tlearn: 0.0340658\ttest: 0.0383579\tbest: 0.0383579 (5077)\ttotal: 26m 6s\tremaining: 25m 18s\n",
      "5078:\tlearn: 0.0340657\ttest: 0.0383579\tbest: 0.0383579 (5078)\ttotal: 26m 7s\tremaining: 25m 18s\n",
      "5079:\tlearn: 0.0340657\ttest: 0.0383579\tbest: 0.0383579 (5079)\ttotal: 26m 7s\tremaining: 25m 18s\n",
      "5080:\tlearn: 0.0340657\ttest: 0.0383579\tbest: 0.0383579 (5079)\ttotal: 26m 7s\tremaining: 25m 17s\n",
      "5081:\tlearn: 0.0340658\ttest: 0.0383579\tbest: 0.0383579 (5081)\ttotal: 26m 7s\tremaining: 25m 17s\n",
      "5082:\tlearn: 0.0340657\ttest: 0.0383579\tbest: 0.0383579 (5082)\ttotal: 26m 8s\tremaining: 25m 16s\n",
      "5083:\tlearn: 0.0340614\ttest: 0.0383578\tbest: 0.0383578 (5083)\ttotal: 26m 8s\tremaining: 25m 16s\n",
      "5084:\tlearn: 0.0340614\ttest: 0.0383578\tbest: 0.0383578 (5084)\ttotal: 26m 8s\tremaining: 25m 16s\n",
      "5085:\tlearn: 0.0340614\ttest: 0.0383578\tbest: 0.0383578 (5084)\ttotal: 26m 9s\tremaining: 25m 15s\n",
      "5086:\tlearn: 0.0340614\ttest: 0.0383578\tbest: 0.0383578 (5084)\ttotal: 26m 9s\tremaining: 25m 15s\n",
      "5087:\tlearn: 0.0340614\ttest: 0.0383578\tbest: 0.0383578 (5087)\ttotal: 26m 9s\tremaining: 25m 15s\n",
      "5088:\tlearn: 0.0340614\ttest: 0.0383578\tbest: 0.0383578 (5087)\ttotal: 26m 9s\tremaining: 25m 14s\n",
      "5089:\tlearn: 0.0340552\ttest: 0.0383576\tbest: 0.0383576 (5089)\ttotal: 26m 10s\tremaining: 25m 14s\n",
      "5090:\tlearn: 0.0340494\ttest: 0.0383535\tbest: 0.0383535 (5090)\ttotal: 26m 10s\tremaining: 25m 14s\n",
      "5091:\tlearn: 0.0340494\ttest: 0.0383535\tbest: 0.0383535 (5090)\ttotal: 26m 10s\tremaining: 25m 13s\n",
      "5092:\tlearn: 0.0340494\ttest: 0.0383535\tbest: 0.0383535 (5092)\ttotal: 26m 10s\tremaining: 25m 13s\n",
      "5093:\tlearn: 0.0340494\ttest: 0.0383535\tbest: 0.0383535 (5093)\ttotal: 26m 11s\tremaining: 25m 13s\n",
      "5094:\tlearn: 0.0340494\ttest: 0.0383535\tbest: 0.0383535 (5093)\ttotal: 26m 11s\tremaining: 25m 12s\n",
      "5095:\tlearn: 0.0340457\ttest: 0.0383535\tbest: 0.0383535 (5095)\ttotal: 26m 11s\tremaining: 25m 12s\n",
      "5096:\tlearn: 0.0340457\ttest: 0.0383535\tbest: 0.0383535 (5096)\ttotal: 26m 11s\tremaining: 25m 12s\n",
      "5097:\tlearn: 0.0340457\ttest: 0.0383535\tbest: 0.0383535 (5097)\ttotal: 26m 12s\tremaining: 25m 11s\n",
      "5098:\tlearn: 0.0340457\ttest: 0.0383535\tbest: 0.0383535 (5097)\ttotal: 26m 12s\tremaining: 25m 11s\n",
      "5099:\tlearn: 0.0340457\ttest: 0.0383535\tbest: 0.0383535 (5097)\ttotal: 26m 12s\tremaining: 25m 11s\n",
      "5100:\tlearn: 0.0340457\ttest: 0.0383535\tbest: 0.0383535 (5100)\ttotal: 26m 13s\tremaining: 25m 10s\n",
      "5101:\tlearn: 0.0340457\ttest: 0.0383535\tbest: 0.0383535 (5100)\ttotal: 26m 13s\tremaining: 25m 10s\n",
      "5102:\tlearn: 0.0340457\ttest: 0.0383535\tbest: 0.0383535 (5102)\ttotal: 26m 13s\tremaining: 25m 10s\n",
      "5103:\tlearn: 0.0340457\ttest: 0.0383535\tbest: 0.0383535 (5102)\ttotal: 26m 14s\tremaining: 25m 10s\n",
      "5104:\tlearn: 0.0340457\ttest: 0.0383535\tbest: 0.0383535 (5104)\ttotal: 26m 14s\tremaining: 25m 9s\n",
      "5105:\tlearn: 0.0340457\ttest: 0.0383534\tbest: 0.0383534 (5105)\ttotal: 26m 15s\tremaining: 25m 9s\n",
      "5106:\tlearn: 0.0340457\ttest: 0.0383534\tbest: 0.0383534 (5106)\ttotal: 26m 15s\tremaining: 25m 9s\n",
      "5107:\tlearn: 0.0340457\ttest: 0.0383534\tbest: 0.0383534 (5106)\ttotal: 26m 16s\tremaining: 25m 9s\n",
      "5108:\tlearn: 0.0340456\ttest: 0.0383534\tbest: 0.0383534 (5106)\ttotal: 26m 16s\tremaining: 25m 9s\n",
      "5109:\tlearn: 0.0340456\ttest: 0.0383534\tbest: 0.0383534 (5106)\ttotal: 26m 17s\tremaining: 25m 9s\n",
      "5110:\tlearn: 0.0340456\ttest: 0.0383534\tbest: 0.0383534 (5110)\ttotal: 26m 17s\tremaining: 25m 8s\n",
      "5111:\tlearn: 0.0340456\ttest: 0.0383534\tbest: 0.0383534 (5111)\ttotal: 26m 17s\tremaining: 25m 8s\n",
      "5112:\tlearn: 0.0340456\ttest: 0.0383534\tbest: 0.0383534 (5111)\ttotal: 26m 17s\tremaining: 25m 8s\n",
      "5113:\tlearn: 0.0340456\ttest: 0.0383534\tbest: 0.0383534 (5113)\ttotal: 26m 18s\tremaining: 25m 7s\n",
      "5114:\tlearn: 0.0340456\ttest: 0.0383534\tbest: 0.0383534 (5114)\ttotal: 26m 18s\tremaining: 25m 7s\n",
      "5115:\tlearn: 0.0340456\ttest: 0.0383534\tbest: 0.0383534 (5114)\ttotal: 26m 18s\tremaining: 25m 7s\n",
      "5116:\tlearn: 0.0340456\ttest: 0.0383534\tbest: 0.0383534 (5116)\ttotal: 26m 18s\tremaining: 25m 6s\n",
      "5117:\tlearn: 0.0340456\ttest: 0.0383534\tbest: 0.0383534 (5116)\ttotal: 26m 19s\tremaining: 25m 6s\n",
      "5118:\tlearn: 0.0340456\ttest: 0.0383534\tbest: 0.0383534 (5118)\ttotal: 26m 19s\tremaining: 25m 6s\n",
      "5119:\tlearn: 0.0340456\ttest: 0.0383534\tbest: 0.0383534 (5118)\ttotal: 26m 19s\tremaining: 25m 5s\n",
      "5120:\tlearn: 0.0340456\ttest: 0.0383534\tbest: 0.0383534 (5120)\ttotal: 26m 19s\tremaining: 25m 5s\n",
      "5121:\tlearn: 0.0340456\ttest: 0.0383534\tbest: 0.0383534 (5121)\ttotal: 26m 20s\tremaining: 25m 4s\n",
      "5122:\tlearn: 0.0340456\ttest: 0.0383534\tbest: 0.0383534 (5122)\ttotal: 26m 20s\tremaining: 25m 4s\n",
      "5123:\tlearn: 0.0340456\ttest: 0.0383534\tbest: 0.0383534 (5123)\ttotal: 26m 20s\tremaining: 25m 4s\n",
      "5124:\tlearn: 0.0340416\ttest: 0.0383515\tbest: 0.0383515 (5124)\ttotal: 26m 21s\tremaining: 25m 3s\n",
      "5125:\tlearn: 0.0340416\ttest: 0.0383515\tbest: 0.0383515 (5125)\ttotal: 26m 21s\tremaining: 25m 3s\n",
      "5126:\tlearn: 0.0340416\ttest: 0.0383515\tbest: 0.0383515 (5126)\ttotal: 26m 21s\tremaining: 25m 3s\n",
      "5127:\tlearn: 0.0340416\ttest: 0.0383515\tbest: 0.0383515 (5127)\ttotal: 26m 21s\tremaining: 25m 2s\n",
      "5128:\tlearn: 0.0340416\ttest: 0.0383515\tbest: 0.0383515 (5128)\ttotal: 26m 22s\tremaining: 25m 2s\n",
      "5129:\tlearn: 0.0340416\ttest: 0.0383515\tbest: 0.0383515 (5129)\ttotal: 26m 22s\tremaining: 25m 2s\n",
      "5130:\tlearn: 0.0340416\ttest: 0.0383515\tbest: 0.0383515 (5129)\ttotal: 26m 22s\tremaining: 25m 1s\n",
      "5131:\tlearn: 0.0340415\ttest: 0.0383515\tbest: 0.0383515 (5129)\ttotal: 26m 22s\tremaining: 25m 1s\n",
      "5132:\tlearn: 0.0340415\ttest: 0.0383515\tbest: 0.0383515 (5132)\ttotal: 26m 23s\tremaining: 25m 1s\n",
      "5133:\tlearn: 0.0340415\ttest: 0.0383515\tbest: 0.0383515 (5133)\ttotal: 26m 23s\tremaining: 25m\n",
      "5134:\tlearn: 0.0340415\ttest: 0.0383515\tbest: 0.0383515 (5134)\ttotal: 26m 23s\tremaining: 25m\n",
      "5135:\tlearn: 0.0340414\ttest: 0.0383514\tbest: 0.0383514 (5135)\ttotal: 26m 23s\tremaining: 25m\n",
      "5136:\tlearn: 0.0340414\ttest: 0.0383514\tbest: 0.0383514 (5136)\ttotal: 26m 24s\tremaining: 24m 59s\n",
      "5137:\tlearn: 0.0340414\ttest: 0.0383514\tbest: 0.0383514 (5136)\ttotal: 26m 24s\tremaining: 24m 59s\n",
      "5138:\tlearn: 0.0340414\ttest: 0.0383514\tbest: 0.0383514 (5136)\ttotal: 26m 24s\tremaining: 24m 59s\n",
      "5139:\tlearn: 0.0340414\ttest: 0.0383514\tbest: 0.0383514 (5136)\ttotal: 26m 25s\tremaining: 24m 58s\n",
      "5140:\tlearn: 0.0340414\ttest: 0.0383514\tbest: 0.0383514 (5136)\ttotal: 26m 25s\tremaining: 24m 58s\n",
      "5141:\tlearn: 0.0340414\ttest: 0.0383514\tbest: 0.0383514 (5141)\ttotal: 26m 25s\tremaining: 24m 57s\n",
      "5142:\tlearn: 0.0340369\ttest: 0.0383507\tbest: 0.0383507 (5142)\ttotal: 26m 25s\tremaining: 24m 57s\n",
      "5143:\tlearn: 0.0340369\ttest: 0.0383507\tbest: 0.0383507 (5143)\ttotal: 26m 26s\tremaining: 24m 57s\n",
      "5144:\tlearn: 0.0340369\ttest: 0.0383507\tbest: 0.0383507 (5144)\ttotal: 26m 26s\tremaining: 24m 56s\n",
      "5145:\tlearn: 0.0340369\ttest: 0.0383507\tbest: 0.0383507 (5145)\ttotal: 26m 26s\tremaining: 24m 56s\n",
      "5146:\tlearn: 0.0340369\ttest: 0.0383507\tbest: 0.0383507 (5146)\ttotal: 26m 26s\tremaining: 24m 56s\n",
      "5147:\tlearn: 0.0340368\ttest: 0.0383507\tbest: 0.0383507 (5146)\ttotal: 26m 27s\tremaining: 24m 55s\n",
      "5148:\tlearn: 0.0340368\ttest: 0.0383507\tbest: 0.0383507 (5148)\ttotal: 26m 27s\tremaining: 24m 55s\n",
      "5149:\tlearn: 0.0340368\ttest: 0.0383507\tbest: 0.0383507 (5148)\ttotal: 26m 27s\tremaining: 24m 55s\n",
      "5150:\tlearn: 0.0340368\ttest: 0.0383507\tbest: 0.0383507 (5150)\ttotal: 26m 28s\tremaining: 24m 55s\n",
      "5151:\tlearn: 0.0340368\ttest: 0.0383507\tbest: 0.0383507 (5150)\ttotal: 26m 28s\tremaining: 24m 55s\n",
      "5152:\tlearn: 0.0340368\ttest: 0.0383507\tbest: 0.0383507 (5152)\ttotal: 26m 29s\tremaining: 24m 54s\n",
      "5153:\tlearn: 0.0340368\ttest: 0.0383507\tbest: 0.0383507 (5152)\ttotal: 26m 29s\tremaining: 24m 54s\n",
      "5154:\tlearn: 0.0340368\ttest: 0.0383507\tbest: 0.0383507 (5154)\ttotal: 26m 30s\tremaining: 24m 54s\n",
      "5155:\tlearn: 0.0340368\ttest: 0.0383507\tbest: 0.0383507 (5155)\ttotal: 26m 30s\tremaining: 24m 54s\n",
      "5156:\tlearn: 0.0340329\ttest: 0.0383499\tbest: 0.0383499 (5156)\ttotal: 26m 31s\tremaining: 24m 54s\n",
      "5157:\tlearn: 0.0340299\ttest: 0.0383503\tbest: 0.0383499 (5156)\ttotal: 26m 31s\tremaining: 24m 54s\n",
      "5158:\tlearn: 0.0340299\ttest: 0.0383503\tbest: 0.0383499 (5156)\ttotal: 26m 31s\tremaining: 24m 53s\n",
      "5159:\tlearn: 0.0340299\ttest: 0.0383503\tbest: 0.0383499 (5156)\ttotal: 26m 32s\tremaining: 24m 53s\n",
      "5160:\tlearn: 0.0340272\ttest: 0.0383498\tbest: 0.0383498 (5160)\ttotal: 26m 32s\tremaining: 24m 52s\n",
      "5161:\tlearn: 0.0340272\ttest: 0.0383498\tbest: 0.0383498 (5160)\ttotal: 26m 32s\tremaining: 24m 52s\n",
      "5162:\tlearn: 0.0340272\ttest: 0.0383498\tbest: 0.0383498 (5162)\ttotal: 26m 32s\tremaining: 24m 52s\n",
      "5163:\tlearn: 0.0340272\ttest: 0.0383498\tbest: 0.0383498 (5163)\ttotal: 26m 33s\tremaining: 24m 51s\n",
      "5164:\tlearn: 0.0340272\ttest: 0.0383498\tbest: 0.0383498 (5164)\ttotal: 26m 33s\tremaining: 24m 51s\n",
      "5165:\tlearn: 0.0340272\ttest: 0.0383498\tbest: 0.0383498 (5165)\ttotal: 26m 33s\tremaining: 24m 51s\n",
      "5166:\tlearn: 0.0340272\ttest: 0.0383498\tbest: 0.0383498 (5166)\ttotal: 26m 33s\tremaining: 24m 50s\n",
      "5167:\tlearn: 0.0340272\ttest: 0.0383498\tbest: 0.0383498 (5167)\ttotal: 26m 34s\tremaining: 24m 50s\n",
      "5168:\tlearn: 0.0340271\ttest: 0.0383498\tbest: 0.0383498 (5167)\ttotal: 26m 34s\tremaining: 24m 50s\n",
      "5169:\tlearn: 0.0340271\ttest: 0.0383498\tbest: 0.0383498 (5167)\ttotal: 26m 34s\tremaining: 24m 49s\n",
      "5170:\tlearn: 0.0340271\ttest: 0.0383498\tbest: 0.0383498 (5167)\ttotal: 26m 34s\tremaining: 24m 49s\n",
      "5171:\tlearn: 0.0340271\ttest: 0.0383498\tbest: 0.0383498 (5167)\ttotal: 26m 35s\tremaining: 24m 49s\n",
      "5172:\tlearn: 0.0340271\ttest: 0.0383498\tbest: 0.0383498 (5167)\ttotal: 26m 35s\tremaining: 24m 48s\n",
      "5173:\tlearn: 0.0340271\ttest: 0.0383498\tbest: 0.0383498 (5167)\ttotal: 26m 35s\tremaining: 24m 48s\n",
      "5174:\tlearn: 0.0340271\ttest: 0.0383498\tbest: 0.0383498 (5167)\ttotal: 26m 35s\tremaining: 24m 47s\n",
      "5175:\tlearn: 0.0340271\ttest: 0.0383498\tbest: 0.0383498 (5167)\ttotal: 26m 36s\tremaining: 24m 47s\n",
      "5176:\tlearn: 0.0340271\ttest: 0.0383498\tbest: 0.0383498 (5167)\ttotal: 26m 36s\tremaining: 24m 47s\n",
      "5177:\tlearn: 0.0340271\ttest: 0.0383498\tbest: 0.0383498 (5167)\ttotal: 26m 36s\tremaining: 24m 46s\n",
      "5178:\tlearn: 0.0340271\ttest: 0.0383498\tbest: 0.0383498 (5167)\ttotal: 26m 36s\tremaining: 24m 46s\n",
      "5179:\tlearn: 0.0340271\ttest: 0.0383498\tbest: 0.0383498 (5167)\ttotal: 26m 37s\tremaining: 24m 46s\n",
      "5180:\tlearn: 0.0340271\ttest: 0.0383498\tbest: 0.0383498 (5167)\ttotal: 26m 37s\tremaining: 24m 45s\n",
      "5181:\tlearn: 0.0340271\ttest: 0.0383498\tbest: 0.0383498 (5167)\ttotal: 26m 37s\tremaining: 24m 45s\n",
      "5182:\tlearn: 0.0340271\ttest: 0.0383498\tbest: 0.0383498 (5167)\ttotal: 26m 38s\tremaining: 24m 45s\n",
      "5183:\tlearn: 0.0340271\ttest: 0.0383498\tbest: 0.0383498 (5167)\ttotal: 26m 38s\tremaining: 24m 44s\n",
      "5184:\tlearn: 0.0340270\ttest: 0.0383498\tbest: 0.0383498 (5167)\ttotal: 26m 38s\tremaining: 24m 44s\n",
      "5185:\tlearn: 0.0340270\ttest: 0.0383498\tbest: 0.0383498 (5167)\ttotal: 26m 38s\tremaining: 24m 44s\n",
      "5186:\tlearn: 0.0340270\ttest: 0.0383498\tbest: 0.0383498 (5167)\ttotal: 26m 39s\tremaining: 24m 43s\n",
      "5187:\tlearn: 0.0340238\ttest: 0.0383489\tbest: 0.0383489 (5187)\ttotal: 26m 39s\tremaining: 24m 43s\n",
      "5188:\tlearn: 0.0340237\ttest: 0.0383489\tbest: 0.0383489 (5188)\ttotal: 26m 39s\tremaining: 24m 43s\n",
      "5189:\tlearn: 0.0340179\ttest: 0.0383479\tbest: 0.0383479 (5189)\ttotal: 26m 39s\tremaining: 24m 42s\n",
      "5190:\tlearn: 0.0340179\ttest: 0.0383479\tbest: 0.0383479 (5190)\ttotal: 26m 40s\tremaining: 24m 42s\n",
      "5191:\tlearn: 0.0340179\ttest: 0.0383479\tbest: 0.0383479 (5190)\ttotal: 26m 40s\tremaining: 24m 42s\n",
      "5192:\tlearn: 0.0340179\ttest: 0.0383479\tbest: 0.0383479 (5190)\ttotal: 26m 40s\tremaining: 24m 41s\n",
      "5193:\tlearn: 0.0340179\ttest: 0.0383479\tbest: 0.0383479 (5193)\ttotal: 26m 41s\tremaining: 24m 41s\n",
      "5194:\tlearn: 0.0340179\ttest: 0.0383479\tbest: 0.0383479 (5194)\ttotal: 26m 41s\tremaining: 24m 41s\n",
      "5195:\tlearn: 0.0340179\ttest: 0.0383479\tbest: 0.0383479 (5195)\ttotal: 26m 41s\tremaining: 24m 40s\n",
      "5196:\tlearn: 0.0340179\ttest: 0.0383479\tbest: 0.0383479 (5196)\ttotal: 26m 42s\tremaining: 24m 40s\n",
      "5197:\tlearn: 0.0340179\ttest: 0.0383479\tbest: 0.0383479 (5197)\ttotal: 26m 42s\tremaining: 24m 40s\n",
      "5198:\tlearn: 0.0340179\ttest: 0.0383479\tbest: 0.0383479 (5198)\ttotal: 26m 43s\tremaining: 24m 40s\n",
      "5199:\tlearn: 0.0340179\ttest: 0.0383479\tbest: 0.0383479 (5199)\ttotal: 26m 43s\tremaining: 24m 40s\n",
      "5200:\tlearn: 0.0340179\ttest: 0.0383479\tbest: 0.0383479 (5199)\ttotal: 26m 44s\tremaining: 24m 40s\n",
      "5201:\tlearn: 0.0340179\ttest: 0.0383479\tbest: 0.0383479 (5201)\ttotal: 26m 44s\tremaining: 24m 39s\n",
      "5202:\tlearn: 0.0340178\ttest: 0.0383479\tbest: 0.0383479 (5201)\ttotal: 26m 44s\tremaining: 24m 39s\n",
      "5203:\tlearn: 0.0340179\ttest: 0.0383479\tbest: 0.0383479 (5201)\ttotal: 26m 45s\tremaining: 24m 39s\n",
      "5204:\tlearn: 0.0340178\ttest: 0.0383479\tbest: 0.0383479 (5204)\ttotal: 26m 45s\tremaining: 24m 39s\n",
      "5205:\tlearn: 0.0340178\ttest: 0.0383479\tbest: 0.0383479 (5204)\ttotal: 26m 45s\tremaining: 24m 38s\n",
      "5206:\tlearn: 0.0340178\ttest: 0.0383478\tbest: 0.0383478 (5206)\ttotal: 26m 46s\tremaining: 24m 38s\n",
      "5207:\tlearn: 0.0340178\ttest: 0.0383478\tbest: 0.0383478 (5207)\ttotal: 26m 46s\tremaining: 24m 38s\n",
      "5208:\tlearn: 0.0340145\ttest: 0.0383467\tbest: 0.0383467 (5208)\ttotal: 26m 46s\tremaining: 24m 37s\n",
      "5209:\tlearn: 0.0340145\ttest: 0.0383467\tbest: 0.0383467 (5208)\ttotal: 26m 47s\tremaining: 24m 37s\n",
      "5210:\tlearn: 0.0340145\ttest: 0.0383467\tbest: 0.0383467 (5210)\ttotal: 26m 47s\tremaining: 24m 37s\n",
      "5211:\tlearn: 0.0340145\ttest: 0.0383467\tbest: 0.0383467 (5211)\ttotal: 26m 47s\tremaining: 24m 36s\n",
      "5212:\tlearn: 0.0340145\ttest: 0.0383467\tbest: 0.0383467 (5212)\ttotal: 26m 47s\tremaining: 24m 36s\n",
      "5213:\tlearn: 0.0340145\ttest: 0.0383467\tbest: 0.0383467 (5212)\ttotal: 26m 48s\tremaining: 24m 36s\n",
      "5214:\tlearn: 0.0340145\ttest: 0.0383467\tbest: 0.0383467 (5212)\ttotal: 26m 48s\tremaining: 24m 35s\n",
      "5215:\tlearn: 0.0340145\ttest: 0.0383467\tbest: 0.0383467 (5215)\ttotal: 26m 48s\tremaining: 24m 35s\n",
      "5216:\tlearn: 0.0340145\ttest: 0.0383467\tbest: 0.0383467 (5216)\ttotal: 26m 48s\tremaining: 24m 34s\n",
      "5217:\tlearn: 0.0340145\ttest: 0.0383467\tbest: 0.0383467 (5216)\ttotal: 26m 49s\tremaining: 24m 34s\n",
      "5218:\tlearn: 0.0340145\ttest: 0.0383467\tbest: 0.0383467 (5218)\ttotal: 26m 49s\tremaining: 24m 34s\n",
      "5219:\tlearn: 0.0340145\ttest: 0.0383467\tbest: 0.0383467 (5218)\ttotal: 26m 49s\tremaining: 24m 33s\n",
      "5220:\tlearn: 0.0340145\ttest: 0.0383466\tbest: 0.0383466 (5220)\ttotal: 26m 49s\tremaining: 24m 33s\n",
      "5221:\tlearn: 0.0340144\ttest: 0.0383466\tbest: 0.0383466 (5221)\ttotal: 26m 50s\tremaining: 24m 33s\n",
      "5222:\tlearn: 0.0340144\ttest: 0.0383466\tbest: 0.0383466 (5222)\ttotal: 26m 50s\tremaining: 24m 32s\n",
      "5223:\tlearn: 0.0340114\ttest: 0.0383466\tbest: 0.0383466 (5222)\ttotal: 26m 50s\tremaining: 24m 32s\n",
      "5224:\tlearn: 0.0340114\ttest: 0.0383466\tbest: 0.0383466 (5224)\ttotal: 26m 50s\tremaining: 24m 32s\n",
      "5225:\tlearn: 0.0340114\ttest: 0.0383466\tbest: 0.0383466 (5224)\ttotal: 26m 51s\tremaining: 24m 31s\n",
      "5226:\tlearn: 0.0340072\ttest: 0.0383450\tbest: 0.0383450 (5226)\ttotal: 26m 51s\tremaining: 24m 31s\n",
      "5227:\tlearn: 0.0340072\ttest: 0.0383450\tbest: 0.0383450 (5227)\ttotal: 26m 51s\tremaining: 24m 31s\n",
      "5228:\tlearn: 0.0340072\ttest: 0.0383450\tbest: 0.0383450 (5228)\ttotal: 26m 52s\tremaining: 24m 30s\n",
      "5229:\tlearn: 0.0340072\ttest: 0.0383450\tbest: 0.0383450 (5229)\ttotal: 26m 52s\tremaining: 24m 30s\n",
      "5230:\tlearn: 0.0340072\ttest: 0.0383450\tbest: 0.0383450 (5230)\ttotal: 26m 52s\tremaining: 24m 30s\n",
      "5231:\tlearn: 0.0340072\ttest: 0.0383450\tbest: 0.0383450 (5230)\ttotal: 26m 52s\tremaining: 24m 29s\n",
      "5232:\tlearn: 0.0340072\ttest: 0.0383450\tbest: 0.0383450 (5230)\ttotal: 26m 53s\tremaining: 24m 29s\n",
      "5233:\tlearn: 0.0340072\ttest: 0.0383450\tbest: 0.0383450 (5230)\ttotal: 26m 53s\tremaining: 24m 29s\n",
      "5234:\tlearn: 0.0340072\ttest: 0.0383450\tbest: 0.0383450 (5230)\ttotal: 26m 53s\tremaining: 24m 28s\n",
      "5235:\tlearn: 0.0340045\ttest: 0.0383451\tbest: 0.0383450 (5230)\ttotal: 26m 53s\tremaining: 24m 28s\n",
      "5236:\tlearn: 0.0340045\ttest: 0.0383451\tbest: 0.0383450 (5230)\ttotal: 26m 54s\tremaining: 24m 28s\n",
      "5237:\tlearn: 0.0340045\ttest: 0.0383451\tbest: 0.0383450 (5230)\ttotal: 26m 54s\tremaining: 24m 27s\n",
      "5238:\tlearn: 0.0340045\ttest: 0.0383451\tbest: 0.0383450 (5230)\ttotal: 26m 54s\tremaining: 24m 27s\n",
      "5239:\tlearn: 0.0340044\ttest: 0.0383451\tbest: 0.0383450 (5230)\ttotal: 26m 54s\tremaining: 24m 26s\n",
      "5240:\tlearn: 0.0340044\ttest: 0.0383451\tbest: 0.0383450 (5230)\ttotal: 26m 55s\tremaining: 24m 26s\n",
      "5241:\tlearn: 0.0340044\ttest: 0.0383451\tbest: 0.0383450 (5230)\ttotal: 26m 55s\tremaining: 24m 26s\n",
      "5242:\tlearn: 0.0340000\ttest: 0.0383425\tbest: 0.0383425 (5242)\ttotal: 26m 55s\tremaining: 24m 26s\n",
      "5243:\tlearn: 0.0339949\ttest: 0.0383407\tbest: 0.0383407 (5243)\ttotal: 26m 56s\tremaining: 24m 26s\n",
      "5244:\tlearn: 0.0339910\ttest: 0.0383412\tbest: 0.0383407 (5243)\ttotal: 26m 57s\tremaining: 24m 26s\n",
      "5245:\tlearn: 0.0339910\ttest: 0.0383412\tbest: 0.0383407 (5243)\ttotal: 26m 57s\tremaining: 24m 25s\n",
      "5246:\tlearn: 0.0339910\ttest: 0.0383412\tbest: 0.0383407 (5243)\ttotal: 26m 58s\tremaining: 24m 25s\n",
      "5247:\tlearn: 0.0339910\ttest: 0.0383412\tbest: 0.0383407 (5243)\ttotal: 26m 58s\tremaining: 24m 25s\n",
      "5248:\tlearn: 0.0339867\ttest: 0.0383379\tbest: 0.0383379 (5248)\ttotal: 26m 59s\tremaining: 24m 25s\n",
      "5249:\tlearn: 0.0339867\ttest: 0.0383379\tbest: 0.0383379 (5249)\ttotal: 26m 59s\tremaining: 24m 25s\n",
      "5250:\tlearn: 0.0339867\ttest: 0.0383379\tbest: 0.0383379 (5249)\ttotal: 27m\tremaining: 24m 25s\n",
      "5251:\tlearn: 0.0339866\ttest: 0.0383378\tbest: 0.0383378 (5251)\ttotal: 27m\tremaining: 24m 25s\n",
      "5252:\tlearn: 0.0339826\ttest: 0.0383377\tbest: 0.0383377 (5252)\ttotal: 27m 1s\tremaining: 24m 25s\n",
      "5253:\tlearn: 0.0339826\ttest: 0.0383377\tbest: 0.0383377 (5252)\ttotal: 27m 1s\tremaining: 24m 24s\n",
      "5254:\tlearn: 0.0339826\ttest: 0.0383377\tbest: 0.0383377 (5252)\ttotal: 27m 2s\tremaining: 24m 24s\n",
      "5255:\tlearn: 0.0339826\ttest: 0.0383377\tbest: 0.0383377 (5252)\ttotal: 27m 2s\tremaining: 24m 24s\n",
      "5256:\tlearn: 0.0339826\ttest: 0.0383377\tbest: 0.0383377 (5256)\ttotal: 27m 3s\tremaining: 24m 24s\n",
      "5257:\tlearn: 0.0339826\ttest: 0.0383377\tbest: 0.0383377 (5257)\ttotal: 27m 3s\tremaining: 24m 23s\n",
      "5258:\tlearn: 0.0339826\ttest: 0.0383377\tbest: 0.0383377 (5258)\ttotal: 27m 3s\tremaining: 24m 23s\n",
      "5259:\tlearn: 0.0339826\ttest: 0.0383377\tbest: 0.0383377 (5259)\ttotal: 27m 3s\tremaining: 24m 23s\n",
      "5260:\tlearn: 0.0339826\ttest: 0.0383377\tbest: 0.0383377 (5259)\ttotal: 27m 4s\tremaining: 24m 22s\n",
      "5261:\tlearn: 0.0339826\ttest: 0.0383377\tbest: 0.0383377 (5259)\ttotal: 27m 4s\tremaining: 24m 22s\n",
      "5262:\tlearn: 0.0339826\ttest: 0.0383377\tbest: 0.0383377 (5262)\ttotal: 27m 4s\tremaining: 24m 22s\n",
      "5263:\tlearn: 0.0339826\ttest: 0.0383377\tbest: 0.0383377 (5263)\ttotal: 27m 4s\tremaining: 24m 21s\n",
      "5264:\tlearn: 0.0339776\ttest: 0.0383354\tbest: 0.0383354 (5264)\ttotal: 27m 5s\tremaining: 24m 21s\n",
      "5265:\tlearn: 0.0339776\ttest: 0.0383354\tbest: 0.0383354 (5265)\ttotal: 27m 5s\tremaining: 24m 21s\n",
      "5266:\tlearn: 0.0339776\ttest: 0.0383354\tbest: 0.0383354 (5266)\ttotal: 27m 5s\tremaining: 24m 20s\n",
      "5267:\tlearn: 0.0339776\ttest: 0.0383354\tbest: 0.0383354 (5267)\ttotal: 27m 5s\tremaining: 24m 20s\n",
      "5268:\tlearn: 0.0339776\ttest: 0.0383354\tbest: 0.0383354 (5268)\ttotal: 27m 6s\tremaining: 24m 20s\n",
      "5269:\tlearn: 0.0339775\ttest: 0.0383354\tbest: 0.0383354 (5269)\ttotal: 27m 6s\tremaining: 24m 19s\n",
      "5270:\tlearn: 0.0339738\ttest: 0.0383348\tbest: 0.0383348 (5270)\ttotal: 27m 6s\tremaining: 24m 19s\n",
      "5271:\tlearn: 0.0339738\ttest: 0.0383348\tbest: 0.0383348 (5270)\ttotal: 27m 6s\tremaining: 24m 19s\n",
      "5272:\tlearn: 0.0339738\ttest: 0.0383348\tbest: 0.0383348 (5270)\ttotal: 27m 7s\tremaining: 24m 18s\n",
      "5273:\tlearn: 0.0339738\ttest: 0.0383348\tbest: 0.0383348 (5273)\ttotal: 27m 7s\tremaining: 24m 18s\n",
      "5274:\tlearn: 0.0339738\ttest: 0.0383348\tbest: 0.0383348 (5274)\ttotal: 27m 7s\tremaining: 24m 18s\n",
      "5275:\tlearn: 0.0339738\ttest: 0.0383348\tbest: 0.0383348 (5275)\ttotal: 27m 7s\tremaining: 24m 17s\n",
      "5276:\tlearn: 0.0339738\ttest: 0.0383348\tbest: 0.0383348 (5276)\ttotal: 27m 8s\tremaining: 24m 17s\n",
      "5277:\tlearn: 0.0339685\ttest: 0.0383335\tbest: 0.0383335 (5277)\ttotal: 27m 8s\tremaining: 24m 17s\n",
      "5278:\tlearn: 0.0339685\ttest: 0.0383335\tbest: 0.0383335 (5278)\ttotal: 27m 8s\tremaining: 24m 16s\n",
      "5279:\tlearn: 0.0339685\ttest: 0.0383334\tbest: 0.0383334 (5279)\ttotal: 27m 9s\tremaining: 24m 16s\n",
      "5280:\tlearn: 0.0339684\ttest: 0.0383334\tbest: 0.0383334 (5280)\ttotal: 27m 9s\tremaining: 24m 15s\n",
      "5281:\tlearn: 0.0339685\ttest: 0.0383334\tbest: 0.0383334 (5281)\ttotal: 27m 9s\tremaining: 24m 15s\n",
      "5282:\tlearn: 0.0339685\ttest: 0.0383334\tbest: 0.0383334 (5281)\ttotal: 27m 9s\tremaining: 24m 15s\n",
      "5283:\tlearn: 0.0339685\ttest: 0.0383334\tbest: 0.0383334 (5283)\ttotal: 27m 10s\tremaining: 24m 14s\n",
      "5284:\tlearn: 0.0339685\ttest: 0.0383334\tbest: 0.0383334 (5283)\ttotal: 27m 10s\tremaining: 24m 14s\n",
      "5285:\tlearn: 0.0339685\ttest: 0.0383334\tbest: 0.0383334 (5283)\ttotal: 27m 10s\tremaining: 24m 14s\n",
      "5286:\tlearn: 0.0339684\ttest: 0.0383334\tbest: 0.0383334 (5286)\ttotal: 27m 10s\tremaining: 24m 13s\n",
      "5287:\tlearn: 0.0339684\ttest: 0.0383334\tbest: 0.0383334 (5286)\ttotal: 27m 11s\tremaining: 24m 13s\n",
      "5288:\tlearn: 0.0339684\ttest: 0.0383334\tbest: 0.0383334 (5288)\ttotal: 27m 11s\tremaining: 24m 13s\n",
      "5289:\tlearn: 0.0339684\ttest: 0.0383334\tbest: 0.0383334 (5289)\ttotal: 27m 11s\tremaining: 24m 12s\n",
      "5290:\tlearn: 0.0339684\ttest: 0.0383334\tbest: 0.0383334 (5289)\ttotal: 27m 11s\tremaining: 24m 12s\n",
      "5291:\tlearn: 0.0339684\ttest: 0.0383334\tbest: 0.0383334 (5291)\ttotal: 27m 12s\tremaining: 24m 12s\n",
      "5292:\tlearn: 0.0339682\ttest: 0.0383333\tbest: 0.0383333 (5292)\ttotal: 27m 12s\tremaining: 24m 11s\n",
      "5293:\tlearn: 0.0339646\ttest: 0.0383322\tbest: 0.0383322 (5293)\ttotal: 27m 12s\tremaining: 24m 11s\n",
      "5294:\tlearn: 0.0339646\ttest: 0.0383322\tbest: 0.0383322 (5294)\ttotal: 27m 13s\tremaining: 24m 11s\n",
      "5295:\tlearn: 0.0339646\ttest: 0.0383322\tbest: 0.0383322 (5295)\ttotal: 27m 13s\tremaining: 24m 11s\n",
      "5296:\tlearn: 0.0339646\ttest: 0.0383322\tbest: 0.0383322 (5296)\ttotal: 27m 14s\tremaining: 24m 11s\n",
      "5297:\tlearn: 0.0339646\ttest: 0.0383322\tbest: 0.0383322 (5296)\ttotal: 27m 14s\tremaining: 24m 10s\n",
      "5298:\tlearn: 0.0339646\ttest: 0.0383322\tbest: 0.0383322 (5298)\ttotal: 27m 15s\tremaining: 24m 10s\n",
      "5299:\tlearn: 0.0339588\ttest: 0.0383297\tbest: 0.0383297 (5299)\ttotal: 27m 15s\tremaining: 24m 10s\n",
      "5300:\tlearn: 0.0339572\ttest: 0.0383300\tbest: 0.0383297 (5299)\ttotal: 27m 16s\tremaining: 24m 10s\n",
      "5301:\tlearn: 0.0339572\ttest: 0.0383300\tbest: 0.0383297 (5299)\ttotal: 27m 16s\tremaining: 24m 10s\n",
      "5302:\tlearn: 0.0339572\ttest: 0.0383300\tbest: 0.0383297 (5299)\ttotal: 27m 16s\tremaining: 24m 9s\n",
      "5303:\tlearn: 0.0339572\ttest: 0.0383300\tbest: 0.0383297 (5299)\ttotal: 27m 17s\tremaining: 24m 9s\n",
      "5304:\tlearn: 0.0339572\ttest: 0.0383300\tbest: 0.0383297 (5299)\ttotal: 27m 17s\tremaining: 24m 9s\n",
      "5305:\tlearn: 0.0339509\ttest: 0.0383295\tbest: 0.0383295 (5305)\ttotal: 27m 17s\tremaining: 24m 8s\n",
      "5306:\tlearn: 0.0339509\ttest: 0.0383295\tbest: 0.0383295 (5305)\ttotal: 27m 17s\tremaining: 24m 8s\n",
      "5307:\tlearn: 0.0339509\ttest: 0.0383295\tbest: 0.0383295 (5305)\ttotal: 27m 18s\tremaining: 24m 8s\n",
      "5308:\tlearn: 0.0339476\ttest: 0.0383289\tbest: 0.0383289 (5308)\ttotal: 27m 18s\tremaining: 24m 7s\n",
      "5309:\tlearn: 0.0339475\ttest: 0.0383289\tbest: 0.0383289 (5309)\ttotal: 27m 18s\tremaining: 24m 7s\n",
      "5310:\tlearn: 0.0339475\ttest: 0.0383289\tbest: 0.0383289 (5310)\ttotal: 27m 18s\tremaining: 24m 7s\n",
      "5311:\tlearn: 0.0339475\ttest: 0.0383289\tbest: 0.0383289 (5310)\ttotal: 27m 19s\tremaining: 24m 6s\n",
      "5312:\tlearn: 0.0339475\ttest: 0.0383289\tbest: 0.0383289 (5312)\ttotal: 27m 19s\tremaining: 24m 6s\n",
      "5313:\tlearn: 0.0339475\ttest: 0.0383289\tbest: 0.0383289 (5312)\ttotal: 27m 19s\tremaining: 24m 5s\n",
      "5314:\tlearn: 0.0339475\ttest: 0.0383289\tbest: 0.0383289 (5312)\ttotal: 27m 20s\tremaining: 24m 5s\n",
      "5315:\tlearn: 0.0339475\ttest: 0.0383289\tbest: 0.0383289 (5315)\ttotal: 27m 20s\tremaining: 24m 5s\n",
      "5316:\tlearn: 0.0339475\ttest: 0.0383289\tbest: 0.0383289 (5316)\ttotal: 27m 20s\tremaining: 24m 4s\n",
      "5317:\tlearn: 0.0339475\ttest: 0.0383289\tbest: 0.0383289 (5317)\ttotal: 27m 20s\tremaining: 24m 4s\n",
      "5318:\tlearn: 0.0339475\ttest: 0.0383289\tbest: 0.0383289 (5317)\ttotal: 27m 21s\tremaining: 24m 4s\n",
      "5319:\tlearn: 0.0339475\ttest: 0.0383289\tbest: 0.0383289 (5319)\ttotal: 27m 21s\tremaining: 24m 3s\n",
      "5320:\tlearn: 0.0339475\ttest: 0.0383289\tbest: 0.0383289 (5319)\ttotal: 27m 21s\tremaining: 24m 3s\n",
      "5321:\tlearn: 0.0339475\ttest: 0.0383289\tbest: 0.0383289 (5321)\ttotal: 27m 21s\tremaining: 24m 3s\n",
      "5322:\tlearn: 0.0339475\ttest: 0.0383289\tbest: 0.0383289 (5321)\ttotal: 27m 22s\tremaining: 24m 2s\n",
      "5323:\tlearn: 0.0339475\ttest: 0.0383289\tbest: 0.0383289 (5323)\ttotal: 27m 22s\tremaining: 24m 2s\n",
      "5324:\tlearn: 0.0339400\ttest: 0.0383241\tbest: 0.0383241 (5324)\ttotal: 27m 22s\tremaining: 24m 2s\n",
      "5325:\tlearn: 0.0339400\ttest: 0.0383241\tbest: 0.0383241 (5325)\ttotal: 27m 22s\tremaining: 24m 1s\n",
      "5326:\tlearn: 0.0339400\ttest: 0.0383241\tbest: 0.0383241 (5325)\ttotal: 27m 23s\tremaining: 24m 1s\n",
      "5327:\tlearn: 0.0339400\ttest: 0.0383241\tbest: 0.0383241 (5327)\ttotal: 27m 23s\tremaining: 24m 1s\n",
      "5328:\tlearn: 0.0339400\ttest: 0.0383241\tbest: 0.0383241 (5328)\ttotal: 27m 23s\tremaining: 24m\n",
      "5329:\tlearn: 0.0339400\ttest: 0.0383241\tbest: 0.0383241 (5329)\ttotal: 27m 23s\tremaining: 24m\n",
      "5330:\tlearn: 0.0339400\ttest: 0.0383241\tbest: 0.0383241 (5329)\ttotal: 27m 24s\tremaining: 24m\n",
      "5331:\tlearn: 0.0339400\ttest: 0.0383241\tbest: 0.0383241 (5331)\ttotal: 27m 24s\tremaining: 23m 59s\n",
      "5332:\tlearn: 0.0339400\ttest: 0.0383241\tbest: 0.0383241 (5331)\ttotal: 27m 24s\tremaining: 23m 59s\n",
      "5333:\tlearn: 0.0339382\ttest: 0.0383246\tbest: 0.0383241 (5331)\ttotal: 27m 25s\tremaining: 23m 59s\n",
      "5334:\tlearn: 0.0339382\ttest: 0.0383246\tbest: 0.0383241 (5331)\ttotal: 27m 25s\tremaining: 23m 58s\n",
      "5335:\tlearn: 0.0339382\ttest: 0.0383246\tbest: 0.0383241 (5331)\ttotal: 27m 25s\tremaining: 23m 58s\n",
      "5336:\tlearn: 0.0339382\ttest: 0.0383246\tbest: 0.0383241 (5331)\ttotal: 27m 25s\tremaining: 23m 57s\n",
      "5337:\tlearn: 0.0339350\ttest: 0.0383242\tbest: 0.0383241 (5331)\ttotal: 27m 26s\tremaining: 23m 57s\n",
      "5338:\tlearn: 0.0339350\ttest: 0.0383242\tbest: 0.0383241 (5331)\ttotal: 27m 26s\tremaining: 23m 57s\n",
      "5339:\tlearn: 0.0339350\ttest: 0.0383242\tbest: 0.0383241 (5331)\ttotal: 27m 26s\tremaining: 23m 56s\n",
      "5340:\tlearn: 0.0339317\ttest: 0.0383243\tbest: 0.0383241 (5331)\ttotal: 27m 27s\tremaining: 23m 56s\n",
      "5341:\tlearn: 0.0339317\ttest: 0.0383243\tbest: 0.0383241 (5331)\ttotal: 27m 27s\tremaining: 23m 56s\n",
      "5342:\tlearn: 0.0339317\ttest: 0.0383243\tbest: 0.0383241 (5331)\ttotal: 27m 27s\tremaining: 23m 56s\n",
      "5343:\tlearn: 0.0339317\ttest: 0.0383243\tbest: 0.0383241 (5331)\ttotal: 27m 28s\tremaining: 23m 56s\n",
      "5344:\tlearn: 0.0339283\ttest: 0.0383228\tbest: 0.0383228 (5344)\ttotal: 27m 28s\tremaining: 23m 56s\n",
      "5345:\tlearn: 0.0339262\ttest: 0.0383230\tbest: 0.0383228 (5344)\ttotal: 27m 29s\tremaining: 23m 55s\n",
      "5346:\tlearn: 0.0339262\ttest: 0.0383230\tbest: 0.0383228 (5344)\ttotal: 27m 29s\tremaining: 23m 55s\n",
      "5347:\tlearn: 0.0339262\ttest: 0.0383230\tbest: 0.0383228 (5344)\ttotal: 27m 30s\tremaining: 23m 55s\n",
      "5348:\tlearn: 0.0339262\ttest: 0.0383230\tbest: 0.0383228 (5344)\ttotal: 27m 30s\tremaining: 23m 55s\n",
      "5349:\tlearn: 0.0339225\ttest: 0.0383223\tbest: 0.0383223 (5349)\ttotal: 27m 31s\tremaining: 23m 55s\n",
      "5350:\tlearn: 0.0339225\ttest: 0.0383223\tbest: 0.0383223 (5350)\ttotal: 27m 31s\tremaining: 23m 54s\n",
      "5351:\tlearn: 0.0339225\ttest: 0.0383223\tbest: 0.0383223 (5350)\ttotal: 27m 31s\tremaining: 23m 54s\n",
      "5352:\tlearn: 0.0339225\ttest: 0.0383223\tbest: 0.0383223 (5350)\ttotal: 27m 31s\tremaining: 23m 53s\n",
      "5353:\tlearn: 0.0339195\ttest: 0.0383220\tbest: 0.0383220 (5353)\ttotal: 27m 32s\tremaining: 23m 53s\n",
      "5354:\tlearn: 0.0339195\ttest: 0.0383220\tbest: 0.0383220 (5354)\ttotal: 27m 32s\tremaining: 23m 53s\n",
      "5355:\tlearn: 0.0339195\ttest: 0.0383220\tbest: 0.0383220 (5354)\ttotal: 27m 32s\tremaining: 23m 52s\n",
      "5356:\tlearn: 0.0339138\ttest: 0.0383199\tbest: 0.0383199 (5356)\ttotal: 27m 32s\tremaining: 23m 52s\n",
      "5357:\tlearn: 0.0339138\ttest: 0.0383199\tbest: 0.0383199 (5356)\ttotal: 27m 33s\tremaining: 23m 52s\n",
      "5358:\tlearn: 0.0339137\ttest: 0.0383199\tbest: 0.0383199 (5358)\ttotal: 27m 33s\tremaining: 23m 51s\n",
      "5359:\tlearn: 0.0339137\ttest: 0.0383199\tbest: 0.0383199 (5358)\ttotal: 27m 33s\tremaining: 23m 51s\n",
      "5360:\tlearn: 0.0339137\ttest: 0.0383199\tbest: 0.0383199 (5360)\ttotal: 27m 33s\tremaining: 23m 51s\n",
      "5361:\tlearn: 0.0339137\ttest: 0.0383199\tbest: 0.0383199 (5361)\ttotal: 27m 34s\tremaining: 23m 50s\n",
      "5362:\tlearn: 0.0339137\ttest: 0.0383199\tbest: 0.0383199 (5362)\ttotal: 27m 34s\tremaining: 23m 50s\n",
      "5363:\tlearn: 0.0339137\ttest: 0.0383199\tbest: 0.0383199 (5362)\ttotal: 27m 34s\tremaining: 23m 50s\n",
      "5364:\tlearn: 0.0339137\ttest: 0.0383199\tbest: 0.0383199 (5362)\ttotal: 27m 34s\tremaining: 23m 49s\n",
      "5365:\tlearn: 0.0339137\ttest: 0.0383199\tbest: 0.0383199 (5365)\ttotal: 27m 35s\tremaining: 23m 49s\n",
      "5366:\tlearn: 0.0339137\ttest: 0.0383199\tbest: 0.0383199 (5366)\ttotal: 27m 35s\tremaining: 23m 49s\n",
      "5367:\tlearn: 0.0339137\ttest: 0.0383199\tbest: 0.0383199 (5366)\ttotal: 27m 35s\tremaining: 23m 48s\n",
      "5368:\tlearn: 0.0339137\ttest: 0.0383199\tbest: 0.0383199 (5366)\ttotal: 27m 35s\tremaining: 23m 48s\n",
      "5369:\tlearn: 0.0339119\ttest: 0.0383198\tbest: 0.0383198 (5369)\ttotal: 27m 36s\tremaining: 23m 48s\n",
      "5370:\tlearn: 0.0339119\ttest: 0.0383198\tbest: 0.0383198 (5370)\ttotal: 27m 36s\tremaining: 23m 47s\n",
      "5371:\tlearn: 0.0339119\ttest: 0.0383198\tbest: 0.0383198 (5370)\ttotal: 27m 36s\tremaining: 23m 47s\n",
      "5372:\tlearn: 0.0339098\ttest: 0.0383196\tbest: 0.0383196 (5372)\ttotal: 27m 37s\tremaining: 23m 47s\n",
      "5373:\tlearn: 0.0339098\ttest: 0.0383196\tbest: 0.0383196 (5372)\ttotal: 27m 37s\tremaining: 23m 46s\n",
      "5374:\tlearn: 0.0339097\ttest: 0.0383196\tbest: 0.0383196 (5374)\ttotal: 27m 37s\tremaining: 23m 46s\n",
      "5375:\tlearn: 0.0339098\ttest: 0.0383196\tbest: 0.0383196 (5375)\ttotal: 27m 37s\tremaining: 23m 45s\n",
      "5376:\tlearn: 0.0339097\ttest: 0.0383196\tbest: 0.0383196 (5375)\ttotal: 27m 38s\tremaining: 23m 45s\n",
      "5377:\tlearn: 0.0339097\ttest: 0.0383196\tbest: 0.0383196 (5375)\ttotal: 27m 38s\tremaining: 23m 45s\n",
      "5378:\tlearn: 0.0339097\ttest: 0.0383196\tbest: 0.0383196 (5378)\ttotal: 27m 38s\tremaining: 23m 44s\n",
      "5379:\tlearn: 0.0339097\ttest: 0.0383196\tbest: 0.0383196 (5379)\ttotal: 27m 38s\tremaining: 23m 44s\n",
      "5380:\tlearn: 0.0339097\ttest: 0.0383196\tbest: 0.0383196 (5380)\ttotal: 27m 39s\tremaining: 23m 44s\n",
      "5381:\tlearn: 0.0339097\ttest: 0.0383196\tbest: 0.0383196 (5381)\ttotal: 27m 39s\tremaining: 23m 43s\n",
      "5382:\tlearn: 0.0339063\ttest: 0.0383195\tbest: 0.0383195 (5382)\ttotal: 27m 39s\tremaining: 23m 43s\n",
      "5383:\tlearn: 0.0339063\ttest: 0.0383195\tbest: 0.0383195 (5382)\ttotal: 27m 40s\tremaining: 23m 43s\n",
      "5384:\tlearn: 0.0339031\ttest: 0.0383199\tbest: 0.0383195 (5382)\ttotal: 27m 40s\tremaining: 23m 42s\n",
      "5385:\tlearn: 0.0339030\ttest: 0.0383199\tbest: 0.0383195 (5382)\ttotal: 27m 40s\tremaining: 23m 42s\n",
      "5386:\tlearn: 0.0339030\ttest: 0.0383199\tbest: 0.0383195 (5382)\ttotal: 27m 41s\tremaining: 23m 42s\n",
      "5387:\tlearn: 0.0339030\ttest: 0.0383199\tbest: 0.0383195 (5382)\ttotal: 27m 41s\tremaining: 23m 42s\n",
      "5388:\tlearn: 0.0339030\ttest: 0.0383199\tbest: 0.0383195 (5382)\ttotal: 27m 41s\tremaining: 23m 41s\n",
      "5389:\tlearn: 0.0339030\ttest: 0.0383199\tbest: 0.0383195 (5382)\ttotal: 27m 42s\tremaining: 23m 41s\n",
      "5390:\tlearn: 0.0339030\ttest: 0.0383199\tbest: 0.0383195 (5382)\ttotal: 27m 42s\tremaining: 23m 41s\n",
      "5391:\tlearn: 0.0339030\ttest: 0.0383199\tbest: 0.0383195 (5382)\ttotal: 27m 43s\tremaining: 23m 41s\n",
      "5392:\tlearn: 0.0339030\ttest: 0.0383199\tbest: 0.0383195 (5382)\ttotal: 27m 43s\tremaining: 23m 41s\n",
      "5393:\tlearn: 0.0339030\ttest: 0.0383199\tbest: 0.0383195 (5382)\ttotal: 27m 44s\tremaining: 23m 41s\n",
      "5394:\tlearn: 0.0339030\ttest: 0.0383199\tbest: 0.0383195 (5382)\ttotal: 27m 44s\tremaining: 23m 40s\n",
      "5395:\tlearn: 0.0339030\ttest: 0.0383199\tbest: 0.0383195 (5382)\ttotal: 27m 44s\tremaining: 23m 40s\n",
      "5396:\tlearn: 0.0339030\ttest: 0.0383199\tbest: 0.0383195 (5382)\ttotal: 27m 45s\tremaining: 23m 40s\n",
      "5397:\tlearn: 0.0339030\ttest: 0.0383199\tbest: 0.0383195 (5382)\ttotal: 27m 45s\tremaining: 23m 39s\n",
      "5398:\tlearn: 0.0339030\ttest: 0.0383199\tbest: 0.0383195 (5382)\ttotal: 27m 45s\tremaining: 23m 39s\n",
      "5399:\tlearn: 0.0338986\ttest: 0.0383194\tbest: 0.0383194 (5399)\ttotal: 27m 46s\tremaining: 23m 39s\n",
      "5400:\tlearn: 0.0338986\ttest: 0.0383194\tbest: 0.0383194 (5399)\ttotal: 27m 46s\tremaining: 23m 38s\n",
      "5401:\tlearn: 0.0338986\ttest: 0.0383194\tbest: 0.0383194 (5399)\ttotal: 27m 46s\tremaining: 23m 38s\n",
      "5402:\tlearn: 0.0338985\ttest: 0.0383194\tbest: 0.0383194 (5399)\ttotal: 27m 46s\tremaining: 23m 38s\n",
      "5403:\tlearn: 0.0338985\ttest: 0.0383194\tbest: 0.0383194 (5399)\ttotal: 27m 47s\tremaining: 23m 37s\n",
      "5404:\tlearn: 0.0338985\ttest: 0.0383194\tbest: 0.0383194 (5399)\ttotal: 27m 47s\tremaining: 23m 37s\n",
      "5405:\tlearn: 0.0338985\ttest: 0.0383194\tbest: 0.0383194 (5399)\ttotal: 27m 47s\tremaining: 23m 37s\n",
      "5406:\tlearn: 0.0338985\ttest: 0.0383194\tbest: 0.0383194 (5399)\ttotal: 27m 47s\tremaining: 23m 36s\n",
      "5407:\tlearn: 0.0338985\ttest: 0.0383194\tbest: 0.0383194 (5407)\ttotal: 27m 48s\tremaining: 23m 36s\n",
      "5408:\tlearn: 0.0338985\ttest: 0.0383194\tbest: 0.0383194 (5407)\ttotal: 27m 48s\tremaining: 23m 36s\n",
      "5409:\tlearn: 0.0338985\ttest: 0.0383194\tbest: 0.0383194 (5409)\ttotal: 27m 48s\tremaining: 23m 35s\n",
      "5410:\tlearn: 0.0338985\ttest: 0.0383194\tbest: 0.0383194 (5409)\ttotal: 27m 48s\tremaining: 23m 35s\n",
      "5411:\tlearn: 0.0338985\ttest: 0.0383194\tbest: 0.0383194 (5411)\ttotal: 27m 49s\tremaining: 23m 34s\n",
      "5412:\tlearn: 0.0338944\ttest: 0.0383184\tbest: 0.0383184 (5412)\ttotal: 27m 49s\tremaining: 23m 34s\n",
      "5413:\tlearn: 0.0338944\ttest: 0.0383184\tbest: 0.0383184 (5412)\ttotal: 27m 49s\tremaining: 23m 34s\n",
      "5414:\tlearn: 0.0338944\ttest: 0.0383184\tbest: 0.0383184 (5414)\ttotal: 27m 49s\tremaining: 23m 33s\n",
      "5415:\tlearn: 0.0338911\ttest: 0.0383184\tbest: 0.0383184 (5414)\ttotal: 27m 50s\tremaining: 23m 33s\n",
      "5416:\tlearn: 0.0338911\ttest: 0.0383184\tbest: 0.0383184 (5414)\ttotal: 27m 50s\tremaining: 23m 33s\n",
      "5417:\tlearn: 0.0338911\ttest: 0.0383184\tbest: 0.0383184 (5414)\ttotal: 27m 50s\tremaining: 23m 32s\n",
      "5418:\tlearn: 0.0338911\ttest: 0.0383184\tbest: 0.0383184 (5414)\ttotal: 27m 50s\tremaining: 23m 32s\n",
      "5419:\tlearn: 0.0338911\ttest: 0.0383184\tbest: 0.0383184 (5414)\ttotal: 27m 51s\tremaining: 23m 32s\n",
      "5420:\tlearn: 0.0338911\ttest: 0.0383184\tbest: 0.0383184 (5414)\ttotal: 27m 51s\tremaining: 23m 31s\n",
      "5421:\tlearn: 0.0338911\ttest: 0.0383184\tbest: 0.0383184 (5414)\ttotal: 27m 51s\tremaining: 23m 31s\n",
      "5422:\tlearn: 0.0338911\ttest: 0.0383184\tbest: 0.0383184 (5414)\ttotal: 27m 51s\tremaining: 23m 31s\n",
      "5423:\tlearn: 0.0338911\ttest: 0.0383184\tbest: 0.0383184 (5414)\ttotal: 27m 52s\tremaining: 23m 30s\n",
      "5424:\tlearn: 0.0338911\ttest: 0.0383184\tbest: 0.0383184 (5414)\ttotal: 27m 52s\tremaining: 23m 30s\n",
      "5425:\tlearn: 0.0338911\ttest: 0.0383184\tbest: 0.0383184 (5414)\ttotal: 27m 52s\tremaining: 23m 30s\n",
      "5426:\tlearn: 0.0338911\ttest: 0.0383184\tbest: 0.0383184 (5414)\ttotal: 27m 53s\tremaining: 23m 29s\n",
      "5427:\tlearn: 0.0338910\ttest: 0.0383184\tbest: 0.0383184 (5414)\ttotal: 27m 53s\tremaining: 23m 29s\n",
      "5428:\tlearn: 0.0338910\ttest: 0.0383184\tbest: 0.0383184 (5414)\ttotal: 27m 53s\tremaining: 23m 29s\n",
      "5429:\tlearn: 0.0338911\ttest: 0.0383184\tbest: 0.0383184 (5414)\ttotal: 27m 53s\tremaining: 23m 28s\n",
      "5430:\tlearn: 0.0338911\ttest: 0.0383184\tbest: 0.0383184 (5414)\ttotal: 27m 54s\tremaining: 23m 28s\n",
      "5431:\tlearn: 0.0338866\ttest: 0.0383177\tbest: 0.0383177 (5431)\ttotal: 27m 54s\tremaining: 23m 28s\n",
      "5432:\tlearn: 0.0338866\ttest: 0.0383177\tbest: 0.0383177 (5432)\ttotal: 27m 54s\tremaining: 23m 27s\n",
      "5433:\tlearn: 0.0338866\ttest: 0.0383177\tbest: 0.0383177 (5432)\ttotal: 27m 55s\tremaining: 23m 27s\n",
      "5434:\tlearn: 0.0338866\ttest: 0.0383177\tbest: 0.0383177 (5432)\ttotal: 27m 55s\tremaining: 23m 27s\n",
      "5435:\tlearn: 0.0338866\ttest: 0.0383177\tbest: 0.0383177 (5432)\ttotal: 27m 55s\tremaining: 23m 27s\n",
      "5436:\tlearn: 0.0338866\ttest: 0.0383177\tbest: 0.0383177 (5432)\ttotal: 27m 56s\tremaining: 23m 26s\n",
      "5437:\tlearn: 0.0338866\ttest: 0.0383177\tbest: 0.0383177 (5432)\ttotal: 27m 56s\tremaining: 23m 26s\n",
      "5438:\tlearn: 0.0338822\ttest: 0.0383170\tbest: 0.0383170 (5438)\ttotal: 27m 57s\tremaining: 23m 26s\n",
      "5439:\tlearn: 0.0338822\ttest: 0.0383170\tbest: 0.0383170 (5439)\ttotal: 27m 57s\tremaining: 23m 26s\n",
      "5440:\tlearn: 0.0338822\ttest: 0.0383170\tbest: 0.0383170 (5440)\ttotal: 27m 58s\tremaining: 23m 26s\n",
      "5441:\tlearn: 0.0338822\ttest: 0.0383170\tbest: 0.0383170 (5440)\ttotal: 27m 58s\tremaining: 23m 26s\n",
      "5442:\tlearn: 0.0338822\ttest: 0.0383170\tbest: 0.0383170 (5440)\ttotal: 27m 59s\tremaining: 23m 25s\n",
      "5443:\tlearn: 0.0338822\ttest: 0.0383170\tbest: 0.0383170 (5440)\ttotal: 27m 59s\tremaining: 23m 25s\n",
      "5444:\tlearn: 0.0338822\ttest: 0.0383170\tbest: 0.0383170 (5444)\ttotal: 27m 59s\tremaining: 23m 25s\n",
      "5445:\tlearn: 0.0338822\ttest: 0.0383170\tbest: 0.0383170 (5444)\ttotal: 27m 59s\tremaining: 23m 24s\n",
      "5446:\tlearn: 0.0338795\ttest: 0.0383162\tbest: 0.0383162 (5446)\ttotal: 28m\tremaining: 23m 24s\n",
      "5447:\tlearn: 0.0338763\ttest: 0.0383160\tbest: 0.0383160 (5447)\ttotal: 28m\tremaining: 23m 24s\n",
      "5448:\tlearn: 0.0338763\ttest: 0.0383160\tbest: 0.0383160 (5447)\ttotal: 28m\tremaining: 23m 23s\n",
      "5449:\tlearn: 0.0338763\ttest: 0.0383160\tbest: 0.0383160 (5449)\ttotal: 28m\tremaining: 23m 23s\n",
      "5450:\tlearn: 0.0338763\ttest: 0.0383160\tbest: 0.0383160 (5450)\ttotal: 28m 1s\tremaining: 23m 22s\n",
      "5451:\tlearn: 0.0338763\ttest: 0.0383160\tbest: 0.0383160 (5450)\ttotal: 28m 1s\tremaining: 23m 22s\n",
      "5452:\tlearn: 0.0338763\ttest: 0.0383160\tbest: 0.0383160 (5450)\ttotal: 28m 1s\tremaining: 23m 22s\n",
      "5453:\tlearn: 0.0338703\ttest: 0.0383142\tbest: 0.0383142 (5453)\ttotal: 28m 2s\tremaining: 23m 21s\n",
      "5454:\tlearn: 0.0338703\ttest: 0.0383142\tbest: 0.0383142 (5453)\ttotal: 28m 2s\tremaining: 23m 21s\n",
      "5455:\tlearn: 0.0338670\ttest: 0.0383137\tbest: 0.0383137 (5455)\ttotal: 28m 2s\tremaining: 23m 21s\n",
      "5456:\tlearn: 0.0338670\ttest: 0.0383137\tbest: 0.0383137 (5456)\ttotal: 28m 2s\tremaining: 23m 20s\n",
      "5457:\tlearn: 0.0338670\ttest: 0.0383137\tbest: 0.0383137 (5457)\ttotal: 28m 3s\tremaining: 23m 20s\n",
      "5458:\tlearn: 0.0338670\ttest: 0.0383137\tbest: 0.0383137 (5458)\ttotal: 28m 3s\tremaining: 23m 20s\n",
      "5459:\tlearn: 0.0338670\ttest: 0.0383137\tbest: 0.0383137 (5458)\ttotal: 28m 3s\tremaining: 23m 19s\n",
      "5460:\tlearn: 0.0338621\ttest: 0.0383121\tbest: 0.0383121 (5460)\ttotal: 28m 3s\tremaining: 23m 19s\n",
      "5461:\tlearn: 0.0338621\ttest: 0.0383121\tbest: 0.0383121 (5460)\ttotal: 28m 4s\tremaining: 23m 19s\n",
      "5462:\tlearn: 0.0338579\ttest: 0.0383112\tbest: 0.0383112 (5462)\ttotal: 28m 4s\tremaining: 23m 18s\n",
      "5463:\tlearn: 0.0338579\ttest: 0.0383112\tbest: 0.0383112 (5463)\ttotal: 28m 4s\tremaining: 23m 18s\n",
      "5464:\tlearn: 0.0338579\ttest: 0.0383112\tbest: 0.0383112 (5464)\ttotal: 28m 5s\tremaining: 23m 18s\n",
      "5465:\tlearn: 0.0338579\ttest: 0.0383112\tbest: 0.0383112 (5465)\ttotal: 28m 5s\tremaining: 23m 17s\n",
      "5466:\tlearn: 0.0338533\ttest: 0.0383106\tbest: 0.0383106 (5466)\ttotal: 28m 5s\tremaining: 23m 17s\n",
      "5467:\tlearn: 0.0338533\ttest: 0.0383106\tbest: 0.0383106 (5466)\ttotal: 28m 5s\tremaining: 23m 17s\n",
      "5468:\tlearn: 0.0338533\ttest: 0.0383106\tbest: 0.0383106 (5466)\ttotal: 28m 6s\tremaining: 23m 16s\n",
      "5469:\tlearn: 0.0338533\ttest: 0.0383106\tbest: 0.0383106 (5469)\ttotal: 28m 6s\tremaining: 23m 16s\n",
      "5470:\tlearn: 0.0338533\ttest: 0.0383106\tbest: 0.0383106 (5470)\ttotal: 28m 6s\tremaining: 23m 16s\n",
      "5471:\tlearn: 0.0338532\ttest: 0.0383106\tbest: 0.0383106 (5471)\ttotal: 28m 6s\tremaining: 23m 15s\n",
      "5472:\tlearn: 0.0338485\ttest: 0.0383105\tbest: 0.0383105 (5472)\ttotal: 28m 7s\tremaining: 23m 15s\n",
      "5473:\tlearn: 0.0338485\ttest: 0.0383105\tbest: 0.0383105 (5473)\ttotal: 28m 7s\tremaining: 23m 15s\n",
      "5474:\tlearn: 0.0338485\ttest: 0.0383105\tbest: 0.0383105 (5474)\ttotal: 28m 7s\tremaining: 23m 14s\n",
      "5475:\tlearn: 0.0338485\ttest: 0.0383105\tbest: 0.0383105 (5474)\ttotal: 28m 8s\tremaining: 23m 14s\n",
      "5476:\tlearn: 0.0338485\ttest: 0.0383105\tbest: 0.0383105 (5476)\ttotal: 28m 8s\tremaining: 23m 14s\n",
      "5477:\tlearn: 0.0338485\ttest: 0.0383105\tbest: 0.0383105 (5477)\ttotal: 28m 8s\tremaining: 23m 13s\n",
      "5478:\tlearn: 0.0338485\ttest: 0.0383105\tbest: 0.0383105 (5478)\ttotal: 28m 8s\tremaining: 23m 13s\n",
      "5479:\tlearn: 0.0338485\ttest: 0.0383105\tbest: 0.0383105 (5479)\ttotal: 28m 9s\tremaining: 23m 13s\n",
      "5480:\tlearn: 0.0338485\ttest: 0.0383105\tbest: 0.0383105 (5480)\ttotal: 28m 9s\tremaining: 23m 13s\n",
      "5481:\tlearn: 0.0338485\ttest: 0.0383105\tbest: 0.0383105 (5480)\ttotal: 28m 10s\tremaining: 23m 12s\n",
      "5482:\tlearn: 0.0338485\ttest: 0.0383105\tbest: 0.0383105 (5482)\ttotal: 28m 10s\tremaining: 23m 12s\n",
      "5483:\tlearn: 0.0338485\ttest: 0.0383105\tbest: 0.0383105 (5483)\ttotal: 28m 11s\tremaining: 23m 12s\n",
      "5484:\tlearn: 0.0338484\ttest: 0.0383105\tbest: 0.0383105 (5484)\ttotal: 28m 11s\tremaining: 23m 12s\n",
      "5485:\tlearn: 0.0338485\ttest: 0.0383105\tbest: 0.0383105 (5485)\ttotal: 28m 11s\tremaining: 23m 12s\n",
      "5486:\tlearn: 0.0338484\ttest: 0.0383105\tbest: 0.0383105 (5486)\ttotal: 28m 12s\tremaining: 23m 11s\n",
      "5487:\tlearn: 0.0338457\ttest: 0.0383100\tbest: 0.0383100 (5487)\ttotal: 28m 12s\tremaining: 23m 11s\n",
      "5488:\tlearn: 0.0338457\ttest: 0.0383100\tbest: 0.0383100 (5488)\ttotal: 28m 12s\tremaining: 23m 11s\n",
      "5489:\tlearn: 0.0338457\ttest: 0.0383100\tbest: 0.0383100 (5489)\ttotal: 28m 13s\tremaining: 23m 10s\n",
      "5490:\tlearn: 0.0338457\ttest: 0.0383100\tbest: 0.0383100 (5490)\ttotal: 28m 13s\tremaining: 23m 10s\n",
      "5491:\tlearn: 0.0338457\ttest: 0.0383100\tbest: 0.0383100 (5491)\ttotal: 28m 13s\tremaining: 23m 10s\n",
      "5492:\tlearn: 0.0338457\ttest: 0.0383100\tbest: 0.0383100 (5491)\ttotal: 28m 14s\tremaining: 23m 9s\n",
      "5493:\tlearn: 0.0338456\ttest: 0.0383100\tbest: 0.0383100 (5493)\ttotal: 28m 14s\tremaining: 23m 9s\n",
      "5494:\tlearn: 0.0338456\ttest: 0.0383100\tbest: 0.0383100 (5494)\ttotal: 28m 14s\tremaining: 23m 9s\n",
      "5495:\tlearn: 0.0338456\ttest: 0.0383100\tbest: 0.0383100 (5494)\ttotal: 28m 14s\tremaining: 23m 8s\n",
      "5496:\tlearn: 0.0338417\ttest: 0.0383099\tbest: 0.0383099 (5496)\ttotal: 28m 15s\tremaining: 23m 8s\n",
      "5497:\tlearn: 0.0338360\ttest: 0.0383076\tbest: 0.0383076 (5497)\ttotal: 28m 15s\tremaining: 23m 8s\n",
      "5498:\tlearn: 0.0338360\ttest: 0.0383076\tbest: 0.0383076 (5498)\ttotal: 28m 15s\tremaining: 23m 7s\n",
      "5499:\tlearn: 0.0338360\ttest: 0.0383076\tbest: 0.0383076 (5499)\ttotal: 28m 15s\tremaining: 23m 7s\n",
      "5500:\tlearn: 0.0338360\ttest: 0.0383076\tbest: 0.0383076 (5500)\ttotal: 28m 16s\tremaining: 23m 7s\n",
      "5501:\tlearn: 0.0338360\ttest: 0.0383076\tbest: 0.0383076 (5501)\ttotal: 28m 16s\tremaining: 23m 6s\n",
      "5502:\tlearn: 0.0338360\ttest: 0.0383076\tbest: 0.0383076 (5502)\ttotal: 28m 16s\tremaining: 23m 6s\n",
      "5503:\tlearn: 0.0338340\ttest: 0.0383075\tbest: 0.0383075 (5503)\ttotal: 28m 17s\tremaining: 23m 6s\n",
      "5504:\tlearn: 0.0338340\ttest: 0.0383075\tbest: 0.0383075 (5504)\ttotal: 28m 17s\tremaining: 23m 5s\n",
      "5505:\tlearn: 0.0338340\ttest: 0.0383075\tbest: 0.0383075 (5505)\ttotal: 28m 17s\tremaining: 23m 5s\n",
      "5506:\tlearn: 0.0338294\ttest: 0.0383069\tbest: 0.0383069 (5506)\ttotal: 28m 17s\tremaining: 23m 5s\n",
      "5507:\tlearn: 0.0338294\ttest: 0.0383069\tbest: 0.0383069 (5506)\ttotal: 28m 18s\tremaining: 23m 4s\n",
      "5508:\tlearn: 0.0338294\ttest: 0.0383069\tbest: 0.0383069 (5508)\ttotal: 28m 18s\tremaining: 23m 4s\n",
      "5509:\tlearn: 0.0338251\ttest: 0.0383069\tbest: 0.0383069 (5509)\ttotal: 28m 18s\tremaining: 23m 4s\n",
      "5510:\tlearn: 0.0338251\ttest: 0.0383069\tbest: 0.0383069 (5510)\ttotal: 28m 18s\tremaining: 23m 3s\n",
      "5511:\tlearn: 0.0338234\ttest: 0.0383070\tbest: 0.0383069 (5510)\ttotal: 28m 19s\tremaining: 23m 3s\n",
      "5512:\tlearn: 0.0338234\ttest: 0.0383070\tbest: 0.0383069 (5510)\ttotal: 28m 19s\tremaining: 23m 3s\n",
      "5513:\tlearn: 0.0338234\ttest: 0.0383070\tbest: 0.0383069 (5510)\ttotal: 28m 19s\tremaining: 23m 2s\n",
      "5514:\tlearn: 0.0338234\ttest: 0.0383070\tbest: 0.0383069 (5510)\ttotal: 28m 19s\tremaining: 23m 2s\n",
      "5515:\tlearn: 0.0338181\ttest: 0.0383064\tbest: 0.0383064 (5515)\ttotal: 28m 20s\tremaining: 23m 2s\n",
      "5516:\tlearn: 0.0338180\ttest: 0.0383064\tbest: 0.0383064 (5515)\ttotal: 28m 20s\tremaining: 23m 1s\n",
      "5517:\tlearn: 0.0338180\ttest: 0.0383064\tbest: 0.0383064 (5517)\ttotal: 28m 20s\tremaining: 23m 1s\n",
      "5518:\tlearn: 0.0338180\ttest: 0.0383064\tbest: 0.0383064 (5517)\ttotal: 28m 21s\tremaining: 23m 1s\n",
      "5519:\tlearn: 0.0338140\ttest: 0.0383060\tbest: 0.0383060 (5519)\ttotal: 28m 21s\tremaining: 23m\n",
      "5520:\tlearn: 0.0338140\ttest: 0.0383060\tbest: 0.0383060 (5520)\ttotal: 28m 21s\tremaining: 23m\n",
      "5521:\tlearn: 0.0338140\ttest: 0.0383060\tbest: 0.0383060 (5521)\ttotal: 28m 21s\tremaining: 23m\n",
      "5522:\tlearn: 0.0338140\ttest: 0.0383060\tbest: 0.0383060 (5521)\ttotal: 28m 22s\tremaining: 22m 59s\n",
      "5523:\tlearn: 0.0338140\ttest: 0.0383060\tbest: 0.0383060 (5523)\ttotal: 28m 22s\tremaining: 22m 59s\n",
      "5524:\tlearn: 0.0338140\ttest: 0.0383060\tbest: 0.0383060 (5524)\ttotal: 28m 22s\tremaining: 22m 59s\n",
      "5525:\tlearn: 0.0338140\ttest: 0.0383060\tbest: 0.0383060 (5525)\ttotal: 28m 23s\tremaining: 22m 59s\n",
      "5526:\tlearn: 0.0338140\ttest: 0.0383060\tbest: 0.0383060 (5526)\ttotal: 28m 23s\tremaining: 22m 58s\n",
      "5527:\tlearn: 0.0338139\ttest: 0.0383060\tbest: 0.0383060 (5527)\ttotal: 28m 24s\tremaining: 22m 58s\n",
      "5528:\tlearn: 0.0338139\ttest: 0.0383060\tbest: 0.0383060 (5528)\ttotal: 28m 24s\tremaining: 22m 58s\n",
      "5529:\tlearn: 0.0338139\ttest: 0.0383060\tbest: 0.0383060 (5529)\ttotal: 28m 25s\tremaining: 22m 58s\n",
      "5530:\tlearn: 0.0338139\ttest: 0.0383060\tbest: 0.0383060 (5530)\ttotal: 28m 25s\tremaining: 22m 58s\n",
      "5531:\tlearn: 0.0338139\ttest: 0.0383060\tbest: 0.0383060 (5531)\ttotal: 28m 26s\tremaining: 22m 57s\n",
      "5532:\tlearn: 0.0338138\ttest: 0.0383060\tbest: 0.0383060 (5532)\ttotal: 28m 26s\tremaining: 22m 57s\n",
      "5533:\tlearn: 0.0338138\ttest: 0.0383060\tbest: 0.0383060 (5533)\ttotal: 28m 26s\tremaining: 22m 57s\n",
      "5534:\tlearn: 0.0338138\ttest: 0.0383060\tbest: 0.0383060 (5534)\ttotal: 28m 26s\tremaining: 22m 56s\n",
      "5535:\tlearn: 0.0338138\ttest: 0.0383060\tbest: 0.0383060 (5534)\ttotal: 28m 27s\tremaining: 22m 56s\n",
      "5536:\tlearn: 0.0338138\ttest: 0.0383060\tbest: 0.0383060 (5534)\ttotal: 28m 27s\tremaining: 22m 56s\n",
      "5537:\tlearn: 0.0338138\ttest: 0.0383060\tbest: 0.0383060 (5534)\ttotal: 28m 27s\tremaining: 22m 55s\n",
      "5538:\tlearn: 0.0338138\ttest: 0.0383060\tbest: 0.0383060 (5538)\ttotal: 28m 27s\tremaining: 22m 55s\n",
      "5539:\tlearn: 0.0338138\ttest: 0.0383060\tbest: 0.0383060 (5539)\ttotal: 28m 28s\tremaining: 22m 55s\n",
      "5540:\tlearn: 0.0338138\ttest: 0.0383060\tbest: 0.0383060 (5539)\ttotal: 28m 28s\tremaining: 22m 54s\n",
      "5541:\tlearn: 0.0338138\ttest: 0.0383060\tbest: 0.0383060 (5541)\ttotal: 28m 28s\tremaining: 22m 54s\n",
      "5542:\tlearn: 0.0338138\ttest: 0.0383060\tbest: 0.0383060 (5542)\ttotal: 28m 28s\tremaining: 22m 54s\n",
      "5543:\tlearn: 0.0338098\ttest: 0.0383058\tbest: 0.0383058 (5543)\ttotal: 28m 29s\tremaining: 22m 53s\n",
      "5544:\tlearn: 0.0338098\ttest: 0.0383058\tbest: 0.0383058 (5544)\ttotal: 28m 29s\tremaining: 22m 53s\n",
      "5545:\tlearn: 0.0338098\ttest: 0.0383058\tbest: 0.0383058 (5544)\ttotal: 28m 29s\tremaining: 22m 53s\n",
      "5546:\tlearn: 0.0338097\ttest: 0.0383058\tbest: 0.0383058 (5546)\ttotal: 28m 29s\tremaining: 22m 52s\n",
      "5547:\tlearn: 0.0338097\ttest: 0.0383058\tbest: 0.0383058 (5547)\ttotal: 28m 30s\tremaining: 22m 52s\n",
      "5548:\tlearn: 0.0338097\ttest: 0.0383058\tbest: 0.0383058 (5548)\ttotal: 28m 30s\tremaining: 22m 51s\n",
      "5549:\tlearn: 0.0338097\ttest: 0.0383058\tbest: 0.0383058 (5548)\ttotal: 28m 30s\tremaining: 22m 51s\n",
      "5550:\tlearn: 0.0338097\ttest: 0.0383058\tbest: 0.0383058 (5550)\ttotal: 28m 30s\tremaining: 22m 51s\n",
      "5551:\tlearn: 0.0338097\ttest: 0.0383058\tbest: 0.0383058 (5551)\ttotal: 28m 31s\tremaining: 22m 50s\n",
      "5552:\tlearn: 0.0338097\ttest: 0.0383058\tbest: 0.0383058 (5551)\ttotal: 28m 31s\tremaining: 22m 50s\n",
      "5553:\tlearn: 0.0338097\ttest: 0.0383058\tbest: 0.0383058 (5553)\ttotal: 28m 31s\tremaining: 22m 50s\n",
      "5554:\tlearn: 0.0338097\ttest: 0.0383058\tbest: 0.0383058 (5553)\ttotal: 28m 31s\tremaining: 22m 49s\n",
      "5555:\tlearn: 0.0338097\ttest: 0.0383058\tbest: 0.0383058 (5553)\ttotal: 28m 32s\tremaining: 22m 49s\n",
      "5556:\tlearn: 0.0338062\ttest: 0.0383050\tbest: 0.0383050 (5556)\ttotal: 28m 32s\tremaining: 22m 49s\n",
      "5557:\tlearn: 0.0338062\ttest: 0.0383050\tbest: 0.0383050 (5557)\ttotal: 28m 32s\tremaining: 22m 48s\n",
      "5558:\tlearn: 0.0338062\ttest: 0.0383050\tbest: 0.0383050 (5558)\ttotal: 28m 32s\tremaining: 22m 48s\n",
      "5559:\tlearn: 0.0338062\ttest: 0.0383050\tbest: 0.0383050 (5558)\ttotal: 28m 33s\tremaining: 22m 48s\n",
      "5560:\tlearn: 0.0338062\ttest: 0.0383050\tbest: 0.0383050 (5560)\ttotal: 28m 33s\tremaining: 22m 47s\n",
      "5561:\tlearn: 0.0338062\ttest: 0.0383050\tbest: 0.0383050 (5561)\ttotal: 28m 33s\tremaining: 22m 47s\n",
      "5562:\tlearn: 0.0338062\ttest: 0.0383050\tbest: 0.0383050 (5561)\ttotal: 28m 33s\tremaining: 22m 47s\n",
      "5563:\tlearn: 0.0338062\ttest: 0.0383050\tbest: 0.0383050 (5563)\ttotal: 28m 34s\tremaining: 22m 46s\n",
      "5564:\tlearn: 0.0338061\ttest: 0.0383050\tbest: 0.0383050 (5564)\ttotal: 28m 34s\tremaining: 22m 46s\n",
      "5565:\tlearn: 0.0338061\ttest: 0.0383050\tbest: 0.0383050 (5564)\ttotal: 28m 34s\tremaining: 22m 45s\n",
      "5566:\tlearn: 0.0338061\ttest: 0.0383050\tbest: 0.0383050 (5564)\ttotal: 28m 34s\tremaining: 22m 45s\n",
      "5567:\tlearn: 0.0338061\ttest: 0.0383050\tbest: 0.0383050 (5564)\ttotal: 28m 35s\tremaining: 22m 45s\n",
      "5568:\tlearn: 0.0338061\ttest: 0.0383050\tbest: 0.0383050 (5568)\ttotal: 28m 35s\tremaining: 22m 44s\n",
      "5569:\tlearn: 0.0338061\ttest: 0.0383050\tbest: 0.0383050 (5568)\ttotal: 28m 35s\tremaining: 22m 44s\n",
      "5570:\tlearn: 0.0338061\ttest: 0.0383050\tbest: 0.0383050 (5568)\ttotal: 28m 36s\tremaining: 22m 44s\n",
      "5571:\tlearn: 0.0338061\ttest: 0.0383050\tbest: 0.0383050 (5571)\ttotal: 28m 36s\tremaining: 22m 44s\n",
      "5572:\tlearn: 0.0338061\ttest: 0.0383050\tbest: 0.0383050 (5572)\ttotal: 28m 36s\tremaining: 22m 43s\n",
      "5573:\tlearn: 0.0338061\ttest: 0.0383050\tbest: 0.0383050 (5573)\ttotal: 28m 37s\tremaining: 22m 43s\n",
      "5574:\tlearn: 0.0338061\ttest: 0.0383050\tbest: 0.0383050 (5573)\ttotal: 28m 37s\tremaining: 22m 43s\n",
      "5575:\tlearn: 0.0338061\ttest: 0.0383050\tbest: 0.0383050 (5573)\ttotal: 28m 38s\tremaining: 22m 43s\n",
      "5576:\tlearn: 0.0338061\ttest: 0.0383050\tbest: 0.0383050 (5573)\ttotal: 28m 38s\tremaining: 22m 43s\n",
      "5577:\tlearn: 0.0338061\ttest: 0.0383050\tbest: 0.0383050 (5573)\ttotal: 28m 39s\tremaining: 22m 42s\n",
      "5578:\tlearn: 0.0338061\ttest: 0.0383050\tbest: 0.0383050 (5573)\ttotal: 28m 39s\tremaining: 22m 42s\n",
      "5579:\tlearn: 0.0338061\ttest: 0.0383050\tbest: 0.0383050 (5579)\ttotal: 28m 40s\tremaining: 22m 42s\n",
      "5580:\tlearn: 0.0338061\ttest: 0.0383050\tbest: 0.0383050 (5580)\ttotal: 28m 40s\tremaining: 22m 42s\n",
      "5581:\tlearn: 0.0338061\ttest: 0.0383050\tbest: 0.0383050 (5580)\ttotal: 28m 40s\tremaining: 22m 41s\n",
      "5582:\tlearn: 0.0338061\ttest: 0.0383050\tbest: 0.0383050 (5582)\ttotal: 28m 40s\tremaining: 22m 41s\n",
      "5583:\tlearn: 0.0338061\ttest: 0.0383050\tbest: 0.0383050 (5583)\ttotal: 28m 41s\tremaining: 22m 41s\n",
      "5584:\tlearn: 0.0338061\ttest: 0.0383050\tbest: 0.0383050 (5584)\ttotal: 28m 41s\tremaining: 22m 40s\n",
      "5585:\tlearn: 0.0338061\ttest: 0.0383050\tbest: 0.0383050 (5585)\ttotal: 28m 41s\tremaining: 22m 40s\n",
      "5586:\tlearn: 0.0338061\ttest: 0.0383050\tbest: 0.0383050 (5586)\ttotal: 28m 41s\tremaining: 22m 40s\n",
      "5587:\tlearn: 0.0338061\ttest: 0.0383050\tbest: 0.0383050 (5587)\ttotal: 28m 42s\tremaining: 22m 39s\n",
      "5588:\tlearn: 0.0338061\ttest: 0.0383050\tbest: 0.0383050 (5588)\ttotal: 28m 42s\tremaining: 22m 39s\n",
      "5589:\tlearn: 0.0338061\ttest: 0.0383050\tbest: 0.0383050 (5589)\ttotal: 28m 42s\tremaining: 22m 39s\n",
      "5590:\tlearn: 0.0338061\ttest: 0.0383050\tbest: 0.0383050 (5590)\ttotal: 28m 42s\tremaining: 22m 38s\n",
      "5591:\tlearn: 0.0338061\ttest: 0.0383050\tbest: 0.0383050 (5591)\ttotal: 28m 43s\tremaining: 22m 38s\n",
      "5592:\tlearn: 0.0338061\ttest: 0.0383050\tbest: 0.0383050 (5592)\ttotal: 28m 43s\tremaining: 22m 37s\n",
      "5593:\tlearn: 0.0338033\ttest: 0.0383046\tbest: 0.0383046 (5593)\ttotal: 28m 43s\tremaining: 22m 37s\n",
      "5594:\tlearn: 0.0338033\ttest: 0.0383046\tbest: 0.0383046 (5593)\ttotal: 28m 43s\tremaining: 22m 37s\n",
      "5595:\tlearn: 0.0338033\ttest: 0.0383046\tbest: 0.0383046 (5595)\ttotal: 28m 44s\tremaining: 22m 37s\n",
      "5596:\tlearn: 0.0338033\ttest: 0.0383046\tbest: 0.0383046 (5596)\ttotal: 28m 44s\tremaining: 22m 36s\n",
      "5597:\tlearn: 0.0338033\ttest: 0.0383046\tbest: 0.0383046 (5596)\ttotal: 28m 44s\tremaining: 22m 36s\n",
      "5598:\tlearn: 0.0338033\ttest: 0.0383046\tbest: 0.0383046 (5598)\ttotal: 28m 45s\tremaining: 22m 35s\n",
      "5599:\tlearn: 0.0338033\ttest: 0.0383046\tbest: 0.0383046 (5598)\ttotal: 28m 45s\tremaining: 22m 35s\n",
      "5600:\tlearn: 0.0338033\ttest: 0.0383046\tbest: 0.0383046 (5600)\ttotal: 28m 45s\tremaining: 22m 35s\n",
      "5601:\tlearn: 0.0338033\ttest: 0.0383046\tbest: 0.0383046 (5600)\ttotal: 28m 45s\tremaining: 22m 34s\n",
      "5602:\tlearn: 0.0338033\ttest: 0.0383046\tbest: 0.0383046 (5600)\ttotal: 28m 46s\tremaining: 22m 34s\n",
      "5603:\tlearn: 0.0338033\ttest: 0.0383046\tbest: 0.0383046 (5600)\ttotal: 28m 46s\tremaining: 22m 34s\n",
      "5604:\tlearn: 0.0338033\ttest: 0.0383046\tbest: 0.0383046 (5600)\ttotal: 28m 46s\tremaining: 22m 33s\n",
      "5605:\tlearn: 0.0338033\ttest: 0.0383046\tbest: 0.0383046 (5605)\ttotal: 28m 46s\tremaining: 22m 33s\n",
      "5606:\tlearn: 0.0338033\ttest: 0.0383046\tbest: 0.0383046 (5606)\ttotal: 28m 47s\tremaining: 22m 33s\n",
      "5607:\tlearn: 0.0337992\ttest: 0.0383036\tbest: 0.0383036 (5607)\ttotal: 28m 47s\tremaining: 22m 32s\n",
      "5608:\tlearn: 0.0337992\ttest: 0.0383036\tbest: 0.0383036 (5608)\ttotal: 28m 47s\tremaining: 22m 32s\n",
      "5609:\tlearn: 0.0337992\ttest: 0.0383036\tbest: 0.0383036 (5608)\ttotal: 28m 47s\tremaining: 22m 32s\n",
      "5610:\tlearn: 0.0337992\ttest: 0.0383036\tbest: 0.0383036 (5610)\ttotal: 28m 48s\tremaining: 22m 31s\n",
      "5611:\tlearn: 0.0337992\ttest: 0.0383036\tbest: 0.0383036 (5610)\ttotal: 28m 48s\tremaining: 22m 31s\n",
      "5612:\tlearn: 0.0337992\ttest: 0.0383036\tbest: 0.0383036 (5612)\ttotal: 28m 48s\tremaining: 22m 31s\n",
      "5613:\tlearn: 0.0337992\ttest: 0.0383036\tbest: 0.0383036 (5612)\ttotal: 28m 48s\tremaining: 22m 30s\n",
      "5614:\tlearn: 0.0337992\ttest: 0.0383036\tbest: 0.0383036 (5612)\ttotal: 28m 49s\tremaining: 22m 30s\n",
      "5615:\tlearn: 0.0337992\ttest: 0.0383036\tbest: 0.0383036 (5615)\ttotal: 28m 49s\tremaining: 22m 30s\n",
      "5616:\tlearn: 0.0337992\ttest: 0.0383036\tbest: 0.0383036 (5616)\ttotal: 28m 49s\tremaining: 22m 29s\n",
      "5617:\tlearn: 0.0337992\ttest: 0.0383036\tbest: 0.0383036 (5617)\ttotal: 28m 50s\tremaining: 22m 29s\n",
      "5618:\tlearn: 0.0337992\ttest: 0.0383036\tbest: 0.0383036 (5618)\ttotal: 28m 50s\tremaining: 22m 29s\n",
      "5619:\tlearn: 0.0337992\ttest: 0.0383036\tbest: 0.0383036 (5618)\ttotal: 28m 50s\tremaining: 22m 28s\n",
      "5620:\tlearn: 0.0337992\ttest: 0.0383036\tbest: 0.0383036 (5618)\ttotal: 28m 51s\tremaining: 22m 28s\n",
      "5621:\tlearn: 0.0337991\ttest: 0.0383036\tbest: 0.0383036 (5621)\ttotal: 28m 51s\tremaining: 22m 28s\n",
      "5622:\tlearn: 0.0337992\ttest: 0.0383036\tbest: 0.0383036 (5622)\ttotal: 28m 52s\tremaining: 22m 28s\n",
      "5623:\tlearn: 0.0337978\ttest: 0.0383035\tbest: 0.0383035 (5623)\ttotal: 28m 52s\tremaining: 22m 28s\n",
      "5624:\tlearn: 0.0337978\ttest: 0.0383035\tbest: 0.0383035 (5623)\ttotal: 28m 53s\tremaining: 22m 28s\n",
      "5625:\tlearn: 0.0337978\ttest: 0.0383035\tbest: 0.0383035 (5625)\ttotal: 28m 53s\tremaining: 22m 27s\n",
      "5626:\tlearn: 0.0337978\ttest: 0.0383035\tbest: 0.0383035 (5625)\ttotal: 28m 54s\tremaining: 22m 27s\n",
      "5627:\tlearn: 0.0337978\ttest: 0.0383035\tbest: 0.0383035 (5625)\ttotal: 28m 54s\tremaining: 22m 27s\n",
      "5628:\tlearn: 0.0337977\ttest: 0.0383035\tbest: 0.0383035 (5628)\ttotal: 28m 54s\tremaining: 22m 26s\n",
      "5629:\tlearn: 0.0337977\ttest: 0.0383035\tbest: 0.0383035 (5628)\ttotal: 28m 54s\tremaining: 22m 26s\n",
      "5630:\tlearn: 0.0337977\ttest: 0.0383035\tbest: 0.0383035 (5630)\ttotal: 28m 55s\tremaining: 22m 26s\n",
      "5631:\tlearn: 0.0337977\ttest: 0.0383035\tbest: 0.0383035 (5631)\ttotal: 28m 55s\tremaining: 22m 25s\n",
      "5632:\tlearn: 0.0337977\ttest: 0.0383035\tbest: 0.0383035 (5632)\ttotal: 28m 55s\tremaining: 22m 25s\n",
      "5633:\tlearn: 0.0337946\ttest: 0.0383034\tbest: 0.0383034 (5633)\ttotal: 28m 55s\tremaining: 22m 25s\n",
      "5634:\tlearn: 0.0337946\ttest: 0.0383034\tbest: 0.0383034 (5634)\ttotal: 28m 56s\tremaining: 22m 24s\n",
      "5635:\tlearn: 0.0337946\ttest: 0.0383034\tbest: 0.0383034 (5634)\ttotal: 28m 56s\tremaining: 22m 24s\n",
      "5636:\tlearn: 0.0337946\ttest: 0.0383034\tbest: 0.0383034 (5634)\ttotal: 28m 56s\tremaining: 22m 24s\n",
      "5637:\tlearn: 0.0337945\ttest: 0.0383034\tbest: 0.0383034 (5634)\ttotal: 28m 57s\tremaining: 22m 23s\n",
      "5638:\tlearn: 0.0337945\ttest: 0.0383034\tbest: 0.0383034 (5634)\ttotal: 28m 57s\tremaining: 22m 23s\n",
      "5639:\tlearn: 0.0337945\ttest: 0.0383034\tbest: 0.0383034 (5634)\ttotal: 28m 57s\tremaining: 22m 23s\n",
      "5640:\tlearn: 0.0337945\ttest: 0.0383034\tbest: 0.0383034 (5634)\ttotal: 28m 57s\tremaining: 22m 22s\n",
      "5641:\tlearn: 0.0337945\ttest: 0.0383034\tbest: 0.0383034 (5634)\ttotal: 28m 58s\tremaining: 22m 22s\n",
      "5642:\tlearn: 0.0337945\ttest: 0.0383034\tbest: 0.0383034 (5634)\ttotal: 28m 58s\tremaining: 22m 22s\n",
      "5643:\tlearn: 0.0337945\ttest: 0.0383034\tbest: 0.0383034 (5634)\ttotal: 28m 58s\tremaining: 22m 21s\n",
      "5644:\tlearn: 0.0337945\ttest: 0.0383034\tbest: 0.0383034 (5634)\ttotal: 28m 58s\tremaining: 22m 21s\n",
      "5645:\tlearn: 0.0337945\ttest: 0.0383034\tbest: 0.0383034 (5634)\ttotal: 28m 59s\tremaining: 22m 21s\n",
      "5646:\tlearn: 0.0337945\ttest: 0.0383034\tbest: 0.0383034 (5634)\ttotal: 28m 59s\tremaining: 22m 20s\n",
      "5647:\tlearn: 0.0337945\ttest: 0.0383034\tbest: 0.0383034 (5634)\ttotal: 28m 59s\tremaining: 22m 20s\n",
      "5648:\tlearn: 0.0337945\ttest: 0.0383034\tbest: 0.0383034 (5634)\ttotal: 28m 59s\tremaining: 22m 20s\n",
      "5649:\tlearn: 0.0337945\ttest: 0.0383034\tbest: 0.0383034 (5634)\ttotal: 28m 59s\tremaining: 22m 19s\n",
      "5650:\tlearn: 0.0337945\ttest: 0.0383034\tbest: 0.0383034 (5634)\ttotal: 29m\tremaining: 22m 19s\n",
      "5651:\tlearn: 0.0337945\ttest: 0.0383034\tbest: 0.0383034 (5634)\ttotal: 29m\tremaining: 22m 18s\n",
      "5652:\tlearn: 0.0337900\ttest: 0.0383013\tbest: 0.0383013 (5652)\ttotal: 29m\tremaining: 22m 18s\n",
      "5653:\tlearn: 0.0337899\ttest: 0.0383013\tbest: 0.0383013 (5652)\ttotal: 29m 1s\tremaining: 22m 18s\n",
      "5654:\tlearn: 0.0337900\ttest: 0.0383013\tbest: 0.0383013 (5652)\ttotal: 29m 1s\tremaining: 22m 17s\n",
      "5655:\tlearn: 0.0337899\ttest: 0.0383013\tbest: 0.0383013 (5655)\ttotal: 29m 1s\tremaining: 22m 17s\n",
      "5656:\tlearn: 0.0337899\ttest: 0.0383013\tbest: 0.0383013 (5655)\ttotal: 29m 1s\tremaining: 22m 17s\n",
      "5657:\tlearn: 0.0337899\ttest: 0.0383013\tbest: 0.0383013 (5655)\ttotal: 29m 2s\tremaining: 22m 16s\n",
      "5658:\tlearn: 0.0337899\ttest: 0.0383013\tbest: 0.0383013 (5655)\ttotal: 29m 2s\tremaining: 22m 16s\n",
      "5659:\tlearn: 0.0337899\ttest: 0.0383013\tbest: 0.0383013 (5659)\ttotal: 29m 2s\tremaining: 22m 16s\n",
      "5660:\tlearn: 0.0337899\ttest: 0.0383013\tbest: 0.0383013 (5660)\ttotal: 29m 2s\tremaining: 22m 15s\n",
      "5661:\tlearn: 0.0337899\ttest: 0.0383013\tbest: 0.0383013 (5661)\ttotal: 29m 3s\tremaining: 22m 15s\n",
      "5662:\tlearn: 0.0337899\ttest: 0.0383013\tbest: 0.0383013 (5661)\ttotal: 29m 3s\tremaining: 22m 15s\n",
      "5663:\tlearn: 0.0337899\ttest: 0.0383013\tbest: 0.0383013 (5661)\ttotal: 29m 3s\tremaining: 22m 14s\n",
      "5664:\tlearn: 0.0337899\ttest: 0.0383013\tbest: 0.0383013 (5661)\ttotal: 29m 3s\tremaining: 22m 14s\n",
      "5665:\tlearn: 0.0337899\ttest: 0.0383013\tbest: 0.0383013 (5665)\ttotal: 29m 4s\tremaining: 22m 14s\n",
      "5666:\tlearn: 0.0337899\ttest: 0.0383013\tbest: 0.0383013 (5666)\ttotal: 29m 4s\tremaining: 22m 13s\n",
      "5667:\tlearn: 0.0337899\ttest: 0.0383013\tbest: 0.0383013 (5667)\ttotal: 29m 5s\tremaining: 22m 13s\n",
      "5668:\tlearn: 0.0337899\ttest: 0.0383013\tbest: 0.0383013 (5667)\ttotal: 29m 5s\tremaining: 22m 13s\n",
      "5669:\tlearn: 0.0337899\ttest: 0.0383013\tbest: 0.0383013 (5667)\ttotal: 29m 5s\tremaining: 22m 13s\n",
      "5670:\tlearn: 0.0337899\ttest: 0.0383013\tbest: 0.0383013 (5670)\ttotal: 29m 6s\tremaining: 22m 13s\n",
      "5671:\tlearn: 0.0337899\ttest: 0.0383013\tbest: 0.0383013 (5671)\ttotal: 29m 6s\tremaining: 22m 12s\n",
      "5672:\tlearn: 0.0337899\ttest: 0.0383013\tbest: 0.0383013 (5672)\ttotal: 29m 7s\tremaining: 22m 12s\n",
      "5673:\tlearn: 0.0337899\ttest: 0.0383013\tbest: 0.0383013 (5673)\ttotal: 29m 7s\tremaining: 22m 12s\n",
      "5674:\tlearn: 0.0337899\ttest: 0.0383013\tbest: 0.0383013 (5673)\ttotal: 29m 8s\tremaining: 22m 12s\n",
      "5675:\tlearn: 0.0337899\ttest: 0.0383013\tbest: 0.0383013 (5673)\ttotal: 29m 8s\tremaining: 22m 11s\n",
      "5676:\tlearn: 0.0337898\ttest: 0.0383013\tbest: 0.0383013 (5676)\ttotal: 29m 8s\tremaining: 22m 11s\n",
      "5677:\tlearn: 0.0337898\ttest: 0.0383013\tbest: 0.0383013 (5677)\ttotal: 29m 9s\tremaining: 22m 11s\n",
      "5678:\tlearn: 0.0337873\ttest: 0.0383011\tbest: 0.0383011 (5678)\ttotal: 29m 9s\tremaining: 22m 11s\n",
      "5679:\tlearn: 0.0337872\ttest: 0.0383011\tbest: 0.0383011 (5679)\ttotal: 29m 9s\tremaining: 22m 10s\n",
      "5680:\tlearn: 0.0337872\ttest: 0.0383011\tbest: 0.0383011 (5680)\ttotal: 29m 9s\tremaining: 22m 10s\n",
      "5681:\tlearn: 0.0337834\ttest: 0.0383011\tbest: 0.0383011 (5680)\ttotal: 29m 10s\tremaining: 22m 10s\n",
      "5682:\tlearn: 0.0337788\ttest: 0.0383011\tbest: 0.0383011 (5680)\ttotal: 29m 10s\tremaining: 22m 9s\n",
      "5683:\tlearn: 0.0337788\ttest: 0.0383011\tbest: 0.0383011 (5680)\ttotal: 29m 10s\tremaining: 22m 9s\n",
      "5684:\tlearn: 0.0337788\ttest: 0.0383011\tbest: 0.0383011 (5680)\ttotal: 29m 10s\tremaining: 22m 9s\n",
      "5685:\tlearn: 0.0337788\ttest: 0.0383011\tbest: 0.0383011 (5680)\ttotal: 29m 11s\tremaining: 22m 8s\n",
      "5686:\tlearn: 0.0337788\ttest: 0.0383011\tbest: 0.0383011 (5680)\ttotal: 29m 11s\tremaining: 22m 8s\n",
      "5687:\tlearn: 0.0337788\ttest: 0.0383011\tbest: 0.0383011 (5680)\ttotal: 29m 11s\tremaining: 22m 7s\n",
      "5688:\tlearn: 0.0337788\ttest: 0.0383011\tbest: 0.0383011 (5680)\ttotal: 29m 11s\tremaining: 22m 7s\n",
      "5689:\tlearn: 0.0337788\ttest: 0.0383011\tbest: 0.0383011 (5680)\ttotal: 29m 12s\tremaining: 22m 7s\n",
      "5690:\tlearn: 0.0337787\ttest: 0.0383011\tbest: 0.0383011 (5690)\ttotal: 29m 12s\tremaining: 22m 6s\n",
      "5691:\tlearn: 0.0337787\ttest: 0.0383011\tbest: 0.0383011 (5691)\ttotal: 29m 12s\tremaining: 22m 6s\n",
      "5692:\tlearn: 0.0337787\ttest: 0.0383011\tbest: 0.0383011 (5692)\ttotal: 29m 12s\tremaining: 22m 6s\n",
      "5693:\tlearn: 0.0337787\ttest: 0.0383011\tbest: 0.0383011 (5693)\ttotal: 29m 13s\tremaining: 22m 5s\n",
      "5694:\tlearn: 0.0337787\ttest: 0.0383011\tbest: 0.0383011 (5693)\ttotal: 29m 13s\tremaining: 22m 5s\n",
      "5695:\tlearn: 0.0337787\ttest: 0.0383011\tbest: 0.0383011 (5695)\ttotal: 29m 13s\tremaining: 22m 5s\n",
      "5696:\tlearn: 0.0337787\ttest: 0.0383011\tbest: 0.0383011 (5695)\ttotal: 29m 14s\tremaining: 22m 4s\n",
      "5697:\tlearn: 0.0337787\ttest: 0.0383011\tbest: 0.0383011 (5695)\ttotal: 29m 14s\tremaining: 22m 4s\n",
      "5698:\tlearn: 0.0337787\ttest: 0.0383011\tbest: 0.0383011 (5698)\ttotal: 29m 14s\tremaining: 22m 4s\n",
      "5699:\tlearn: 0.0337787\ttest: 0.0383011\tbest: 0.0383011 (5699)\ttotal: 29m 14s\tremaining: 22m 3s\n",
      "5700:\tlearn: 0.0337769\ttest: 0.0383009\tbest: 0.0383009 (5700)\ttotal: 29m 15s\tremaining: 22m 3s\n",
      "5701:\tlearn: 0.0337720\ttest: 0.0383000\tbest: 0.0383000 (5701)\ttotal: 29m 15s\tremaining: 22m 3s\n",
      "5702:\tlearn: 0.0337720\ttest: 0.0383000\tbest: 0.0383000 (5702)\ttotal: 29m 15s\tremaining: 22m 2s\n",
      "5703:\tlearn: 0.0337695\ttest: 0.0383001\tbest: 0.0383000 (5702)\ttotal: 29m 16s\tremaining: 22m 2s\n",
      "5704:\tlearn: 0.0337695\ttest: 0.0383001\tbest: 0.0383000 (5702)\ttotal: 29m 16s\tremaining: 22m 2s\n",
      "5705:\tlearn: 0.0337695\ttest: 0.0383001\tbest: 0.0383000 (5702)\ttotal: 29m 16s\tremaining: 22m 1s\n",
      "5706:\tlearn: 0.0337695\ttest: 0.0383001\tbest: 0.0383000 (5702)\ttotal: 29m 16s\tremaining: 22m 1s\n",
      "5707:\tlearn: 0.0337666\ttest: 0.0383008\tbest: 0.0383000 (5702)\ttotal: 29m 17s\tremaining: 22m 1s\n",
      "5708:\tlearn: 0.0337666\ttest: 0.0383008\tbest: 0.0383000 (5702)\ttotal: 29m 17s\tremaining: 22m\n",
      "5709:\tlearn: 0.0337666\ttest: 0.0383008\tbest: 0.0383000 (5702)\ttotal: 29m 17s\tremaining: 22m\n",
      "5710:\tlearn: 0.0337666\ttest: 0.0383008\tbest: 0.0383000 (5702)\ttotal: 29m 17s\tremaining: 22m\n",
      "5711:\tlearn: 0.0337666\ttest: 0.0383008\tbest: 0.0383000 (5702)\ttotal: 29m 18s\tremaining: 21m 59s\n",
      "5712:\tlearn: 0.0337666\ttest: 0.0383008\tbest: 0.0383000 (5702)\ttotal: 29m 18s\tremaining: 21m 59s\n",
      "5713:\tlearn: 0.0337629\ttest: 0.0382998\tbest: 0.0382998 (5713)\ttotal: 29m 18s\tremaining: 21m 59s\n",
      "5714:\tlearn: 0.0337629\ttest: 0.0382998\tbest: 0.0382998 (5713)\ttotal: 29m 19s\tremaining: 21m 59s\n",
      "5715:\tlearn: 0.0337629\ttest: 0.0382998\tbest: 0.0382998 (5713)\ttotal: 29m 19s\tremaining: 21m 58s\n",
      "5716:\tlearn: 0.0337629\ttest: 0.0382998\tbest: 0.0382998 (5716)\ttotal: 29m 20s\tremaining: 21m 58s\n",
      "5717:\tlearn: 0.0337629\ttest: 0.0382998\tbest: 0.0382998 (5716)\ttotal: 29m 20s\tremaining: 21m 58s\n",
      "5718:\tlearn: 0.0337590\ttest: 0.0383009\tbest: 0.0382998 (5716)\ttotal: 29m 21s\tremaining: 21m 58s\n",
      "5719:\tlearn: 0.0337590\ttest: 0.0383009\tbest: 0.0382998 (5716)\ttotal: 29m 21s\tremaining: 21m 58s\n",
      "5720:\tlearn: 0.0337590\ttest: 0.0383009\tbest: 0.0382998 (5716)\ttotal: 29m 21s\tremaining: 21m 57s\n",
      "5721:\tlearn: 0.0337590\ttest: 0.0383009\tbest: 0.0382998 (5716)\ttotal: 29m 22s\tremaining: 21m 57s\n",
      "5722:\tlearn: 0.0337590\ttest: 0.0383009\tbest: 0.0382998 (5716)\ttotal: 29m 22s\tremaining: 21m 57s\n",
      "5723:\tlearn: 0.0337589\ttest: 0.0383008\tbest: 0.0382998 (5716)\ttotal: 29m 22s\tremaining: 21m 56s\n",
      "5724:\tlearn: 0.0337589\ttest: 0.0383008\tbest: 0.0382998 (5716)\ttotal: 29m 22s\tremaining: 21m 56s\n",
      "5725:\tlearn: 0.0337589\ttest: 0.0383008\tbest: 0.0382998 (5716)\ttotal: 29m 23s\tremaining: 21m 56s\n",
      "5726:\tlearn: 0.0337554\ttest: 0.0382995\tbest: 0.0382995 (5726)\ttotal: 29m 23s\tremaining: 21m 55s\n",
      "5727:\tlearn: 0.0337554\ttest: 0.0382995\tbest: 0.0382995 (5726)\ttotal: 29m 23s\tremaining: 21m 55s\n",
      "5728:\tlearn: 0.0337554\ttest: 0.0382995\tbest: 0.0382995 (5726)\ttotal: 29m 24s\tremaining: 21m 55s\n",
      "5729:\tlearn: 0.0337554\ttest: 0.0382995\tbest: 0.0382995 (5726)\ttotal: 29m 24s\tremaining: 21m 54s\n",
      "5730:\tlearn: 0.0337554\ttest: 0.0382995\tbest: 0.0382995 (5726)\ttotal: 29m 24s\tremaining: 21m 54s\n",
      "5731:\tlearn: 0.0337554\ttest: 0.0382995\tbest: 0.0382995 (5726)\ttotal: 29m 24s\tremaining: 21m 54s\n",
      "5732:\tlearn: 0.0337554\ttest: 0.0382995\tbest: 0.0382995 (5726)\ttotal: 29m 25s\tremaining: 21m 53s\n",
      "5733:\tlearn: 0.0337554\ttest: 0.0382995\tbest: 0.0382995 (5726)\ttotal: 29m 25s\tremaining: 21m 53s\n",
      "5734:\tlearn: 0.0337554\ttest: 0.0382995\tbest: 0.0382995 (5726)\ttotal: 29m 25s\tremaining: 21m 53s\n",
      "5735:\tlearn: 0.0337553\ttest: 0.0382995\tbest: 0.0382995 (5726)\ttotal: 29m 25s\tremaining: 21m 52s\n",
      "5736:\tlearn: 0.0337553\ttest: 0.0382995\tbest: 0.0382995 (5726)\ttotal: 29m 26s\tremaining: 21m 52s\n",
      "5737:\tlearn: 0.0337553\ttest: 0.0382995\tbest: 0.0382995 (5726)\ttotal: 29m 26s\tremaining: 21m 51s\n",
      "5738:\tlearn: 0.0337553\ttest: 0.0382995\tbest: 0.0382995 (5738)\ttotal: 29m 26s\tremaining: 21m 51s\n",
      "5739:\tlearn: 0.0337553\ttest: 0.0382995\tbest: 0.0382995 (5738)\ttotal: 29m 26s\tremaining: 21m 51s\n",
      "5740:\tlearn: 0.0337553\ttest: 0.0382995\tbest: 0.0382995 (5740)\ttotal: 29m 27s\tremaining: 21m 50s\n",
      "5741:\tlearn: 0.0337553\ttest: 0.0382995\tbest: 0.0382995 (5741)\ttotal: 29m 27s\tremaining: 21m 50s\n",
      "5742:\tlearn: 0.0337553\ttest: 0.0382995\tbest: 0.0382995 (5741)\ttotal: 29m 27s\tremaining: 21m 50s\n",
      "5743:\tlearn: 0.0337529\ttest: 0.0382992\tbest: 0.0382992 (5743)\ttotal: 29m 27s\tremaining: 21m 49s\n",
      "5744:\tlearn: 0.0337489\ttest: 0.0382984\tbest: 0.0382984 (5744)\ttotal: 29m 28s\tremaining: 21m 49s\n",
      "5745:\tlearn: 0.0337462\ttest: 0.0382984\tbest: 0.0382984 (5745)\ttotal: 29m 28s\tremaining: 21m 49s\n",
      "5746:\tlearn: 0.0337462\ttest: 0.0382984\tbest: 0.0382984 (5745)\ttotal: 29m 28s\tremaining: 21m 48s\n",
      "5747:\tlearn: 0.0337462\ttest: 0.0382984\tbest: 0.0382984 (5745)\ttotal: 29m 29s\tremaining: 21m 48s\n",
      "5748:\tlearn: 0.0337415\ttest: 0.0382977\tbest: 0.0382977 (5748)\ttotal: 29m 29s\tremaining: 21m 48s\n",
      "5749:\tlearn: 0.0337356\ttest: 0.0382965\tbest: 0.0382965 (5749)\ttotal: 29m 29s\tremaining: 21m 48s\n",
      "5750:\tlearn: 0.0337356\ttest: 0.0382965\tbest: 0.0382965 (5750)\ttotal: 29m 29s\tremaining: 21m 47s\n",
      "5751:\tlearn: 0.0337356\ttest: 0.0382965\tbest: 0.0382965 (5751)\ttotal: 29m 30s\tremaining: 21m 47s\n",
      "5752:\tlearn: 0.0337356\ttest: 0.0382965\tbest: 0.0382965 (5751)\ttotal: 29m 30s\tremaining: 21m 46s\n",
      "5753:\tlearn: 0.0337356\ttest: 0.0382965\tbest: 0.0382965 (5753)\ttotal: 29m 30s\tremaining: 21m 46s\n",
      "5754:\tlearn: 0.0337356\ttest: 0.0382965\tbest: 0.0382965 (5753)\ttotal: 29m 30s\tremaining: 21m 46s\n",
      "5755:\tlearn: 0.0337356\ttest: 0.0382965\tbest: 0.0382965 (5753)\ttotal: 29m 31s\tremaining: 21m 45s\n",
      "5756:\tlearn: 0.0337327\ttest: 0.0382966\tbest: 0.0382965 (5753)\ttotal: 29m 31s\tremaining: 21m 45s\n",
      "5757:\tlearn: 0.0337327\ttest: 0.0382966\tbest: 0.0382965 (5753)\ttotal: 29m 31s\tremaining: 21m 45s\n",
      "5758:\tlearn: 0.0337327\ttest: 0.0382966\tbest: 0.0382965 (5753)\ttotal: 29m 32s\tremaining: 21m 45s\n",
      "5759:\tlearn: 0.0337327\ttest: 0.0382966\tbest: 0.0382965 (5753)\ttotal: 29m 32s\tremaining: 21m 44s\n",
      "5760:\tlearn: 0.0337326\ttest: 0.0382966\tbest: 0.0382965 (5753)\ttotal: 29m 33s\tremaining: 21m 44s\n",
      "5761:\tlearn: 0.0337326\ttest: 0.0382966\tbest: 0.0382965 (5753)\ttotal: 29m 33s\tremaining: 21m 44s\n",
      "5762:\tlearn: 0.0337326\ttest: 0.0382966\tbest: 0.0382965 (5753)\ttotal: 29m 34s\tremaining: 21m 44s\n",
      "5763:\tlearn: 0.0337326\ttest: 0.0382966\tbest: 0.0382965 (5753)\ttotal: 29m 34s\tremaining: 21m 44s\n",
      "5764:\tlearn: 0.0337326\ttest: 0.0382966\tbest: 0.0382965 (5753)\ttotal: 29m 34s\tremaining: 21m 43s\n",
      "5765:\tlearn: 0.0337326\ttest: 0.0382966\tbest: 0.0382965 (5753)\ttotal: 29m 35s\tremaining: 21m 43s\n",
      "5766:\tlearn: 0.0337326\ttest: 0.0382966\tbest: 0.0382965 (5753)\ttotal: 29m 35s\tremaining: 21m 43s\n",
      "5767:\tlearn: 0.0337326\ttest: 0.0382966\tbest: 0.0382965 (5753)\ttotal: 29m 36s\tremaining: 21m 43s\n",
      "5768:\tlearn: 0.0337326\ttest: 0.0382966\tbest: 0.0382965 (5753)\ttotal: 29m 36s\tremaining: 21m 43s\n",
      "5769:\tlearn: 0.0337326\ttest: 0.0382966\tbest: 0.0382965 (5753)\ttotal: 29m 37s\tremaining: 21m 42s\n",
      "5770:\tlearn: 0.0337326\ttest: 0.0382966\tbest: 0.0382965 (5753)\ttotal: 29m 37s\tremaining: 21m 42s\n",
      "5771:\tlearn: 0.0337326\ttest: 0.0382966\tbest: 0.0382965 (5753)\ttotal: 29m 38s\tremaining: 21m 42s\n",
      "5772:\tlearn: 0.0337326\ttest: 0.0382966\tbest: 0.0382965 (5753)\ttotal: 29m 38s\tremaining: 21m 42s\n",
      "5773:\tlearn: 0.0337326\ttest: 0.0382966\tbest: 0.0382965 (5753)\ttotal: 29m 39s\tremaining: 21m 42s\n",
      "5774:\tlearn: 0.0337305\ttest: 0.0382964\tbest: 0.0382964 (5774)\ttotal: 29m 39s\tremaining: 21m 41s\n",
      "5775:\tlearn: 0.0337305\ttest: 0.0382964\tbest: 0.0382964 (5774)\ttotal: 29m 39s\tremaining: 21m 41s\n",
      "5776:\tlearn: 0.0337305\ttest: 0.0382964\tbest: 0.0382964 (5776)\ttotal: 29m 40s\tremaining: 21m 41s\n",
      "5777:\tlearn: 0.0337299\ttest: 0.0382963\tbest: 0.0382963 (5777)\ttotal: 29m 40s\tremaining: 21m 41s\n",
      "5778:\tlearn: 0.0337299\ttest: 0.0382963\tbest: 0.0382963 (5778)\ttotal: 29m 40s\tremaining: 21m 40s\n",
      "5779:\tlearn: 0.0337299\ttest: 0.0382963\tbest: 0.0382963 (5778)\ttotal: 29m 41s\tremaining: 21m 40s\n",
      "5780:\tlearn: 0.0337299\ttest: 0.0382963\tbest: 0.0382963 (5780)\ttotal: 29m 41s\tremaining: 21m 39s\n",
      "5781:\tlearn: 0.0337299\ttest: 0.0382963\tbest: 0.0382963 (5781)\ttotal: 29m 41s\tremaining: 21m 39s\n",
      "5782:\tlearn: 0.0337299\ttest: 0.0382963\tbest: 0.0382963 (5782)\ttotal: 29m 41s\tremaining: 21m 39s\n",
      "5783:\tlearn: 0.0337299\ttest: 0.0382963\tbest: 0.0382963 (5783)\ttotal: 29m 42s\tremaining: 21m 38s\n",
      "5784:\tlearn: 0.0337299\ttest: 0.0382963\tbest: 0.0382963 (5783)\ttotal: 29m 42s\tremaining: 21m 38s\n",
      "5785:\tlearn: 0.0337299\ttest: 0.0382963\tbest: 0.0382963 (5783)\ttotal: 29m 42s\tremaining: 21m 38s\n",
      "5786:\tlearn: 0.0337299\ttest: 0.0382963\tbest: 0.0382963 (5786)\ttotal: 29m 42s\tremaining: 21m 37s\n",
      "5787:\tlearn: 0.0337299\ttest: 0.0382963\tbest: 0.0382963 (5786)\ttotal: 29m 43s\tremaining: 21m 37s\n",
      "5788:\tlearn: 0.0337299\ttest: 0.0382963\tbest: 0.0382963 (5788)\ttotal: 29m 43s\tremaining: 21m 37s\n",
      "5789:\tlearn: 0.0337299\ttest: 0.0382963\tbest: 0.0382963 (5789)\ttotal: 29m 43s\tremaining: 21m 36s\n",
      "5790:\tlearn: 0.0337288\ttest: 0.0382957\tbest: 0.0382957 (5790)\ttotal: 29m 43s\tremaining: 21m 36s\n",
      "5791:\tlearn: 0.0337288\ttest: 0.0382957\tbest: 0.0382957 (5790)\ttotal: 29m 44s\tremaining: 21m 36s\n",
      "5792:\tlearn: 0.0337288\ttest: 0.0382957\tbest: 0.0382957 (5790)\ttotal: 29m 44s\tremaining: 21m 35s\n",
      "5793:\tlearn: 0.0337288\ttest: 0.0382957\tbest: 0.0382957 (5790)\ttotal: 29m 44s\tremaining: 21m 35s\n",
      "5794:\tlearn: 0.0337288\ttest: 0.0382957\tbest: 0.0382957 (5790)\ttotal: 29m 44s\tremaining: 21m 35s\n",
      "5795:\tlearn: 0.0337288\ttest: 0.0382957\tbest: 0.0382957 (5795)\ttotal: 29m 45s\tremaining: 21m 34s\n",
      "5796:\tlearn: 0.0337288\ttest: 0.0382957\tbest: 0.0382957 (5796)\ttotal: 29m 45s\tremaining: 21m 34s\n",
      "5797:\tlearn: 0.0337253\ttest: 0.0382956\tbest: 0.0382956 (5797)\ttotal: 29m 45s\tremaining: 21m 34s\n",
      "5798:\tlearn: 0.0337253\ttest: 0.0382956\tbest: 0.0382956 (5797)\ttotal: 29m 45s\tremaining: 21m 33s\n",
      "5799:\tlearn: 0.0337252\ttest: 0.0382956\tbest: 0.0382956 (5799)\ttotal: 29m 46s\tremaining: 21m 33s\n",
      "5800:\tlearn: 0.0337252\ttest: 0.0382956\tbest: 0.0382956 (5800)\ttotal: 29m 46s\tremaining: 21m 33s\n",
      "5801:\tlearn: 0.0337252\ttest: 0.0382956\tbest: 0.0382956 (5800)\ttotal: 29m 47s\tremaining: 21m 33s\n",
      "5802:\tlearn: 0.0337252\ttest: 0.0382956\tbest: 0.0382956 (5802)\ttotal: 29m 47s\tremaining: 21m 32s\n",
      "5803:\tlearn: 0.0337252\ttest: 0.0382956\tbest: 0.0382956 (5803)\ttotal: 29m 48s\tremaining: 21m 32s\n",
      "5804:\tlearn: 0.0337252\ttest: 0.0382956\tbest: 0.0382956 (5803)\ttotal: 29m 48s\tremaining: 21m 32s\n",
      "5805:\tlearn: 0.0337252\ttest: 0.0382956\tbest: 0.0382956 (5803)\ttotal: 29m 48s\tremaining: 21m 32s\n",
      "5806:\tlearn: 0.0337252\ttest: 0.0382956\tbest: 0.0382956 (5806)\ttotal: 29m 49s\tremaining: 21m 32s\n",
      "5807:\tlearn: 0.0337252\ttest: 0.0382956\tbest: 0.0382956 (5806)\ttotal: 29m 49s\tremaining: 21m 31s\n",
      "5808:\tlearn: 0.0337252\ttest: 0.0382956\tbest: 0.0382956 (5808)\ttotal: 29m 50s\tremaining: 21m 31s\n",
      "5809:\tlearn: 0.0337219\ttest: 0.0382943\tbest: 0.0382943 (5809)\ttotal: 29m 50s\tremaining: 21m 31s\n",
      "5810:\tlearn: 0.0337180\ttest: 0.0382930\tbest: 0.0382930 (5810)\ttotal: 29m 50s\tremaining: 21m 30s\n",
      "5811:\tlearn: 0.0337180\ttest: 0.0382930\tbest: 0.0382930 (5811)\ttotal: 29m 51s\tremaining: 21m 30s\n",
      "5812:\tlearn: 0.0337155\ttest: 0.0382914\tbest: 0.0382914 (5812)\ttotal: 29m 51s\tremaining: 21m 30s\n",
      "5813:\tlearn: 0.0337122\ttest: 0.0382914\tbest: 0.0382914 (5813)\ttotal: 29m 51s\tremaining: 21m 30s\n",
      "5814:\tlearn: 0.0337122\ttest: 0.0382914\tbest: 0.0382914 (5813)\ttotal: 29m 51s\tremaining: 21m 29s\n",
      "5815:\tlearn: 0.0337122\ttest: 0.0382914\tbest: 0.0382914 (5815)\ttotal: 29m 52s\tremaining: 21m 29s\n",
      "5816:\tlearn: 0.0337122\ttest: 0.0382914\tbest: 0.0382914 (5815)\ttotal: 29m 52s\tremaining: 21m 28s\n",
      "5817:\tlearn: 0.0337098\ttest: 0.0382914\tbest: 0.0382914 (5815)\ttotal: 29m 52s\tremaining: 21m 28s\n",
      "5818:\tlearn: 0.0337098\ttest: 0.0382914\tbest: 0.0382914 (5815)\ttotal: 29m 52s\tremaining: 21m 28s\n",
      "5819:\tlearn: 0.0337099\ttest: 0.0382914\tbest: 0.0382914 (5815)\ttotal: 29m 53s\tremaining: 21m 27s\n",
      "5820:\tlearn: 0.0337071\ttest: 0.0382908\tbest: 0.0382908 (5820)\ttotal: 29m 53s\tremaining: 21m 27s\n",
      "5821:\tlearn: 0.0337071\ttest: 0.0382908\tbest: 0.0382908 (5821)\ttotal: 29m 53s\tremaining: 21m 27s\n",
      "5822:\tlearn: 0.0337071\ttest: 0.0382908\tbest: 0.0382908 (5821)\ttotal: 29m 54s\tremaining: 21m 26s\n",
      "5823:\tlearn: 0.0337071\ttest: 0.0382908\tbest: 0.0382908 (5823)\ttotal: 29m 54s\tremaining: 21m 26s\n",
      "5824:\tlearn: 0.0337070\ttest: 0.0382908\tbest: 0.0382908 (5823)\ttotal: 29m 54s\tremaining: 21m 26s\n",
      "5825:\tlearn: 0.0337069\ttest: 0.0382908\tbest: 0.0382908 (5823)\ttotal: 29m 54s\tremaining: 21m 25s\n",
      "5826:\tlearn: 0.0337069\ttest: 0.0382908\tbest: 0.0382908 (5823)\ttotal: 29m 55s\tremaining: 21m 25s\n",
      "5827:\tlearn: 0.0337069\ttest: 0.0382908\tbest: 0.0382908 (5823)\ttotal: 29m 55s\tremaining: 21m 25s\n",
      "5828:\tlearn: 0.0337007\ttest: 0.0382892\tbest: 0.0382892 (5828)\ttotal: 29m 55s\tremaining: 21m 24s\n",
      "5829:\tlearn: 0.0337007\ttest: 0.0382892\tbest: 0.0382892 (5828)\ttotal: 29m 55s\tremaining: 21m 24s\n",
      "5830:\tlearn: 0.0337007\ttest: 0.0382892\tbest: 0.0382892 (5828)\ttotal: 29m 56s\tremaining: 21m 24s\n",
      "5831:\tlearn: 0.0337007\ttest: 0.0382892\tbest: 0.0382892 (5828)\ttotal: 29m 56s\tremaining: 21m 23s\n",
      "5832:\tlearn: 0.0336955\ttest: 0.0382893\tbest: 0.0382892 (5828)\ttotal: 29m 56s\tremaining: 21m 23s\n",
      "5833:\tlearn: 0.0336955\ttest: 0.0382893\tbest: 0.0382892 (5828)\ttotal: 29m 56s\tremaining: 21m 23s\n",
      "5834:\tlearn: 0.0336955\ttest: 0.0382893\tbest: 0.0382892 (5828)\ttotal: 29m 57s\tremaining: 21m 22s\n",
      "5835:\tlearn: 0.0336955\ttest: 0.0382893\tbest: 0.0382892 (5828)\ttotal: 29m 57s\tremaining: 21m 22s\n",
      "5836:\tlearn: 0.0336934\ttest: 0.0382884\tbest: 0.0382884 (5836)\ttotal: 29m 57s\tremaining: 21m 22s\n",
      "5837:\tlearn: 0.0336934\ttest: 0.0382884\tbest: 0.0382884 (5836)\ttotal: 29m 57s\tremaining: 21m 21s\n",
      "5838:\tlearn: 0.0336892\ttest: 0.0382886\tbest: 0.0382884 (5836)\ttotal: 29m 58s\tremaining: 21m 21s\n",
      "5839:\tlearn: 0.0336892\ttest: 0.0382886\tbest: 0.0382884 (5836)\ttotal: 29m 58s\tremaining: 21m 21s\n",
      "5840:\tlearn: 0.0336892\ttest: 0.0382886\tbest: 0.0382884 (5836)\ttotal: 29m 58s\tremaining: 21m 20s\n",
      "5841:\tlearn: 0.0336892\ttest: 0.0382886\tbest: 0.0382884 (5836)\ttotal: 29m 59s\tremaining: 21m 20s\n",
      "5842:\tlearn: 0.0336892\ttest: 0.0382886\tbest: 0.0382884 (5836)\ttotal: 29m 59s\tremaining: 21m 20s\n",
      "5843:\tlearn: 0.0336892\ttest: 0.0382886\tbest: 0.0382884 (5836)\ttotal: 29m 59s\tremaining: 21m 19s\n",
      "5844:\tlearn: 0.0336892\ttest: 0.0382886\tbest: 0.0382884 (5836)\ttotal: 29m 59s\tremaining: 21m 19s\n",
      "5845:\tlearn: 0.0336859\ttest: 0.0382877\tbest: 0.0382877 (5845)\ttotal: 30m\tremaining: 21m 19s\n",
      "5846:\tlearn: 0.0336858\ttest: 0.0382877\tbest: 0.0382877 (5846)\ttotal: 30m\tremaining: 21m 18s\n",
      "5847:\tlearn: 0.0336858\ttest: 0.0382877\tbest: 0.0382877 (5847)\ttotal: 30m\tremaining: 21m 18s\n",
      "5848:\tlearn: 0.0336858\ttest: 0.0382877\tbest: 0.0382877 (5847)\ttotal: 30m 1s\tremaining: 21m 18s\n",
      "5849:\tlearn: 0.0336858\ttest: 0.0382877\tbest: 0.0382877 (5847)\ttotal: 30m 1s\tremaining: 21m 18s\n",
      "5850:\tlearn: 0.0336858\ttest: 0.0382877\tbest: 0.0382877 (5847)\ttotal: 30m 2s\tremaining: 21m 17s\n",
      "5851:\tlearn: 0.0336858\ttest: 0.0382877\tbest: 0.0382877 (5851)\ttotal: 30m 2s\tremaining: 21m 17s\n",
      "5852:\tlearn: 0.0336858\ttest: 0.0382877\tbest: 0.0382877 (5852)\ttotal: 30m 3s\tremaining: 21m 17s\n",
      "5853:\tlearn: 0.0336858\ttest: 0.0382877\tbest: 0.0382877 (5852)\ttotal: 30m 3s\tremaining: 21m 17s\n",
      "5854:\tlearn: 0.0336858\ttest: 0.0382877\tbest: 0.0382877 (5852)\ttotal: 30m 3s\tremaining: 21m 17s\n",
      "5855:\tlearn: 0.0336817\ttest: 0.0382864\tbest: 0.0382864 (5855)\ttotal: 30m 4s\tremaining: 21m 16s\n",
      "5856:\tlearn: 0.0336817\ttest: 0.0382864\tbest: 0.0382864 (5855)\ttotal: 30m 4s\tremaining: 21m 16s\n",
      "5857:\tlearn: 0.0336786\ttest: 0.0382857\tbest: 0.0382857 (5857)\ttotal: 30m 4s\tremaining: 21m 16s\n",
      "5858:\tlearn: 0.0336786\ttest: 0.0382857\tbest: 0.0382857 (5857)\ttotal: 30m 5s\tremaining: 21m 15s\n",
      "5859:\tlearn: 0.0336786\ttest: 0.0382857\tbest: 0.0382857 (5859)\ttotal: 30m 5s\tremaining: 21m 15s\n",
      "5860:\tlearn: 0.0336786\ttest: 0.0382857\tbest: 0.0382857 (5859)\ttotal: 30m 5s\tremaining: 21m 15s\n",
      "5861:\tlearn: 0.0336786\ttest: 0.0382857\tbest: 0.0382857 (5861)\ttotal: 30m 5s\tremaining: 21m 14s\n",
      "5862:\tlearn: 0.0336786\ttest: 0.0382857\tbest: 0.0382857 (5861)\ttotal: 30m 6s\tremaining: 21m 14s\n",
      "5863:\tlearn: 0.0336786\ttest: 0.0382857\tbest: 0.0382857 (5861)\ttotal: 30m 6s\tremaining: 21m 14s\n",
      "5864:\tlearn: 0.0336786\ttest: 0.0382857\tbest: 0.0382857 (5864)\ttotal: 30m 6s\tremaining: 21m 13s\n",
      "5865:\tlearn: 0.0336786\ttest: 0.0382857\tbest: 0.0382857 (5864)\ttotal: 30m 6s\tremaining: 21m 13s\n",
      "5866:\tlearn: 0.0336786\ttest: 0.0382857\tbest: 0.0382857 (5866)\ttotal: 30m 7s\tremaining: 21m 13s\n",
      "5867:\tlearn: 0.0336786\ttest: 0.0382857\tbest: 0.0382857 (5867)\ttotal: 30m 7s\tremaining: 21m 12s\n",
      "5868:\tlearn: 0.0336786\ttest: 0.0382857\tbest: 0.0382857 (5867)\ttotal: 30m 7s\tremaining: 21m 12s\n",
      "5869:\tlearn: 0.0336786\ttest: 0.0382857\tbest: 0.0382857 (5869)\ttotal: 30m 8s\tremaining: 21m 12s\n",
      "5870:\tlearn: 0.0336786\ttest: 0.0382857\tbest: 0.0382857 (5870)\ttotal: 30m 8s\tremaining: 21m 11s\n",
      "5871:\tlearn: 0.0336786\ttest: 0.0382857\tbest: 0.0382857 (5870)\ttotal: 30m 8s\tremaining: 21m 11s\n",
      "5872:\tlearn: 0.0336785\ttest: 0.0382857\tbest: 0.0382857 (5872)\ttotal: 30m 8s\tremaining: 21m 11s\n",
      "5873:\tlearn: 0.0336785\ttest: 0.0382857\tbest: 0.0382857 (5873)\ttotal: 30m 9s\tremaining: 21m 10s\n",
      "5874:\tlearn: 0.0336785\ttest: 0.0382857\tbest: 0.0382857 (5873)\ttotal: 30m 9s\tremaining: 21m 10s\n",
      "5875:\tlearn: 0.0336785\ttest: 0.0382857\tbest: 0.0382857 (5875)\ttotal: 30m 9s\tremaining: 21m 10s\n",
      "5876:\tlearn: 0.0336785\ttest: 0.0382857\tbest: 0.0382857 (5876)\ttotal: 30m 9s\tremaining: 21m 9s\n",
      "5877:\tlearn: 0.0336758\ttest: 0.0382847\tbest: 0.0382847 (5877)\ttotal: 30m 10s\tremaining: 21m 9s\n",
      "5878:\tlearn: 0.0336758\ttest: 0.0382847\tbest: 0.0382847 (5877)\ttotal: 30m 10s\tremaining: 21m 9s\n",
      "5879:\tlearn: 0.0336758\ttest: 0.0382847\tbest: 0.0382847 (5877)\ttotal: 30m 10s\tremaining: 21m 8s\n",
      "5880:\tlearn: 0.0336758\ttest: 0.0382847\tbest: 0.0382847 (5880)\ttotal: 30m 10s\tremaining: 21m 8s\n",
      "5881:\tlearn: 0.0336758\ttest: 0.0382847\tbest: 0.0382847 (5880)\ttotal: 30m 11s\tremaining: 21m 7s\n",
      "5882:\tlearn: 0.0336758\ttest: 0.0382847\tbest: 0.0382847 (5882)\ttotal: 30m 11s\tremaining: 21m 7s\n",
      "5883:\tlearn: 0.0336727\ttest: 0.0382827\tbest: 0.0382827 (5883)\ttotal: 30m 11s\tremaining: 21m 7s\n",
      "5884:\tlearn: 0.0336727\ttest: 0.0382827\tbest: 0.0382827 (5884)\ttotal: 30m 11s\tremaining: 21m 6s\n",
      "5885:\tlearn: 0.0336682\ttest: 0.0382816\tbest: 0.0382816 (5885)\ttotal: 30m 12s\tremaining: 21m 6s\n",
      "5886:\tlearn: 0.0336682\ttest: 0.0382816\tbest: 0.0382816 (5886)\ttotal: 30m 12s\tremaining: 21m 6s\n",
      "5887:\tlearn: 0.0336682\ttest: 0.0382816\tbest: 0.0382816 (5887)\ttotal: 30m 12s\tremaining: 21m 5s\n",
      "5888:\tlearn: 0.0336682\ttest: 0.0382816\tbest: 0.0382816 (5888)\ttotal: 30m 13s\tremaining: 21m 5s\n",
      "5889:\tlearn: 0.0336682\ttest: 0.0382816\tbest: 0.0382816 (5888)\ttotal: 30m 13s\tremaining: 21m 5s\n",
      "5890:\tlearn: 0.0336682\ttest: 0.0382816\tbest: 0.0382816 (5890)\ttotal: 30m 13s\tremaining: 21m 4s\n",
      "5891:\tlearn: 0.0336682\ttest: 0.0382816\tbest: 0.0382816 (5891)\ttotal: 30m 13s\tremaining: 21m 4s\n",
      "5892:\tlearn: 0.0336682\ttest: 0.0382816\tbest: 0.0382816 (5892)\ttotal: 30m 14s\tremaining: 21m 4s\n",
      "5893:\tlearn: 0.0336682\ttest: 0.0382816\tbest: 0.0382816 (5892)\ttotal: 30m 14s\tremaining: 21m 3s\n",
      "5894:\tlearn: 0.0336682\ttest: 0.0382816\tbest: 0.0382816 (5892)\ttotal: 30m 14s\tremaining: 21m 3s\n",
      "5895:\tlearn: 0.0336682\ttest: 0.0382816\tbest: 0.0382816 (5895)\ttotal: 30m 15s\tremaining: 21m 3s\n",
      "5896:\tlearn: 0.0336682\ttest: 0.0382816\tbest: 0.0382816 (5895)\ttotal: 30m 15s\tremaining: 21m 3s\n",
      "5897:\tlearn: 0.0336682\ttest: 0.0382816\tbest: 0.0382816 (5897)\ttotal: 30m 16s\tremaining: 21m 3s\n",
      "5898:\tlearn: 0.0336682\ttest: 0.0382816\tbest: 0.0382816 (5897)\ttotal: 30m 16s\tremaining: 21m 2s\n",
      "5899:\tlearn: 0.0336682\ttest: 0.0382816\tbest: 0.0382816 (5897)\ttotal: 30m 17s\tremaining: 21m 2s\n",
      "5900:\tlearn: 0.0336655\ttest: 0.0382822\tbest: 0.0382816 (5897)\ttotal: 30m 17s\tremaining: 21m 2s\n",
      "5901:\tlearn: 0.0336655\ttest: 0.0382822\tbest: 0.0382816 (5897)\ttotal: 30m 17s\tremaining: 21m 2s\n",
      "5902:\tlearn: 0.0336655\ttest: 0.0382822\tbest: 0.0382816 (5897)\ttotal: 30m 18s\tremaining: 21m 2s\n",
      "5903:\tlearn: 0.0336655\ttest: 0.0382822\tbest: 0.0382816 (5897)\ttotal: 30m 18s\tremaining: 21m 1s\n",
      "5904:\tlearn: 0.0336645\ttest: 0.0382825\tbest: 0.0382816 (5897)\ttotal: 30m 18s\tremaining: 21m 1s\n",
      "5905:\tlearn: 0.0336645\ttest: 0.0382825\tbest: 0.0382816 (5897)\ttotal: 30m 19s\tremaining: 21m 1s\n",
      "5906:\tlearn: 0.0336645\ttest: 0.0382825\tbest: 0.0382816 (5897)\ttotal: 30m 19s\tremaining: 21m\n",
      "5907:\tlearn: 0.0336645\ttest: 0.0382825\tbest: 0.0382816 (5897)\ttotal: 30m 19s\tremaining: 21m\n",
      "5908:\tlearn: 0.0336645\ttest: 0.0382825\tbest: 0.0382816 (5897)\ttotal: 30m 19s\tremaining: 21m\n",
      "5909:\tlearn: 0.0336645\ttest: 0.0382825\tbest: 0.0382816 (5897)\ttotal: 30m 20s\tremaining: 20m 59s\n",
      "5910:\tlearn: 0.0336645\ttest: 0.0382825\tbest: 0.0382816 (5897)\ttotal: 30m 20s\tremaining: 20m 59s\n",
      "5911:\tlearn: 0.0336645\ttest: 0.0382825\tbest: 0.0382816 (5897)\ttotal: 30m 20s\tremaining: 20m 58s\n",
      "5912:\tlearn: 0.0336645\ttest: 0.0382825\tbest: 0.0382816 (5897)\ttotal: 30m 20s\tremaining: 20m 58s\n",
      "5913:\tlearn: 0.0336645\ttest: 0.0382825\tbest: 0.0382816 (5897)\ttotal: 30m 21s\tremaining: 20m 58s\n",
      "5914:\tlearn: 0.0336645\ttest: 0.0382825\tbest: 0.0382816 (5897)\ttotal: 30m 21s\tremaining: 20m 57s\n",
      "5915:\tlearn: 0.0336644\ttest: 0.0382825\tbest: 0.0382816 (5897)\ttotal: 30m 21s\tremaining: 20m 57s\n",
      "5916:\tlearn: 0.0336644\ttest: 0.0382825\tbest: 0.0382816 (5897)\ttotal: 30m 21s\tremaining: 20m 57s\n",
      "5917:\tlearn: 0.0336644\ttest: 0.0382825\tbest: 0.0382816 (5897)\ttotal: 30m 22s\tremaining: 20m 56s\n",
      "5918:\tlearn: 0.0336644\ttest: 0.0382825\tbest: 0.0382816 (5897)\ttotal: 30m 22s\tremaining: 20m 56s\n",
      "5919:\tlearn: 0.0336644\ttest: 0.0382825\tbest: 0.0382816 (5897)\ttotal: 30m 22s\tremaining: 20m 56s\n",
      "5920:\tlearn: 0.0336644\ttest: 0.0382825\tbest: 0.0382816 (5897)\ttotal: 30m 22s\tremaining: 20m 55s\n",
      "5921:\tlearn: 0.0336644\ttest: 0.0382825\tbest: 0.0382816 (5897)\ttotal: 30m 23s\tremaining: 20m 55s\n",
      "5922:\tlearn: 0.0336644\ttest: 0.0382825\tbest: 0.0382816 (5897)\ttotal: 30m 23s\tremaining: 20m 55s\n",
      "5923:\tlearn: 0.0336644\ttest: 0.0382825\tbest: 0.0382816 (5897)\ttotal: 30m 23s\tremaining: 20m 54s\n",
      "5924:\tlearn: 0.0336644\ttest: 0.0382825\tbest: 0.0382816 (5897)\ttotal: 30m 24s\tremaining: 20m 54s\n",
      "5925:\tlearn: 0.0336644\ttest: 0.0382825\tbest: 0.0382816 (5897)\ttotal: 30m 24s\tremaining: 20m 54s\n",
      "5926:\tlearn: 0.0336644\ttest: 0.0382825\tbest: 0.0382816 (5897)\ttotal: 30m 24s\tremaining: 20m 53s\n",
      "5927:\tlearn: 0.0336644\ttest: 0.0382825\tbest: 0.0382816 (5897)\ttotal: 30m 24s\tremaining: 20m 53s\n",
      "5928:\tlearn: 0.0336644\ttest: 0.0382825\tbest: 0.0382816 (5897)\ttotal: 30m 25s\tremaining: 20m 53s\n",
      "5929:\tlearn: 0.0336644\ttest: 0.0382825\tbest: 0.0382816 (5897)\ttotal: 30m 25s\tremaining: 20m 52s\n",
      "5930:\tlearn: 0.0336644\ttest: 0.0382825\tbest: 0.0382816 (5897)\ttotal: 30m 25s\tremaining: 20m 52s\n",
      "5931:\tlearn: 0.0336644\ttest: 0.0382825\tbest: 0.0382816 (5897)\ttotal: 30m 25s\tremaining: 20m 52s\n",
      "5932:\tlearn: 0.0336644\ttest: 0.0382825\tbest: 0.0382816 (5897)\ttotal: 30m 26s\tremaining: 20m 51s\n",
      "5933:\tlearn: 0.0336644\ttest: 0.0382825\tbest: 0.0382816 (5897)\ttotal: 30m 26s\tremaining: 20m 51s\n",
      "5934:\tlearn: 0.0336644\ttest: 0.0382825\tbest: 0.0382816 (5897)\ttotal: 30m 26s\tremaining: 20m 51s\n",
      "5935:\tlearn: 0.0336644\ttest: 0.0382825\tbest: 0.0382816 (5897)\ttotal: 30m 26s\tremaining: 20m 50s\n",
      "5936:\tlearn: 0.0336644\ttest: 0.0382825\tbest: 0.0382816 (5897)\ttotal: 30m 27s\tremaining: 20m 50s\n",
      "5937:\tlearn: 0.0336644\ttest: 0.0382825\tbest: 0.0382816 (5897)\ttotal: 30m 27s\tremaining: 20m 50s\n",
      "5938:\tlearn: 0.0336644\ttest: 0.0382825\tbest: 0.0382816 (5897)\ttotal: 30m 27s\tremaining: 20m 49s\n",
      "5939:\tlearn: 0.0336644\ttest: 0.0382825\tbest: 0.0382816 (5897)\ttotal: 30m 27s\tremaining: 20m 49s\n",
      "5940:\tlearn: 0.0336607\ttest: 0.0382827\tbest: 0.0382816 (5897)\ttotal: 30m 28s\tremaining: 20m 49s\n",
      "5941:\tlearn: 0.0336607\ttest: 0.0382827\tbest: 0.0382816 (5897)\ttotal: 30m 28s\tremaining: 20m 48s\n",
      "5942:\tlearn: 0.0336607\ttest: 0.0382827\tbest: 0.0382816 (5897)\ttotal: 30m 28s\tremaining: 20m 48s\n",
      "5943:\tlearn: 0.0336550\ttest: 0.0382805\tbest: 0.0382805 (5943)\ttotal: 30m 29s\tremaining: 20m 48s\n",
      "5944:\tlearn: 0.0336550\ttest: 0.0382805\tbest: 0.0382805 (5943)\ttotal: 30m 29s\tremaining: 20m 48s\n",
      "5945:\tlearn: 0.0336550\ttest: 0.0382805\tbest: 0.0382805 (5945)\ttotal: 30m 30s\tremaining: 20m 47s\n",
      "5946:\tlearn: 0.0336550\ttest: 0.0382805\tbest: 0.0382805 (5945)\ttotal: 30m 30s\tremaining: 20m 47s\n",
      "5947:\tlearn: 0.0336550\ttest: 0.0382805\tbest: 0.0382805 (5945)\ttotal: 30m 31s\tremaining: 20m 47s\n",
      "5948:\tlearn: 0.0336550\ttest: 0.0382805\tbest: 0.0382805 (5945)\ttotal: 30m 31s\tremaining: 20m 47s\n",
      "5949:\tlearn: 0.0336550\ttest: 0.0382805\tbest: 0.0382805 (5945)\ttotal: 30m 32s\tremaining: 20m 47s\n",
      "5950:\tlearn: 0.0336550\ttest: 0.0382805\tbest: 0.0382805 (5945)\ttotal: 30m 32s\tremaining: 20m 46s\n",
      "5951:\tlearn: 0.0336550\ttest: 0.0382805\tbest: 0.0382805 (5945)\ttotal: 30m 32s\tremaining: 20m 46s\n",
      "5952:\tlearn: 0.0336550\ttest: 0.0382805\tbest: 0.0382805 (5945)\ttotal: 30m 32s\tremaining: 20m 46s\n",
      "5953:\tlearn: 0.0336549\ttest: 0.0382805\tbest: 0.0382805 (5945)\ttotal: 30m 33s\tremaining: 20m 45s\n",
      "5954:\tlearn: 0.0336549\ttest: 0.0382805\tbest: 0.0382805 (5945)\ttotal: 30m 33s\tremaining: 20m 45s\n",
      "5955:\tlearn: 0.0336549\ttest: 0.0382805\tbest: 0.0382805 (5945)\ttotal: 30m 33s\tremaining: 20m 45s\n",
      "5956:\tlearn: 0.0336549\ttest: 0.0382805\tbest: 0.0382805 (5945)\ttotal: 30m 33s\tremaining: 20m 44s\n",
      "5957:\tlearn: 0.0336512\ttest: 0.0382783\tbest: 0.0382783 (5957)\ttotal: 30m 34s\tremaining: 20m 44s\n",
      "5958:\tlearn: 0.0336474\ttest: 0.0382772\tbest: 0.0382772 (5958)\ttotal: 30m 34s\tremaining: 20m 44s\n",
      "5959:\tlearn: 0.0336474\ttest: 0.0382772\tbest: 0.0382772 (5959)\ttotal: 30m 34s\tremaining: 20m 43s\n",
      "5960:\tlearn: 0.0336474\ttest: 0.0382772\tbest: 0.0382772 (5960)\ttotal: 30m 35s\tremaining: 20m 43s\n",
      "5961:\tlearn: 0.0336474\ttest: 0.0382772\tbest: 0.0382772 (5961)\ttotal: 30m 35s\tremaining: 20m 43s\n",
      "5962:\tlearn: 0.0336474\ttest: 0.0382772\tbest: 0.0382772 (5962)\ttotal: 30m 35s\tremaining: 20m 42s\n",
      "5963:\tlearn: 0.0336474\ttest: 0.0382772\tbest: 0.0382772 (5962)\ttotal: 30m 35s\tremaining: 20m 42s\n",
      "5964:\tlearn: 0.0336474\ttest: 0.0382772\tbest: 0.0382772 (5964)\ttotal: 30m 36s\tremaining: 20m 41s\n",
      "5965:\tlearn: 0.0336474\ttest: 0.0382772\tbest: 0.0382772 (5965)\ttotal: 30m 36s\tremaining: 20m 41s\n",
      "5966:\tlearn: 0.0336473\ttest: 0.0382772\tbest: 0.0382772 (5966)\ttotal: 30m 36s\tremaining: 20m 41s\n",
      "5967:\tlearn: 0.0336428\ttest: 0.0382761\tbest: 0.0382761 (5967)\ttotal: 30m 36s\tremaining: 20m 41s\n",
      "5968:\tlearn: 0.0336428\ttest: 0.0382761\tbest: 0.0382761 (5967)\ttotal: 30m 37s\tremaining: 20m 40s\n",
      "5969:\tlearn: 0.0336428\ttest: 0.0382761\tbest: 0.0382761 (5969)\ttotal: 30m 37s\tremaining: 20m 40s\n",
      "5970:\tlearn: 0.0336401\ttest: 0.0382761\tbest: 0.0382761 (5970)\ttotal: 30m 37s\tremaining: 20m 40s\n",
      "5971:\tlearn: 0.0336401\ttest: 0.0382761\tbest: 0.0382761 (5970)\ttotal: 30m 37s\tremaining: 20m 39s\n",
      "5972:\tlearn: 0.0336401\ttest: 0.0382761\tbest: 0.0382761 (5972)\ttotal: 30m 38s\tremaining: 20m 39s\n",
      "5973:\tlearn: 0.0336401\ttest: 0.0382761\tbest: 0.0382761 (5973)\ttotal: 30m 38s\tremaining: 20m 38s\n",
      "5974:\tlearn: 0.0336401\ttest: 0.0382761\tbest: 0.0382761 (5973)\ttotal: 30m 38s\tremaining: 20m 38s\n",
      "5975:\tlearn: 0.0336401\ttest: 0.0382761\tbest: 0.0382761 (5975)\ttotal: 30m 39s\tremaining: 20m 38s\n",
      "5976:\tlearn: 0.0336401\ttest: 0.0382761\tbest: 0.0382761 (5975)\ttotal: 30m 39s\tremaining: 20m 37s\n",
      "5977:\tlearn: 0.0336383\ttest: 0.0382758\tbest: 0.0382758 (5977)\ttotal: 30m 39s\tremaining: 20m 37s\n",
      "5978:\tlearn: 0.0336383\ttest: 0.0382758\tbest: 0.0382758 (5977)\ttotal: 30m 39s\tremaining: 20m 37s\n",
      "5979:\tlearn: 0.0336383\ttest: 0.0382758\tbest: 0.0382758 (5979)\ttotal: 30m 40s\tremaining: 20m 36s\n",
      "5980:\tlearn: 0.0336346\ttest: 0.0382747\tbest: 0.0382747 (5980)\ttotal: 30m 40s\tremaining: 20m 36s\n",
      "5981:\tlearn: 0.0336346\ttest: 0.0382747\tbest: 0.0382747 (5980)\ttotal: 30m 40s\tremaining: 20m 36s\n",
      "5982:\tlearn: 0.0336346\ttest: 0.0382747\tbest: 0.0382747 (5980)\ttotal: 30m 40s\tremaining: 20m 35s\n",
      "5983:\tlearn: 0.0336346\ttest: 0.0382747\tbest: 0.0382747 (5983)\ttotal: 30m 41s\tremaining: 20m 35s\n",
      "5984:\tlearn: 0.0336346\ttest: 0.0382747\tbest: 0.0382747 (5984)\ttotal: 30m 41s\tremaining: 20m 35s\n",
      "5985:\tlearn: 0.0336346\ttest: 0.0382747\tbest: 0.0382747 (5984)\ttotal: 30m 41s\tremaining: 20m 34s\n",
      "5986:\tlearn: 0.0336346\ttest: 0.0382747\tbest: 0.0382747 (5986)\ttotal: 30m 41s\tremaining: 20m 34s\n",
      "5987:\tlearn: 0.0336346\ttest: 0.0382747\tbest: 0.0382747 (5986)\ttotal: 30m 42s\tremaining: 20m 34s\n",
      "5988:\tlearn: 0.0336346\ttest: 0.0382747\tbest: 0.0382747 (5986)\ttotal: 30m 42s\tremaining: 20m 34s\n",
      "5989:\tlearn: 0.0336346\ttest: 0.0382747\tbest: 0.0382747 (5989)\ttotal: 30m 43s\tremaining: 20m 33s\n",
      "5990:\tlearn: 0.0336346\ttest: 0.0382747\tbest: 0.0382747 (5990)\ttotal: 30m 43s\tremaining: 20m 33s\n",
      "5991:\tlearn: 0.0336346\ttest: 0.0382747\tbest: 0.0382747 (5991)\ttotal: 30m 44s\tremaining: 20m 33s\n",
      "5992:\tlearn: 0.0336332\ttest: 0.0382747\tbest: 0.0382747 (5991)\ttotal: 30m 44s\tremaining: 20m 33s\n",
      "5993:\tlearn: 0.0336332\ttest: 0.0382747\tbest: 0.0382747 (5991)\ttotal: 30m 44s\tremaining: 20m 33s\n",
      "5994:\tlearn: 0.0336332\ttest: 0.0382747\tbest: 0.0382747 (5991)\ttotal: 30m 45s\tremaining: 20m 32s\n",
      "5995:\tlearn: 0.0336332\ttest: 0.0382747\tbest: 0.0382747 (5991)\ttotal: 30m 45s\tremaining: 20m 32s\n",
      "5996:\tlearn: 0.0336332\ttest: 0.0382747\tbest: 0.0382747 (5991)\ttotal: 30m 46s\tremaining: 20m 32s\n",
      "5997:\tlearn: 0.0336332\ttest: 0.0382747\tbest: 0.0382747 (5991)\ttotal: 30m 46s\tremaining: 20m 31s\n",
      "5998:\tlearn: 0.0336332\ttest: 0.0382747\tbest: 0.0382747 (5991)\ttotal: 30m 46s\tremaining: 20m 31s\n",
      "5999:\tlearn: 0.0336295\ttest: 0.0382740\tbest: 0.0382740 (5999)\ttotal: 30m 46s\tremaining: 20m 31s\n",
      "6000:\tlearn: 0.0336295\ttest: 0.0382740\tbest: 0.0382740 (6000)\ttotal: 30m 47s\tremaining: 20m 30s\n",
      "6001:\tlearn: 0.0336295\ttest: 0.0382740\tbest: 0.0382740 (6000)\ttotal: 30m 47s\tremaining: 20m 30s\n",
      "6002:\tlearn: 0.0336295\ttest: 0.0382740\tbest: 0.0382740 (6000)\ttotal: 30m 47s\tremaining: 20m 30s\n",
      "6003:\tlearn: 0.0336295\ttest: 0.0382740\tbest: 0.0382740 (6000)\ttotal: 30m 48s\tremaining: 20m 29s\n",
      "6004:\tlearn: 0.0336295\ttest: 0.0382740\tbest: 0.0382740 (6000)\ttotal: 30m 48s\tremaining: 20m 29s\n",
      "6005:\tlearn: 0.0336295\ttest: 0.0382740\tbest: 0.0382740 (6000)\ttotal: 30m 48s\tremaining: 20m 29s\n",
      "6006:\tlearn: 0.0336295\ttest: 0.0382740\tbest: 0.0382740 (6000)\ttotal: 30m 48s\tremaining: 20m 28s\n",
      "6007:\tlearn: 0.0336295\ttest: 0.0382740\tbest: 0.0382740 (6000)\ttotal: 30m 49s\tremaining: 20m 28s\n",
      "6008:\tlearn: 0.0336295\ttest: 0.0382740\tbest: 0.0382740 (6000)\ttotal: 30m 49s\tremaining: 20m 28s\n",
      "6009:\tlearn: 0.0336295\ttest: 0.0382740\tbest: 0.0382740 (6000)\ttotal: 30m 49s\tremaining: 20m 27s\n",
      "6010:\tlearn: 0.0336295\ttest: 0.0382740\tbest: 0.0382740 (6010)\ttotal: 30m 49s\tremaining: 20m 27s\n",
      "6011:\tlearn: 0.0336280\ttest: 0.0382742\tbest: 0.0382740 (6010)\ttotal: 30m 50s\tremaining: 20m 27s\n",
      "6012:\tlearn: 0.0336280\ttest: 0.0382742\tbest: 0.0382740 (6010)\ttotal: 30m 50s\tremaining: 20m 26s\n",
      "6013:\tlearn: 0.0336280\ttest: 0.0382742\tbest: 0.0382740 (6010)\ttotal: 30m 50s\tremaining: 20m 26s\n",
      "6014:\tlearn: 0.0336280\ttest: 0.0382742\tbest: 0.0382740 (6010)\ttotal: 30m 50s\tremaining: 20m 26s\n",
      "6015:\tlearn: 0.0336280\ttest: 0.0382742\tbest: 0.0382740 (6010)\ttotal: 30m 51s\tremaining: 20m 25s\n",
      "6016:\tlearn: 0.0336280\ttest: 0.0382742\tbest: 0.0382740 (6010)\ttotal: 30m 51s\tremaining: 20m 25s\n",
      "6017:\tlearn: 0.0336280\ttest: 0.0382742\tbest: 0.0382740 (6010)\ttotal: 30m 51s\tremaining: 20m 25s\n",
      "6018:\tlearn: 0.0336280\ttest: 0.0382742\tbest: 0.0382740 (6010)\ttotal: 30m 51s\tremaining: 20m 24s\n",
      "6019:\tlearn: 0.0336243\ttest: 0.0382734\tbest: 0.0382734 (6019)\ttotal: 30m 52s\tremaining: 20m 24s\n",
      "6020:\tlearn: 0.0336243\ttest: 0.0382734\tbest: 0.0382734 (6020)\ttotal: 30m 52s\tremaining: 20m 24s\n",
      "6021:\tlearn: 0.0336243\ttest: 0.0382734\tbest: 0.0382734 (6020)\ttotal: 30m 52s\tremaining: 20m 23s\n",
      "6022:\tlearn: 0.0336243\ttest: 0.0382734\tbest: 0.0382734 (6022)\ttotal: 30m 52s\tremaining: 20m 23s\n",
      "6023:\tlearn: 0.0336243\ttest: 0.0382734\tbest: 0.0382734 (6022)\ttotal: 30m 53s\tremaining: 20m 23s\n",
      "6024:\tlearn: 0.0336243\ttest: 0.0382734\tbest: 0.0382734 (6022)\ttotal: 30m 53s\tremaining: 20m 22s\n",
      "6025:\tlearn: 0.0336243\ttest: 0.0382734\tbest: 0.0382734 (6022)\ttotal: 30m 53s\tremaining: 20m 22s\n",
      "6026:\tlearn: 0.0336243\ttest: 0.0382734\tbest: 0.0382734 (6022)\ttotal: 30m 53s\tremaining: 20m 22s\n",
      "6027:\tlearn: 0.0336243\ttest: 0.0382734\tbest: 0.0382734 (6022)\ttotal: 30m 54s\tremaining: 20m 21s\n",
      "6028:\tlearn: 0.0336243\ttest: 0.0382734\tbest: 0.0382734 (6022)\ttotal: 30m 54s\tremaining: 20m 21s\n",
      "6029:\tlearn: 0.0336243\ttest: 0.0382734\tbest: 0.0382734 (6029)\ttotal: 30m 54s\tremaining: 20m 21s\n",
      "6030:\tlearn: 0.0336243\ttest: 0.0382734\tbest: 0.0382734 (6029)\ttotal: 30m 54s\tremaining: 20m 20s\n",
      "6031:\tlearn: 0.0336243\ttest: 0.0382734\tbest: 0.0382734 (6031)\ttotal: 30m 55s\tremaining: 20m 20s\n",
      "6032:\tlearn: 0.0336242\ttest: 0.0382734\tbest: 0.0382734 (6032)\ttotal: 30m 55s\tremaining: 20m 19s\n",
      "6033:\tlearn: 0.0336242\ttest: 0.0382734\tbest: 0.0382734 (6032)\ttotal: 30m 55s\tremaining: 20m 19s\n",
      "6034:\tlearn: 0.0336243\ttest: 0.0382734\tbest: 0.0382734 (6034)\ttotal: 30m 55s\tremaining: 20m 19s\n",
      "6035:\tlearn: 0.0336243\ttest: 0.0382734\tbest: 0.0382734 (6035)\ttotal: 30m 56s\tremaining: 20m 19s\n",
      "6036:\tlearn: 0.0336208\ttest: 0.0382734\tbest: 0.0382734 (6036)\ttotal: 30m 56s\tremaining: 20m 18s\n",
      "6037:\tlearn: 0.0336208\ttest: 0.0382734\tbest: 0.0382734 (6037)\ttotal: 30m 57s\tremaining: 20m 18s\n",
      "6038:\tlearn: 0.0336207\ttest: 0.0382734\tbest: 0.0382734 (6037)\ttotal: 30m 57s\tremaining: 20m 18s\n",
      "6039:\tlearn: 0.0336207\ttest: 0.0382734\tbest: 0.0382734 (6037)\ttotal: 30m 58s\tremaining: 20m 18s\n",
      "6040:\tlearn: 0.0336207\ttest: 0.0382734\tbest: 0.0382734 (6037)\ttotal: 30m 58s\tremaining: 20m 18s\n",
      "6041:\tlearn: 0.0336207\ttest: 0.0382734\tbest: 0.0382734 (6037)\ttotal: 30m 59s\tremaining: 20m 17s\n",
      "6042:\tlearn: 0.0336207\ttest: 0.0382734\tbest: 0.0382734 (6037)\ttotal: 30m 59s\tremaining: 20m 17s\n",
      "6043:\tlearn: 0.0336163\ttest: 0.0382726\tbest: 0.0382726 (6043)\ttotal: 31m\tremaining: 20m 17s\n",
      "6044:\tlearn: 0.0336163\ttest: 0.0382726\tbest: 0.0382726 (6043)\ttotal: 31m\tremaining: 20m 17s\n",
      "6045:\tlearn: 0.0336163\ttest: 0.0382726\tbest: 0.0382726 (6043)\ttotal: 31m\tremaining: 20m 16s\n",
      "6046:\tlearn: 0.0336163\ttest: 0.0382726\tbest: 0.0382726 (6043)\ttotal: 31m\tremaining: 20m 16s\n",
      "6047:\tlearn: 0.0336163\ttest: 0.0382726\tbest: 0.0382726 (6043)\ttotal: 31m 1s\tremaining: 20m 16s\n",
      "6048:\tlearn: 0.0336138\ttest: 0.0382719\tbest: 0.0382719 (6048)\ttotal: 31m 1s\tremaining: 20m 15s\n",
      "6049:\tlearn: 0.0336123\ttest: 0.0382713\tbest: 0.0382713 (6049)\ttotal: 31m 1s\tremaining: 20m 15s\n",
      "6050:\tlearn: 0.0336123\ttest: 0.0382713\tbest: 0.0382713 (6049)\ttotal: 31m 1s\tremaining: 20m 15s\n",
      "6051:\tlearn: 0.0336085\ttest: 0.0382713\tbest: 0.0382713 (6049)\ttotal: 31m 2s\tremaining: 20m 14s\n",
      "6052:\tlearn: 0.0336084\ttest: 0.0382713\tbest: 0.0382713 (6049)\ttotal: 31m 2s\tremaining: 20m 14s\n",
      "6053:\tlearn: 0.0336085\ttest: 0.0382713\tbest: 0.0382713 (6049)\ttotal: 31m 2s\tremaining: 20m 14s\n",
      "6054:\tlearn: 0.0336084\ttest: 0.0382713\tbest: 0.0382713 (6049)\ttotal: 31m 2s\tremaining: 20m 13s\n",
      "6055:\tlearn: 0.0336084\ttest: 0.0382713\tbest: 0.0382713 (6049)\ttotal: 31m 3s\tremaining: 20m 13s\n",
      "6056:\tlearn: 0.0336084\ttest: 0.0382713\tbest: 0.0382713 (6049)\ttotal: 31m 3s\tremaining: 20m 13s\n",
      "6057:\tlearn: 0.0336084\ttest: 0.0382713\tbest: 0.0382713 (6049)\ttotal: 31m 3s\tremaining: 20m 12s\n",
      "6058:\tlearn: 0.0336084\ttest: 0.0382713\tbest: 0.0382713 (6049)\ttotal: 31m 3s\tremaining: 20m 12s\n",
      "6059:\tlearn: 0.0336084\ttest: 0.0382713\tbest: 0.0382713 (6049)\ttotal: 31m 4s\tremaining: 20m 12s\n",
      "6060:\tlearn: 0.0336051\ttest: 0.0382718\tbest: 0.0382713 (6049)\ttotal: 31m 4s\tremaining: 20m 11s\n",
      "6061:\tlearn: 0.0336051\ttest: 0.0382718\tbest: 0.0382713 (6049)\ttotal: 31m 4s\tremaining: 20m 11s\n",
      "6062:\tlearn: 0.0336051\ttest: 0.0382718\tbest: 0.0382713 (6049)\ttotal: 31m 4s\tremaining: 20m 11s\n",
      "6063:\tlearn: 0.0336051\ttest: 0.0382718\tbest: 0.0382713 (6049)\ttotal: 31m 5s\tremaining: 20m 10s\n",
      "6064:\tlearn: 0.0336008\ttest: 0.0382720\tbest: 0.0382713 (6049)\ttotal: 31m 5s\tremaining: 20m 10s\n",
      "6065:\tlearn: 0.0336008\ttest: 0.0382720\tbest: 0.0382713 (6049)\ttotal: 31m 5s\tremaining: 20m 10s\n",
      "6066:\tlearn: 0.0336008\ttest: 0.0382720\tbest: 0.0382713 (6049)\ttotal: 31m 6s\tremaining: 20m 9s\n",
      "6067:\tlearn: 0.0336008\ttest: 0.0382720\tbest: 0.0382713 (6049)\ttotal: 31m 6s\tremaining: 20m 9s\n",
      "6068:\tlearn: 0.0336008\ttest: 0.0382720\tbest: 0.0382713 (6049)\ttotal: 31m 6s\tremaining: 20m 9s\n",
      "6069:\tlearn: 0.0336008\ttest: 0.0382720\tbest: 0.0382713 (6049)\ttotal: 31m 6s\tremaining: 20m 8s\n",
      "6070:\tlearn: 0.0336008\ttest: 0.0382720\tbest: 0.0382713 (6049)\ttotal: 31m 7s\tremaining: 20m 8s\n",
      "6071:\tlearn: 0.0336008\ttest: 0.0382720\tbest: 0.0382713 (6049)\ttotal: 31m 7s\tremaining: 20m 7s\n",
      "6072:\tlearn: 0.0336008\ttest: 0.0382720\tbest: 0.0382713 (6049)\ttotal: 31m 7s\tremaining: 20m 7s\n",
      "6073:\tlearn: 0.0335979\ttest: 0.0382715\tbest: 0.0382713 (6049)\ttotal: 31m 7s\tremaining: 20m 7s\n",
      "6074:\tlearn: 0.0335979\ttest: 0.0382715\tbest: 0.0382713 (6049)\ttotal: 31m 8s\tremaining: 20m 7s\n",
      "6075:\tlearn: 0.0335979\ttest: 0.0382715\tbest: 0.0382713 (6049)\ttotal: 31m 8s\tremaining: 20m 6s\n",
      "6076:\tlearn: 0.0335979\ttest: 0.0382715\tbest: 0.0382713 (6049)\ttotal: 31m 8s\tremaining: 20m 6s\n",
      "6077:\tlearn: 0.0335979\ttest: 0.0382715\tbest: 0.0382713 (6049)\ttotal: 31m 8s\tremaining: 20m 5s\n",
      "6078:\tlearn: 0.0335979\ttest: 0.0382715\tbest: 0.0382713 (6049)\ttotal: 31m 9s\tremaining: 20m 5s\n",
      "6079:\tlearn: 0.0335979\ttest: 0.0382715\tbest: 0.0382713 (6049)\ttotal: 31m 9s\tremaining: 20m 5s\n",
      "6080:\tlearn: 0.0335978\ttest: 0.0382716\tbest: 0.0382713 (6049)\ttotal: 31m 9s\tremaining: 20m 4s\n",
      "6081:\tlearn: 0.0335978\ttest: 0.0382716\tbest: 0.0382713 (6049)\ttotal: 31m 9s\tremaining: 20m 4s\n",
      "6082:\tlearn: 0.0335978\ttest: 0.0382716\tbest: 0.0382713 (6049)\ttotal: 31m 10s\tremaining: 20m 4s\n",
      "6083:\tlearn: 0.0335978\ttest: 0.0382716\tbest: 0.0382713 (6049)\ttotal: 31m 10s\tremaining: 20m 4s\n",
      "6084:\tlearn: 0.0335978\ttest: 0.0382716\tbest: 0.0382713 (6049)\ttotal: 31m 11s\tremaining: 20m 3s\n",
      "6085:\tlearn: 0.0335978\ttest: 0.0382716\tbest: 0.0382713 (6049)\ttotal: 31m 11s\tremaining: 20m 3s\n",
      "6086:\tlearn: 0.0335978\ttest: 0.0382716\tbest: 0.0382713 (6049)\ttotal: 31m 12s\tremaining: 20m 3s\n",
      "6087:\tlearn: 0.0335978\ttest: 0.0382716\tbest: 0.0382713 (6049)\ttotal: 31m 12s\tremaining: 20m 3s\n",
      "6088:\tlearn: 0.0335978\ttest: 0.0382716\tbest: 0.0382713 (6049)\ttotal: 31m 13s\tremaining: 20m 3s\n",
      "6089:\tlearn: 0.0335978\ttest: 0.0382716\tbest: 0.0382713 (6049)\ttotal: 31m 13s\tremaining: 20m 2s\n",
      "6090:\tlearn: 0.0335923\ttest: 0.0382700\tbest: 0.0382700 (6090)\ttotal: 31m 14s\tremaining: 20m 2s\n",
      "6091:\tlearn: 0.0335923\ttest: 0.0382700\tbest: 0.0382700 (6090)\ttotal: 31m 14s\tremaining: 20m 2s\n",
      "6092:\tlearn: 0.0335923\ttest: 0.0382700\tbest: 0.0382700 (6092)\ttotal: 31m 14s\tremaining: 20m 2s\n",
      "6093:\tlearn: 0.0335923\ttest: 0.0382700\tbest: 0.0382700 (6093)\ttotal: 31m 14s\tremaining: 20m 1s\n",
      "6094:\tlearn: 0.0335923\ttest: 0.0382700\tbest: 0.0382700 (6094)\ttotal: 31m 15s\tremaining: 20m 1s\n",
      "6095:\tlearn: 0.0335923\ttest: 0.0382700\tbest: 0.0382700 (6095)\ttotal: 31m 15s\tremaining: 20m 1s\n",
      "6096:\tlearn: 0.0335923\ttest: 0.0382700\tbest: 0.0382700 (6096)\ttotal: 31m 15s\tremaining: 20m\n",
      "6097:\tlearn: 0.0335923\ttest: 0.0382700\tbest: 0.0382700 (6096)\ttotal: 31m 15s\tremaining: 20m\n",
      "6098:\tlearn: 0.0335877\ttest: 0.0382693\tbest: 0.0382693 (6098)\ttotal: 31m 16s\tremaining: 20m\n",
      "6099:\tlearn: 0.0335877\ttest: 0.0382693\tbest: 0.0382693 (6098)\ttotal: 31m 16s\tremaining: 19m 59s\n",
      "6100:\tlearn: 0.0335877\ttest: 0.0382693\tbest: 0.0382693 (6100)\ttotal: 31m 16s\tremaining: 19m 59s\n",
      "6101:\tlearn: 0.0335877\ttest: 0.0382693\tbest: 0.0382693 (6100)\ttotal: 31m 16s\tremaining: 19m 59s\n",
      "6102:\tlearn: 0.0335877\ttest: 0.0382693\tbest: 0.0382693 (6100)\ttotal: 31m 17s\tremaining: 19m 58s\n",
      "6103:\tlearn: 0.0335877\ttest: 0.0382693\tbest: 0.0382693 (6100)\ttotal: 31m 17s\tremaining: 19m 58s\n",
      "6104:\tlearn: 0.0335877\ttest: 0.0382693\tbest: 0.0382693 (6100)\ttotal: 31m 17s\tremaining: 19m 58s\n",
      "6105:\tlearn: 0.0335877\ttest: 0.0382693\tbest: 0.0382693 (6105)\ttotal: 31m 18s\tremaining: 19m 57s\n",
      "6106:\tlearn: 0.0335877\ttest: 0.0382693\tbest: 0.0382693 (6106)\ttotal: 31m 18s\tremaining: 19m 57s\n",
      "6107:\tlearn: 0.0335877\ttest: 0.0382693\tbest: 0.0382693 (6106)\ttotal: 31m 18s\tremaining: 19m 56s\n",
      "6108:\tlearn: 0.0335877\ttest: 0.0382693\tbest: 0.0382693 (6108)\ttotal: 31m 18s\tremaining: 19m 56s\n",
      "6109:\tlearn: 0.0335877\ttest: 0.0382693\tbest: 0.0382693 (6109)\ttotal: 31m 19s\tremaining: 19m 56s\n",
      "6110:\tlearn: 0.0335876\ttest: 0.0382693\tbest: 0.0382693 (6109)\ttotal: 31m 19s\tremaining: 19m 55s\n",
      "6111:\tlearn: 0.0335876\ttest: 0.0382693\tbest: 0.0382693 (6111)\ttotal: 31m 19s\tremaining: 19m 55s\n",
      "6112:\tlearn: 0.0335877\ttest: 0.0382693\tbest: 0.0382693 (6111)\ttotal: 31m 19s\tremaining: 19m 55s\n",
      "6113:\tlearn: 0.0335855\ttest: 0.0382692\tbest: 0.0382692 (6113)\ttotal: 31m 20s\tremaining: 19m 54s\n",
      "6114:\tlearn: 0.0335855\ttest: 0.0382692\tbest: 0.0382692 (6114)\ttotal: 31m 20s\tremaining: 19m 54s\n",
      "6115:\tlearn: 0.0335854\ttest: 0.0382692\tbest: 0.0382692 (6115)\ttotal: 31m 20s\tremaining: 19m 54s\n",
      "6116:\tlearn: 0.0335854\ttest: 0.0382692\tbest: 0.0382692 (6116)\ttotal: 31m 20s\tremaining: 19m 53s\n",
      "6117:\tlearn: 0.0335854\ttest: 0.0382692\tbest: 0.0382692 (6117)\ttotal: 31m 21s\tremaining: 19m 53s\n",
      "6118:\tlearn: 0.0335854\ttest: 0.0382692\tbest: 0.0382692 (6118)\ttotal: 31m 21s\tremaining: 19m 53s\n",
      "6119:\tlearn: 0.0335854\ttest: 0.0382692\tbest: 0.0382692 (6118)\ttotal: 31m 21s\tremaining: 19m 52s\n",
      "6120:\tlearn: 0.0335833\ttest: 0.0382693\tbest: 0.0382692 (6118)\ttotal: 31m 22s\tremaining: 19m 52s\n",
      "6121:\tlearn: 0.0335833\ttest: 0.0382693\tbest: 0.0382692 (6118)\ttotal: 31m 22s\tremaining: 19m 52s\n",
      "6122:\tlearn: 0.0335833\ttest: 0.0382693\tbest: 0.0382692 (6118)\ttotal: 31m 22s\tremaining: 19m 51s\n",
      "6123:\tlearn: 0.0335833\ttest: 0.0382693\tbest: 0.0382692 (6118)\ttotal: 31m 22s\tremaining: 19m 51s\n",
      "6124:\tlearn: 0.0335834\ttest: 0.0382693\tbest: 0.0382692 (6118)\ttotal: 31m 23s\tremaining: 19m 51s\n",
      "6125:\tlearn: 0.0335833\ttest: 0.0382693\tbest: 0.0382692 (6118)\ttotal: 31m 23s\tremaining: 19m 50s\n",
      "6126:\tlearn: 0.0335833\ttest: 0.0382693\tbest: 0.0382692 (6118)\ttotal: 31m 23s\tremaining: 19m 50s\n",
      "6127:\tlearn: 0.0335833\ttest: 0.0382693\tbest: 0.0382692 (6118)\ttotal: 31m 23s\tremaining: 19m 50s\n",
      "6128:\tlearn: 0.0335833\ttest: 0.0382693\tbest: 0.0382692 (6118)\ttotal: 31m 24s\tremaining: 19m 49s\n",
      "6129:\tlearn: 0.0335833\ttest: 0.0382693\tbest: 0.0382692 (6118)\ttotal: 31m 24s\tremaining: 19m 49s\n",
      "6130:\tlearn: 0.0335833\ttest: 0.0382693\tbest: 0.0382692 (6118)\ttotal: 31m 24s\tremaining: 19m 49s\n",
      "6131:\tlearn: 0.0335833\ttest: 0.0382693\tbest: 0.0382692 (6118)\ttotal: 31m 25s\tremaining: 19m 49s\n",
      "6132:\tlearn: 0.0335834\ttest: 0.0382693\tbest: 0.0382692 (6118)\ttotal: 31m 25s\tremaining: 19m 49s\n",
      "6133:\tlearn: 0.0335807\ttest: 0.0382688\tbest: 0.0382688 (6133)\ttotal: 31m 26s\tremaining: 19m 48s\n",
      "6134:\tlearn: 0.0335807\ttest: 0.0382688\tbest: 0.0382688 (6134)\ttotal: 31m 26s\tremaining: 19m 48s\n",
      "6135:\tlearn: 0.0335769\ttest: 0.0382684\tbest: 0.0382684 (6135)\ttotal: 31m 27s\tremaining: 19m 48s\n",
      "6136:\tlearn: 0.0335720\ttest: 0.0382671\tbest: 0.0382671 (6136)\ttotal: 31m 27s\tremaining: 19m 48s\n",
      "6137:\tlearn: 0.0335719\ttest: 0.0382671\tbest: 0.0382671 (6136)\ttotal: 31m 28s\tremaining: 19m 48s\n",
      "6138:\tlearn: 0.0335719\ttest: 0.0382671\tbest: 0.0382671 (6136)\ttotal: 31m 28s\tremaining: 19m 47s\n",
      "6139:\tlearn: 0.0335719\ttest: 0.0382671\tbest: 0.0382671 (6136)\ttotal: 31m 28s\tremaining: 19m 47s\n",
      "6140:\tlearn: 0.0335719\ttest: 0.0382671\tbest: 0.0382671 (6136)\ttotal: 31m 29s\tremaining: 19m 47s\n",
      "6141:\tlearn: 0.0335719\ttest: 0.0382671\tbest: 0.0382671 (6136)\ttotal: 31m 29s\tremaining: 19m 46s\n",
      "6142:\tlearn: 0.0335689\ttest: 0.0382670\tbest: 0.0382670 (6142)\ttotal: 31m 29s\tremaining: 19m 46s\n",
      "6143:\tlearn: 0.0335688\ttest: 0.0382670\tbest: 0.0382670 (6143)\ttotal: 31m 29s\tremaining: 19m 46s\n",
      "6144:\tlearn: 0.0335689\ttest: 0.0382670\tbest: 0.0382670 (6143)\ttotal: 31m 30s\tremaining: 19m 45s\n",
      "6145:\tlearn: 0.0335688\ttest: 0.0382670\tbest: 0.0382670 (6145)\ttotal: 31m 30s\tremaining: 19m 45s\n",
      "6146:\tlearn: 0.0335688\ttest: 0.0382670\tbest: 0.0382670 (6145)\ttotal: 31m 30s\tremaining: 19m 45s\n",
      "6147:\tlearn: 0.0335688\ttest: 0.0382670\tbest: 0.0382670 (6147)\ttotal: 31m 30s\tremaining: 19m 44s\n",
      "6148:\tlearn: 0.0335651\ttest: 0.0382660\tbest: 0.0382660 (6148)\ttotal: 31m 31s\tremaining: 19m 44s\n",
      "6149:\tlearn: 0.0335651\ttest: 0.0382660\tbest: 0.0382660 (6149)\ttotal: 31m 31s\tremaining: 19m 44s\n",
      "6150:\tlearn: 0.0335618\ttest: 0.0382653\tbest: 0.0382653 (6150)\ttotal: 31m 31s\tremaining: 19m 43s\n",
      "6151:\tlearn: 0.0335618\ttest: 0.0382653\tbest: 0.0382653 (6150)\ttotal: 31m 31s\tremaining: 19m 43s\n",
      "6152:\tlearn: 0.0335618\ttest: 0.0382653\tbest: 0.0382653 (6152)\ttotal: 31m 32s\tremaining: 19m 43s\n",
      "6153:\tlearn: 0.0335618\ttest: 0.0382653\tbest: 0.0382653 (6152)\ttotal: 31m 32s\tremaining: 19m 42s\n",
      "6154:\tlearn: 0.0335618\ttest: 0.0382653\tbest: 0.0382653 (6152)\ttotal: 31m 32s\tremaining: 19m 42s\n",
      "6155:\tlearn: 0.0335618\ttest: 0.0382652\tbest: 0.0382652 (6155)\ttotal: 31m 32s\tremaining: 19m 42s\n",
      "6156:\tlearn: 0.0335618\ttest: 0.0382652\tbest: 0.0382652 (6156)\ttotal: 31m 33s\tremaining: 19m 41s\n",
      "6157:\tlearn: 0.0335581\ttest: 0.0382651\tbest: 0.0382651 (6157)\ttotal: 31m 33s\tremaining: 19m 41s\n",
      "6158:\tlearn: 0.0335581\ttest: 0.0382651\tbest: 0.0382651 (6157)\ttotal: 31m 33s\tremaining: 19m 41s\n",
      "6159:\tlearn: 0.0335581\ttest: 0.0382651\tbest: 0.0382651 (6159)\ttotal: 31m 34s\tremaining: 19m 40s\n",
      "6160:\tlearn: 0.0335581\ttest: 0.0382651\tbest: 0.0382651 (6159)\ttotal: 31m 34s\tremaining: 19m 40s\n",
      "6161:\tlearn: 0.0335581\ttest: 0.0382651\tbest: 0.0382651 (6161)\ttotal: 31m 34s\tremaining: 19m 40s\n",
      "6162:\tlearn: 0.0335549\ttest: 0.0382646\tbest: 0.0382646 (6162)\ttotal: 31m 34s\tremaining: 19m 39s\n",
      "6163:\tlearn: 0.0335548\ttest: 0.0382646\tbest: 0.0382646 (6162)\ttotal: 31m 35s\tremaining: 19m 39s\n",
      "6164:\tlearn: 0.0335548\ttest: 0.0382646\tbest: 0.0382646 (6162)\ttotal: 31m 35s\tremaining: 19m 39s\n",
      "6165:\tlearn: 0.0335548\ttest: 0.0382646\tbest: 0.0382646 (6162)\ttotal: 31m 35s\tremaining: 19m 38s\n",
      "6166:\tlearn: 0.0335548\ttest: 0.0382646\tbest: 0.0382646 (6162)\ttotal: 31m 35s\tremaining: 19m 38s\n",
      "6167:\tlearn: 0.0335548\ttest: 0.0382646\tbest: 0.0382646 (6167)\ttotal: 31m 36s\tremaining: 19m 38s\n",
      "6168:\tlearn: 0.0335548\ttest: 0.0382646\tbest: 0.0382646 (6168)\ttotal: 31m 36s\tremaining: 19m 37s\n",
      "6169:\tlearn: 0.0335523\ttest: 0.0382633\tbest: 0.0382633 (6169)\ttotal: 31m 36s\tremaining: 19m 37s\n",
      "6170:\tlearn: 0.0335523\ttest: 0.0382633\tbest: 0.0382633 (6169)\ttotal: 31m 36s\tremaining: 19m 37s\n",
      "6171:\tlearn: 0.0335523\ttest: 0.0382633\tbest: 0.0382633 (6169)\ttotal: 31m 37s\tremaining: 19m 36s\n",
      "6172:\tlearn: 0.0335523\ttest: 0.0382633\tbest: 0.0382633 (6172)\ttotal: 31m 37s\tremaining: 19m 36s\n",
      "6173:\tlearn: 0.0335523\ttest: 0.0382633\tbest: 0.0382633 (6172)\ttotal: 31m 37s\tremaining: 19m 36s\n",
      "6174:\tlearn: 0.0335523\ttest: 0.0382633\tbest: 0.0382633 (6174)\ttotal: 31m 38s\tremaining: 19m 35s\n",
      "6175:\tlearn: 0.0335523\ttest: 0.0382633\tbest: 0.0382633 (6174)\ttotal: 31m 38s\tremaining: 19m 35s\n",
      "6176:\tlearn: 0.0335523\ttest: 0.0382633\tbest: 0.0382633 (6174)\ttotal: 31m 38s\tremaining: 19m 35s\n",
      "6177:\tlearn: 0.0335523\ttest: 0.0382633\tbest: 0.0382633 (6177)\ttotal: 31m 39s\tremaining: 19m 34s\n",
      "6178:\tlearn: 0.0335523\ttest: 0.0382633\tbest: 0.0382633 (6178)\ttotal: 31m 39s\tremaining: 19m 34s\n",
      "6179:\tlearn: 0.0335523\ttest: 0.0382633\tbest: 0.0382633 (6178)\ttotal: 31m 40s\tremaining: 19m 34s\n",
      "6180:\tlearn: 0.0335523\ttest: 0.0382633\tbest: 0.0382633 (6178)\ttotal: 31m 40s\tremaining: 19m 34s\n",
      "6181:\tlearn: 0.0335503\ttest: 0.0382634\tbest: 0.0382633 (6178)\ttotal: 31m 41s\tremaining: 19m 34s\n",
      "6182:\tlearn: 0.0335502\ttest: 0.0382634\tbest: 0.0382633 (6178)\ttotal: 31m 41s\tremaining: 19m 33s\n",
      "6183:\tlearn: 0.0335502\ttest: 0.0382634\tbest: 0.0382633 (6178)\ttotal: 31m 41s\tremaining: 19m 33s\n",
      "6184:\tlearn: 0.0335502\ttest: 0.0382634\tbest: 0.0382633 (6178)\ttotal: 31m 42s\tremaining: 19m 33s\n",
      "6185:\tlearn: 0.0335502\ttest: 0.0382634\tbest: 0.0382633 (6178)\ttotal: 31m 42s\tremaining: 19m 33s\n",
      "6186:\tlearn: 0.0335502\ttest: 0.0382634\tbest: 0.0382633 (6178)\ttotal: 31m 42s\tremaining: 19m 32s\n",
      "6187:\tlearn: 0.0335502\ttest: 0.0382634\tbest: 0.0382633 (6178)\ttotal: 31m 43s\tremaining: 19m 32s\n",
      "6188:\tlearn: 0.0335502\ttest: 0.0382634\tbest: 0.0382633 (6178)\ttotal: 31m 43s\tremaining: 19m 32s\n",
      "6189:\tlearn: 0.0335502\ttest: 0.0382634\tbest: 0.0382633 (6178)\ttotal: 31m 43s\tremaining: 19m 31s\n",
      "6190:\tlearn: 0.0335502\ttest: 0.0382634\tbest: 0.0382633 (6178)\ttotal: 31m 43s\tremaining: 19m 31s\n",
      "6191:\tlearn: 0.0335502\ttest: 0.0382634\tbest: 0.0382633 (6178)\ttotal: 31m 44s\tremaining: 19m 30s\n",
      "6192:\tlearn: 0.0335502\ttest: 0.0382634\tbest: 0.0382633 (6178)\ttotal: 31m 44s\tremaining: 19m 30s\n",
      "6193:\tlearn: 0.0335494\ttest: 0.0382633\tbest: 0.0382633 (6178)\ttotal: 31m 44s\tremaining: 19m 30s\n",
      "6194:\tlearn: 0.0335494\ttest: 0.0382633\tbest: 0.0382633 (6178)\ttotal: 31m 44s\tremaining: 19m 30s\n",
      "6195:\tlearn: 0.0335494\ttest: 0.0382633\tbest: 0.0382633 (6178)\ttotal: 31m 45s\tremaining: 19m 29s\n",
      "6196:\tlearn: 0.0335494\ttest: 0.0382633\tbest: 0.0382633 (6178)\ttotal: 31m 45s\tremaining: 19m 29s\n",
      "6197:\tlearn: 0.0335494\ttest: 0.0382633\tbest: 0.0382633 (6178)\ttotal: 31m 45s\tremaining: 19m 28s\n",
      "6198:\tlearn: 0.0335494\ttest: 0.0382633\tbest: 0.0382633 (6178)\ttotal: 31m 45s\tremaining: 19m 28s\n",
      "6199:\tlearn: 0.0335494\ttest: 0.0382633\tbest: 0.0382633 (6178)\ttotal: 31m 46s\tremaining: 19m 28s\n",
      "6200:\tlearn: 0.0335494\ttest: 0.0382633\tbest: 0.0382633 (6178)\ttotal: 31m 46s\tremaining: 19m 27s\n",
      "6201:\tlearn: 0.0335494\ttest: 0.0382633\tbest: 0.0382633 (6178)\ttotal: 31m 46s\tremaining: 19m 27s\n",
      "6202:\tlearn: 0.0335494\ttest: 0.0382633\tbest: 0.0382633 (6178)\ttotal: 31m 46s\tremaining: 19m 27s\n",
      "6203:\tlearn: 0.0335494\ttest: 0.0382633\tbest: 0.0382633 (6178)\ttotal: 31m 47s\tremaining: 19m 26s\n",
      "6204:\tlearn: 0.0335494\ttest: 0.0382633\tbest: 0.0382633 (6178)\ttotal: 31m 47s\tremaining: 19m 26s\n",
      "6205:\tlearn: 0.0335494\ttest: 0.0382633\tbest: 0.0382633 (6178)\ttotal: 31m 47s\tremaining: 19m 26s\n",
      "6206:\tlearn: 0.0335494\ttest: 0.0382633\tbest: 0.0382633 (6178)\ttotal: 31m 47s\tremaining: 19m 25s\n",
      "6207:\tlearn: 0.0335494\ttest: 0.0382633\tbest: 0.0382633 (6178)\ttotal: 31m 48s\tremaining: 19m 25s\n",
      "6208:\tlearn: 0.0335494\ttest: 0.0382633\tbest: 0.0382633 (6178)\ttotal: 31m 48s\tremaining: 19m 25s\n",
      "6209:\tlearn: 0.0335493\ttest: 0.0382633\tbest: 0.0382633 (6178)\ttotal: 31m 48s\tremaining: 19m 24s\n",
      "6210:\tlearn: 0.0335493\ttest: 0.0382633\tbest: 0.0382633 (6178)\ttotal: 31m 48s\tremaining: 19m 24s\n",
      "6211:\tlearn: 0.0335493\ttest: 0.0382633\tbest: 0.0382633 (6178)\ttotal: 31m 49s\tremaining: 19m 24s\n",
      "6212:\tlearn: 0.0335493\ttest: 0.0382633\tbest: 0.0382633 (6178)\ttotal: 31m 49s\tremaining: 19m 23s\n",
      "6213:\tlearn: 0.0335493\ttest: 0.0382633\tbest: 0.0382633 (6178)\ttotal: 31m 49s\tremaining: 19m 23s\n",
      "6214:\tlearn: 0.0335493\ttest: 0.0382633\tbest: 0.0382633 (6178)\ttotal: 31m 49s\tremaining: 19m 23s\n",
      "6215:\tlearn: 0.0335493\ttest: 0.0382633\tbest: 0.0382633 (6178)\ttotal: 31m 50s\tremaining: 19m 22s\n",
      "6216:\tlearn: 0.0335474\ttest: 0.0382633\tbest: 0.0382633 (6178)\ttotal: 31m 50s\tremaining: 19m 22s\n",
      "6217:\tlearn: 0.0335474\ttest: 0.0382633\tbest: 0.0382633 (6178)\ttotal: 31m 50s\tremaining: 19m 22s\n",
      "6218:\tlearn: 0.0335474\ttest: 0.0382633\tbest: 0.0382633 (6178)\ttotal: 31m 51s\tremaining: 19m 21s\n",
      "6219:\tlearn: 0.0335453\ttest: 0.0382635\tbest: 0.0382633 (6178)\ttotal: 31m 51s\tremaining: 19m 21s\n",
      "6220:\tlearn: 0.0335453\ttest: 0.0382635\tbest: 0.0382633 (6178)\ttotal: 31m 51s\tremaining: 19m 21s\n",
      "6221:\tlearn: 0.0335452\ttest: 0.0382635\tbest: 0.0382633 (6178)\ttotal: 31m 51s\tremaining: 19m 20s\n",
      "6222:\tlearn: 0.0335452\ttest: 0.0382635\tbest: 0.0382633 (6178)\ttotal: 31m 52s\tremaining: 19m 20s\n",
      "6223:\tlearn: 0.0335452\ttest: 0.0382635\tbest: 0.0382633 (6178)\ttotal: 31m 52s\tremaining: 19m 20s\n",
      "6224:\tlearn: 0.0335452\ttest: 0.0382635\tbest: 0.0382633 (6178)\ttotal: 31m 52s\tremaining: 19m 20s\n",
      "6225:\tlearn: 0.0335450\ttest: 0.0382635\tbest: 0.0382633 (6178)\ttotal: 31m 53s\tremaining: 19m 19s\n",
      "6226:\tlearn: 0.0335450\ttest: 0.0382635\tbest: 0.0382633 (6178)\ttotal: 31m 53s\tremaining: 19m 19s\n",
      "6227:\tlearn: 0.0335450\ttest: 0.0382635\tbest: 0.0382633 (6178)\ttotal: 31m 54s\tremaining: 19m 19s\n",
      "6228:\tlearn: 0.0335422\ttest: 0.0382638\tbest: 0.0382633 (6178)\ttotal: 31m 54s\tremaining: 19m 19s\n",
      "6229:\tlearn: 0.0335422\ttest: 0.0382638\tbest: 0.0382633 (6178)\ttotal: 31m 55s\tremaining: 19m 18s\n",
      "6230:\tlearn: 0.0335422\ttest: 0.0382638\tbest: 0.0382633 (6178)\ttotal: 31m 55s\tremaining: 19m 18s\n",
      "6231:\tlearn: 0.0335422\ttest: 0.0382638\tbest: 0.0382633 (6178)\ttotal: 31m 56s\tremaining: 19m 18s\n",
      "6232:\tlearn: 0.0335422\ttest: 0.0382638\tbest: 0.0382633 (6178)\ttotal: 31m 56s\tremaining: 19m 18s\n",
      "6233:\tlearn: 0.0335368\ttest: 0.0382629\tbest: 0.0382629 (6233)\ttotal: 31m 56s\tremaining: 19m 17s\n",
      "6234:\tlearn: 0.0335321\ttest: 0.0382617\tbest: 0.0382617 (6234)\ttotal: 31m 56s\tremaining: 19m 17s\n",
      "6235:\tlearn: 0.0335321\ttest: 0.0382617\tbest: 0.0382617 (6234)\ttotal: 31m 57s\tremaining: 19m 17s\n",
      "6236:\tlearn: 0.0335321\ttest: 0.0382617\tbest: 0.0382617 (6234)\ttotal: 31m 57s\tremaining: 19m 16s\n",
      "6237:\tlearn: 0.0335273\ttest: 0.0382608\tbest: 0.0382608 (6237)\ttotal: 31m 57s\tremaining: 19m 16s\n",
      "6238:\tlearn: 0.0335273\ttest: 0.0382608\tbest: 0.0382608 (6238)\ttotal: 31m 57s\tremaining: 19m 16s\n",
      "6239:\tlearn: 0.0335273\ttest: 0.0382608\tbest: 0.0382608 (6239)\ttotal: 31m 58s\tremaining: 19m 15s\n",
      "6240:\tlearn: 0.0335273\ttest: 0.0382608\tbest: 0.0382608 (6240)\ttotal: 31m 58s\tremaining: 19m 15s\n",
      "6241:\tlearn: 0.0335272\ttest: 0.0382608\tbest: 0.0382608 (6240)\ttotal: 31m 58s\tremaining: 19m 15s\n",
      "6242:\tlearn: 0.0335272\ttest: 0.0382608\tbest: 0.0382608 (6240)\ttotal: 31m 59s\tremaining: 19m 14s\n",
      "6243:\tlearn: 0.0335272\ttest: 0.0382607\tbest: 0.0382607 (6243)\ttotal: 31m 59s\tremaining: 19m 14s\n",
      "6244:\tlearn: 0.0335272\ttest: 0.0382608\tbest: 0.0382607 (6243)\ttotal: 31m 59s\tremaining: 19m 14s\n",
      "6245:\tlearn: 0.0335271\ttest: 0.0382607\tbest: 0.0382607 (6245)\ttotal: 31m 59s\tremaining: 19m 13s\n",
      "6246:\tlearn: 0.0335271\ttest: 0.0382607\tbest: 0.0382607 (6245)\ttotal: 32m\tremaining: 19m 13s\n",
      "6247:\tlearn: 0.0335271\ttest: 0.0382607\tbest: 0.0382607 (6245)\ttotal: 32m\tremaining: 19m 13s\n",
      "6248:\tlearn: 0.0335271\ttest: 0.0382607\tbest: 0.0382607 (6248)\ttotal: 32m\tremaining: 19m 12s\n",
      "6249:\tlearn: 0.0335271\ttest: 0.0382607\tbest: 0.0382607 (6249)\ttotal: 32m\tremaining: 19m 12s\n",
      "6250:\tlearn: 0.0335271\ttest: 0.0382607\tbest: 0.0382607 (6249)\ttotal: 32m 1s\tremaining: 19m 12s\n",
      "6251:\tlearn: 0.0335271\ttest: 0.0382607\tbest: 0.0382607 (6251)\ttotal: 32m 1s\tremaining: 19m 11s\n",
      "6252:\tlearn: 0.0335228\ttest: 0.0382597\tbest: 0.0382597 (6252)\ttotal: 32m 1s\tremaining: 19m 11s\n",
      "6253:\tlearn: 0.0335228\ttest: 0.0382597\tbest: 0.0382597 (6253)\ttotal: 32m 1s\tremaining: 19m 11s\n",
      "6254:\tlearn: 0.0335228\ttest: 0.0382597\tbest: 0.0382597 (6254)\ttotal: 32m 2s\tremaining: 19m 10s\n",
      "6255:\tlearn: 0.0335228\ttest: 0.0382597\tbest: 0.0382597 (6255)\ttotal: 32m 2s\tremaining: 19m 10s\n",
      "6256:\tlearn: 0.0335228\ttest: 0.0382597\tbest: 0.0382597 (6255)\ttotal: 32m 2s\tremaining: 19m 10s\n",
      "6257:\tlearn: 0.0335228\ttest: 0.0382597\tbest: 0.0382597 (6257)\ttotal: 32m 2s\tremaining: 19m 9s\n",
      "6258:\tlearn: 0.0335228\ttest: 0.0382597\tbest: 0.0382597 (6258)\ttotal: 32m 3s\tremaining: 19m 9s\n",
      "6259:\tlearn: 0.0335227\ttest: 0.0382597\tbest: 0.0382597 (6258)\ttotal: 32m 3s\tremaining: 19m 9s\n",
      "6260:\tlearn: 0.0335227\ttest: 0.0382597\tbest: 0.0382597 (6258)\ttotal: 32m 3s\tremaining: 19m 8s\n",
      "6261:\tlearn: 0.0335228\ttest: 0.0382597\tbest: 0.0382597 (6261)\ttotal: 32m 3s\tremaining: 19m 8s\n",
      "6262:\tlearn: 0.0335228\ttest: 0.0382597\tbest: 0.0382597 (6262)\ttotal: 32m 4s\tremaining: 19m 8s\n",
      "6263:\tlearn: 0.0335228\ttest: 0.0382597\tbest: 0.0382597 (6262)\ttotal: 32m 4s\tremaining: 19m 7s\n",
      "6264:\tlearn: 0.0335227\ttest: 0.0382597\tbest: 0.0382597 (6262)\ttotal: 32m 4s\tremaining: 19m 7s\n",
      "6265:\tlearn: 0.0335227\ttest: 0.0382597\tbest: 0.0382597 (6262)\ttotal: 32m 5s\tremaining: 19m 7s\n",
      "6266:\tlearn: 0.0335227\ttest: 0.0382597\tbest: 0.0382597 (6262)\ttotal: 32m 5s\tremaining: 19m 6s\n",
      "6267:\tlearn: 0.0335227\ttest: 0.0382597\tbest: 0.0382597 (6262)\ttotal: 32m 5s\tremaining: 19m 6s\n",
      "6268:\tlearn: 0.0335227\ttest: 0.0382597\tbest: 0.0382597 (6262)\ttotal: 32m 5s\tremaining: 19m 6s\n",
      "6269:\tlearn: 0.0335227\ttest: 0.0382597\tbest: 0.0382597 (6262)\ttotal: 32m 6s\tremaining: 19m 5s\n",
      "6270:\tlearn: 0.0335227\ttest: 0.0382597\tbest: 0.0382597 (6270)\ttotal: 32m 6s\tremaining: 19m 5s\n",
      "6271:\tlearn: 0.0335227\ttest: 0.0382597\tbest: 0.0382597 (6270)\ttotal: 32m 7s\tremaining: 19m 5s\n",
      "6272:\tlearn: 0.0335227\ttest: 0.0382597\tbest: 0.0382597 (6270)\ttotal: 32m 7s\tremaining: 19m 5s\n",
      "6273:\tlearn: 0.0335227\ttest: 0.0382597\tbest: 0.0382597 (6270)\ttotal: 32m 8s\tremaining: 19m 5s\n",
      "6274:\tlearn: 0.0335227\ttest: 0.0382597\tbest: 0.0382597 (6270)\ttotal: 32m 8s\tremaining: 19m 4s\n",
      "6275:\tlearn: 0.0335227\ttest: 0.0382597\tbest: 0.0382597 (6275)\ttotal: 32m 9s\tremaining: 19m 4s\n",
      "6276:\tlearn: 0.0335227\ttest: 0.0382597\tbest: 0.0382597 (6276)\ttotal: 32m 9s\tremaining: 19m 4s\n",
      "6277:\tlearn: 0.0335175\ttest: 0.0382588\tbest: 0.0382588 (6277)\ttotal: 32m 10s\tremaining: 19m 4s\n",
      "6278:\tlearn: 0.0335175\ttest: 0.0382588\tbest: 0.0382588 (6278)\ttotal: 32m 10s\tremaining: 19m 3s\n",
      "6279:\tlearn: 0.0335175\ttest: 0.0382588\tbest: 0.0382588 (6279)\ttotal: 32m 10s\tremaining: 19m 3s\n",
      "6280:\tlearn: 0.0335175\ttest: 0.0382588\tbest: 0.0382588 (6280)\ttotal: 32m 10s\tremaining: 19m 3s\n",
      "6281:\tlearn: 0.0335175\ttest: 0.0382588\tbest: 0.0382588 (6281)\ttotal: 32m 11s\tremaining: 19m 2s\n",
      "6282:\tlearn: 0.0335175\ttest: 0.0382588\tbest: 0.0382588 (6281)\ttotal: 32m 11s\tremaining: 19m 2s\n",
      "6283:\tlearn: 0.0335175\ttest: 0.0382588\tbest: 0.0382588 (6283)\ttotal: 32m 11s\tremaining: 19m 2s\n",
      "6284:\tlearn: 0.0335174\ttest: 0.0382588\tbest: 0.0382588 (6284)\ttotal: 32m 11s\tremaining: 19m 1s\n",
      "6285:\tlearn: 0.0335174\ttest: 0.0382588\tbest: 0.0382588 (6284)\ttotal: 32m 12s\tremaining: 19m 1s\n",
      "6286:\tlearn: 0.0335128\ttest: 0.0382562\tbest: 0.0382562 (6286)\ttotal: 32m 12s\tremaining: 19m 1s\n",
      "6287:\tlearn: 0.0335128\ttest: 0.0382562\tbest: 0.0382562 (6287)\ttotal: 32m 12s\tremaining: 19m\n",
      "6288:\tlearn: 0.0335128\ttest: 0.0382562\tbest: 0.0382562 (6288)\ttotal: 32m 12s\tremaining: 19m\n",
      "6289:\tlearn: 0.0335128\ttest: 0.0382562\tbest: 0.0382562 (6289)\ttotal: 32m 13s\tremaining: 19m\n",
      "6290:\tlearn: 0.0335128\ttest: 0.0382562\tbest: 0.0382562 (6289)\ttotal: 32m 13s\tremaining: 18m 59s\n",
      "6291:\tlearn: 0.0335128\ttest: 0.0382562\tbest: 0.0382562 (6291)\ttotal: 32m 13s\tremaining: 18m 59s\n",
      "6292:\tlearn: 0.0335093\ttest: 0.0382558\tbest: 0.0382558 (6292)\ttotal: 32m 14s\tremaining: 18m 59s\n",
      "6293:\tlearn: 0.0335093\ttest: 0.0382558\tbest: 0.0382558 (6292)\ttotal: 32m 14s\tremaining: 18m 58s\n",
      "6294:\tlearn: 0.0335093\ttest: 0.0382558\tbest: 0.0382558 (6292)\ttotal: 32m 14s\tremaining: 18m 58s\n",
      "6295:\tlearn: 0.0335093\ttest: 0.0382558\tbest: 0.0382558 (6295)\ttotal: 32m 14s\tremaining: 18m 58s\n",
      "6296:\tlearn: 0.0335059\ttest: 0.0382543\tbest: 0.0382543 (6296)\ttotal: 32m 15s\tremaining: 18m 58s\n",
      "6297:\tlearn: 0.0335059\ttest: 0.0382543\tbest: 0.0382543 (6297)\ttotal: 32m 15s\tremaining: 18m 57s\n",
      "6298:\tlearn: 0.0335059\ttest: 0.0382543\tbest: 0.0382543 (6298)\ttotal: 32m 15s\tremaining: 18m 57s\n",
      "6299:\tlearn: 0.0335059\ttest: 0.0382543\tbest: 0.0382543 (6298)\ttotal: 32m 15s\tremaining: 18m 56s\n",
      "6300:\tlearn: 0.0335057\ttest: 0.0382542\tbest: 0.0382542 (6300)\ttotal: 32m 16s\tremaining: 18m 56s\n",
      "6301:\tlearn: 0.0335007\ttest: 0.0382535\tbest: 0.0382535 (6301)\ttotal: 32m 16s\tremaining: 18m 56s\n",
      "6302:\tlearn: 0.0335007\ttest: 0.0382535\tbest: 0.0382535 (6301)\ttotal: 32m 16s\tremaining: 18m 56s\n",
      "6303:\tlearn: 0.0335007\ttest: 0.0382535\tbest: 0.0382535 (6301)\ttotal: 32m 17s\tremaining: 18m 55s\n",
      "6304:\tlearn: 0.0335007\ttest: 0.0382535\tbest: 0.0382535 (6301)\ttotal: 32m 17s\tremaining: 18m 55s\n",
      "6305:\tlearn: 0.0334962\ttest: 0.0382530\tbest: 0.0382530 (6305)\ttotal: 32m 17s\tremaining: 18m 55s\n",
      "6306:\tlearn: 0.0334961\ttest: 0.0382530\tbest: 0.0382530 (6305)\ttotal: 32m 18s\tremaining: 18m 54s\n",
      "6307:\tlearn: 0.0334961\ttest: 0.0382530\tbest: 0.0382530 (6305)\ttotal: 32m 18s\tremaining: 18m 54s\n",
      "6308:\tlearn: 0.0334961\ttest: 0.0382530\tbest: 0.0382530 (6305)\ttotal: 32m 18s\tremaining: 18m 54s\n",
      "6309:\tlearn: 0.0334961\ttest: 0.0382530\tbest: 0.0382530 (6305)\ttotal: 32m 19s\tremaining: 18m 54s\n",
      "6310:\tlearn: 0.0334961\ttest: 0.0382530\tbest: 0.0382530 (6305)\ttotal: 32m 19s\tremaining: 18m 53s\n",
      "6311:\tlearn: 0.0334961\ttest: 0.0382530\tbest: 0.0382530 (6311)\ttotal: 32m 20s\tremaining: 18m 53s\n",
      "6312:\tlearn: 0.0334961\ttest: 0.0382530\tbest: 0.0382530 (6311)\ttotal: 32m 20s\tremaining: 18m 53s\n",
      "6313:\tlearn: 0.0334961\ttest: 0.0382530\tbest: 0.0382530 (6313)\ttotal: 32m 21s\tremaining: 18m 53s\n",
      "6314:\tlearn: 0.0334961\ttest: 0.0382530\tbest: 0.0382530 (6313)\ttotal: 32m 21s\tremaining: 18m 53s\n",
      "6315:\tlearn: 0.0334915\ttest: 0.0382504\tbest: 0.0382504 (6315)\ttotal: 32m 22s\tremaining: 18m 52s\n",
      "6316:\tlearn: 0.0334915\ttest: 0.0382504\tbest: 0.0382504 (6316)\ttotal: 32m 22s\tremaining: 18m 52s\n",
      "6317:\tlearn: 0.0334915\ttest: 0.0382504\tbest: 0.0382504 (6317)\ttotal: 32m 23s\tremaining: 18m 52s\n",
      "6318:\tlearn: 0.0334915\ttest: 0.0382504\tbest: 0.0382504 (6317)\ttotal: 32m 23s\tremaining: 18m 52s\n",
      "6319:\tlearn: 0.0334914\ttest: 0.0382504\tbest: 0.0382504 (6317)\ttotal: 32m 24s\tremaining: 18m 52s\n",
      "6320:\tlearn: 0.0334915\ttest: 0.0382504\tbest: 0.0382504 (6320)\ttotal: 32m 24s\tremaining: 18m 51s\n",
      "6321:\tlearn: 0.0334915\ttest: 0.0382504\tbest: 0.0382504 (6320)\ttotal: 32m 25s\tremaining: 18m 51s\n",
      "6322:\tlearn: 0.0334915\ttest: 0.0382504\tbest: 0.0382504 (6320)\ttotal: 32m 25s\tremaining: 18m 51s\n",
      "6323:\tlearn: 0.0334914\ttest: 0.0382504\tbest: 0.0382504 (6323)\ttotal: 32m 25s\tremaining: 18m 51s\n",
      "6324:\tlearn: 0.0334914\ttest: 0.0382504\tbest: 0.0382504 (6324)\ttotal: 32m 26s\tremaining: 18m 50s\n",
      "6325:\tlearn: 0.0334914\ttest: 0.0382504\tbest: 0.0382504 (6325)\ttotal: 32m 26s\tremaining: 18m 50s\n",
      "6326:\tlearn: 0.0334914\ttest: 0.0382504\tbest: 0.0382504 (6325)\ttotal: 32m 26s\tremaining: 18m 50s\n",
      "6327:\tlearn: 0.0334914\ttest: 0.0382504\tbest: 0.0382504 (6325)\ttotal: 32m 26s\tremaining: 18m 49s\n",
      "6328:\tlearn: 0.0334914\ttest: 0.0382504\tbest: 0.0382504 (6325)\ttotal: 32m 27s\tremaining: 18m 49s\n",
      "6329:\tlearn: 0.0334914\ttest: 0.0382504\tbest: 0.0382504 (6325)\ttotal: 32m 27s\tremaining: 18m 48s\n",
      "6330:\tlearn: 0.0334884\ttest: 0.0382502\tbest: 0.0382502 (6330)\ttotal: 32m 27s\tremaining: 18m 48s\n",
      "6331:\tlearn: 0.0334840\ttest: 0.0382497\tbest: 0.0382497 (6331)\ttotal: 32m 27s\tremaining: 18m 48s\n",
      "6332:\tlearn: 0.0334840\ttest: 0.0382497\tbest: 0.0382497 (6331)\ttotal: 32m 28s\tremaining: 18m 48s\n",
      "6333:\tlearn: 0.0334840\ttest: 0.0382497\tbest: 0.0382497 (6333)\ttotal: 32m 28s\tremaining: 18m 47s\n",
      "6334:\tlearn: 0.0334840\ttest: 0.0382497\tbest: 0.0382497 (6334)\ttotal: 32m 28s\tremaining: 18m 47s\n",
      "6335:\tlearn: 0.0334840\ttest: 0.0382497\tbest: 0.0382497 (6334)\ttotal: 32m 28s\tremaining: 18m 47s\n",
      "6336:\tlearn: 0.0334840\ttest: 0.0382497\tbest: 0.0382497 (6334)\ttotal: 32m 29s\tremaining: 18m 46s\n",
      "6337:\tlearn: 0.0334840\ttest: 0.0382497\tbest: 0.0382497 (6337)\ttotal: 32m 29s\tremaining: 18m 46s\n",
      "6338:\tlearn: 0.0334840\ttest: 0.0382497\tbest: 0.0382497 (6338)\ttotal: 32m 29s\tremaining: 18m 46s\n",
      "6339:\tlearn: 0.0334840\ttest: 0.0382497\tbest: 0.0382497 (6338)\ttotal: 32m 30s\tremaining: 18m 45s\n",
      "6340:\tlearn: 0.0334840\ttest: 0.0382497\tbest: 0.0382497 (6338)\ttotal: 32m 30s\tremaining: 18m 45s\n",
      "6341:\tlearn: 0.0334840\ttest: 0.0382497\tbest: 0.0382497 (6338)\ttotal: 32m 30s\tremaining: 18m 45s\n",
      "6342:\tlearn: 0.0334840\ttest: 0.0382497\tbest: 0.0382497 (6342)\ttotal: 32m 30s\tremaining: 18m 44s\n",
      "6343:\tlearn: 0.0334840\ttest: 0.0382496\tbest: 0.0382496 (6343)\ttotal: 32m 31s\tremaining: 18m 44s\n",
      "6344:\tlearn: 0.0334840\ttest: 0.0382496\tbest: 0.0382496 (6344)\ttotal: 32m 31s\tremaining: 18m 44s\n",
      "6345:\tlearn: 0.0334840\ttest: 0.0382496\tbest: 0.0382496 (6345)\ttotal: 32m 31s\tremaining: 18m 43s\n",
      "6346:\tlearn: 0.0334840\ttest: 0.0382496\tbest: 0.0382496 (6345)\ttotal: 32m 31s\tremaining: 18m 43s\n",
      "6347:\tlearn: 0.0334816\ttest: 0.0382497\tbest: 0.0382496 (6345)\ttotal: 32m 32s\tremaining: 18m 43s\n",
      "6348:\tlearn: 0.0334815\ttest: 0.0382497\tbest: 0.0382496 (6345)\ttotal: 32m 32s\tremaining: 18m 42s\n",
      "6349:\tlearn: 0.0334815\ttest: 0.0382497\tbest: 0.0382496 (6345)\ttotal: 32m 32s\tremaining: 18m 42s\n",
      "6350:\tlearn: 0.0334815\ttest: 0.0382497\tbest: 0.0382496 (6345)\ttotal: 32m 32s\tremaining: 18m 42s\n",
      "6351:\tlearn: 0.0334772\ttest: 0.0382489\tbest: 0.0382489 (6351)\ttotal: 32m 33s\tremaining: 18m 41s\n",
      "6352:\tlearn: 0.0334772\ttest: 0.0382489\tbest: 0.0382489 (6352)\ttotal: 32m 33s\tremaining: 18m 41s\n",
      "6353:\tlearn: 0.0334772\ttest: 0.0382489\tbest: 0.0382489 (6353)\ttotal: 32m 33s\tremaining: 18m 41s\n",
      "6354:\tlearn: 0.0334772\ttest: 0.0382489\tbest: 0.0382489 (6354)\ttotal: 32m 33s\tremaining: 18m 40s\n",
      "6355:\tlearn: 0.0334772\ttest: 0.0382489\tbest: 0.0382489 (6354)\ttotal: 32m 34s\tremaining: 18m 40s\n",
      "6356:\tlearn: 0.0334772\ttest: 0.0382489\tbest: 0.0382489 (6354)\ttotal: 32m 34s\tremaining: 18m 40s\n",
      "6357:\tlearn: 0.0334772\ttest: 0.0382489\tbest: 0.0382489 (6357)\ttotal: 32m 34s\tremaining: 18m 39s\n",
      "6358:\tlearn: 0.0334772\ttest: 0.0382489\tbest: 0.0382489 (6358)\ttotal: 32m 34s\tremaining: 18m 39s\n",
      "6359:\tlearn: 0.0334772\ttest: 0.0382489\tbest: 0.0382489 (6358)\ttotal: 32m 35s\tremaining: 18m 39s\n",
      "6360:\tlearn: 0.0334772\ttest: 0.0382489\tbest: 0.0382489 (6360)\ttotal: 32m 35s\tremaining: 18m 38s\n",
      "6361:\tlearn: 0.0334772\ttest: 0.0382489\tbest: 0.0382489 (6360)\ttotal: 32m 35s\tremaining: 18m 38s\n",
      "6362:\tlearn: 0.0334724\ttest: 0.0382486\tbest: 0.0382486 (6362)\ttotal: 32m 36s\tremaining: 18m 38s\n",
      "6363:\tlearn: 0.0334724\ttest: 0.0382486\tbest: 0.0382486 (6363)\ttotal: 32m 36s\tremaining: 18m 38s\n",
      "6364:\tlearn: 0.0334724\ttest: 0.0382486\tbest: 0.0382486 (6364)\ttotal: 32m 37s\tremaining: 18m 37s\n",
      "6365:\tlearn: 0.0334724\ttest: 0.0382486\tbest: 0.0382486 (6364)\ttotal: 32m 37s\tremaining: 18m 37s\n",
      "6366:\tlearn: 0.0334724\ttest: 0.0382486\tbest: 0.0382486 (6366)\ttotal: 32m 38s\tremaining: 18m 37s\n",
      "6367:\tlearn: 0.0334724\ttest: 0.0382486\tbest: 0.0382486 (6367)\ttotal: 32m 38s\tremaining: 18m 37s\n",
      "6368:\tlearn: 0.0334724\ttest: 0.0382486\tbest: 0.0382486 (6367)\ttotal: 32m 39s\tremaining: 18m 37s\n",
      "6369:\tlearn: 0.0334724\ttest: 0.0382486\tbest: 0.0382486 (6369)\ttotal: 32m 39s\tremaining: 18m 36s\n",
      "6370:\tlearn: 0.0334724\ttest: 0.0382486\tbest: 0.0382486 (6370)\ttotal: 32m 39s\tremaining: 18m 36s\n",
      "6371:\tlearn: 0.0334724\ttest: 0.0382486\tbest: 0.0382486 (6370)\ttotal: 32m 40s\tremaining: 18m 36s\n",
      "6372:\tlearn: 0.0334724\ttest: 0.0382486\tbest: 0.0382486 (6372)\ttotal: 32m 40s\tremaining: 18m 35s\n",
      "6373:\tlearn: 0.0334724\ttest: 0.0382486\tbest: 0.0382486 (6373)\ttotal: 32m 40s\tremaining: 18m 35s\n",
      "6374:\tlearn: 0.0334724\ttest: 0.0382486\tbest: 0.0382486 (6373)\ttotal: 32m 40s\tremaining: 18m 35s\n",
      "6375:\tlearn: 0.0334723\ttest: 0.0382486\tbest: 0.0382486 (6375)\ttotal: 32m 41s\tremaining: 18m 34s\n",
      "6376:\tlearn: 0.0334723\ttest: 0.0382486\tbest: 0.0382486 (6375)\ttotal: 32m 41s\tremaining: 18m 34s\n",
      "6377:\tlearn: 0.0334723\ttest: 0.0382486\tbest: 0.0382486 (6377)\ttotal: 32m 41s\tremaining: 18m 34s\n",
      "6378:\tlearn: 0.0334723\ttest: 0.0382486\tbest: 0.0382486 (6377)\ttotal: 32m 41s\tremaining: 18m 33s\n",
      "6379:\tlearn: 0.0334723\ttest: 0.0382486\tbest: 0.0382486 (6379)\ttotal: 32m 42s\tremaining: 18m 33s\n",
      "6380:\tlearn: 0.0334723\ttest: 0.0382486\tbest: 0.0382486 (6380)\ttotal: 32m 42s\tremaining: 18m 32s\n",
      "6381:\tlearn: 0.0334723\ttest: 0.0382486\tbest: 0.0382486 (6380)\ttotal: 32m 42s\tremaining: 18m 32s\n",
      "6382:\tlearn: 0.0334723\ttest: 0.0382486\tbest: 0.0382486 (6380)\ttotal: 32m 42s\tremaining: 18m 32s\n",
      "6383:\tlearn: 0.0334682\ttest: 0.0382489\tbest: 0.0382486 (6380)\ttotal: 32m 43s\tremaining: 18m 32s\n",
      "6384:\tlearn: 0.0334682\ttest: 0.0382489\tbest: 0.0382486 (6380)\ttotal: 32m 43s\tremaining: 18m 31s\n",
      "6385:\tlearn: 0.0334682\ttest: 0.0382489\tbest: 0.0382486 (6380)\ttotal: 32m 43s\tremaining: 18m 31s\n",
      "6386:\tlearn: 0.0334681\ttest: 0.0382489\tbest: 0.0382486 (6380)\ttotal: 32m 44s\tremaining: 18m 31s\n",
      "6387:\tlearn: 0.0334681\ttest: 0.0382489\tbest: 0.0382486 (6380)\ttotal: 32m 44s\tremaining: 18m 30s\n",
      "6388:\tlearn: 0.0334643\ttest: 0.0382488\tbest: 0.0382486 (6380)\ttotal: 32m 44s\tremaining: 18m 30s\n",
      "6389:\tlearn: 0.0334643\ttest: 0.0382488\tbest: 0.0382486 (6380)\ttotal: 32m 44s\tremaining: 18m 30s\n",
      "6390:\tlearn: 0.0334602\ttest: 0.0382477\tbest: 0.0382477 (6390)\ttotal: 32m 45s\tremaining: 18m 29s\n",
      "6391:\tlearn: 0.0334602\ttest: 0.0382477\tbest: 0.0382477 (6390)\ttotal: 32m 45s\tremaining: 18m 29s\n",
      "6392:\tlearn: 0.0334602\ttest: 0.0382477\tbest: 0.0382477 (6390)\ttotal: 32m 45s\tremaining: 18m 29s\n",
      "6393:\tlearn: 0.0334602\ttest: 0.0382477\tbest: 0.0382477 (6390)\ttotal: 32m 45s\tremaining: 18m 28s\n",
      "6394:\tlearn: 0.0334601\ttest: 0.0382477\tbest: 0.0382477 (6390)\ttotal: 32m 46s\tremaining: 18m 28s\n",
      "6395:\tlearn: 0.0334601\ttest: 0.0382477\tbest: 0.0382477 (6390)\ttotal: 32m 46s\tremaining: 18m 28s\n",
      "6396:\tlearn: 0.0334601\ttest: 0.0382477\tbest: 0.0382477 (6390)\ttotal: 32m 46s\tremaining: 18m 27s\n",
      "6397:\tlearn: 0.0334568\ttest: 0.0382472\tbest: 0.0382472 (6397)\ttotal: 32m 46s\tremaining: 18m 27s\n",
      "6398:\tlearn: 0.0334568\ttest: 0.0382472\tbest: 0.0382472 (6398)\ttotal: 32m 47s\tremaining: 18m 27s\n",
      "6399:\tlearn: 0.0334568\ttest: 0.0382472\tbest: 0.0382472 (6399)\ttotal: 32m 47s\tremaining: 18m 26s\n",
      "6400:\tlearn: 0.0334568\ttest: 0.0382472\tbest: 0.0382472 (6399)\ttotal: 32m 47s\tremaining: 18m 26s\n",
      "6401:\tlearn: 0.0334527\ttest: 0.0382478\tbest: 0.0382472 (6399)\ttotal: 32m 48s\tremaining: 18m 26s\n",
      "6402:\tlearn: 0.0334527\ttest: 0.0382478\tbest: 0.0382472 (6399)\ttotal: 32m 48s\tremaining: 18m 25s\n",
      "6403:\tlearn: 0.0334527\ttest: 0.0382478\tbest: 0.0382472 (6399)\ttotal: 32m 48s\tremaining: 18m 25s\n",
      "6404:\tlearn: 0.0334527\ttest: 0.0382478\tbest: 0.0382472 (6399)\ttotal: 32m 48s\tremaining: 18m 25s\n",
      "6405:\tlearn: 0.0334527\ttest: 0.0382478\tbest: 0.0382472 (6399)\ttotal: 32m 49s\tremaining: 18m 24s\n",
      "6406:\tlearn: 0.0334527\ttest: 0.0382478\tbest: 0.0382472 (6399)\ttotal: 32m 49s\tremaining: 18m 24s\n",
      "6407:\tlearn: 0.0334527\ttest: 0.0382478\tbest: 0.0382472 (6399)\ttotal: 32m 49s\tremaining: 18m 24s\n",
      "6408:\tlearn: 0.0334527\ttest: 0.0382478\tbest: 0.0382472 (6399)\ttotal: 32m 50s\tremaining: 18m 23s\n",
      "6409:\tlearn: 0.0334527\ttest: 0.0382478\tbest: 0.0382472 (6399)\ttotal: 32m 50s\tremaining: 18m 23s\n",
      "6410:\tlearn: 0.0334527\ttest: 0.0382478\tbest: 0.0382472 (6399)\ttotal: 32m 51s\tremaining: 18m 23s\n",
      "6411:\tlearn: 0.0334527\ttest: 0.0382478\tbest: 0.0382472 (6399)\ttotal: 32m 51s\tremaining: 18m 23s\n",
      "6412:\tlearn: 0.0334527\ttest: 0.0382478\tbest: 0.0382472 (6399)\ttotal: 32m 52s\tremaining: 18m 23s\n",
      "6413:\tlearn: 0.0334527\ttest: 0.0382478\tbest: 0.0382472 (6399)\ttotal: 32m 52s\tremaining: 18m 22s\n",
      "6414:\tlearn: 0.0334527\ttest: 0.0382478\tbest: 0.0382472 (6399)\ttotal: 32m 53s\tremaining: 18m 22s\n",
      "6415:\tlearn: 0.0334526\ttest: 0.0382478\tbest: 0.0382472 (6399)\ttotal: 32m 53s\tremaining: 18m 22s\n",
      "6416:\tlearn: 0.0334526\ttest: 0.0382478\tbest: 0.0382472 (6399)\ttotal: 32m 53s\tremaining: 18m 22s\n",
      "6417:\tlearn: 0.0334526\ttest: 0.0382478\tbest: 0.0382472 (6399)\ttotal: 32m 54s\tremaining: 18m 21s\n",
      "6418:\tlearn: 0.0334526\ttest: 0.0382478\tbest: 0.0382472 (6399)\ttotal: 32m 54s\tremaining: 18m 21s\n",
      "6419:\tlearn: 0.0334526\ttest: 0.0382478\tbest: 0.0382472 (6399)\ttotal: 32m 54s\tremaining: 18m 21s\n",
      "6420:\tlearn: 0.0334526\ttest: 0.0382478\tbest: 0.0382472 (6399)\ttotal: 32m 54s\tremaining: 18m 20s\n",
      "6421:\tlearn: 0.0334526\ttest: 0.0382478\tbest: 0.0382472 (6399)\ttotal: 32m 55s\tremaining: 18m 20s\n",
      "6422:\tlearn: 0.0334526\ttest: 0.0382478\tbest: 0.0382472 (6399)\ttotal: 32m 55s\tremaining: 18m 20s\n",
      "6423:\tlearn: 0.0334526\ttest: 0.0382478\tbest: 0.0382472 (6399)\ttotal: 32m 55s\tremaining: 18m 19s\n",
      "6424:\tlearn: 0.0334526\ttest: 0.0382478\tbest: 0.0382472 (6399)\ttotal: 32m 55s\tremaining: 18m 19s\n",
      "6425:\tlearn: 0.0334526\ttest: 0.0382478\tbest: 0.0382472 (6399)\ttotal: 32m 56s\tremaining: 18m 19s\n",
      "6426:\tlearn: 0.0334526\ttest: 0.0382478\tbest: 0.0382472 (6399)\ttotal: 32m 56s\tremaining: 18m 18s\n",
      "6427:\tlearn: 0.0334526\ttest: 0.0382478\tbest: 0.0382472 (6399)\ttotal: 32m 56s\tremaining: 18m 18s\n",
      "6428:\tlearn: 0.0334466\ttest: 0.0382463\tbest: 0.0382463 (6428)\ttotal: 32m 56s\tremaining: 18m 18s\n",
      "6429:\tlearn: 0.0334466\ttest: 0.0382463\tbest: 0.0382463 (6428)\ttotal: 32m 57s\tremaining: 18m 17s\n",
      "6430:\tlearn: 0.0334466\ttest: 0.0382463\tbest: 0.0382463 (6428)\ttotal: 32m 57s\tremaining: 18m 17s\n",
      "6431:\tlearn: 0.0334466\ttest: 0.0382463\tbest: 0.0382463 (6428)\ttotal: 32m 57s\tremaining: 18m 17s\n",
      "6432:\tlearn: 0.0334466\ttest: 0.0382463\tbest: 0.0382463 (6432)\ttotal: 32m 57s\tremaining: 18m 16s\n",
      "6433:\tlearn: 0.0334466\ttest: 0.0382463\tbest: 0.0382463 (6433)\ttotal: 32m 58s\tremaining: 18m 16s\n",
      "6434:\tlearn: 0.0334466\ttest: 0.0382463\tbest: 0.0382463 (6433)\ttotal: 32m 58s\tremaining: 18m 16s\n",
      "6435:\tlearn: 0.0334466\ttest: 0.0382463\tbest: 0.0382463 (6433)\ttotal: 32m 58s\tremaining: 18m 15s\n",
      "6436:\tlearn: 0.0334431\ttest: 0.0382452\tbest: 0.0382452 (6436)\ttotal: 32m 59s\tremaining: 18m 15s\n",
      "6437:\tlearn: 0.0334431\ttest: 0.0382452\tbest: 0.0382452 (6437)\ttotal: 32m 59s\tremaining: 18m 15s\n",
      "6438:\tlearn: 0.0334431\ttest: 0.0382452\tbest: 0.0382452 (6438)\ttotal: 32m 59s\tremaining: 18m 14s\n",
      "6439:\tlearn: 0.0334431\ttest: 0.0382452\tbest: 0.0382452 (6438)\ttotal: 32m 59s\tremaining: 18m 14s\n",
      "6440:\tlearn: 0.0334431\ttest: 0.0382452\tbest: 0.0382452 (6438)\ttotal: 33m\tremaining: 18m 14s\n",
      "6441:\tlearn: 0.0334431\ttest: 0.0382452\tbest: 0.0382452 (6441)\ttotal: 33m\tremaining: 18m 13s\n",
      "6442:\tlearn: 0.0334431\ttest: 0.0382452\tbest: 0.0382452 (6441)\ttotal: 33m\tremaining: 18m 13s\n",
      "6443:\tlearn: 0.0334431\ttest: 0.0382452\tbest: 0.0382452 (6441)\ttotal: 33m\tremaining: 18m 13s\n",
      "6444:\tlearn: 0.0334431\ttest: 0.0382452\tbest: 0.0382452 (6441)\ttotal: 33m 1s\tremaining: 18m 12s\n",
      "6445:\tlearn: 0.0334431\ttest: 0.0382452\tbest: 0.0382452 (6441)\ttotal: 33m 1s\tremaining: 18m 12s\n",
      "6446:\tlearn: 0.0334431\ttest: 0.0382452\tbest: 0.0382452 (6446)\ttotal: 33m 1s\tremaining: 18m 12s\n",
      "6447:\tlearn: 0.0334431\ttest: 0.0382452\tbest: 0.0382452 (6446)\ttotal: 33m 1s\tremaining: 18m 11s\n",
      "6448:\tlearn: 0.0334431\ttest: 0.0382452\tbest: 0.0382452 (6446)\ttotal: 33m 2s\tremaining: 18m 11s\n",
      "6449:\tlearn: 0.0334431\ttest: 0.0382452\tbest: 0.0382452 (6446)\ttotal: 33m 2s\tremaining: 18m 11s\n",
      "6450:\tlearn: 0.0334431\ttest: 0.0382452\tbest: 0.0382452 (6450)\ttotal: 33m 2s\tremaining: 18m 10s\n",
      "6451:\tlearn: 0.0334431\ttest: 0.0382452\tbest: 0.0382452 (6450)\ttotal: 33m 2s\tremaining: 18m 10s\n",
      "6452:\tlearn: 0.0334431\ttest: 0.0382452\tbest: 0.0382452 (6452)\ttotal: 33m 3s\tremaining: 18m 10s\n",
      "6453:\tlearn: 0.0334430\ttest: 0.0382452\tbest: 0.0382452 (6453)\ttotal: 33m 3s\tremaining: 18m 9s\n",
      "6454:\tlearn: 0.0334431\ttest: 0.0382452\tbest: 0.0382452 (6454)\ttotal: 33m 3s\tremaining: 18m 9s\n",
      "6455:\tlearn: 0.0334431\ttest: 0.0382452\tbest: 0.0382452 (6454)\ttotal: 33m 4s\tremaining: 18m 9s\n",
      "6456:\tlearn: 0.0334431\ttest: 0.0382452\tbest: 0.0382452 (6454)\ttotal: 33m 4s\tremaining: 18m 8s\n",
      "6457:\tlearn: 0.0334430\ttest: 0.0382452\tbest: 0.0382452 (6454)\ttotal: 33m 5s\tremaining: 18m 8s\n",
      "6458:\tlearn: 0.0334382\ttest: 0.0382444\tbest: 0.0382444 (6458)\ttotal: 33m 5s\tremaining: 18m 8s\n",
      "6459:\tlearn: 0.0334382\ttest: 0.0382443\tbest: 0.0382443 (6459)\ttotal: 33m 6s\tremaining: 18m 8s\n",
      "6460:\tlearn: 0.0334382\ttest: 0.0382443\tbest: 0.0382443 (6460)\ttotal: 33m 6s\tremaining: 18m 8s\n",
      "6461:\tlearn: 0.0334382\ttest: 0.0382443\tbest: 0.0382443 (6461)\ttotal: 33m 7s\tremaining: 18m 7s\n",
      "6462:\tlearn: 0.0334381\ttest: 0.0382443\tbest: 0.0382443 (6462)\ttotal: 33m 7s\tremaining: 18m 7s\n",
      "6463:\tlearn: 0.0334381\ttest: 0.0382443\tbest: 0.0382443 (6463)\ttotal: 33m 7s\tremaining: 18m 7s\n",
      "6464:\tlearn: 0.0334381\ttest: 0.0382443\tbest: 0.0382443 (6463)\ttotal: 33m 8s\tremaining: 18m 7s\n",
      "6465:\tlearn: 0.0334381\ttest: 0.0382443\tbest: 0.0382443 (6463)\ttotal: 33m 8s\tremaining: 18m 6s\n",
      "6466:\tlearn: 0.0334381\ttest: 0.0382443\tbest: 0.0382443 (6463)\ttotal: 33m 8s\tremaining: 18m 6s\n",
      "6467:\tlearn: 0.0334381\ttest: 0.0382443\tbest: 0.0382443 (6467)\ttotal: 33m 8s\tremaining: 18m 6s\n",
      "6468:\tlearn: 0.0334381\ttest: 0.0382443\tbest: 0.0382443 (6468)\ttotal: 33m 9s\tremaining: 18m 5s\n",
      "6469:\tlearn: 0.0334381\ttest: 0.0382443\tbest: 0.0382443 (6469)\ttotal: 33m 9s\tremaining: 18m 5s\n",
      "6470:\tlearn: 0.0334381\ttest: 0.0382443\tbest: 0.0382443 (6469)\ttotal: 33m 9s\tremaining: 18m 5s\n",
      "6471:\tlearn: 0.0334381\ttest: 0.0382443\tbest: 0.0382443 (6469)\ttotal: 33m 9s\tremaining: 18m 4s\n",
      "6472:\tlearn: 0.0334381\ttest: 0.0382443\tbest: 0.0382443 (6469)\ttotal: 33m 10s\tremaining: 18m 4s\n",
      "6473:\tlearn: 0.0334381\ttest: 0.0382443\tbest: 0.0382443 (6473)\ttotal: 33m 10s\tremaining: 18m 4s\n",
      "6474:\tlearn: 0.0334381\ttest: 0.0382443\tbest: 0.0382443 (6474)\ttotal: 33m 10s\tremaining: 18m 3s\n",
      "6475:\tlearn: 0.0334381\ttest: 0.0382443\tbest: 0.0382443 (6475)\ttotal: 33m 10s\tremaining: 18m 3s\n",
      "6476:\tlearn: 0.0334381\ttest: 0.0382443\tbest: 0.0382443 (6476)\ttotal: 33m 11s\tremaining: 18m 3s\n",
      "6477:\tlearn: 0.0334381\ttest: 0.0382443\tbest: 0.0382443 (6477)\ttotal: 33m 11s\tremaining: 18m 2s\n",
      "6478:\tlearn: 0.0334381\ttest: 0.0382443\tbest: 0.0382443 (6477)\ttotal: 33m 11s\tremaining: 18m 2s\n",
      "6479:\tlearn: 0.0334381\ttest: 0.0382443\tbest: 0.0382443 (6479)\ttotal: 33m 11s\tremaining: 18m 2s\n",
      "6480:\tlearn: 0.0334338\ttest: 0.0382440\tbest: 0.0382440 (6480)\ttotal: 33m 12s\tremaining: 18m 1s\n",
      "6481:\tlearn: 0.0334338\ttest: 0.0382440\tbest: 0.0382440 (6481)\ttotal: 33m 12s\tremaining: 18m 1s\n",
      "6482:\tlearn: 0.0334338\ttest: 0.0382440\tbest: 0.0382440 (6481)\ttotal: 33m 12s\tremaining: 18m 1s\n",
      "6483:\tlearn: 0.0334337\ttest: 0.0382440\tbest: 0.0382440 (6481)\ttotal: 33m 13s\tremaining: 18m\n",
      "6484:\tlearn: 0.0334337\ttest: 0.0382440\tbest: 0.0382440 (6484)\ttotal: 33m 13s\tremaining: 18m\n",
      "6485:\tlearn: 0.0334337\ttest: 0.0382440\tbest: 0.0382440 (6484)\ttotal: 33m 13s\tremaining: 18m\n",
      "6486:\tlearn: 0.0334337\ttest: 0.0382440\tbest: 0.0382440 (6484)\ttotal: 33m 13s\tremaining: 17m 59s\n",
      "6487:\tlearn: 0.0334337\ttest: 0.0382440\tbest: 0.0382440 (6487)\ttotal: 33m 14s\tremaining: 17m 59s\n",
      "6488:\tlearn: 0.0334294\ttest: 0.0382452\tbest: 0.0382440 (6487)\ttotal: 33m 14s\tremaining: 17m 59s\n",
      "6489:\tlearn: 0.0334265\ttest: 0.0382445\tbest: 0.0382440 (6487)\ttotal: 33m 14s\tremaining: 17m 58s\n",
      "6490:\tlearn: 0.0334225\ttest: 0.0382438\tbest: 0.0382438 (6490)\ttotal: 33m 15s\tremaining: 17m 58s\n",
      "6491:\tlearn: 0.0334225\ttest: 0.0382438\tbest: 0.0382438 (6490)\ttotal: 33m 15s\tremaining: 17m 58s\n",
      "6492:\tlearn: 0.0334225\ttest: 0.0382438\tbest: 0.0382438 (6492)\ttotal: 33m 15s\tremaining: 17m 57s\n",
      "6493:\tlearn: 0.0334225\ttest: 0.0382438\tbest: 0.0382438 (6493)\ttotal: 33m 15s\tremaining: 17m 57s\n",
      "6494:\tlearn: 0.0334225\ttest: 0.0382438\tbest: 0.0382438 (6494)\ttotal: 33m 16s\tremaining: 17m 57s\n",
      "6495:\tlearn: 0.0334225\ttest: 0.0382438\tbest: 0.0382438 (6495)\ttotal: 33m 16s\tremaining: 17m 56s\n",
      "6496:\tlearn: 0.0334225\ttest: 0.0382438\tbest: 0.0382438 (6495)\ttotal: 33m 16s\tremaining: 17m 56s\n",
      "6497:\tlearn: 0.0334225\ttest: 0.0382438\tbest: 0.0382438 (6497)\ttotal: 33m 16s\tremaining: 17m 56s\n",
      "6498:\tlearn: 0.0334225\ttest: 0.0382438\tbest: 0.0382438 (6497)\ttotal: 33m 17s\tremaining: 17m 55s\n",
      "6499:\tlearn: 0.0334225\ttest: 0.0382438\tbest: 0.0382438 (6497)\ttotal: 33m 17s\tremaining: 17m 55s\n",
      "6500:\tlearn: 0.0334225\ttest: 0.0382438\tbest: 0.0382438 (6497)\ttotal: 33m 17s\tremaining: 17m 55s\n",
      "6501:\tlearn: 0.0334225\ttest: 0.0382438\tbest: 0.0382438 (6497)\ttotal: 33m 18s\tremaining: 17m 54s\n",
      "6502:\tlearn: 0.0334225\ttest: 0.0382438\tbest: 0.0382438 (6502)\ttotal: 33m 18s\tremaining: 17m 54s\n",
      "6503:\tlearn: 0.0334225\ttest: 0.0382438\tbest: 0.0382438 (6503)\ttotal: 33m 19s\tremaining: 17m 54s\n",
      "6504:\tlearn: 0.0334225\ttest: 0.0382438\tbest: 0.0382438 (6504)\ttotal: 33m 19s\tremaining: 17m 54s\n",
      "6505:\tlearn: 0.0334225\ttest: 0.0382438\tbest: 0.0382438 (6505)\ttotal: 33m 19s\tremaining: 17m 54s\n",
      "6506:\tlearn: 0.0334205\ttest: 0.0382439\tbest: 0.0382438 (6505)\ttotal: 33m 20s\tremaining: 17m 53s\n",
      "6507:\tlearn: 0.0334205\ttest: 0.0382439\tbest: 0.0382438 (6505)\ttotal: 33m 20s\tremaining: 17m 53s\n",
      "6508:\tlearn: 0.0334148\ttest: 0.0382425\tbest: 0.0382425 (6508)\ttotal: 33m 21s\tremaining: 17m 53s\n",
      "6509:\tlearn: 0.0334148\ttest: 0.0382425\tbest: 0.0382425 (6508)\ttotal: 33m 21s\tremaining: 17m 53s\n",
      "6510:\tlearn: 0.0334148\ttest: 0.0382425\tbest: 0.0382425 (6508)\ttotal: 33m 22s\tremaining: 17m 52s\n",
      "6511:\tlearn: 0.0334148\ttest: 0.0382425\tbest: 0.0382425 (6511)\ttotal: 33m 22s\tremaining: 17m 52s\n",
      "6512:\tlearn: 0.0334148\ttest: 0.0382425\tbest: 0.0382425 (6511)\ttotal: 33m 22s\tremaining: 17m 52s\n",
      "6513:\tlearn: 0.0334119\ttest: 0.0382420\tbest: 0.0382420 (6513)\ttotal: 33m 22s\tremaining: 17m 51s\n",
      "6514:\tlearn: 0.0334119\ttest: 0.0382420\tbest: 0.0382420 (6513)\ttotal: 33m 23s\tremaining: 17m 51s\n",
      "6515:\tlearn: 0.0334119\ttest: 0.0382420\tbest: 0.0382420 (6515)\ttotal: 33m 23s\tremaining: 17m 51s\n",
      "6516:\tlearn: 0.0334119\ttest: 0.0382420\tbest: 0.0382420 (6515)\ttotal: 33m 23s\tremaining: 17m 50s\n",
      "6517:\tlearn: 0.0334119\ttest: 0.0382420\tbest: 0.0382420 (6515)\ttotal: 33m 23s\tremaining: 17m 50s\n",
      "6518:\tlearn: 0.0334119\ttest: 0.0382420\tbest: 0.0382420 (6518)\ttotal: 33m 24s\tremaining: 17m 50s\n",
      "6519:\tlearn: 0.0334118\ttest: 0.0382420\tbest: 0.0382420 (6518)\ttotal: 33m 24s\tremaining: 17m 49s\n",
      "6520:\tlearn: 0.0334118\ttest: 0.0382420\tbest: 0.0382420 (6520)\ttotal: 33m 24s\tremaining: 17m 49s\n",
      "6521:\tlearn: 0.0334118\ttest: 0.0382420\tbest: 0.0382420 (6521)\ttotal: 33m 24s\tremaining: 17m 49s\n",
      "6522:\tlearn: 0.0334118\ttest: 0.0382420\tbest: 0.0382420 (6522)\ttotal: 33m 25s\tremaining: 17m 48s\n",
      "6523:\tlearn: 0.0334118\ttest: 0.0382420\tbest: 0.0382420 (6523)\ttotal: 33m 25s\tremaining: 17m 48s\n",
      "6524:\tlearn: 0.0334118\ttest: 0.0382420\tbest: 0.0382420 (6524)\ttotal: 33m 25s\tremaining: 17m 48s\n",
      "6525:\tlearn: 0.0334063\ttest: 0.0382408\tbest: 0.0382408 (6525)\ttotal: 33m 25s\tremaining: 17m 47s\n",
      "6526:\tlearn: 0.0334063\ttest: 0.0382408\tbest: 0.0382408 (6525)\ttotal: 33m 26s\tremaining: 17m 47s\n",
      "6527:\tlearn: 0.0334063\ttest: 0.0382408\tbest: 0.0382408 (6525)\ttotal: 33m 26s\tremaining: 17m 47s\n",
      "6528:\tlearn: 0.0334063\ttest: 0.0382408\tbest: 0.0382408 (6528)\ttotal: 33m 26s\tremaining: 17m 46s\n",
      "6529:\tlearn: 0.0334063\ttest: 0.0382408\tbest: 0.0382408 (6529)\ttotal: 33m 26s\tremaining: 17m 46s\n",
      "6530:\tlearn: 0.0334063\ttest: 0.0382408\tbest: 0.0382408 (6529)\ttotal: 33m 27s\tremaining: 17m 46s\n",
      "6531:\tlearn: 0.0334063\ttest: 0.0382408\tbest: 0.0382408 (6531)\ttotal: 33m 27s\tremaining: 17m 45s\n",
      "6532:\tlearn: 0.0334063\ttest: 0.0382408\tbest: 0.0382408 (6532)\ttotal: 33m 27s\tremaining: 17m 45s\n",
      "6533:\tlearn: 0.0334063\ttest: 0.0382408\tbest: 0.0382408 (6533)\ttotal: 33m 28s\tremaining: 17m 45s\n",
      "6534:\tlearn: 0.0334063\ttest: 0.0382408\tbest: 0.0382408 (6533)\ttotal: 33m 28s\tremaining: 17m 44s\n",
      "6535:\tlearn: 0.0334063\ttest: 0.0382408\tbest: 0.0382408 (6535)\ttotal: 33m 28s\tremaining: 17m 44s\n",
      "6536:\tlearn: 0.0334063\ttest: 0.0382408\tbest: 0.0382408 (6536)\ttotal: 33m 28s\tremaining: 17m 44s\n",
      "6537:\tlearn: 0.0334063\ttest: 0.0382408\tbest: 0.0382408 (6536)\ttotal: 33m 29s\tremaining: 17m 43s\n",
      "6538:\tlearn: 0.0334063\ttest: 0.0382408\tbest: 0.0382408 (6536)\ttotal: 33m 29s\tremaining: 17m 43s\n",
      "6539:\tlearn: 0.0334063\ttest: 0.0382408\tbest: 0.0382408 (6536)\ttotal: 33m 29s\tremaining: 17m 43s\n",
      "6540:\tlearn: 0.0334026\ttest: 0.0382389\tbest: 0.0382389 (6540)\ttotal: 33m 29s\tremaining: 17m 42s\n",
      "6541:\tlearn: 0.0334025\ttest: 0.0382389\tbest: 0.0382389 (6541)\ttotal: 33m 30s\tremaining: 17m 42s\n",
      "6542:\tlearn: 0.0334025\ttest: 0.0382389\tbest: 0.0382389 (6541)\ttotal: 33m 30s\tremaining: 17m 42s\n",
      "6543:\tlearn: 0.0334025\ttest: 0.0382389\tbest: 0.0382389 (6541)\ttotal: 33m 30s\tremaining: 17m 41s\n",
      "6544:\tlearn: 0.0334025\ttest: 0.0382389\tbest: 0.0382389 (6541)\ttotal: 33m 30s\tremaining: 17m 41s\n",
      "6545:\tlearn: 0.0334025\ttest: 0.0382389\tbest: 0.0382389 (6541)\ttotal: 33m 31s\tremaining: 17m 41s\n",
      "6546:\tlearn: 0.0334025\ttest: 0.0382389\tbest: 0.0382389 (6546)\ttotal: 33m 31s\tremaining: 17m 40s\n",
      "6547:\tlearn: 0.0334025\ttest: 0.0382389\tbest: 0.0382389 (6546)\ttotal: 33m 31s\tremaining: 17m 40s\n",
      "6548:\tlearn: 0.0334025\ttest: 0.0382389\tbest: 0.0382389 (6546)\ttotal: 33m 32s\tremaining: 17m 40s\n",
      "6549:\tlearn: 0.0334025\ttest: 0.0382389\tbest: 0.0382389 (6549)\ttotal: 33m 32s\tremaining: 17m 40s\n",
      "6550:\tlearn: 0.0334023\ttest: 0.0382388\tbest: 0.0382388 (6550)\ttotal: 33m 32s\tremaining: 17m 39s\n",
      "6551:\tlearn: 0.0334023\ttest: 0.0382388\tbest: 0.0382388 (6550)\ttotal: 33m 33s\tremaining: 17m 39s\n",
      "6552:\tlearn: 0.0334023\ttest: 0.0382388\tbest: 0.0382388 (6550)\ttotal: 33m 33s\tremaining: 17m 39s\n",
      "6553:\tlearn: 0.0334023\ttest: 0.0382388\tbest: 0.0382388 (6550)\ttotal: 33m 34s\tremaining: 17m 39s\n",
      "6554:\tlearn: 0.0334023\ttest: 0.0382388\tbest: 0.0382388 (6550)\ttotal: 33m 34s\tremaining: 17m 38s\n",
      "6555:\tlearn: 0.0334023\ttest: 0.0382388\tbest: 0.0382388 (6550)\ttotal: 33m 35s\tremaining: 17m 38s\n",
      "6556:\tlearn: 0.0334023\ttest: 0.0382388\tbest: 0.0382388 (6550)\ttotal: 33m 35s\tremaining: 17m 38s\n",
      "6557:\tlearn: 0.0334023\ttest: 0.0382388\tbest: 0.0382388 (6557)\ttotal: 33m 35s\tremaining: 17m 38s\n",
      "6558:\tlearn: 0.0334023\ttest: 0.0382388\tbest: 0.0382388 (6558)\ttotal: 33m 36s\tremaining: 17m 37s\n",
      "6559:\tlearn: 0.0334023\ttest: 0.0382388\tbest: 0.0382388 (6558)\ttotal: 33m 36s\tremaining: 17m 37s\n",
      "6560:\tlearn: 0.0334023\ttest: 0.0382388\tbest: 0.0382388 (6558)\ttotal: 33m 36s\tremaining: 17m 37s\n",
      "6561:\tlearn: 0.0334023\ttest: 0.0382388\tbest: 0.0382388 (6558)\ttotal: 33m 36s\tremaining: 17m 36s\n",
      "6562:\tlearn: 0.0334022\ttest: 0.0382388\tbest: 0.0382388 (6562)\ttotal: 33m 37s\tremaining: 17m 36s\n",
      "6563:\tlearn: 0.0334023\ttest: 0.0382388\tbest: 0.0382388 (6563)\ttotal: 33m 37s\tremaining: 17m 36s\n",
      "6564:\tlearn: 0.0334023\ttest: 0.0382388\tbest: 0.0382388 (6564)\ttotal: 33m 37s\tremaining: 17m 35s\n",
      "6565:\tlearn: 0.0334023\ttest: 0.0382388\tbest: 0.0382388 (6564)\ttotal: 33m 37s\tremaining: 17m 35s\n",
      "6566:\tlearn: 0.0334022\ttest: 0.0382388\tbest: 0.0382388 (6566)\ttotal: 33m 38s\tremaining: 17m 35s\n",
      "6567:\tlearn: 0.0334022\ttest: 0.0382388\tbest: 0.0382388 (6567)\ttotal: 33m 38s\tremaining: 17m 34s\n",
      "6568:\tlearn: 0.0334022\ttest: 0.0382388\tbest: 0.0382388 (6567)\ttotal: 33m 38s\tremaining: 17m 34s\n",
      "6569:\tlearn: 0.0334022\ttest: 0.0382388\tbest: 0.0382388 (6569)\ttotal: 33m 38s\tremaining: 17m 34s\n",
      "6570:\tlearn: 0.0334022\ttest: 0.0382388\tbest: 0.0382388 (6570)\ttotal: 33m 39s\tremaining: 17m 33s\n",
      "6571:\tlearn: 0.0334022\ttest: 0.0382388\tbest: 0.0382388 (6570)\ttotal: 33m 39s\tremaining: 17m 33s\n",
      "6572:\tlearn: 0.0334022\ttest: 0.0382388\tbest: 0.0382388 (6570)\ttotal: 33m 39s\tremaining: 17m 33s\n",
      "6573:\tlearn: 0.0334022\ttest: 0.0382388\tbest: 0.0382388 (6570)\ttotal: 33m 39s\tremaining: 17m 32s\n",
      "6574:\tlearn: 0.0334022\ttest: 0.0382388\tbest: 0.0382388 (6570)\ttotal: 33m 40s\tremaining: 17m 32s\n",
      "6575:\tlearn: 0.0334022\ttest: 0.0382388\tbest: 0.0382388 (6570)\ttotal: 33m 40s\tremaining: 17m 32s\n",
      "6576:\tlearn: 0.0334022\ttest: 0.0382388\tbest: 0.0382388 (6576)\ttotal: 33m 40s\tremaining: 17m 31s\n",
      "6577:\tlearn: 0.0334022\ttest: 0.0382388\tbest: 0.0382388 (6577)\ttotal: 33m 41s\tremaining: 17m 31s\n",
      "6578:\tlearn: 0.0334022\ttest: 0.0382388\tbest: 0.0382388 (6578)\ttotal: 33m 41s\tremaining: 17m 31s\n",
      "6579:\tlearn: 0.0334022\ttest: 0.0382388\tbest: 0.0382388 (6578)\ttotal: 33m 41s\tremaining: 17m 30s\n",
      "6580:\tlearn: 0.0334021\ttest: 0.0382388\tbest: 0.0382388 (6578)\ttotal: 33m 41s\tremaining: 17m 30s\n",
      "6581:\tlearn: 0.0334021\ttest: 0.0382388\tbest: 0.0382388 (6578)\ttotal: 33m 42s\tremaining: 17m 30s\n",
      "6582:\tlearn: 0.0334021\ttest: 0.0382388\tbest: 0.0382388 (6578)\ttotal: 33m 42s\tremaining: 17m 29s\n",
      "6583:\tlearn: 0.0334021\ttest: 0.0382388\tbest: 0.0382388 (6583)\ttotal: 33m 42s\tremaining: 17m 29s\n",
      "6584:\tlearn: 0.0333986\ttest: 0.0382382\tbest: 0.0382382 (6584)\ttotal: 33m 42s\tremaining: 17m 29s\n",
      "6585:\tlearn: 0.0333986\ttest: 0.0382382\tbest: 0.0382382 (6585)\ttotal: 33m 43s\tremaining: 17m 28s\n",
      "6586:\tlearn: 0.0333986\ttest: 0.0382382\tbest: 0.0382382 (6586)\ttotal: 33m 43s\tremaining: 17m 28s\n",
      "6587:\tlearn: 0.0333986\ttest: 0.0382382\tbest: 0.0382382 (6587)\ttotal: 33m 43s\tremaining: 17m 28s\n",
      "6588:\tlearn: 0.0333986\ttest: 0.0382382\tbest: 0.0382382 (6588)\ttotal: 33m 43s\tremaining: 17m 27s\n",
      "6589:\tlearn: 0.0333986\ttest: 0.0382382\tbest: 0.0382382 (6589)\ttotal: 33m 44s\tremaining: 17m 27s\n",
      "6590:\tlearn: 0.0333986\ttest: 0.0382382\tbest: 0.0382382 (6589)\ttotal: 33m 44s\tremaining: 17m 27s\n",
      "6591:\tlearn: 0.0333986\ttest: 0.0382382\tbest: 0.0382382 (6589)\ttotal: 33m 44s\tremaining: 17m 26s\n",
      "6592:\tlearn: 0.0333986\ttest: 0.0382382\tbest: 0.0382382 (6589)\ttotal: 33m 44s\tremaining: 17m 26s\n",
      "6593:\tlearn: 0.0333986\ttest: 0.0382382\tbest: 0.0382382 (6589)\ttotal: 33m 45s\tremaining: 17m 26s\n",
      "6594:\tlearn: 0.0333984\ttest: 0.0382381\tbest: 0.0382381 (6594)\ttotal: 33m 45s\tremaining: 17m 25s\n",
      "6595:\tlearn: 0.0333950\ttest: 0.0382372\tbest: 0.0382372 (6595)\ttotal: 33m 45s\tremaining: 17m 25s\n",
      "6596:\tlearn: 0.0333950\ttest: 0.0382372\tbest: 0.0382372 (6595)\ttotal: 33m 46s\tremaining: 17m 25s\n",
      "6597:\tlearn: 0.0333950\ttest: 0.0382372\tbest: 0.0382372 (6595)\ttotal: 33m 46s\tremaining: 17m 25s\n",
      "6598:\tlearn: 0.0333950\ttest: 0.0382372\tbest: 0.0382372 (6595)\ttotal: 33m 47s\tremaining: 17m 24s\n",
      "6599:\tlearn: 0.0333950\ttest: 0.0382372\tbest: 0.0382372 (6595)\ttotal: 33m 47s\tremaining: 17m 24s\n",
      "6600:\tlearn: 0.0333950\ttest: 0.0382372\tbest: 0.0382372 (6600)\ttotal: 33m 48s\tremaining: 17m 24s\n",
      "6601:\tlearn: 0.0333950\ttest: 0.0382372\tbest: 0.0382372 (6600)\ttotal: 33m 48s\tremaining: 17m 24s\n",
      "6602:\tlearn: 0.0333950\ttest: 0.0382372\tbest: 0.0382372 (6600)\ttotal: 33m 49s\tremaining: 17m 23s\n",
      "6603:\tlearn: 0.0333950\ttest: 0.0382372\tbest: 0.0382372 (6600)\ttotal: 33m 49s\tremaining: 17m 23s\n",
      "6604:\tlearn: 0.0333950\ttest: 0.0382372\tbest: 0.0382372 (6600)\ttotal: 33m 49s\tremaining: 17m 23s\n",
      "6605:\tlearn: 0.0333911\ttest: 0.0382344\tbest: 0.0382344 (6605)\ttotal: 33m 50s\tremaining: 17m 23s\n",
      "6606:\tlearn: 0.0333911\ttest: 0.0382344\tbest: 0.0382344 (6605)\ttotal: 33m 50s\tremaining: 17m 22s\n",
      "6607:\tlearn: 0.0333911\ttest: 0.0382344\tbest: 0.0382344 (6607)\ttotal: 33m 50s\tremaining: 17m 22s\n",
      "6608:\tlearn: 0.0333911\ttest: 0.0382344\tbest: 0.0382344 (6608)\ttotal: 33m 51s\tremaining: 17m 22s\n",
      "6609:\tlearn: 0.0333911\ttest: 0.0382344\tbest: 0.0382344 (6608)\ttotal: 33m 51s\tremaining: 17m 21s\n",
      "6610:\tlearn: 0.0333872\ttest: 0.0382340\tbest: 0.0382340 (6610)\ttotal: 33m 51s\tremaining: 17m 21s\n",
      "6611:\tlearn: 0.0333872\ttest: 0.0382340\tbest: 0.0382340 (6610)\ttotal: 33m 51s\tremaining: 17m 21s\n",
      "6612:\tlearn: 0.0333872\ttest: 0.0382340\tbest: 0.0382340 (6612)\ttotal: 33m 52s\tremaining: 17m 20s\n",
      "6613:\tlearn: 0.0333872\ttest: 0.0382340\tbest: 0.0382340 (6613)\ttotal: 33m 52s\tremaining: 17m 20s\n",
      "6614:\tlearn: 0.0333872\ttest: 0.0382340\tbest: 0.0382340 (6613)\ttotal: 33m 52s\tremaining: 17m 20s\n",
      "6615:\tlearn: 0.0333872\ttest: 0.0382340\tbest: 0.0382340 (6615)\ttotal: 33m 52s\tremaining: 17m 19s\n",
      "6616:\tlearn: 0.0333872\ttest: 0.0382340\tbest: 0.0382340 (6616)\ttotal: 33m 53s\tremaining: 17m 19s\n",
      "6617:\tlearn: 0.0333849\ttest: 0.0382344\tbest: 0.0382340 (6616)\ttotal: 33m 53s\tremaining: 17m 19s\n",
      "6618:\tlearn: 0.0333849\ttest: 0.0382344\tbest: 0.0382340 (6616)\ttotal: 33m 53s\tremaining: 17m 18s\n",
      "6619:\tlearn: 0.0333849\ttest: 0.0382344\tbest: 0.0382340 (6616)\ttotal: 33m 53s\tremaining: 17m 18s\n",
      "6620:\tlearn: 0.0333849\ttest: 0.0382344\tbest: 0.0382340 (6616)\ttotal: 33m 54s\tremaining: 17m 18s\n",
      "6621:\tlearn: 0.0333824\ttest: 0.0382338\tbest: 0.0382338 (6621)\ttotal: 33m 54s\tremaining: 17m 17s\n",
      "6622:\tlearn: 0.0333824\ttest: 0.0382338\tbest: 0.0382338 (6621)\ttotal: 33m 54s\tremaining: 17m 17s\n",
      "6623:\tlearn: 0.0333824\ttest: 0.0382338\tbest: 0.0382338 (6623)\ttotal: 33m 54s\tremaining: 17m 17s\n",
      "6624:\tlearn: 0.0333824\ttest: 0.0382338\tbest: 0.0382338 (6624)\ttotal: 33m 55s\tremaining: 17m 16s\n",
      "6625:\tlearn: 0.0333824\ttest: 0.0382338\tbest: 0.0382338 (6625)\ttotal: 33m 55s\tremaining: 17m 16s\n",
      "6626:\tlearn: 0.0333824\ttest: 0.0382338\tbest: 0.0382338 (6626)\ttotal: 33m 55s\tremaining: 17m 16s\n",
      "6627:\tlearn: 0.0333824\ttest: 0.0382338\tbest: 0.0382338 (6627)\ttotal: 33m 56s\tremaining: 17m 15s\n",
      "6628:\tlearn: 0.0333808\ttest: 0.0382341\tbest: 0.0382338 (6627)\ttotal: 33m 56s\tremaining: 17m 15s\n",
      "6629:\tlearn: 0.0333808\ttest: 0.0382341\tbest: 0.0382338 (6627)\ttotal: 33m 56s\tremaining: 17m 15s\n",
      "6630:\tlearn: 0.0333771\ttest: 0.0382335\tbest: 0.0382335 (6630)\ttotal: 33m 56s\tremaining: 17m 14s\n",
      "6631:\tlearn: 0.0333771\ttest: 0.0382335\tbest: 0.0382335 (6630)\ttotal: 33m 57s\tremaining: 17m 14s\n",
      "6632:\tlearn: 0.0333771\ttest: 0.0382335\tbest: 0.0382335 (6630)\ttotal: 33m 57s\tremaining: 17m 14s\n",
      "6633:\tlearn: 0.0333771\ttest: 0.0382335\tbest: 0.0382335 (6630)\ttotal: 33m 57s\tremaining: 17m 13s\n",
      "6634:\tlearn: 0.0333771\ttest: 0.0382335\tbest: 0.0382335 (6630)\ttotal: 33m 57s\tremaining: 17m 13s\n",
      "6635:\tlearn: 0.0333771\ttest: 0.0382335\tbest: 0.0382335 (6630)\ttotal: 33m 58s\tremaining: 17m 13s\n",
      "6636:\tlearn: 0.0333771\ttest: 0.0382335\tbest: 0.0382335 (6636)\ttotal: 33m 58s\tremaining: 17m 12s\n",
      "6637:\tlearn: 0.0333771\ttest: 0.0382335\tbest: 0.0382335 (6637)\ttotal: 33m 58s\tremaining: 17m 12s\n",
      "6638:\tlearn: 0.0333734\ttest: 0.0382322\tbest: 0.0382322 (6638)\ttotal: 33m 58s\tremaining: 17m 12s\n",
      "6639:\tlearn: 0.0333734\ttest: 0.0382322\tbest: 0.0382322 (6638)\ttotal: 33m 59s\tremaining: 17m 11s\n",
      "6640:\tlearn: 0.0333734\ttest: 0.0382322\tbest: 0.0382322 (6638)\ttotal: 33m 59s\tremaining: 17m 11s\n",
      "6641:\tlearn: 0.0333734\ttest: 0.0382322\tbest: 0.0382322 (6638)\ttotal: 33m 59s\tremaining: 17m 11s\n",
      "6642:\tlearn: 0.0333734\ttest: 0.0382322\tbest: 0.0382322 (6638)\ttotal: 34m\tremaining: 17m 10s\n",
      "6643:\tlearn: 0.0333734\ttest: 0.0382322\tbest: 0.0382322 (6643)\ttotal: 34m\tremaining: 17m 10s\n",
      "6644:\tlearn: 0.0333734\ttest: 0.0382322\tbest: 0.0382322 (6643)\ttotal: 34m 1s\tremaining: 17m 10s\n",
      "6645:\tlearn: 0.0333734\ttest: 0.0382322\tbest: 0.0382322 (6645)\ttotal: 34m 1s\tremaining: 17m 10s\n",
      "6646:\tlearn: 0.0333734\ttest: 0.0382322\tbest: 0.0382322 (6646)\ttotal: 34m 2s\tremaining: 17m 10s\n",
      "6647:\tlearn: 0.0333734\ttest: 0.0382322\tbest: 0.0382322 (6647)\ttotal: 34m 2s\tremaining: 17m 9s\n",
      "6648:\tlearn: 0.0333734\ttest: 0.0382322\tbest: 0.0382322 (6647)\ttotal: 34m 2s\tremaining: 17m 9s\n",
      "6649:\tlearn: 0.0333734\ttest: 0.0382322\tbest: 0.0382322 (6647)\ttotal: 34m 3s\tremaining: 17m 9s\n",
      "6650:\tlearn: 0.0333734\ttest: 0.0382322\tbest: 0.0382322 (6647)\ttotal: 34m 3s\tremaining: 17m 9s\n",
      "6651:\tlearn: 0.0333718\ttest: 0.0382316\tbest: 0.0382316 (6651)\ttotal: 34m 4s\tremaining: 17m 8s\n",
      "6652:\tlearn: 0.0333718\ttest: 0.0382316\tbest: 0.0382316 (6652)\ttotal: 34m 4s\tremaining: 17m 8s\n",
      "6653:\tlearn: 0.0333718\ttest: 0.0382316\tbest: 0.0382316 (6653)\ttotal: 34m 4s\tremaining: 17m 8s\n",
      "6654:\tlearn: 0.0333718\ttest: 0.0382316\tbest: 0.0382316 (6653)\ttotal: 34m 4s\tremaining: 17m 7s\n",
      "6655:\tlearn: 0.0333717\ttest: 0.0382316\tbest: 0.0382316 (6655)\ttotal: 34m 5s\tremaining: 17m 7s\n",
      "6656:\tlearn: 0.0333717\ttest: 0.0382316\tbest: 0.0382316 (6655)\ttotal: 34m 5s\tremaining: 17m 7s\n",
      "6657:\tlearn: 0.0333717\ttest: 0.0382316\tbest: 0.0382316 (6655)\ttotal: 34m 5s\tremaining: 17m 6s\n",
      "6658:\tlearn: 0.0333717\ttest: 0.0382316\tbest: 0.0382316 (6658)\ttotal: 34m 5s\tremaining: 17m 6s\n",
      "6659:\tlearn: 0.0333717\ttest: 0.0382316\tbest: 0.0382316 (6658)\ttotal: 34m 6s\tremaining: 17m 6s\n",
      "6660:\tlearn: 0.0333717\ttest: 0.0382316\tbest: 0.0382316 (6660)\ttotal: 34m 6s\tremaining: 17m 5s\n",
      "6661:\tlearn: 0.0333717\ttest: 0.0382316\tbest: 0.0382316 (6661)\ttotal: 34m 6s\tremaining: 17m 5s\n",
      "6662:\tlearn: 0.0333717\ttest: 0.0382316\tbest: 0.0382316 (6662)\ttotal: 34m 6s\tremaining: 17m 5s\n",
      "6663:\tlearn: 0.0333717\ttest: 0.0382316\tbest: 0.0382316 (6662)\ttotal: 34m 7s\tremaining: 17m 4s\n",
      "6664:\tlearn: 0.0333717\ttest: 0.0382316\tbest: 0.0382316 (6664)\ttotal: 34m 7s\tremaining: 17m 4s\n",
      "6665:\tlearn: 0.0333717\ttest: 0.0382316\tbest: 0.0382316 (6665)\ttotal: 34m 7s\tremaining: 17m 4s\n",
      "6666:\tlearn: 0.0333717\ttest: 0.0382316\tbest: 0.0382316 (6665)\ttotal: 34m 7s\tremaining: 17m 3s\n",
      "6667:\tlearn: 0.0333717\ttest: 0.0382316\tbest: 0.0382316 (6667)\ttotal: 34m 8s\tremaining: 17m 3s\n",
      "6668:\tlearn: 0.0333717\ttest: 0.0382316\tbest: 0.0382316 (6668)\ttotal: 34m 8s\tremaining: 17m 3s\n",
      "6669:\tlearn: 0.0333717\ttest: 0.0382316\tbest: 0.0382316 (6668)\ttotal: 34m 8s\tremaining: 17m 2s\n",
      "6670:\tlearn: 0.0333716\ttest: 0.0382316\tbest: 0.0382316 (6668)\ttotal: 34m 9s\tremaining: 17m 2s\n",
      "6671:\tlearn: 0.0333716\ttest: 0.0382316\tbest: 0.0382316 (6671)\ttotal: 34m 9s\tremaining: 17m 2s\n",
      "6672:\tlearn: 0.0333716\ttest: 0.0382316\tbest: 0.0382316 (6671)\ttotal: 34m 9s\tremaining: 17m 1s\n",
      "6673:\tlearn: 0.0333716\ttest: 0.0382316\tbest: 0.0382316 (6673)\ttotal: 34m 9s\tremaining: 17m 1s\n",
      "6674:\tlearn: 0.0333716\ttest: 0.0382316\tbest: 0.0382316 (6674)\ttotal: 34m 10s\tremaining: 17m 1s\n",
      "6675:\tlearn: 0.0333716\ttest: 0.0382316\tbest: 0.0382316 (6675)\ttotal: 34m 10s\tremaining: 17m\n",
      "6676:\tlearn: 0.0333716\ttest: 0.0382316\tbest: 0.0382316 (6676)\ttotal: 34m 10s\tremaining: 17m\n",
      "6677:\tlearn: 0.0333687\ttest: 0.0382314\tbest: 0.0382314 (6677)\ttotal: 34m 10s\tremaining: 17m\n",
      "6678:\tlearn: 0.0333687\ttest: 0.0382314\tbest: 0.0382314 (6677)\ttotal: 34m 11s\tremaining: 16m 59s\n",
      "6679:\tlearn: 0.0333687\ttest: 0.0382314\tbest: 0.0382314 (6677)\ttotal: 34m 11s\tremaining: 16m 59s\n",
      "6680:\tlearn: 0.0333687\ttest: 0.0382314\tbest: 0.0382314 (6677)\ttotal: 34m 11s\tremaining: 16m 59s\n",
      "6681:\tlearn: 0.0333687\ttest: 0.0382314\tbest: 0.0382314 (6677)\ttotal: 34m 11s\tremaining: 16m 58s\n",
      "6682:\tlearn: 0.0333638\ttest: 0.0382306\tbest: 0.0382306 (6682)\ttotal: 34m 12s\tremaining: 16m 58s\n",
      "6683:\tlearn: 0.0333638\ttest: 0.0382306\tbest: 0.0382306 (6683)\ttotal: 34m 12s\tremaining: 16m 58s\n",
      "6684:\tlearn: 0.0333599\ttest: 0.0382308\tbest: 0.0382306 (6683)\ttotal: 34m 12s\tremaining: 16m 57s\n",
      "6685:\tlearn: 0.0333599\ttest: 0.0382308\tbest: 0.0382306 (6683)\ttotal: 34m 13s\tremaining: 16m 57s\n",
      "6686:\tlearn: 0.0333599\ttest: 0.0382308\tbest: 0.0382306 (6683)\ttotal: 34m 13s\tremaining: 16m 57s\n",
      "6687:\tlearn: 0.0333599\ttest: 0.0382308\tbest: 0.0382306 (6683)\ttotal: 34m 13s\tremaining: 16m 56s\n",
      "6688:\tlearn: 0.0333567\ttest: 0.0382307\tbest: 0.0382306 (6683)\ttotal: 34m 14s\tremaining: 16m 56s\n",
      "6689:\tlearn: 0.0333567\ttest: 0.0382307\tbest: 0.0382306 (6683)\ttotal: 34m 14s\tremaining: 16m 56s\n",
      "6690:\tlearn: 0.0333567\ttest: 0.0382307\tbest: 0.0382306 (6683)\ttotal: 34m 15s\tremaining: 16m 56s\n",
      "6691:\tlearn: 0.0333567\ttest: 0.0382307\tbest: 0.0382306 (6683)\ttotal: 34m 15s\tremaining: 16m 56s\n",
      "6692:\tlearn: 0.0333544\ttest: 0.0382308\tbest: 0.0382306 (6683)\ttotal: 34m 16s\tremaining: 16m 55s\n",
      "6693:\tlearn: 0.0333544\ttest: 0.0382308\tbest: 0.0382306 (6683)\ttotal: 34m 16s\tremaining: 16m 55s\n",
      "6694:\tlearn: 0.0333544\ttest: 0.0382308\tbest: 0.0382306 (6683)\ttotal: 34m 17s\tremaining: 16m 55s\n",
      "6695:\tlearn: 0.0333544\ttest: 0.0382308\tbest: 0.0382306 (6683)\ttotal: 34m 17s\tremaining: 16m 55s\n",
      "6696:\tlearn: 0.0333544\ttest: 0.0382308\tbest: 0.0382306 (6683)\ttotal: 34m 17s\tremaining: 16m 54s\n",
      "6697:\tlearn: 0.0333544\ttest: 0.0382308\tbest: 0.0382306 (6683)\ttotal: 34m 18s\tremaining: 16m 54s\n",
      "6698:\tlearn: 0.0333544\ttest: 0.0382308\tbest: 0.0382306 (6683)\ttotal: 34m 18s\tremaining: 16m 54s\n",
      "6699:\tlearn: 0.0333544\ttest: 0.0382308\tbest: 0.0382306 (6683)\ttotal: 34m 18s\tremaining: 16m 53s\n",
      "6700:\tlearn: 0.0333544\ttest: 0.0382308\tbest: 0.0382306 (6683)\ttotal: 34m 18s\tremaining: 16m 53s\n",
      "6701:\tlearn: 0.0333543\ttest: 0.0382308\tbest: 0.0382306 (6683)\ttotal: 34m 19s\tremaining: 16m 53s\n",
      "6702:\tlearn: 0.0333543\ttest: 0.0382308\tbest: 0.0382306 (6683)\ttotal: 34m 19s\tremaining: 16m 53s\n",
      "6703:\tlearn: 0.0333543\ttest: 0.0382308\tbest: 0.0382306 (6683)\ttotal: 34m 19s\tremaining: 16m 52s\n",
      "6704:\tlearn: 0.0333542\ttest: 0.0382308\tbest: 0.0382306 (6683)\ttotal: 34m 20s\tremaining: 16m 52s\n",
      "6705:\tlearn: 0.0333542\ttest: 0.0382308\tbest: 0.0382306 (6683)\ttotal: 34m 20s\tremaining: 16m 52s\n",
      "6706:\tlearn: 0.0333542\ttest: 0.0382308\tbest: 0.0382306 (6683)\ttotal: 34m 20s\tremaining: 16m 51s\n",
      "6707:\tlearn: 0.0333542\ttest: 0.0382308\tbest: 0.0382306 (6683)\ttotal: 34m 20s\tremaining: 16m 51s\n",
      "6708:\tlearn: 0.0333542\ttest: 0.0382308\tbest: 0.0382306 (6683)\ttotal: 34m 21s\tremaining: 16m 51s\n",
      "6709:\tlearn: 0.0333542\ttest: 0.0382308\tbest: 0.0382306 (6683)\ttotal: 34m 21s\tremaining: 16m 50s\n",
      "6710:\tlearn: 0.0333542\ttest: 0.0382308\tbest: 0.0382306 (6683)\ttotal: 34m 21s\tremaining: 16m 50s\n",
      "6711:\tlearn: 0.0333542\ttest: 0.0382308\tbest: 0.0382306 (6683)\ttotal: 34m 21s\tremaining: 16m 50s\n",
      "6712:\tlearn: 0.0333521\ttest: 0.0382312\tbest: 0.0382306 (6683)\ttotal: 34m 22s\tremaining: 16m 49s\n",
      "6713:\tlearn: 0.0333521\ttest: 0.0382312\tbest: 0.0382306 (6683)\ttotal: 34m 22s\tremaining: 16m 49s\n",
      "6714:\tlearn: 0.0333462\ttest: 0.0382289\tbest: 0.0382289 (6714)\ttotal: 34m 22s\tremaining: 16m 49s\n",
      "6715:\tlearn: 0.0333462\ttest: 0.0382289\tbest: 0.0382289 (6714)\ttotal: 34m 22s\tremaining: 16m 48s\n",
      "6716:\tlearn: 0.0333462\ttest: 0.0382289\tbest: 0.0382289 (6714)\ttotal: 34m 23s\tremaining: 16m 48s\n",
      "6717:\tlearn: 0.0333462\ttest: 0.0382289\tbest: 0.0382289 (6714)\ttotal: 34m 23s\tremaining: 16m 48s\n",
      "6718:\tlearn: 0.0333462\ttest: 0.0382289\tbest: 0.0382289 (6714)\ttotal: 34m 23s\tremaining: 16m 47s\n",
      "6719:\tlearn: 0.0333439\ttest: 0.0382289\tbest: 0.0382289 (6719)\ttotal: 34m 24s\tremaining: 16m 47s\n",
      "6720:\tlearn: 0.0333439\ttest: 0.0382289\tbest: 0.0382289 (6719)\ttotal: 34m 24s\tremaining: 16m 47s\n",
      "6721:\tlearn: 0.0333439\ttest: 0.0382289\tbest: 0.0382289 (6719)\ttotal: 34m 24s\tremaining: 16m 46s\n",
      "6722:\tlearn: 0.0333439\ttest: 0.0382289\tbest: 0.0382289 (6719)\ttotal: 34m 24s\tremaining: 16m 46s\n",
      "6723:\tlearn: 0.0333439\ttest: 0.0382289\tbest: 0.0382289 (6719)\ttotal: 34m 25s\tremaining: 16m 46s\n",
      "6724:\tlearn: 0.0333439\ttest: 0.0382289\tbest: 0.0382289 (6719)\ttotal: 34m 25s\tremaining: 16m 45s\n",
      "6725:\tlearn: 0.0333439\ttest: 0.0382289\tbest: 0.0382289 (6725)\ttotal: 34m 25s\tremaining: 16m 45s\n",
      "6726:\tlearn: 0.0333439\ttest: 0.0382289\tbest: 0.0382289 (6725)\ttotal: 34m 25s\tremaining: 16m 45s\n",
      "6727:\tlearn: 0.0333439\ttest: 0.0382289\tbest: 0.0382289 (6727)\ttotal: 34m 26s\tremaining: 16m 44s\n",
      "6728:\tlearn: 0.0333439\ttest: 0.0382289\tbest: 0.0382289 (6728)\ttotal: 34m 26s\tremaining: 16m 44s\n",
      "6729:\tlearn: 0.0333439\ttest: 0.0382289\tbest: 0.0382289 (6729)\ttotal: 34m 26s\tremaining: 16m 44s\n",
      "6730:\tlearn: 0.0333439\ttest: 0.0382289\tbest: 0.0382289 (6729)\ttotal: 34m 26s\tremaining: 16m 43s\n",
      "6731:\tlearn: 0.0333439\ttest: 0.0382289\tbest: 0.0382289 (6731)\ttotal: 34m 27s\tremaining: 16m 43s\n",
      "6732:\tlearn: 0.0333425\ttest: 0.0382292\tbest: 0.0382289 (6731)\ttotal: 34m 27s\tremaining: 16m 43s\n",
      "6733:\tlearn: 0.0333425\ttest: 0.0382292\tbest: 0.0382289 (6731)\ttotal: 34m 27s\tremaining: 16m 42s\n",
      "6734:\tlearn: 0.0333398\ttest: 0.0382286\tbest: 0.0382286 (6734)\ttotal: 34m 28s\tremaining: 16m 42s\n",
      "6735:\tlearn: 0.0333398\ttest: 0.0382286\tbest: 0.0382286 (6735)\ttotal: 34m 28s\tremaining: 16m 42s\n",
      "6736:\tlearn: 0.0333398\ttest: 0.0382286\tbest: 0.0382286 (6736)\ttotal: 34m 28s\tremaining: 16m 42s\n",
      "6737:\tlearn: 0.0333398\ttest: 0.0382286\tbest: 0.0382286 (6736)\ttotal: 34m 29s\tremaining: 16m 41s\n",
      "6738:\tlearn: 0.0333398\ttest: 0.0382286\tbest: 0.0382286 (6738)\ttotal: 34m 29s\tremaining: 16m 41s\n",
      "6739:\tlearn: 0.0333398\ttest: 0.0382286\tbest: 0.0382286 (6738)\ttotal: 34m 30s\tremaining: 16m 41s\n",
      "6740:\tlearn: 0.0333398\ttest: 0.0382286\tbest: 0.0382286 (6740)\ttotal: 34m 30s\tremaining: 16m 41s\n",
      "6741:\tlearn: 0.0333398\ttest: 0.0382286\tbest: 0.0382286 (6741)\ttotal: 34m 31s\tremaining: 16m 40s\n",
      "6742:\tlearn: 0.0333398\ttest: 0.0382286\tbest: 0.0382286 (6741)\ttotal: 34m 31s\tremaining: 16m 40s\n",
      "6743:\tlearn: 0.0333398\ttest: 0.0382286\tbest: 0.0382286 (6743)\ttotal: 34m 32s\tremaining: 16m 40s\n",
      "6744:\tlearn: 0.0333398\ttest: 0.0382286\tbest: 0.0382286 (6744)\ttotal: 34m 32s\tremaining: 16m 40s\n",
      "6745:\tlearn: 0.0333398\ttest: 0.0382286\tbest: 0.0382286 (6745)\ttotal: 34m 32s\tremaining: 16m 39s\n",
      "6746:\tlearn: 0.0333380\ttest: 0.0382281\tbest: 0.0382281 (6746)\ttotal: 34m 32s\tremaining: 16m 39s\n",
      "6747:\tlearn: 0.0333380\ttest: 0.0382281\tbest: 0.0382281 (6747)\ttotal: 34m 33s\tremaining: 16m 39s\n",
      "6748:\tlearn: 0.0333380\ttest: 0.0382281\tbest: 0.0382281 (6748)\ttotal: 34m 33s\tremaining: 16m 38s\n",
      "6749:\tlearn: 0.0333380\ttest: 0.0382281\tbest: 0.0382281 (6748)\ttotal: 34m 33s\tremaining: 16m 38s\n",
      "6750:\tlearn: 0.0333380\ttest: 0.0382281\tbest: 0.0382281 (6748)\ttotal: 34m 33s\tremaining: 16m 38s\n",
      "6751:\tlearn: 0.0333379\ttest: 0.0382281\tbest: 0.0382281 (6751)\ttotal: 34m 34s\tremaining: 16m 37s\n",
      "6752:\tlearn: 0.0333379\ttest: 0.0382281\tbest: 0.0382281 (6751)\ttotal: 34m 34s\tremaining: 16m 37s\n",
      "6753:\tlearn: 0.0333379\ttest: 0.0382281\tbest: 0.0382281 (6753)\ttotal: 34m 34s\tremaining: 16m 37s\n",
      "6754:\tlearn: 0.0333379\ttest: 0.0382281\tbest: 0.0382281 (6754)\ttotal: 34m 34s\tremaining: 16m 36s\n",
      "6755:\tlearn: 0.0333379\ttest: 0.0382281\tbest: 0.0382281 (6755)\ttotal: 34m 35s\tremaining: 16m 36s\n",
      "6756:\tlearn: 0.0333379\ttest: 0.0382281\tbest: 0.0382281 (6755)\ttotal: 34m 35s\tremaining: 16m 36s\n",
      "6757:\tlearn: 0.0333379\ttest: 0.0382281\tbest: 0.0382281 (6755)\ttotal: 34m 35s\tremaining: 16m 35s\n",
      "6758:\tlearn: 0.0333379\ttest: 0.0382281\tbest: 0.0382281 (6758)\ttotal: 34m 35s\tremaining: 16m 35s\n",
      "6759:\tlearn: 0.0333379\ttest: 0.0382281\tbest: 0.0382281 (6759)\ttotal: 34m 36s\tremaining: 16m 35s\n",
      "6760:\tlearn: 0.0333379\ttest: 0.0382281\tbest: 0.0382281 (6759)\ttotal: 34m 36s\tremaining: 16m 34s\n",
      "6761:\tlearn: 0.0333379\ttest: 0.0382281\tbest: 0.0382281 (6759)\ttotal: 34m 36s\tremaining: 16m 34s\n",
      "6762:\tlearn: 0.0333379\ttest: 0.0382281\tbest: 0.0382281 (6759)\ttotal: 34m 36s\tremaining: 16m 34s\n",
      "6763:\tlearn: 0.0333379\ttest: 0.0382281\tbest: 0.0382281 (6763)\ttotal: 34m 37s\tremaining: 16m 33s\n",
      "6764:\tlearn: 0.0333378\ttest: 0.0382281\tbest: 0.0382281 (6764)\ttotal: 34m 37s\tremaining: 16m 33s\n",
      "6765:\tlearn: 0.0333342\ttest: 0.0382263\tbest: 0.0382263 (6765)\ttotal: 34m 37s\tremaining: 16m 33s\n",
      "6766:\tlearn: 0.0333303\ttest: 0.0382258\tbest: 0.0382258 (6766)\ttotal: 34m 38s\tremaining: 16m 32s\n",
      "6767:\tlearn: 0.0333303\ttest: 0.0382258\tbest: 0.0382258 (6767)\ttotal: 34m 38s\tremaining: 16m 32s\n",
      "6768:\tlearn: 0.0333303\ttest: 0.0382258\tbest: 0.0382258 (6767)\ttotal: 34m 38s\tremaining: 16m 32s\n",
      "6769:\tlearn: 0.0333303\ttest: 0.0382258\tbest: 0.0382258 (6769)\ttotal: 34m 38s\tremaining: 16m 31s\n",
      "6770:\tlearn: 0.0333303\ttest: 0.0382258\tbest: 0.0382258 (6769)\ttotal: 34m 39s\tremaining: 16m 31s\n",
      "6771:\tlearn: 0.0333303\ttest: 0.0382258\tbest: 0.0382258 (6769)\ttotal: 34m 39s\tremaining: 16m 31s\n",
      "6772:\tlearn: 0.0333303\ttest: 0.0382258\tbest: 0.0382258 (6769)\ttotal: 34m 39s\tremaining: 16m 30s\n",
      "6773:\tlearn: 0.0333303\ttest: 0.0382258\tbest: 0.0382258 (6769)\ttotal: 34m 39s\tremaining: 16m 30s\n",
      "6774:\tlearn: 0.0333303\ttest: 0.0382258\tbest: 0.0382258 (6769)\ttotal: 34m 40s\tremaining: 16m 30s\n",
      "6775:\tlearn: 0.0333291\ttest: 0.0382254\tbest: 0.0382254 (6775)\ttotal: 34m 40s\tremaining: 16m 29s\n",
      "6776:\tlearn: 0.0333291\ttest: 0.0382254\tbest: 0.0382254 (6776)\ttotal: 34m 40s\tremaining: 16m 29s\n",
      "6777:\tlearn: 0.0333291\ttest: 0.0382254\tbest: 0.0382254 (6776)\ttotal: 34m 40s\tremaining: 16m 29s\n",
      "6778:\tlearn: 0.0333291\ttest: 0.0382254\tbest: 0.0382254 (6776)\ttotal: 34m 41s\tremaining: 16m 28s\n",
      "6779:\tlearn: 0.0333290\ttest: 0.0382254\tbest: 0.0382254 (6779)\ttotal: 34m 41s\tremaining: 16m 28s\n",
      "6780:\tlearn: 0.0333290\ttest: 0.0382254\tbest: 0.0382254 (6780)\ttotal: 34m 41s\tremaining: 16m 28s\n",
      "6781:\tlearn: 0.0333252\ttest: 0.0382254\tbest: 0.0382254 (6781)\ttotal: 34m 42s\tremaining: 16m 27s\n",
      "6782:\tlearn: 0.0333252\ttest: 0.0382254\tbest: 0.0382254 (6781)\ttotal: 34m 42s\tremaining: 16m 27s\n",
      "6783:\tlearn: 0.0333252\ttest: 0.0382254\tbest: 0.0382254 (6783)\ttotal: 34m 43s\tremaining: 16m 27s\n",
      "6784:\tlearn: 0.0333233\ttest: 0.0382251\tbest: 0.0382251 (6784)\ttotal: 34m 43s\tremaining: 16m 27s\n",
      "6785:\tlearn: 0.0333233\ttest: 0.0382251\tbest: 0.0382251 (6784)\ttotal: 34m 44s\tremaining: 16m 27s\n",
      "6786:\tlearn: 0.0333233\ttest: 0.0382251\tbest: 0.0382251 (6786)\ttotal: 34m 44s\tremaining: 16m 26s\n",
      "6787:\tlearn: 0.0333233\ttest: 0.0382251\tbest: 0.0382251 (6786)\ttotal: 34m 44s\tremaining: 16m 26s\n",
      "6788:\tlearn: 0.0333233\ttest: 0.0382251\tbest: 0.0382251 (6788)\ttotal: 34m 45s\tremaining: 16m 26s\n",
      "6789:\tlearn: 0.0333233\ttest: 0.0382250\tbest: 0.0382250 (6789)\ttotal: 34m 45s\tremaining: 16m 26s\n",
      "6790:\tlearn: 0.0333233\ttest: 0.0382250\tbest: 0.0382250 (6790)\ttotal: 34m 46s\tremaining: 16m 25s\n",
      "6791:\tlearn: 0.0333233\ttest: 0.0382250\tbest: 0.0382250 (6791)\ttotal: 34m 46s\tremaining: 16m 25s\n",
      "6792:\tlearn: 0.0333233\ttest: 0.0382250\tbest: 0.0382250 (6792)\ttotal: 34m 46s\tremaining: 16m 25s\n",
      "6793:\tlearn: 0.0333233\ttest: 0.0382250\tbest: 0.0382250 (6792)\ttotal: 34m 47s\tremaining: 16m 24s\n",
      "6794:\tlearn: 0.0333233\ttest: 0.0382250\tbest: 0.0382250 (6792)\ttotal: 34m 47s\tremaining: 16m 24s\n",
      "6795:\tlearn: 0.0333233\ttest: 0.0382250\tbest: 0.0382250 (6792)\ttotal: 34m 47s\tremaining: 16m 24s\n",
      "6796:\tlearn: 0.0333233\ttest: 0.0382250\tbest: 0.0382250 (6792)\ttotal: 34m 47s\tremaining: 16m 23s\n",
      "6797:\tlearn: 0.0333233\ttest: 0.0382250\tbest: 0.0382250 (6792)\ttotal: 34m 48s\tremaining: 16m 23s\n",
      "6798:\tlearn: 0.0333233\ttest: 0.0382250\tbest: 0.0382250 (6798)\ttotal: 34m 48s\tremaining: 16m 23s\n",
      "6799:\tlearn: 0.0333233\ttest: 0.0382250\tbest: 0.0382250 (6798)\ttotal: 34m 48s\tremaining: 16m 22s\n",
      "6800:\tlearn: 0.0333233\ttest: 0.0382250\tbest: 0.0382250 (6800)\ttotal: 34m 48s\tremaining: 16m 22s\n",
      "6801:\tlearn: 0.0333231\ttest: 0.0382250\tbest: 0.0382250 (6801)\ttotal: 34m 49s\tremaining: 16m 22s\n",
      "6802:\tlearn: 0.0333201\ttest: 0.0382255\tbest: 0.0382250 (6801)\ttotal: 34m 49s\tremaining: 16m 21s\n",
      "6803:\tlearn: 0.0333201\ttest: 0.0382255\tbest: 0.0382250 (6801)\ttotal: 34m 49s\tremaining: 16m 21s\n",
      "6804:\tlearn: 0.0333201\ttest: 0.0382255\tbest: 0.0382250 (6801)\ttotal: 34m 49s\tremaining: 16m 21s\n",
      "6805:\tlearn: 0.0333201\ttest: 0.0382255\tbest: 0.0382250 (6801)\ttotal: 34m 50s\tremaining: 16m 20s\n",
      "6806:\tlearn: 0.0333201\ttest: 0.0382255\tbest: 0.0382250 (6801)\ttotal: 34m 50s\tremaining: 16m 20s\n",
      "6807:\tlearn: 0.0333201\ttest: 0.0382255\tbest: 0.0382250 (6801)\ttotal: 34m 50s\tremaining: 16m 20s\n",
      "6808:\tlearn: 0.0333201\ttest: 0.0382255\tbest: 0.0382250 (6801)\ttotal: 34m 50s\tremaining: 16m 19s\n",
      "6809:\tlearn: 0.0333201\ttest: 0.0382255\tbest: 0.0382250 (6801)\ttotal: 34m 51s\tremaining: 16m 19s\n",
      "6810:\tlearn: 0.0333201\ttest: 0.0382255\tbest: 0.0382250 (6801)\ttotal: 34m 51s\tremaining: 16m 19s\n",
      "6811:\tlearn: 0.0333201\ttest: 0.0382255\tbest: 0.0382250 (6801)\ttotal: 34m 51s\tremaining: 16m 18s\n",
      "6812:\tlearn: 0.0333201\ttest: 0.0382255\tbest: 0.0382250 (6801)\ttotal: 34m 52s\tremaining: 16m 18s\n",
      "6813:\tlearn: 0.0333200\ttest: 0.0382255\tbest: 0.0382250 (6801)\ttotal: 34m 52s\tremaining: 16m 18s\n",
      "6814:\tlearn: 0.0333200\ttest: 0.0382255\tbest: 0.0382250 (6801)\ttotal: 34m 52s\tremaining: 16m 17s\n",
      "6815:\tlearn: 0.0333200\ttest: 0.0382255\tbest: 0.0382250 (6801)\ttotal: 34m 52s\tremaining: 16m 17s\n",
      "6816:\tlearn: 0.0333200\ttest: 0.0382255\tbest: 0.0382250 (6801)\ttotal: 34m 53s\tremaining: 16m 17s\n",
      "6817:\tlearn: 0.0333200\ttest: 0.0382255\tbest: 0.0382250 (6801)\ttotal: 34m 53s\tremaining: 16m 16s\n",
      "6818:\tlearn: 0.0333200\ttest: 0.0382255\tbest: 0.0382250 (6801)\ttotal: 34m 53s\tremaining: 16m 16s\n",
      "6819:\tlearn: 0.0333200\ttest: 0.0382255\tbest: 0.0382250 (6801)\ttotal: 34m 53s\tremaining: 16m 16s\n",
      "6820:\tlearn: 0.0333200\ttest: 0.0382255\tbest: 0.0382250 (6801)\ttotal: 34m 54s\tremaining: 16m 15s\n",
      "6821:\tlearn: 0.0333200\ttest: 0.0382255\tbest: 0.0382250 (6801)\ttotal: 34m 54s\tremaining: 16m 15s\n",
      "6822:\tlearn: 0.0333200\ttest: 0.0382255\tbest: 0.0382250 (6801)\ttotal: 34m 54s\tremaining: 16m 15s\n",
      "6823:\tlearn: 0.0333200\ttest: 0.0382255\tbest: 0.0382250 (6801)\ttotal: 34m 54s\tremaining: 16m 14s\n",
      "6824:\tlearn: 0.0333200\ttest: 0.0382255\tbest: 0.0382250 (6801)\ttotal: 34m 54s\tremaining: 16m 14s\n",
      "6825:\tlearn: 0.0333200\ttest: 0.0382255\tbest: 0.0382250 (6801)\ttotal: 34m 55s\tremaining: 16m 14s\n",
      "6826:\tlearn: 0.0333200\ttest: 0.0382255\tbest: 0.0382250 (6801)\ttotal: 34m 55s\tremaining: 16m 13s\n",
      "6827:\tlearn: 0.0333200\ttest: 0.0382255\tbest: 0.0382250 (6801)\ttotal: 34m 55s\tremaining: 16m 13s\n",
      "6828:\tlearn: 0.0333200\ttest: 0.0382255\tbest: 0.0382250 (6801)\ttotal: 34m 55s\tremaining: 16m 13s\n",
      "6829:\tlearn: 0.0333200\ttest: 0.0382255\tbest: 0.0382250 (6801)\ttotal: 34m 56s\tremaining: 16m 12s\n",
      "6830:\tlearn: 0.0333200\ttest: 0.0382255\tbest: 0.0382250 (6801)\ttotal: 34m 56s\tremaining: 16m 12s\n",
      "6831:\tlearn: 0.0333200\ttest: 0.0382255\tbest: 0.0382250 (6801)\ttotal: 34m 57s\tremaining: 16m 12s\n",
      "6832:\tlearn: 0.0333176\ttest: 0.0382249\tbest: 0.0382249 (6832)\ttotal: 34m 57s\tremaining: 16m 12s\n",
      "6833:\tlearn: 0.0333176\ttest: 0.0382249\tbest: 0.0382249 (6833)\ttotal: 34m 58s\tremaining: 16m 12s\n",
      "6834:\tlearn: 0.0333176\ttest: 0.0382249\tbest: 0.0382249 (6833)\ttotal: 34m 58s\tremaining: 16m 11s\n",
      "6835:\tlearn: 0.0333175\ttest: 0.0382249\tbest: 0.0382249 (6835)\ttotal: 34m 59s\tremaining: 16m 11s\n",
      "6836:\tlearn: 0.0333175\ttest: 0.0382249\tbest: 0.0382249 (6835)\ttotal: 34m 59s\tremaining: 16m 11s\n",
      "6837:\tlearn: 0.0333143\ttest: 0.0382250\tbest: 0.0382249 (6835)\ttotal: 35m\tremaining: 16m 11s\n",
      "6838:\tlearn: 0.0333143\ttest: 0.0382250\tbest: 0.0382249 (6835)\ttotal: 35m\tremaining: 16m 10s\n",
      "6839:\tlearn: 0.0333117\ttest: 0.0382246\tbest: 0.0382246 (6839)\ttotal: 35m\tremaining: 16m 10s\n",
      "6840:\tlearn: 0.0333117\ttest: 0.0382246\tbest: 0.0382246 (6839)\ttotal: 35m 1s\tremaining: 16m 10s\n",
      "6841:\tlearn: 0.0333117\ttest: 0.0382246\tbest: 0.0382246 (6839)\ttotal: 35m 1s\tremaining: 16m 10s\n",
      "6842:\tlearn: 0.0333117\ttest: 0.0382246\tbest: 0.0382246 (6842)\ttotal: 35m 2s\tremaining: 16m 9s\n",
      "6843:\tlearn: 0.0333117\ttest: 0.0382246\tbest: 0.0382246 (6843)\ttotal: 35m 2s\tremaining: 16m 9s\n",
      "6844:\tlearn: 0.0333117\ttest: 0.0382246\tbest: 0.0382246 (6844)\ttotal: 35m 3s\tremaining: 16m 9s\n",
      "6845:\tlearn: 0.0333117\ttest: 0.0382246\tbest: 0.0382246 (6844)\ttotal: 35m 3s\tremaining: 16m 9s\n",
      "6846:\tlearn: 0.0333117\ttest: 0.0382246\tbest: 0.0382246 (6844)\ttotal: 35m 3s\tremaining: 16m 8s\n",
      "6847:\tlearn: 0.0333117\ttest: 0.0382246\tbest: 0.0382246 (6844)\ttotal: 35m 4s\tremaining: 16m 8s\n",
      "6848:\tlearn: 0.0333117\ttest: 0.0382246\tbest: 0.0382246 (6844)\ttotal: 35m 4s\tremaining: 16m 8s\n",
      "6849:\tlearn: 0.0333117\ttest: 0.0382246\tbest: 0.0382246 (6844)\ttotal: 35m 5s\tremaining: 16m 8s\n",
      "6850:\tlearn: 0.0333117\ttest: 0.0382246\tbest: 0.0382246 (6844)\ttotal: 35m 5s\tremaining: 16m 7s\n",
      "6851:\tlearn: 0.0333117\ttest: 0.0382246\tbest: 0.0382246 (6851)\ttotal: 35m 5s\tremaining: 16m 7s\n",
      "6852:\tlearn: 0.0333117\ttest: 0.0382246\tbest: 0.0382246 (6852)\ttotal: 35m 5s\tremaining: 16m 7s\n",
      "6853:\tlearn: 0.0333117\ttest: 0.0382246\tbest: 0.0382246 (6853)\ttotal: 35m 6s\tremaining: 16m 6s\n",
      "6854:\tlearn: 0.0333117\ttest: 0.0382246\tbest: 0.0382246 (6853)\ttotal: 35m 6s\tremaining: 16m 6s\n",
      "6855:\tlearn: 0.0333117\ttest: 0.0382246\tbest: 0.0382246 (6853)\ttotal: 35m 6s\tremaining: 16m 6s\n",
      "6856:\tlearn: 0.0333117\ttest: 0.0382246\tbest: 0.0382246 (6853)\ttotal: 35m 6s\tremaining: 16m 5s\n",
      "6857:\tlearn: 0.0333117\ttest: 0.0382246\tbest: 0.0382246 (6853)\ttotal: 35m 7s\tremaining: 16m 5s\n",
      "6858:\tlearn: 0.0333117\ttest: 0.0382246\tbest: 0.0382246 (6853)\ttotal: 35m 7s\tremaining: 16m 5s\n",
      "6859:\tlearn: 0.0333117\ttest: 0.0382246\tbest: 0.0382246 (6853)\ttotal: 35m 7s\tremaining: 16m 4s\n",
      "6860:\tlearn: 0.0333117\ttest: 0.0382246\tbest: 0.0382246 (6853)\ttotal: 35m 7s\tremaining: 16m 4s\n",
      "6861:\tlearn: 0.0333117\ttest: 0.0382246\tbest: 0.0382246 (6853)\ttotal: 35m 8s\tremaining: 16m 4s\n",
      "6862:\tlearn: 0.0333117\ttest: 0.0382246\tbest: 0.0382246 (6853)\ttotal: 35m 8s\tremaining: 16m 3s\n",
      "6863:\tlearn: 0.0333116\ttest: 0.0382246\tbest: 0.0382246 (6853)\ttotal: 35m 8s\tremaining: 16m 3s\n",
      "6864:\tlearn: 0.0333116\ttest: 0.0382246\tbest: 0.0382246 (6853)\ttotal: 35m 8s\tremaining: 16m 3s\n",
      "6865:\tlearn: 0.0333116\ttest: 0.0382246\tbest: 0.0382246 (6853)\ttotal: 35m 9s\tremaining: 16m 2s\n",
      "6866:\tlearn: 0.0333077\ttest: 0.0382249\tbest: 0.0382246 (6853)\ttotal: 35m 9s\tremaining: 16m 2s\n",
      "6867:\tlearn: 0.0333077\ttest: 0.0382249\tbest: 0.0382246 (6853)\ttotal: 35m 9s\tremaining: 16m 2s\n",
      "6868:\tlearn: 0.0333077\ttest: 0.0382249\tbest: 0.0382246 (6853)\ttotal: 35m 10s\tremaining: 16m 1s\n",
      "6869:\tlearn: 0.0333077\ttest: 0.0382249\tbest: 0.0382246 (6853)\ttotal: 35m 10s\tremaining: 16m 1s\n",
      "6870:\tlearn: 0.0333077\ttest: 0.0382249\tbest: 0.0382246 (6853)\ttotal: 35m 10s\tremaining: 16m 1s\n",
      "6871:\tlearn: 0.0333031\ttest: 0.0382234\tbest: 0.0382234 (6871)\ttotal: 35m 11s\tremaining: 16m 1s\n",
      "6872:\tlearn: 0.0333031\ttest: 0.0382234\tbest: 0.0382234 (6872)\ttotal: 35m 11s\tremaining: 16m\n",
      "6873:\tlearn: 0.0333031\ttest: 0.0382234\tbest: 0.0382234 (6873)\ttotal: 35m 12s\tremaining: 16m\n",
      "6874:\tlearn: 0.0333031\ttest: 0.0382234\tbest: 0.0382234 (6873)\ttotal: 35m 12s\tremaining: 16m\n",
      "6875:\tlearn: 0.0333031\ttest: 0.0382234\tbest: 0.0382234 (6873)\ttotal: 35m 12s\tremaining: 15m 59s\n",
      "6876:\tlearn: 0.0333031\ttest: 0.0382234\tbest: 0.0382234 (6873)\ttotal: 35m 13s\tremaining: 15m 59s\n",
      "6877:\tlearn: 0.0333031\ttest: 0.0382234\tbest: 0.0382234 (6873)\ttotal: 35m 13s\tremaining: 15m 59s\n",
      "6878:\tlearn: 0.0333031\ttest: 0.0382234\tbest: 0.0382234 (6873)\ttotal: 35m 14s\tremaining: 15m 59s\n",
      "6879:\tlearn: 0.0333031\ttest: 0.0382234\tbest: 0.0382234 (6873)\ttotal: 35m 14s\tremaining: 15m 58s\n",
      "6880:\tlearn: 0.0333031\ttest: 0.0382234\tbest: 0.0382234 (6880)\ttotal: 35m 14s\tremaining: 15m 58s\n",
      "6881:\tlearn: 0.0333031\ttest: 0.0382234\tbest: 0.0382234 (6881)\ttotal: 35m 15s\tremaining: 15m 58s\n",
      "6882:\tlearn: 0.0333031\ttest: 0.0382234\tbest: 0.0382234 (6882)\ttotal: 35m 15s\tremaining: 15m 57s\n",
      "6883:\tlearn: 0.0333031\ttest: 0.0382234\tbest: 0.0382234 (6883)\ttotal: 35m 15s\tremaining: 15m 57s\n",
      "6884:\tlearn: 0.0333031\ttest: 0.0382234\tbest: 0.0382234 (6883)\ttotal: 35m 15s\tremaining: 15m 57s\n",
      "6885:\tlearn: 0.0333031\ttest: 0.0382234\tbest: 0.0382234 (6885)\ttotal: 35m 16s\tremaining: 15m 56s\n",
      "6886:\tlearn: 0.0333031\ttest: 0.0382234\tbest: 0.0382234 (6886)\ttotal: 35m 16s\tremaining: 15m 56s\n",
      "6887:\tlearn: 0.0333030\ttest: 0.0382234\tbest: 0.0382234 (6887)\ttotal: 35m 16s\tremaining: 15m 56s\n",
      "6888:\tlearn: 0.0333030\ttest: 0.0382234\tbest: 0.0382234 (6887)\ttotal: 35m 16s\tremaining: 15m 55s\n",
      "6889:\tlearn: 0.0333030\ttest: 0.0382234\tbest: 0.0382234 (6887)\ttotal: 35m 17s\tremaining: 15m 55s\n",
      "6890:\tlearn: 0.0333030\ttest: 0.0382234\tbest: 0.0382234 (6887)\ttotal: 35m 17s\tremaining: 15m 55s\n",
      "6891:\tlearn: 0.0333030\ttest: 0.0382234\tbest: 0.0382234 (6887)\ttotal: 35m 17s\tremaining: 15m 54s\n",
      "6892:\tlearn: 0.0333030\ttest: 0.0382234\tbest: 0.0382234 (6887)\ttotal: 35m 17s\tremaining: 15m 54s\n",
      "6893:\tlearn: 0.0332974\ttest: 0.0382218\tbest: 0.0382218 (6893)\ttotal: 35m 18s\tremaining: 15m 54s\n",
      "6894:\tlearn: 0.0332974\ttest: 0.0382218\tbest: 0.0382218 (6894)\ttotal: 35m 18s\tremaining: 15m 54s\n",
      "6895:\tlearn: 0.0332974\ttest: 0.0382218\tbest: 0.0382218 (6894)\ttotal: 35m 18s\tremaining: 15m 53s\n",
      "6896:\tlearn: 0.0332974\ttest: 0.0382218\tbest: 0.0382218 (6896)\ttotal: 35m 19s\tremaining: 15m 53s\n",
      "6897:\tlearn: 0.0332974\ttest: 0.0382218\tbest: 0.0382218 (6897)\ttotal: 35m 19s\tremaining: 15m 53s\n",
      "6898:\tlearn: 0.0332974\ttest: 0.0382218\tbest: 0.0382218 (6898)\ttotal: 35m 19s\tremaining: 15m 52s\n",
      "6899:\tlearn: 0.0332974\ttest: 0.0382218\tbest: 0.0382218 (6899)\ttotal: 35m 19s\tremaining: 15m 52s\n",
      "6900:\tlearn: 0.0332974\ttest: 0.0382218\tbest: 0.0382218 (6899)\ttotal: 35m 20s\tremaining: 15m 52s\n",
      "6901:\tlearn: 0.0332957\ttest: 0.0382221\tbest: 0.0382218 (6899)\ttotal: 35m 20s\tremaining: 15m 51s\n",
      "6902:\tlearn: 0.0332957\ttest: 0.0382221\tbest: 0.0382218 (6899)\ttotal: 35m 20s\tremaining: 15m 51s\n",
      "6903:\tlearn: 0.0332957\ttest: 0.0382221\tbest: 0.0382218 (6899)\ttotal: 35m 20s\tremaining: 15m 51s\n",
      "6904:\tlearn: 0.0332957\ttest: 0.0382221\tbest: 0.0382218 (6899)\ttotal: 35m 21s\tremaining: 15m 50s\n",
      "6905:\tlearn: 0.0332957\ttest: 0.0382221\tbest: 0.0382218 (6899)\ttotal: 35m 21s\tremaining: 15m 50s\n",
      "6906:\tlearn: 0.0332956\ttest: 0.0382222\tbest: 0.0382218 (6899)\ttotal: 35m 21s\tremaining: 15m 50s\n",
      "6907:\tlearn: 0.0332956\ttest: 0.0382222\tbest: 0.0382218 (6899)\ttotal: 35m 21s\tremaining: 15m 49s\n",
      "6908:\tlearn: 0.0332956\ttest: 0.0382222\tbest: 0.0382218 (6899)\ttotal: 35m 22s\tremaining: 15m 49s\n",
      "6909:\tlearn: 0.0332908\ttest: 0.0382220\tbest: 0.0382218 (6899)\ttotal: 35m 22s\tremaining: 15m 49s\n",
      "6910:\tlearn: 0.0332908\ttest: 0.0382220\tbest: 0.0382218 (6899)\ttotal: 35m 22s\tremaining: 15m 48s\n",
      "6911:\tlearn: 0.0332908\ttest: 0.0382220\tbest: 0.0382218 (6899)\ttotal: 35m 22s\tremaining: 15m 48s\n",
      "6912:\tlearn: 0.0332908\ttest: 0.0382220\tbest: 0.0382218 (6899)\ttotal: 35m 23s\tremaining: 15m 48s\n",
      "6913:\tlearn: 0.0332908\ttest: 0.0382220\tbest: 0.0382218 (6899)\ttotal: 35m 23s\tremaining: 15m 47s\n",
      "6914:\tlearn: 0.0332908\ttest: 0.0382220\tbest: 0.0382218 (6899)\ttotal: 35m 23s\tremaining: 15m 47s\n",
      "6915:\tlearn: 0.0332908\ttest: 0.0382220\tbest: 0.0382218 (6899)\ttotal: 35m 24s\tremaining: 15m 47s\n",
      "6916:\tlearn: 0.0332908\ttest: 0.0382220\tbest: 0.0382218 (6899)\ttotal: 35m 24s\tremaining: 15m 46s\n",
      "6917:\tlearn: 0.0332908\ttest: 0.0382220\tbest: 0.0382218 (6899)\ttotal: 35m 24s\tremaining: 15m 46s\n",
      "6918:\tlearn: 0.0332908\ttest: 0.0382220\tbest: 0.0382218 (6899)\ttotal: 35m 25s\tremaining: 15m 46s\n",
      "6919:\tlearn: 0.0332908\ttest: 0.0382220\tbest: 0.0382218 (6899)\ttotal: 35m 25s\tremaining: 15m 46s\n",
      "6920:\tlearn: 0.0332908\ttest: 0.0382220\tbest: 0.0382218 (6899)\ttotal: 35m 25s\tremaining: 15m 45s\n",
      "6921:\tlearn: 0.0332908\ttest: 0.0382220\tbest: 0.0382218 (6899)\ttotal: 35m 26s\tremaining: 15m 45s\n",
      "6922:\tlearn: 0.0332889\ttest: 0.0382215\tbest: 0.0382215 (6922)\ttotal: 35m 26s\tremaining: 15m 45s\n",
      "6923:\tlearn: 0.0332889\ttest: 0.0382215\tbest: 0.0382215 (6923)\ttotal: 35m 27s\tremaining: 15m 45s\n",
      "6924:\tlearn: 0.0332889\ttest: 0.0382215\tbest: 0.0382215 (6924)\ttotal: 35m 27s\tremaining: 15m 44s\n",
      "6925:\tlearn: 0.0332889\ttest: 0.0382215\tbest: 0.0382215 (6924)\ttotal: 35m 28s\tremaining: 15m 44s\n",
      "6926:\tlearn: 0.0332889\ttest: 0.0382215\tbest: 0.0382215 (6924)\ttotal: 35m 28s\tremaining: 15m 44s\n",
      "6927:\tlearn: 0.0332889\ttest: 0.0382215\tbest: 0.0382215 (6927)\ttotal: 35m 28s\tremaining: 15m 43s\n",
      "6928:\tlearn: 0.0332889\ttest: 0.0382215\tbest: 0.0382215 (6928)\ttotal: 35m 29s\tremaining: 15m 43s\n",
      "6929:\tlearn: 0.0332889\ttest: 0.0382215\tbest: 0.0382215 (6928)\ttotal: 35m 29s\tremaining: 15m 43s\n",
      "6930:\tlearn: 0.0332889\ttest: 0.0382215\tbest: 0.0382215 (6928)\ttotal: 35m 29s\tremaining: 15m 42s\n",
      "6931:\tlearn: 0.0332889\ttest: 0.0382215\tbest: 0.0382215 (6928)\ttotal: 35m 29s\tremaining: 15m 42s\n",
      "6932:\tlearn: 0.0332889\ttest: 0.0382215\tbest: 0.0382215 (6932)\ttotal: 35m 30s\tremaining: 15m 42s\n",
      "6933:\tlearn: 0.0332878\ttest: 0.0382218\tbest: 0.0382215 (6932)\ttotal: 35m 30s\tremaining: 15m 42s\n",
      "6934:\tlearn: 0.0332838\ttest: 0.0382215\tbest: 0.0382215 (6932)\ttotal: 35m 30s\tremaining: 15m 41s\n",
      "6935:\tlearn: 0.0332838\ttest: 0.0382215\tbest: 0.0382215 (6932)\ttotal: 35m 30s\tremaining: 15m 41s\n",
      "6936:\tlearn: 0.0332838\ttest: 0.0382215\tbest: 0.0382215 (6932)\ttotal: 35m 31s\tremaining: 15m 41s\n",
      "6937:\tlearn: 0.0332838\ttest: 0.0382215\tbest: 0.0382215 (6932)\ttotal: 35m 31s\tremaining: 15m 40s\n",
      "6938:\tlearn: 0.0332838\ttest: 0.0382215\tbest: 0.0382215 (6932)\ttotal: 35m 31s\tremaining: 15m 40s\n",
      "6939:\tlearn: 0.0332838\ttest: 0.0382215\tbest: 0.0382215 (6932)\ttotal: 35m 32s\tremaining: 15m 40s\n",
      "6940:\tlearn: 0.0332838\ttest: 0.0382215\tbest: 0.0382215 (6932)\ttotal: 35m 32s\tremaining: 15m 39s\n",
      "6941:\tlearn: 0.0332838\ttest: 0.0382215\tbest: 0.0382215 (6932)\ttotal: 35m 32s\tremaining: 15m 39s\n",
      "6942:\tlearn: 0.0332838\ttest: 0.0382215\tbest: 0.0382215 (6932)\ttotal: 35m 32s\tremaining: 15m 39s\n",
      "6943:\tlearn: 0.0332838\ttest: 0.0382215\tbest: 0.0382215 (6932)\ttotal: 35m 33s\tremaining: 15m 38s\n",
      "6944:\tlearn: 0.0332838\ttest: 0.0382215\tbest: 0.0382215 (6932)\ttotal: 35m 33s\tremaining: 15m 38s\n",
      "6945:\tlearn: 0.0332838\ttest: 0.0382215\tbest: 0.0382215 (6932)\ttotal: 35m 33s\tremaining: 15m 38s\n",
      "6946:\tlearn: 0.0332838\ttest: 0.0382215\tbest: 0.0382215 (6932)\ttotal: 35m 33s\tremaining: 15m 37s\n",
      "6947:\tlearn: 0.0332803\ttest: 0.0382197\tbest: 0.0382197 (6947)\ttotal: 35m 34s\tremaining: 15m 37s\n",
      "6948:\tlearn: 0.0332802\ttest: 0.0382197\tbest: 0.0382197 (6948)\ttotal: 35m 34s\tremaining: 15m 37s\n",
      "6949:\tlearn: 0.0332802\ttest: 0.0382197\tbest: 0.0382197 (6949)\ttotal: 35m 34s\tremaining: 15m 36s\n",
      "6950:\tlearn: 0.0332802\ttest: 0.0382197\tbest: 0.0382197 (6950)\ttotal: 35m 34s\tremaining: 15m 36s\n",
      "6951:\tlearn: 0.0332802\ttest: 0.0382197\tbest: 0.0382197 (6951)\ttotal: 35m 35s\tremaining: 15m 36s\n",
      "6952:\tlearn: 0.0332802\ttest: 0.0382197\tbest: 0.0382197 (6951)\ttotal: 35m 35s\tremaining: 15m 35s\n",
      "6953:\tlearn: 0.0332802\ttest: 0.0382197\tbest: 0.0382197 (6953)\ttotal: 35m 35s\tremaining: 15m 35s\n",
      "6954:\tlearn: 0.0332802\ttest: 0.0382197\tbest: 0.0382197 (6953)\ttotal: 35m 35s\tremaining: 15m 35s\n",
      "6955:\tlearn: 0.0332802\ttest: 0.0382197\tbest: 0.0382197 (6953)\ttotal: 35m 36s\tremaining: 15m 34s\n",
      "6956:\tlearn: 0.0332773\ttest: 0.0382187\tbest: 0.0382187 (6956)\ttotal: 35m 36s\tremaining: 15m 34s\n",
      "6957:\tlearn: 0.0332773\ttest: 0.0382187\tbest: 0.0382187 (6956)\ttotal: 35m 36s\tremaining: 15m 34s\n",
      "6958:\tlearn: 0.0332773\ttest: 0.0382187\tbest: 0.0382187 (6958)\ttotal: 35m 36s\tremaining: 15m 33s\n",
      "6959:\tlearn: 0.0332772\ttest: 0.0382187\tbest: 0.0382187 (6959)\ttotal: 35m 37s\tremaining: 15m 33s\n",
      "6960:\tlearn: 0.0332772\ttest: 0.0382187\tbest: 0.0382187 (6960)\ttotal: 35m 37s\tremaining: 15m 33s\n",
      "6961:\tlearn: 0.0332772\ttest: 0.0382187\tbest: 0.0382187 (6961)\ttotal: 35m 37s\tremaining: 15m 32s\n",
      "6962:\tlearn: 0.0332772\ttest: 0.0382187\tbest: 0.0382187 (6961)\ttotal: 35m 38s\tremaining: 15m 32s\n",
      "6963:\tlearn: 0.0332772\ttest: 0.0382187\tbest: 0.0382187 (6963)\ttotal: 35m 38s\tremaining: 15m 32s\n",
      "6964:\tlearn: 0.0332772\ttest: 0.0382187\tbest: 0.0382187 (6964)\ttotal: 35m 38s\tremaining: 15m 31s\n",
      "6965:\tlearn: 0.0332772\ttest: 0.0382187\tbest: 0.0382187 (6965)\ttotal: 35m 39s\tremaining: 15m 31s\n",
      "6966:\tlearn: 0.0332772\ttest: 0.0382187\tbest: 0.0382187 (6966)\ttotal: 35m 39s\tremaining: 15m 31s\n",
      "6967:\tlearn: 0.0332772\ttest: 0.0382187\tbest: 0.0382187 (6966)\ttotal: 35m 40s\tremaining: 15m 31s\n",
      "6968:\tlearn: 0.0332772\ttest: 0.0382187\tbest: 0.0382187 (6966)\ttotal: 35m 40s\tremaining: 15m 31s\n",
      "6969:\tlearn: 0.0332772\ttest: 0.0382187\tbest: 0.0382187 (6966)\ttotal: 35m 41s\tremaining: 15m 30s\n",
      "6970:\tlearn: 0.0332772\ttest: 0.0382187\tbest: 0.0382187 (6966)\ttotal: 35m 41s\tremaining: 15m 30s\n",
      "6971:\tlearn: 0.0332772\ttest: 0.0382187\tbest: 0.0382187 (6966)\ttotal: 35m 41s\tremaining: 15m 30s\n",
      "6972:\tlearn: 0.0332772\ttest: 0.0382187\tbest: 0.0382187 (6966)\ttotal: 35m 42s\tremaining: 15m 29s\n",
      "6973:\tlearn: 0.0332772\ttest: 0.0382187\tbest: 0.0382187 (6966)\ttotal: 35m 42s\tremaining: 15m 29s\n",
      "6974:\tlearn: 0.0332731\ttest: 0.0382184\tbest: 0.0382184 (6974)\ttotal: 35m 42s\tremaining: 15m 29s\n",
      "6975:\tlearn: 0.0332730\ttest: 0.0382184\tbest: 0.0382184 (6975)\ttotal: 35m 43s\tremaining: 15m 29s\n",
      "6976:\tlearn: 0.0332730\ttest: 0.0382184\tbest: 0.0382184 (6975)\ttotal: 35m 43s\tremaining: 15m 28s\n",
      "6977:\tlearn: 0.0332730\ttest: 0.0382184\tbest: 0.0382184 (6977)\ttotal: 35m 43s\tremaining: 15m 28s\n",
      "6978:\tlearn: 0.0332730\ttest: 0.0382184\tbest: 0.0382184 (6978)\ttotal: 35m 43s\tremaining: 15m 28s\n",
      "6979:\tlearn: 0.0332730\ttest: 0.0382184\tbest: 0.0382184 (6979)\ttotal: 35m 44s\tremaining: 15m 27s\n",
      "6980:\tlearn: 0.0332730\ttest: 0.0382184\tbest: 0.0382184 (6980)\ttotal: 35m 44s\tremaining: 15m 27s\n",
      "6981:\tlearn: 0.0332730\ttest: 0.0382184\tbest: 0.0382184 (6980)\ttotal: 35m 44s\tremaining: 15m 27s\n",
      "6982:\tlearn: 0.0332730\ttest: 0.0382184\tbest: 0.0382184 (6982)\ttotal: 35m 44s\tremaining: 15m 26s\n",
      "6983:\tlearn: 0.0332730\ttest: 0.0382184\tbest: 0.0382184 (6983)\ttotal: 35m 45s\tremaining: 15m 26s\n",
      "6984:\tlearn: 0.0332730\ttest: 0.0382184\tbest: 0.0382184 (6984)\ttotal: 35m 45s\tremaining: 15m 26s\n",
      "6985:\tlearn: 0.0332730\ttest: 0.0382184\tbest: 0.0382184 (6985)\ttotal: 35m 45s\tremaining: 15m 25s\n",
      "6986:\tlearn: 0.0332730\ttest: 0.0382184\tbest: 0.0382184 (6985)\ttotal: 35m 46s\tremaining: 15m 25s\n",
      "6987:\tlearn: 0.0332730\ttest: 0.0382184\tbest: 0.0382184 (6987)\ttotal: 35m 46s\tremaining: 15m 25s\n",
      "6988:\tlearn: 0.0332692\ttest: 0.0382172\tbest: 0.0382172 (6988)\ttotal: 35m 46s\tremaining: 15m 24s\n",
      "6989:\tlearn: 0.0332692\ttest: 0.0382172\tbest: 0.0382172 (6988)\ttotal: 35m 46s\tremaining: 15m 24s\n",
      "6990:\tlearn: 0.0332692\ttest: 0.0382172\tbest: 0.0382172 (6990)\ttotal: 35m 47s\tremaining: 15m 24s\n",
      "6991:\tlearn: 0.0332692\ttest: 0.0382172\tbest: 0.0382172 (6991)\ttotal: 35m 47s\tremaining: 15m 23s\n",
      "6992:\tlearn: 0.0332672\ttest: 0.0382171\tbest: 0.0382171 (6992)\ttotal: 35m 47s\tremaining: 15m 23s\n",
      "6993:\tlearn: 0.0332672\ttest: 0.0382171\tbest: 0.0382171 (6992)\ttotal: 35m 47s\tremaining: 15m 23s\n",
      "6994:\tlearn: 0.0332671\ttest: 0.0382171\tbest: 0.0382171 (6994)\ttotal: 35m 48s\tremaining: 15m 22s\n",
      "6995:\tlearn: 0.0332671\ttest: 0.0382171\tbest: 0.0382171 (6995)\ttotal: 35m 48s\tremaining: 15m 22s\n",
      "6996:\tlearn: 0.0332671\ttest: 0.0382171\tbest: 0.0382171 (6996)\ttotal: 35m 48s\tremaining: 15m 22s\n",
      "6997:\tlearn: 0.0332671\ttest: 0.0382171\tbest: 0.0382171 (6996)\ttotal: 35m 48s\tremaining: 15m 21s\n",
      "6998:\tlearn: 0.0332671\ttest: 0.0382171\tbest: 0.0382171 (6996)\ttotal: 35m 49s\tremaining: 15m 21s\n",
      "6999:\tlearn: 0.0332671\ttest: 0.0382171\tbest: 0.0382171 (6996)\ttotal: 35m 49s\tremaining: 15m 21s\n",
      "7000:\tlearn: 0.0332638\ttest: 0.0382171\tbest: 0.0382171 (7000)\ttotal: 35m 49s\tremaining: 15m 20s\n",
      "7001:\tlearn: 0.0332638\ttest: 0.0382171\tbest: 0.0382171 (7001)\ttotal: 35m 50s\tremaining: 15m 20s\n",
      "7002:\tlearn: 0.0332638\ttest: 0.0382171\tbest: 0.0382171 (7002)\ttotal: 35m 50s\tremaining: 15m 20s\n",
      "7003:\tlearn: 0.0332638\ttest: 0.0382171\tbest: 0.0382171 (7003)\ttotal: 35m 50s\tremaining: 15m 19s\n",
      "7004:\tlearn: 0.0332638\ttest: 0.0382171\tbest: 0.0382171 (7004)\ttotal: 35m 50s\tremaining: 15m 19s\n",
      "7005:\tlearn: 0.0332638\ttest: 0.0382171\tbest: 0.0382171 (7004)\ttotal: 35m 51s\tremaining: 15m 19s\n",
      "7006:\tlearn: 0.0332619\ttest: 0.0382173\tbest: 0.0382171 (7004)\ttotal: 35m 51s\tremaining: 15m 18s\n",
      "7007:\tlearn: 0.0332619\ttest: 0.0382173\tbest: 0.0382171 (7004)\ttotal: 35m 51s\tremaining: 15m 18s\n",
      "7008:\tlearn: 0.0332619\ttest: 0.0382173\tbest: 0.0382171 (7004)\ttotal: 35m 51s\tremaining: 15m 18s\n",
      "7009:\tlearn: 0.0332619\ttest: 0.0382173\tbest: 0.0382171 (7004)\ttotal: 35m 52s\tremaining: 15m 17s\n",
      "7010:\tlearn: 0.0332619\ttest: 0.0382173\tbest: 0.0382171 (7004)\ttotal: 35m 52s\tremaining: 15m 17s\n",
      "7011:\tlearn: 0.0332590\ttest: 0.0382164\tbest: 0.0382164 (7011)\ttotal: 35m 52s\tremaining: 15m 17s\n",
      "7012:\tlearn: 0.0332587\ttest: 0.0382164\tbest: 0.0382164 (7012)\ttotal: 35m 53s\tremaining: 15m 17s\n",
      "7013:\tlearn: 0.0332587\ttest: 0.0382164\tbest: 0.0382164 (7012)\ttotal: 35m 53s\tremaining: 15m 16s\n",
      "7014:\tlearn: 0.0332586\ttest: 0.0382164\tbest: 0.0382164 (7014)\ttotal: 35m 54s\tremaining: 15m 16s\n",
      "7015:\tlearn: 0.0332543\ttest: 0.0382160\tbest: 0.0382160 (7015)\ttotal: 35m 54s\tremaining: 15m 16s\n",
      "7016:\tlearn: 0.0332543\ttest: 0.0382160\tbest: 0.0382160 (7015)\ttotal: 35m 55s\tremaining: 15m 16s\n",
      "7017:\tlearn: 0.0332543\ttest: 0.0382160\tbest: 0.0382160 (7017)\ttotal: 35m 55s\tremaining: 15m 16s\n",
      "7018:\tlearn: 0.0332543\ttest: 0.0382160\tbest: 0.0382160 (7018)\ttotal: 35m 56s\tremaining: 15m 15s\n",
      "7019:\tlearn: 0.0332543\ttest: 0.0382160\tbest: 0.0382160 (7019)\ttotal: 35m 56s\tremaining: 15m 15s\n",
      "7020:\tlearn: 0.0332543\ttest: 0.0382160\tbest: 0.0382160 (7020)\ttotal: 35m 56s\tremaining: 15m 15s\n",
      "7021:\tlearn: 0.0332518\ttest: 0.0382162\tbest: 0.0382160 (7020)\ttotal: 35m 57s\tremaining: 15m 14s\n",
      "7022:\tlearn: 0.0332518\ttest: 0.0382162\tbest: 0.0382160 (7020)\ttotal: 35m 57s\tremaining: 15m 14s\n",
      "7023:\tlearn: 0.0332518\ttest: 0.0382162\tbest: 0.0382160 (7020)\ttotal: 35m 57s\tremaining: 15m 14s\n",
      "7024:\tlearn: 0.0332518\ttest: 0.0382162\tbest: 0.0382160 (7020)\ttotal: 35m 57s\tremaining: 15m 13s\n",
      "7025:\tlearn: 0.0332518\ttest: 0.0382162\tbest: 0.0382160 (7020)\ttotal: 35m 58s\tremaining: 15m 13s\n",
      "7026:\tlearn: 0.0332518\ttest: 0.0382162\tbest: 0.0382160 (7020)\ttotal: 35m 58s\tremaining: 15m 13s\n",
      "7027:\tlearn: 0.0332518\ttest: 0.0382162\tbest: 0.0382160 (7020)\ttotal: 35m 58s\tremaining: 15m 12s\n",
      "7028:\tlearn: 0.0332517\ttest: 0.0382162\tbest: 0.0382160 (7020)\ttotal: 35m 58s\tremaining: 15m 12s\n",
      "7029:\tlearn: 0.0332517\ttest: 0.0382162\tbest: 0.0382160 (7020)\ttotal: 35m 59s\tremaining: 15m 12s\n",
      "7030:\tlearn: 0.0332517\ttest: 0.0382162\tbest: 0.0382160 (7020)\ttotal: 35m 59s\tremaining: 15m 11s\n",
      "7031:\tlearn: 0.0332464\ttest: 0.0382144\tbest: 0.0382144 (7031)\ttotal: 35m 59s\tremaining: 15m 11s\n",
      "7032:\tlearn: 0.0332464\ttest: 0.0382144\tbest: 0.0382144 (7032)\ttotal: 36m\tremaining: 15m 11s\n",
      "7033:\tlearn: 0.0332464\ttest: 0.0382144\tbest: 0.0382144 (7033)\ttotal: 36m\tremaining: 15m 10s\n",
      "7034:\tlearn: 0.0332464\ttest: 0.0382144\tbest: 0.0382144 (7033)\ttotal: 36m\tremaining: 15m 10s\n",
      "7035:\tlearn: 0.0332464\ttest: 0.0382144\tbest: 0.0382144 (7035)\ttotal: 36m\tremaining: 15m 10s\n",
      "7036:\tlearn: 0.0332464\ttest: 0.0382144\tbest: 0.0382144 (7035)\ttotal: 36m 1s\tremaining: 15m 9s\n",
      "7037:\tlearn: 0.0332462\ttest: 0.0382144\tbest: 0.0382144 (7037)\ttotal: 36m 1s\tremaining: 15m 9s\n",
      "7038:\tlearn: 0.0332406\ttest: 0.0382137\tbest: 0.0382137 (7038)\ttotal: 36m 1s\tremaining: 15m 9s\n",
      "7039:\tlearn: 0.0332365\ttest: 0.0382132\tbest: 0.0382132 (7039)\ttotal: 36m 1s\tremaining: 15m 9s\n",
      "7040:\tlearn: 0.0332365\ttest: 0.0382132\tbest: 0.0382132 (7040)\ttotal: 36m 2s\tremaining: 15m 8s\n",
      "7041:\tlearn: 0.0332365\ttest: 0.0382132\tbest: 0.0382132 (7041)\ttotal: 36m 2s\tremaining: 15m 8s\n",
      "7042:\tlearn: 0.0332365\ttest: 0.0382132\tbest: 0.0382132 (7041)\ttotal: 36m 2s\tremaining: 15m 8s\n",
      "7043:\tlearn: 0.0332365\ttest: 0.0382132\tbest: 0.0382132 (7043)\ttotal: 36m 3s\tremaining: 15m 7s\n",
      "7044:\tlearn: 0.0332365\ttest: 0.0382132\tbest: 0.0382132 (7044)\ttotal: 36m 3s\tremaining: 15m 7s\n",
      "7045:\tlearn: 0.0332365\ttest: 0.0382132\tbest: 0.0382132 (7045)\ttotal: 36m 3s\tremaining: 15m 7s\n",
      "7046:\tlearn: 0.0332365\ttest: 0.0382132\tbest: 0.0382132 (7045)\ttotal: 36m 3s\tremaining: 15m 6s\n",
      "7047:\tlearn: 0.0332365\ttest: 0.0382132\tbest: 0.0382132 (7045)\ttotal: 36m 4s\tremaining: 15m 6s\n",
      "7048:\tlearn: 0.0332365\ttest: 0.0382132\tbest: 0.0382132 (7048)\ttotal: 36m 4s\tremaining: 15m 6s\n",
      "7049:\tlearn: 0.0332365\ttest: 0.0382132\tbest: 0.0382132 (7049)\ttotal: 36m 4s\tremaining: 15m 5s\n",
      "7050:\tlearn: 0.0332365\ttest: 0.0382132\tbest: 0.0382132 (7050)\ttotal: 36m 4s\tremaining: 15m 5s\n",
      "7051:\tlearn: 0.0332365\ttest: 0.0382132\tbest: 0.0382132 (7051)\ttotal: 36m 5s\tremaining: 15m 5s\n",
      "7052:\tlearn: 0.0332365\ttest: 0.0382132\tbest: 0.0382132 (7052)\ttotal: 36m 5s\tremaining: 15m 4s\n",
      "7053:\tlearn: 0.0332365\ttest: 0.0382132\tbest: 0.0382132 (7053)\ttotal: 36m 5s\tremaining: 15m 4s\n",
      "7054:\tlearn: 0.0332365\ttest: 0.0382132\tbest: 0.0382132 (7054)\ttotal: 36m 5s\tremaining: 15m 4s\n",
      "7055:\tlearn: 0.0332365\ttest: 0.0382132\tbest: 0.0382132 (7055)\ttotal: 36m 6s\tremaining: 15m 3s\n",
      "7056:\tlearn: 0.0332365\ttest: 0.0382132\tbest: 0.0382132 (7055)\ttotal: 36m 6s\tremaining: 15m 3s\n",
      "7057:\tlearn: 0.0332365\ttest: 0.0382132\tbest: 0.0382132 (7055)\ttotal: 36m 6s\tremaining: 15m 3s\n",
      "7058:\tlearn: 0.0332365\ttest: 0.0382132\tbest: 0.0382132 (7058)\ttotal: 36m 7s\tremaining: 15m 2s\n",
      "7059:\tlearn: 0.0332364\ttest: 0.0382132\tbest: 0.0382132 (7058)\ttotal: 36m 7s\tremaining: 15m 2s\n",
      "7060:\tlearn: 0.0332364\ttest: 0.0382132\tbest: 0.0382132 (7060)\ttotal: 36m 8s\tremaining: 15m 2s\n",
      "7061:\tlearn: 0.0332364\ttest: 0.0382132\tbest: 0.0382132 (7061)\ttotal: 36m 8s\tremaining: 15m 2s\n",
      "7062:\tlearn: 0.0332364\ttest: 0.0382132\tbest: 0.0382132 (7061)\ttotal: 36m 8s\tremaining: 15m 1s\n",
      "7063:\tlearn: 0.0332364\ttest: 0.0382132\tbest: 0.0382132 (7061)\ttotal: 36m 9s\tremaining: 15m 1s\n",
      "7064:\tlearn: 0.0332326\ttest: 0.0382125\tbest: 0.0382125 (7064)\ttotal: 36m 9s\tremaining: 15m 1s\n",
      "7065:\tlearn: 0.0332326\ttest: 0.0382125\tbest: 0.0382125 (7065)\ttotal: 36m 10s\tremaining: 15m 1s\n",
      "7066:\tlearn: 0.0332326\ttest: 0.0382125\tbest: 0.0382125 (7065)\ttotal: 36m 10s\tremaining: 15m\n",
      "7067:\tlearn: 0.0332324\ttest: 0.0382126\tbest: 0.0382125 (7065)\ttotal: 36m 11s\tremaining: 15m\n",
      "7068:\tlearn: 0.0332324\ttest: 0.0382126\tbest: 0.0382125 (7065)\ttotal: 36m 11s\tremaining: 15m\n",
      "7069:\tlearn: 0.0332324\ttest: 0.0382126\tbest: 0.0382125 (7065)\ttotal: 36m 11s\tremaining: 14m 59s\n",
      "7070:\tlearn: 0.0332324\ttest: 0.0382126\tbest: 0.0382125 (7065)\ttotal: 36m 11s\tremaining: 14m 59s\n",
      "7071:\tlearn: 0.0332324\ttest: 0.0382126\tbest: 0.0382125 (7065)\ttotal: 36m 12s\tremaining: 14m 59s\n",
      "7072:\tlearn: 0.0332324\ttest: 0.0382126\tbest: 0.0382125 (7065)\ttotal: 36m 12s\tremaining: 14m 58s\n",
      "7073:\tlearn: 0.0332324\ttest: 0.0382126\tbest: 0.0382125 (7065)\ttotal: 36m 12s\tremaining: 14m 58s\n",
      "7074:\tlearn: 0.0332323\ttest: 0.0382126\tbest: 0.0382125 (7065)\ttotal: 36m 12s\tremaining: 14m 58s\n",
      "7075:\tlearn: 0.0332323\ttest: 0.0382126\tbest: 0.0382125 (7065)\ttotal: 36m 13s\tremaining: 14m 57s\n",
      "7076:\tlearn: 0.0332323\ttest: 0.0382126\tbest: 0.0382125 (7065)\ttotal: 36m 13s\tremaining: 14m 57s\n",
      "7077:\tlearn: 0.0332323\ttest: 0.0382126\tbest: 0.0382125 (7065)\ttotal: 36m 13s\tremaining: 14m 57s\n",
      "7078:\tlearn: 0.0332283\ttest: 0.0382121\tbest: 0.0382121 (7078)\ttotal: 36m 13s\tremaining: 14m 57s\n",
      "7079:\tlearn: 0.0332283\ttest: 0.0382121\tbest: 0.0382121 (7079)\ttotal: 36m 14s\tremaining: 14m 56s\n",
      "7080:\tlearn: 0.0332283\ttest: 0.0382121\tbest: 0.0382121 (7080)\ttotal: 36m 14s\tremaining: 14m 56s\n",
      "7081:\tlearn: 0.0332242\ttest: 0.0382133\tbest: 0.0382121 (7080)\ttotal: 36m 14s\tremaining: 14m 56s\n",
      "7082:\tlearn: 0.0332242\ttest: 0.0382133\tbest: 0.0382121 (7080)\ttotal: 36m 15s\tremaining: 14m 55s\n",
      "7083:\tlearn: 0.0332242\ttest: 0.0382133\tbest: 0.0382121 (7080)\ttotal: 36m 15s\tremaining: 14m 55s\n",
      "7084:\tlearn: 0.0332242\ttest: 0.0382133\tbest: 0.0382121 (7080)\ttotal: 36m 15s\tremaining: 14m 55s\n",
      "7085:\tlearn: 0.0332242\ttest: 0.0382133\tbest: 0.0382121 (7080)\ttotal: 36m 15s\tremaining: 14m 54s\n",
      "7086:\tlearn: 0.0332242\ttest: 0.0382133\tbest: 0.0382121 (7080)\ttotal: 36m 16s\tremaining: 14m 54s\n",
      "7087:\tlearn: 0.0332242\ttest: 0.0382133\tbest: 0.0382121 (7080)\ttotal: 36m 16s\tremaining: 14m 54s\n",
      "7088:\tlearn: 0.0332242\ttest: 0.0382133\tbest: 0.0382121 (7080)\ttotal: 36m 16s\tremaining: 14m 53s\n",
      "7089:\tlearn: 0.0332242\ttest: 0.0382133\tbest: 0.0382121 (7080)\ttotal: 36m 16s\tremaining: 14m 53s\n",
      "7090:\tlearn: 0.0332242\ttest: 0.0382133\tbest: 0.0382121 (7080)\ttotal: 36m 17s\tremaining: 14m 53s\n",
      "7091:\tlearn: 0.0332242\ttest: 0.0382133\tbest: 0.0382121 (7080)\ttotal: 36m 17s\tremaining: 14m 52s\n",
      "7092:\tlearn: 0.0332242\ttest: 0.0382133\tbest: 0.0382121 (7080)\ttotal: 36m 17s\tremaining: 14m 52s\n",
      "7093:\tlearn: 0.0332241\ttest: 0.0382133\tbest: 0.0382121 (7080)\ttotal: 36m 17s\tremaining: 14m 52s\n",
      "7094:\tlearn: 0.0332241\ttest: 0.0382133\tbest: 0.0382121 (7080)\ttotal: 36m 18s\tremaining: 14m 51s\n",
      "7095:\tlearn: 0.0332241\ttest: 0.0382133\tbest: 0.0382121 (7080)\ttotal: 36m 18s\tremaining: 14m 51s\n",
      "7096:\tlearn: 0.0332241\ttest: 0.0382133\tbest: 0.0382121 (7080)\ttotal: 36m 18s\tremaining: 14m 51s\n",
      "7097:\tlearn: 0.0332241\ttest: 0.0382133\tbest: 0.0382121 (7080)\ttotal: 36m 18s\tremaining: 14m 50s\n",
      "7098:\tlearn: 0.0332241\ttest: 0.0382133\tbest: 0.0382121 (7080)\ttotal: 36m 19s\tremaining: 14m 50s\n",
      "7099:\tlearn: 0.0332241\ttest: 0.0382133\tbest: 0.0382121 (7080)\ttotal: 36m 19s\tremaining: 14m 50s\n",
      "7100:\tlearn: 0.0332241\ttest: 0.0382133\tbest: 0.0382121 (7080)\ttotal: 36m 19s\tremaining: 14m 49s\n",
      "7101:\tlearn: 0.0332241\ttest: 0.0382133\tbest: 0.0382121 (7080)\ttotal: 36m 19s\tremaining: 14m 49s\n",
      "7102:\tlearn: 0.0332241\ttest: 0.0382133\tbest: 0.0382121 (7080)\ttotal: 36m 20s\tremaining: 14m 49s\n",
      "7103:\tlearn: 0.0332241\ttest: 0.0382133\tbest: 0.0382121 (7080)\ttotal: 36m 20s\tremaining: 14m 48s\n",
      "7104:\tlearn: 0.0332240\ttest: 0.0382133\tbest: 0.0382121 (7080)\ttotal: 36m 20s\tremaining: 14m 48s\n",
      "7105:\tlearn: 0.0332240\ttest: 0.0382133\tbest: 0.0382121 (7080)\ttotal: 36m 21s\tremaining: 14m 48s\n",
      "7106:\tlearn: 0.0332206\ttest: 0.0382126\tbest: 0.0382121 (7080)\ttotal: 36m 21s\tremaining: 14m 48s\n",
      "7107:\tlearn: 0.0332206\ttest: 0.0382126\tbest: 0.0382121 (7080)\ttotal: 36m 22s\tremaining: 14m 47s\n",
      "7108:\tlearn: 0.0332206\ttest: 0.0382126\tbest: 0.0382121 (7080)\ttotal: 36m 22s\tremaining: 14m 47s\n",
      "7109:\tlearn: 0.0332206\ttest: 0.0382126\tbest: 0.0382121 (7080)\ttotal: 36m 23s\tremaining: 14m 47s\n",
      "7110:\tlearn: 0.0332206\ttest: 0.0382126\tbest: 0.0382121 (7080)\ttotal: 36m 23s\tremaining: 14m 47s\n",
      "7111:\tlearn: 0.0332206\ttest: 0.0382126\tbest: 0.0382121 (7080)\ttotal: 36m 24s\tremaining: 14m 46s\n",
      "7112:\tlearn: 0.0332206\ttest: 0.0382126\tbest: 0.0382121 (7080)\ttotal: 36m 24s\tremaining: 14m 46s\n",
      "7113:\tlearn: 0.0332206\ttest: 0.0382126\tbest: 0.0382121 (7080)\ttotal: 36m 24s\tremaining: 14m 46s\n",
      "7114:\tlearn: 0.0332206\ttest: 0.0382126\tbest: 0.0382121 (7080)\ttotal: 36m 25s\tremaining: 14m 46s\n",
      "7115:\tlearn: 0.0332168\ttest: 0.0382123\tbest: 0.0382121 (7080)\ttotal: 36m 25s\tremaining: 14m 45s\n",
      "7116:\tlearn: 0.0332168\ttest: 0.0382123\tbest: 0.0382121 (7080)\ttotal: 36m 25s\tremaining: 14m 45s\n",
      "7117:\tlearn: 0.0332168\ttest: 0.0382123\tbest: 0.0382121 (7080)\ttotal: 36m 25s\tremaining: 14m 45s\n",
      "7118:\tlearn: 0.0332168\ttest: 0.0382123\tbest: 0.0382121 (7080)\ttotal: 36m 26s\tremaining: 14m 44s\n",
      "7119:\tlearn: 0.0332155\ttest: 0.0382119\tbest: 0.0382119 (7119)\ttotal: 36m 26s\tremaining: 14m 44s\n",
      "7120:\tlearn: 0.0332155\ttest: 0.0382119\tbest: 0.0382119 (7119)\ttotal: 36m 26s\tremaining: 14m 44s\n",
      "7121:\tlearn: 0.0332155\ttest: 0.0382119\tbest: 0.0382119 (7119)\ttotal: 36m 27s\tremaining: 14m 43s\n",
      "7122:\tlearn: 0.0332155\ttest: 0.0382119\tbest: 0.0382119 (7122)\ttotal: 36m 27s\tremaining: 14m 43s\n",
      "7123:\tlearn: 0.0332155\ttest: 0.0382119\tbest: 0.0382119 (7122)\ttotal: 36m 27s\tremaining: 14m 43s\n",
      "7124:\tlearn: 0.0332155\ttest: 0.0382119\tbest: 0.0382119 (7122)\ttotal: 36m 27s\tremaining: 14m 42s\n",
      "7125:\tlearn: 0.0332155\ttest: 0.0382119\tbest: 0.0382119 (7122)\ttotal: 36m 28s\tremaining: 14m 42s\n",
      "7126:\tlearn: 0.0332155\ttest: 0.0382119\tbest: 0.0382119 (7126)\ttotal: 36m 28s\tremaining: 14m 42s\n",
      "7127:\tlearn: 0.0332155\ttest: 0.0382119\tbest: 0.0382119 (7126)\ttotal: 36m 28s\tremaining: 14m 41s\n",
      "7128:\tlearn: 0.0332155\ttest: 0.0382119\tbest: 0.0382119 (7126)\ttotal: 36m 28s\tremaining: 14m 41s\n",
      "7129:\tlearn: 0.0332155\ttest: 0.0382119\tbest: 0.0382119 (7126)\ttotal: 36m 29s\tremaining: 14m 41s\n",
      "7130:\tlearn: 0.0332155\ttest: 0.0382119\tbest: 0.0382119 (7126)\ttotal: 36m 29s\tremaining: 14m 40s\n",
      "7131:\tlearn: 0.0332140\ttest: 0.0382113\tbest: 0.0382113 (7131)\ttotal: 36m 29s\tremaining: 14m 40s\n",
      "7132:\tlearn: 0.0332140\ttest: 0.0382113\tbest: 0.0382113 (7132)\ttotal: 36m 29s\tremaining: 14m 40s\n",
      "7133:\tlearn: 0.0332140\ttest: 0.0382113\tbest: 0.0382113 (7132)\ttotal: 36m 30s\tremaining: 14m 39s\n",
      "7134:\tlearn: 0.0332140\ttest: 0.0382113\tbest: 0.0382113 (7134)\ttotal: 36m 30s\tremaining: 14m 39s\n"
     ]
    }
   ],
   "source": [
    "catb_params = {\n",
    "    \"n_estimators\" : 10000,\n",
    "    \"learning_rate\" : 0.05,\n",
    "    'max_bin': 128,\n",
    "    'depth': 13,\n",
    "    'l2_leaf_reg': 6,\n",
    "    'grow_policy': 'SymmetricTree',\n",
    "    'boosting_type': 'Plain',\n",
    "    'bootstrap_type': 'Bernoulli',\n",
    "    'subsample': 0.6\n",
    "}\n",
    "\n",
    "catb_tunned = CatBoostClassifier(**catb_params, random_state=42)\n",
    "\n",
    "cv_summary['catb'], test_preds['catb'], oof_preds['catb'] = cross_validate_score(catb_tunned, x_data , y_data,  cv, changed_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ezFMKhMPDrD5",
   "metadata": {
    "id": "ezFMKhMPDrD5"
   },
   "outputs": [],
   "source": [
    "cv_summary, test_preds, oof_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d70fda",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1723661815420,
     "user": {
      "displayName": "곽명조",
      "userId": "03864110971804242579"
     },
     "user_tz": -540
    },
    "id": "e1d70fda",
    "outputId": "da469adc-044d-431e-b2d6-00c3d858fa92"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['e', 'p', 'p', ..., 'p', 'e', 'e'], dtype=object)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_class = le.inverse_transform(pred)\n",
    "pred_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807068fb",
   "metadata": {
    "id": "807068fb"
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(IDtest, columns=['id'])\n",
    "submission['class'] = pred_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db06f67",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 2875,
     "status": "ok",
     "timestamp": 1723661818292,
     "user": {
      "displayName": "곽명조",
      "userId": "03864110971804242579"
     },
     "user_tz": -540
    },
    "id": "0db06f67",
    "outputId": "5466f12e-8177-4e1d-908f-6d4741c70de7"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "dataframe"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-b3d582f3-df59-4547-8f05-822f8a29ab30\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3116945</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3116946</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3116947</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3116948</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3116949</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2077959</th>\n",
       "      <td>5194904</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2077960</th>\n",
       "      <td>5194905</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2077961</th>\n",
       "      <td>5194906</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2077962</th>\n",
       "      <td>5194907</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2077963</th>\n",
       "      <td>5194908</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2077964 rows × 2 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b3d582f3-df59-4547-8f05-822f8a29ab30')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-b3d582f3-df59-4547-8f05-822f8a29ab30 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-b3d582f3-df59-4547-8f05-822f8a29ab30');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-c2b78eff-0af3-4842-8e4f-ef51219ed54f\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c2b78eff-0af3-4842-8e4f-ef51219ed54f')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-c2b78eff-0af3-4842-8e4f-ef51219ed54f button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "              id class\n",
       "0        3116945     e\n",
       "1        3116946     p\n",
       "2        3116947     p\n",
       "3        3116948     p\n",
       "4        3116949     e\n",
       "...          ...   ...\n",
       "2077959  5194904     p\n",
       "2077960  5194905     p\n",
       "2077961  5194906     p\n",
       "2077962  5194907     e\n",
       "2077963  5194908     e\n",
       "\n",
       "[2077964 rows x 2 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.to_csv('submission8_StraightKFold_XGB2.csv', index=False)\n",
    "pd.read_csv('submission8_StraightKFold_XGB2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a4d638",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 348,
     "status": "ok",
     "timestamp": 1723655799685,
     "user": {
      "displayName": "곽명조",
      "userId": "03864110971804242579"
     },
     "user_tz": -540
    },
    "id": "63a4d638",
    "outputId": "5295c86d-8e3d-44a4-d715-592b771e7655"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'\\n일곱번째 실험,\\nStraight KFold, n_splits=5로 xgb 실험\\n\\n결과:\\nMean Validation MCC: 0.9844321\\n\\n'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "첫 실험,\n",
    "xgb = XGBClassifier(\n",
    "    n_estimators=400,\n",
    "    max_depth=15,\n",
    "    learning_rate=0.01,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.4,\n",
    "    min_child_weight=5,\n",
    ")\n",
    "\n",
    "metric = mcc\n",
    "\n",
    "validation_0-logloss:0.06993\tvalidation_0-mcc:0.98150\n",
    "public score -> 0.98194\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "두번째 실험,\n",
    "동일 모델,\n",
    "eval_metric = 'logloss' 만 다름\n",
    "\n",
    "결과:\n",
    "validation_0-logloss:0.06993\n",
    "public score -> 0.98194 동일...\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "세번째 실험,\n",
    "동일 모델,\n",
    "metric = mcc\n",
    "\n",
    "결과:\n",
    "validation_0-logloss:0.06791\tvalidation_0-mcc:0.98184\n",
    "public score -> 0.98204\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "네번째 실험,\n",
    "n_estimators=1000\n",
    "동일 모델,\n",
    "metric = mcc\n",
    "\n",
    "결과:\n",
    "validation_0-logloss:0.03977\tvalidation_0-mcc:0.98286\n",
    "public score -> 0.98312\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "다섯번째 실험,\n",
    "weird 값을 \"error\"라는 새로운 값으로 처리\n",
    "learning_rate = 0.01 그대로 유지\n",
    "\n",
    "결과:\n",
    "validation_0-logloss:0.03733\tvalidation_0-mcc:0.98425\n",
    "public score -> 0.98464\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "여섯번째 실험,\n",
    "weird 값을 \"error\"라는 새로운 값으로 처리\n",
    "learning_rate = 0.02\n",
    "\n",
    "결과:\n",
    "validation_0-logloss:0.03708\tvalidation_0-mcc:0.98419\n",
    "public score -> 0.98478\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "일곱번째 실험,\n",
    "Straight KFold, n_splits=5로 xgb 실험\n",
    "\n",
    "결과:\n",
    "Mean Validation MCC: 0.9844321\n",
    "public score -> 0.98472\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "여덟번째 실험, 파라미터 안좋네 다시 복\n",
    "Straight KFold, n_splits=5로 xgb2 실험\n",
    "\n",
    "결과:\n",
    "Mean Validation MCC: 0.9842396\n",
    "public score -> 0.98453\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831ca47a",
   "metadata": {
    "id": "831ca47a"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
